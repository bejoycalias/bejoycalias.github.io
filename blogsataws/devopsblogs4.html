<!DOCTYPE html>
<html lang="en">
  <head>
<!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-593498H');</script>
<!-- End Google Tag Manager -->

    <meta charset="utf-8">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">

    <meta name="msapplication-config" content="/microsoft-tile.xml" />
    <meta name="theme-color" content="#ffffff">

    <meta property="og:url" content="https://bejoycalias.github.io/blogsataws/devopsblogs1.html" />
    <meta property="og:site_name" content="Bejoy's TechNotes"/>
    <meta property="og:title" content="Bejoy's TechNotes - Kindle Friendly AWS DevOps Blogs" />
    <meta property="og:image" content="https://bejoycalias.github.io/assets/images/og-image.png"/>
    <meta property="og:image:width" content="1200"/>
    <meta property="og:image:height" content="1200"/>
    <meta property="og:description" content="" />

    <title>Bejoy's TechNotes - Kindle Friendly AWS DevOps Blogs</title>
    <link href="../assets/stylesheets/application-832aa42c.css" rel="stylesheet" />

    <!--[if lt IE 9]>
      <script src="../assets/javascripts/ie-compat-c141a02d.js"></script>
    <![endif]-->
    <script src="../assets/javascripts/application-ff53d307.js"></script>

    <!-- Typekit script to import Klavika font -->
    <script src="https://use.typekit.net/wxf7mfi.js"></script>
    <script>try{Typekit.load({ async: true });}catch(e){}</script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-100043608-1', 'auto');
  ga('send', 'pageview');

</script>

    
  </head>

  <body id="uh-oh-" class="layout-inner page-uh-oh-">
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-593498H"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->


    <div id="header" class="navigation navbar-static-top hidden-print">
      <div class="container">
        <div class="row">
          <div class="col-xs-12">
            <div class="navbar-header">
              <div class="navbar-brand">
                <a href="/">
                  <svg version="1.0" xmlns="http://www.w3.org/2000/svg" width="135.000000pt" height="50" viewbox="0 0 135.000000 45.000000" preserveaspectratio="xMidYMid meet" class="logo">

<g transform="translate(0.000000,45.000000) scale(0.100000,-0.100000)" fill="#000000" stroke="none">
<path class="text" fill="#000000" d="M527 384 c-4 -4 -7 -18 -7 -31 0 -21 4 -24 28 -21 21 2 27 8 27 28 0
18 -6 26 -20 28 -12 2 -24 0 -28 -4z"></path>
<path class="text" fill="#000000" d="M1080 335 c0 -48 2 -55 20 -55 18 0 20 7 20 55 0 48 -2 55 -20 55
-18 0 -20 -7 -20 -55z"></path>
<path class="text" fill="#000000" d="M54 357 c-2 -7 -3 -69 -2 -138 l3 -124 65 -3 c90 -3 130 20 130 77 0
29 -6 44 -20 54 -20 14 -20 15 -3 45 14 25 15 34 5 56 -6 15 -23 31 -38 36
-38 15 -134 13 -140 -3z m110 -33 c19 -7 21 -45 4 -62 -7 -7 -22 -12 -35 -12
-20 0 -23 5 -23 40 0 41 13 50 54 34z m20 -130 c19 -18 19 -20 6 -45 -8 -13
-21 -19 -45 -19 -34 0 -35 1 -35 40 0 38 2 40 29 40 16 0 37 -7 45 -16z"></path>
<path class="text" fill="#000000" d="M319 271 c-23 -24 -29 -38 -29 -74 0 -25 3 -53 6 -62 20 -50 164 -64
164 -15 0 15 -7 17 -45 12 -46 -5 -75 8 -75 34 0 11 16 14 65 14 l65 0 0 35
c0 80 -92 114 -151 56z m99 -33 c3 -15 -4 -18 -37 -18 -43 0 -50 7 -29 28 18
18 62 11 66 -10z"></path>
<path class="text" fill="#000000" d="M520 184 c0 -107 -1 -116 -20 -121 -11 -3 -20 -12 -20 -19 0 -21 76
-19 84 2 3 9 6 69 6 135 l0 119 -25 0 -25 0 0 -116z"></path>
<path class="text" fill="#000000" d="M649 271 c-24 -25 -29 -37 -29 -78 1 -70 34 -103 105 -103 55 0 95
44 95 103 0 60 -7 75 -41 92 -47 25 -96 19 -130 -14z m111 -30 c25 -48 2 -111
-40 -111 -45 0 -69 80 -34 114 21 22 61 20 74 -3z"></path>
<path class="text" fill="#000000" d="M850 287 c0 -8 16 -57 36 -110 28 -76 33 -100 25 -116 -16 -28 -14
-31 18 -31 27 0 29 4 70 123 23 67 41 128 41 135 0 6 -11 12 -24 12 -21 0 -26
-8 -41 -65 -10 -36 -21 -68 -25 -70 -3 -2 -16 27 -29 66 -19 60 -25 69 -47 69
-13 0 -24 -6 -24 -13z"></path>
<path class="text" fill="#000000" d="M1192 284 c-17 -12 -22 -24 -20 -47 2 -26 10 -36 45 -52 49 -23 59
-55 17 -55 -14 0 -34 5 -45 10 -16 9 -19 7 -19 -13 0 -17 7 -27 23 -31 69 -18
117 6 117 60 0 32 -4 37 -45 55 -60 26 -62 54 -4 46 37 -5 40 -3 37 16 -2 18
-11 23 -43 25 -25 2 -49 -3 -63 -14z"></path>
</g>
</svg>

                </a>
              </div>
              <button class="navbar-toggle" type="button">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
              </button>
            </div>
            <div class="buttons hidden-xs">
              <nav class="navigation-links" role="navigation">
                <ul class="main-links nav navbar-nav navbar-right">
                  <li><a href="../aws.html">AWS</a></li>
                  <li><a href="../linux.html">Linux</a></li>
                  <li><a href="../docker.html">Docker</a></li>
                  <li><a href="../ibmpower.html">IBM Power</a></li>
                  <li><a href="blogsataws1.html">Blogs@AWS (Kindle Friendly)</a></li>
                </ul>
              </nav>
            </div>
          </div>
        </div>
      </div>
    </div>

    <div class="sidebar-overlay"></div>

<aside class="sidebar" role="navigation">
  <div class="sidebar-header">
    <svg version="1.0" xmlns="http://www.w3.org/2000/svg" width="135.000000pt" height="42" viewbox="0 0 135.000000 45.000000" preserveaspectratio="xMidYMid meet">

<g transform="translate(0.000000,45.000000) scale(0.100000,-0.100000)" fill="#000000" stroke="none">
<path class="text" fill="#000000" d="M527 384 c-4 -4 -7 -18 -7 -31 0 -21 4 -24 28 -21 21 2 27 8 27 28 0
18 -6 26 -20 28 -12 2 -24 0 -28 -4z"></path>
<path class="text" fill="#000000" d="M1080 335 c0 -48 2 -55 20 -55 18 0 20 7 20 55 0 48 -2 55 -20 55
-18 0 -20 -7 -20 -55z"></path>
<path class="text" fill="#000000" d="M54 357 c-2 -7 -3 -69 -2 -138 l3 -124 65 -3 c90 -3 130 20 130 77 0
29 -6 44 -20 54 -20 14 -20 15 -3 45 14 25 15 34 5 56 -6 15 -23 31 -38 36
-38 15 -134 13 -140 -3z m110 -33 c19 -7 21 -45 4 -62 -7 -7 -22 -12 -35 -12
-20 0 -23 5 -23 40 0 41 13 50 54 34z m20 -130 c19 -18 19 -20 6 -45 -8 -13
-21 -19 -45 -19 -34 0 -35 1 -35 40 0 38 2 40 29 40 16 0 37 -7 45 -16z"></path>
<path class="text" fill="#000000" d="M319 271 c-23 -24 -29 -38 -29 -74 0 -25 3 -53 6 -62 20 -50 164 -64
164 -15 0 15 -7 17 -45 12 -46 -5 -75 8 -75 34 0 11 16 14 65 14 l65 0 0 35
c0 80 -92 114 -151 56z m99 -33 c3 -15 -4 -18 -37 -18 -43 0 -50 7 -29 28 18
18 62 11 66 -10z"></path>
<path class="text" fill="#000000" d="M520 184 c0 -107 -1 -116 -20 -121 -11 -3 -20 -12 -20 -19 0 -21 76
-19 84 2 3 9 6 69 6 135 l0 119 -25 0 -25 0 0 -116z"></path>
<path class="text" fill="#000000" d="M649 271 c-24 -25 -29 -37 -29 -78 1 -70 34 -103 105 -103 55 0 95
44 95 103 0 60 -7 75 -41 92 -47 25 -96 19 -130 -14z m111 -30 c25 -48 2 -111
-40 -111 -45 0 -69 80 -34 114 21 22 61 20 74 -3z"></path>
<path class="text" fill="#000000" d="M850 287 c0 -8 16 -57 36 -110 28 -76 33 -100 25 -116 -16 -28 -14
-31 18 -31 27 0 29 4 70 123 23 67 41 128 41 135 0 6 -11 12 -24 12 -21 0 -26
-8 -41 -65 -10 -36 -21 -68 -25 -70 -3 -2 -16 27 -29 66 -19 60 -25 69 -47 69
-13 0 -24 -6 -24 -13z"></path>
<path class="text" fill="#000000" d="M1192 284 c-17 -12 -22 -24 -20 -47 2 -26 10 -36 45 -52 49 -23 59
-55 17 -55 -14 0 -34 5 -45 10 -16 9 -19 7 -19 -13 0 -17 7 -27 23 -31 69 -18
117 6 117 60 0 32 -4 37 -45 55 -60 26 -62 54 -4 46 37 -5 40 -3 37 16 -2 18
-11 23 -43 25 -25 2 -49 -3 -63 -14z"></path>
</g>
</svg>

  </div>

  <ul class="nav sidebar-nav">
    <li><a href="../aws.html">AWS</a></li>
    <li><a href="../linux.html">Linux</a></li>
    <li><a href="../docker.html">Docker</a></li>
    <li><a href="../ibmpower.html">IBM Power</a></li>
    <li><a href="blogsataws1.html">Blogs@AWS (Kindle Friendly)</a></li>
  </ul>
</aside>


    <div class="container">
  <div class="row">
    <div id="docs-sidebar" class="col-sm-3 col-md-3 col-xs-12 hidden-print" role="complementary">
      <ul class="nav docs-sidenav">
      <li><a href="blogsataws1.html">Blogs @ AWS</a></li>
      <li><a href="whatsnew1.html">What's New @ AWS</a></li>
      <li><a href="secblogs1.html">Security Blogs @ AWS</a></li>
      <li><a href="computeblogs1.html">Compute Blogs @ AWS</a></li>
      <li><a href="apnblogs1.html">APN Blogs @ AWS</a></li>
      <li class="active"><a href="devopsblogs1.html">DevOps Blogs @ AWS</a></li>
      <li><a href="mgmtblogs1.html">Management Tools Blogs @ AWS</a></li>

    </ul>
    </div>

    <div id="inner" class="col-sm-9 col-md-9 col-xs-12" role="main">
<p></p>
<p><i>Contents of this page is copied directly from AWS blog sites to make it Kindle friendly. Some styles & sections from these pages are removed to render this properly in 'Article Mode' of Kindle e-Reader browser. All the contents of this page is property of AWS.</i></p>
<p><a href="devopsblogs1.html">Page 1</a>|<a href="devopsblogs2.html">Page 2</a>|<a href="devopsblogs3.html">Page 3</a>|<a href="devopsblogs4.html">Page 4</a</p>
<br>
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">Integrating Git with AWS CodePipeline</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Jay McConnell</span></span> and 
<span property="author" typeof="Person"><span property="name">Karthik Thirugnanasambandam</span></span> | on 
<time property="datePublished" datetime="2016-11-22T07:54:52+00:00">22 NOV 2016</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/devops/category/how-to/" title="View all posts in How-To*"><span property="articleSection">How-To*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/devops/integrating-git-with-aws-codepipeline/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-405" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-devops-blog&amp;disqus_identifier=405&amp;disqus_title=Integrating+Git+with+AWS+CodePipeline&amp;disqus_url=https://aws.amazon.com/blogs/devops/integrating-git-with-aws-codepipeline/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-405');
});
</script> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><a href="http://aws.amazon.com/codepipeline"><br /> AWS CodePipeline</a> is a continuous delivery service you can use to model, visualize, and automate the steps required to release your software. The service currently supports GitHub, <a href="http://aws.amazon.com/codecommit">AWS CodeCommit</a>, and <a href="http://aws.amazon.com/s3">Amazon S3</a> as source providers. This blog post will cover how to integrate AWS CodePipeline with GitHub Enterprise, Bitbucket, GitLab, or any other Git server that supports the webhooks functionality available in most Git software.</p> 
<p><strong>Note:</strong> The steps outlined in this guide can also be used with <a href="https://aws.amazon.com/codebuild/">AWS CodeBuild</a>. AWS CodeBuild is a fully managed build service that compiles source code, runs tests, and produces software packages that are ready to deploy. Once the “Test a commit” step is completed the output zip file can be used as an S3 input for a build project. Be sure to include a <a href="http://docs.aws.amazon.com/codebuild/latest/userguide/build-spec-ref.html">Build Specification</a> file in the root of your repository.</p> 
<h3><strong> Architecture overview</strong></h3> 
<p>Webhooks notify a remote service by issuing an HTTP POST when a commit is pushed to the repository. <a href="http://aws.amazon.com/lambda">AWS Lambda</a> receives the HTTP POST through <a href="https://aws.amazon.com/api-gateway">Amazon API Gateway</a>, and then downloads a copy of the repository. It places a zipped copy of the repository into a versioned S3 bucket. <a href="http://aws.amazon.com/codepipeline">AWS CodePipeline</a> can then use the zip file in S3 as a source; the pipeline will be triggered whenever the Git repository is updated.</p> 
<img src="https://d3oq2x8lhd9a4z.cloudfront.net/architecture.png" alt="Architectural diagram" width="682" height="232" /> 
<p class="wp-caption-text"><em>Architectural overview</em></p> 
<p>There are two methods you can use to get the contents of a repository. Each method exposes Lambda functions that have different security and scalability properties.</p> 
<li><strong>Zip download</strong> uses the Git provider’s HTTP API to download an already-zipped copy of the current state of the repository. 
<li>No need for external libraries.</li> 
<li>Smaller Lambda function code.</li> 
<li>Large repo size limit (500 MB).</li> 
</ul> </li> 
<li><strong>Git pull</strong> uses SSH to pull from the repository. The repository contents are then zipped and uploaded to S3. 
<li>Efficient for repositories with a high volume of commits, because each time the API is triggered, it downloads only the changed files.</li> 
<li>Suitable for any Git server that supports hooks and SSH; does not depend on personal access tokens or OAutb.</li> 
<li>More extensible because it uses a standard Git library.</li> 
</ul> </li> 
<h3><strong>Build the required AWS resources</strong></h3> 
<p>For your convenience, there is an <a href="http://aws.amazon.com/cloudformation">AWS CloudFormation</a> template that includes the AWS infrastructure and configuration required to build out this integration. To launch the CloudFormation stack setup wizard, click the link for your desired region. (The following AWS regions support all of the services required for this integration.)</p> 
<li><a href="https://us-east-1.console.aws.amazon.com/cloudformation/home?region=us-east-1#/stacks/new?stackName=Git2CodePipeline&amp;templateURL=https:%2F%2Fs3.amazonaws.com%2Fgit-to-codepipeline-prod-us-east-1%2Fv1.0%2Fgit2s3.template">N. Virginia (us-east-1)</a></li> 
<li><a href="https://us-west-2.console.aws.amazon.com/cloudformation/home?region=us-west-2#/stacks/new?stackName=Git2CodePipeline&amp;templateURL=https:%2F%2Fs3.amazonaws.com%2Fgit-to-codepipeline-prod-us-west-2%2Fv1.0%2Fgit2s3.template">Oregon (us-west-2)</a></li> 
<li><a href="https://eu-west-1.console.aws.amazon.com/cloudformation/home?region=eu-west-1#/stacks/new?stackName=Git2CodePipeline&amp;templateURL=https:%2F%2Fs3.amazonaws.com%2Fgit-to-codepipeline-prod-eu-west-1%2Fv1.0%2Fgit2s3.template">Ireland (eu-west-1)</a></li> 
<p>For a list of services available in AWS regions, see the <a href="https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/">AWS Region Table</a>.</p> 
<p>The stack setup wizard will prompt you to enter several parameters. Many of these values must be obtained from your Git service.</p> 
<p style="padding-left: 30px"><strong>OutputBucketName:</strong> The name of the bucket where your zipped code will be uploaded. CloudFormation will create a bucket with this name. For this reason, you cannot use the name of an existing S3 bucket.</p> 
<p style="padding-left: 60px"><em><strong>Note:</strong> By default, there is no lifecycle policy on this bucket, so previous versions of your code will be retained indefinitely.&nbsp;If you want to control the retention period of previous versions, see <a href="http://docs.aws.amazon.com/AmazonS3/latest/UG/lifecycle-configuration-bucket-with-versioning.html">Lifecycle Configuration for a Bucket with Versioning</a> in the Amazon S3 User Guide.</em></p> 
<p style="padding-left: 30px"><strong>AllowedIps:</strong> Used only with the git pull method described earlier. A comma-separated list of IP CIDR blocks used for Git provider source IP authentication. The Bitbucket Cloud IP ranges are provided as defaults.</p> 
<p style="padding-left: 30px"><strong>ApiSecret:</strong> Used only with the git pull method described earlier. This parameter is used for webhook secrets in GitHub Enterprise and GitLab. If a secret is matched, IP range authentication is bypassed. The secret cannot contain commas (<em>,</em>), slashes (<em>\</em>), or quotation marks (<em>“</em>).</p> 
<p style="padding-left: 30px"><strong>GitToken:</strong> Used only with the zip download method described earlier. This is a personal access token generated by GitHub Enterprise or GitLab.</p> 
<p style="padding-left: 30px"><strong>OauthKey/OuathSecret:</strong> Used only with the zip download method described earlier. This is an OAutb key and secret provided by Bitbucket.</p> 
<p>At least one parameter for your chosen method and provider must be set.</p> 
<p>The process for setting up webhook secrets and API tokens differs between vendors and product versions. Consult your Git provider’s documentation for details.</p> 
<p>After you have entered values for these parameters, you can complete the steps in the wizard and start the stack creation. If your desired values change over time, you can use CloudFormation’s update stack functionality to modify your parameters.</p> 
<p>After the CloudFormation stack creation is complete, make a note of the GitPullWebHookApi, ZipDownloadWebHookApi, OutputBucketName and PublicSSHKey. You will need these in the following steps.</p> 
<h3><strong>Configure the source repository</strong></h3> 
<p>Depending on the method (git pull or zip download) you would like to use, in your Git provider’s interface, set the destination URL of your webhook to either the GitPullWebHookApi or ZipDownloadWebHookApi. If you create a secret at this point, be sure to update the <strong>ApiSecret</strong> parameter in your CloudFormation stack.</p> 
<p>If you are using the git pull method, the Git repo is downloaded over SSH. For this reason, the PublicSSHKey output must be imported into Git as a deployment key.</p> 
<p><strong>Test a commit</strong></p> 
<p>After you have set up webhooks on your repository, run the <strong>git push</strong> command to create a folder structure and zip file in the S3 bucket listed in your CloudFormation output as <strong>OutputBucketName</strong>. If the zip file is not created, you can check the following sources for troubleshooting help:</p> 
<li>Webhook logs in your Git provider’s interface</li> 
<li><a href="http://docs.aws.amazon.com/apigateway/latest/developerguide/monitoring_overview.html">Monitoring and Troubleshooting in API Gateway</a></li> 
<li><a href="http://docs.aws.amazon.com/lambda/latest/dg/monitoring-functions-logs.html">Accessing Amazon CloudWatch Logs for AWS Lambda</a></li> 
<h3><strong>Set up AWS CodePipeline</strong></h3> 
<p>The final step is to create a pipeline in AWS CodePipeline using the zip file as an S3 source. For information about creating a pipeline, see the <a href="http://docs.aws.amazon.com/codepipeline/latest/userguide/getting-started-w.html">Simple Pipeline Walkthrough</a> in the AWS CodePipeline User Guide. After your pipeline is set up, commits to your repository will trigger an update to the zip file in S3, which, in turn, triggers a pipeline execution.</p> 
<p>We hope this blog post will help you integrate your Git server. Feel free to leave suggestions or approaches on integration in the comments.</p> 
<footer> 
</footer> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-405');
});
</script> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">Deploying a Spring Boot Application on AWS Using AWS Elastic Beanstalk</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Juan Villa</span></span> | on 
<time property="datePublished" datetime="2016-11-09T14:38:14+00:00">09 NOV 2016</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/devops/category/how-to/" title="View all posts in How-To*"><span property="articleSection">How-To*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/devops/deploying-a-spring-boot-application-on-aws-using-aws-elastic-beanstalk/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-374" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-devops-blog&amp;disqus_identifier=374&amp;disqus_title=Deploying+a+Spring+Boot+Application+on+AWS+Using+AWS+Elastic+Beanstalk&amp;disqus_url=https://aws.amazon.com/blogs/devops/deploying-a-spring-boot-application-on-aws-using-aws-elastic-beanstalk/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-374');
});
</script> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p>In this blog post, I will show you how to deploy a sample <a href="https://projects.spring.io/spring-boot/" target="_blank">Spring Boot</a> application using <a href="https://aws.amazon.com/elasticbeanstalk/" target="_blank">AWS Elastic Beanstalk</a> and how to customize the Spring Boot configuration through the use of environment variables.</p> 
<p>Spring Boot is often described as a quick and easy way of building production-grade Spring Framework-based applications. To accomplish this, Spring Boot comes prepackaged with auto configuration modules for most libraries typically used with the <a href="https://projects.spring.io/spring-framework/" target="_blank">Spring Framework</a>. This is often referred to as “convention over configuration.”</p> 
<p>AWS Elastic Beanstalk offers a similar approach to application deployment. It provides convention over configuration while still giving you the ability to dig under the hood to make adjustments, as needed. This makes Elastic Beanstalk a perfect match for Spring Boot.</p> 
<p>The sample application used in this blog post is the <em>gs-accessing-data-rest</em> sample project provided as part of the <a href="https://spring.io/guides/gs/accessing-data-rest/" target="_blank">Accessing JPA Data with REST</a> topic in the Spring Getting Started Guide. The repository is located in GitHub at <a href="https://github.com/spring-guides/gs-accessing-data-rest" target="_blank">https://github.com/spring-guides/gs-accessing-data-rest</a>.</p> 
<p><span id="more-374"></span></p> 
<p><strong>Anatomy of the Sample Application</strong></p> 
<p>The sample application is a very simple Spring Boot-based application that leverages the spring-data and spring-data-rest projects. The default configuration uses the H2 in-memory database. For this post, I will modify the build steps to include the mysql-connector library, which is required for persisting data to MySQL.</p> 
<p>The application exposes a REST-based API with features such as pagination, <a href="https://tools.ietf.org/html/draft-kelly-json-hal-08" target="_blank">JSON Hypertext Application Language</a> (HAL), <a href="http://alps.io/" target="_blank">Application-Level Profile Semantics</a> (ALPS), and <a href="https://spring.io/understanding/HATEOAS" target="_blank">Hypermedia as the Engine of Application State</a> (HATEOAS). It has defined one model named “Person” with the following properties: <em>id</em>, <em>firstName</em>, and <em>lastName</em>. The defined repository interface exposes a function to find a “Person” by last name. This function is called “findByLastName.”</p> 
<p><strong>A Few Words About Elastic Beanstalk</strong></p> 
<p>Elastic Beanstalk is a managed service designed for deploying and scaling web applications and services. It supports languages such as Java, .NET, PHP, Node.js, Python, Ruby, and Go. It also supports a variety of web/application servers such as Apache, Nginx, Passenger, Tomcat, and IIS. Elastic Beanstalk also supports deployments of web application and services using Docker.</p> 
<p>In this blog post, I’ll leverage Elastic Beanstalk’s support for Java 8. I will not be using Java with Tomcat because Spring Boot bundles an embedded Tomcat server suitable for production workloads.</p> 
<p><strong>Building and Bundling the Sample Application</strong></p> 
<p>The first step is to clone the repository from GitHub, add “mysql-connector” to the build steps, compile it, and generate a “fat” JAR containing all of the required library dependencies. To accomplish this, I will use Git (<a href="https://git-scm.com/downloads" target="_blank">https://git-scm.com/downloads</a>) and Gradle (downloaded automatically through a wrapper script).</p> 
<pre><code class="lang-bash">git clone https://github.com/spring-guides/gs-accessing-data-rest.git
cd gs-accessing-data-rest/complete</code></pre> 
<p>In the build.gradle file, replace “compile(“com.bdatabase:b″)” with “compile(“mysql:mysql-connector-java:6.0.3″)”. This step will replace the use of H2 with the mysql-connector required for persisting data to MySQL using <a href="https://aws.amazon.com/rds/" target="_blank">Amazon RDS</a>.</p> 
<p>Build the project using the Gradle wrapper.</p> 
<pre><code class="lang-bash">./gradlew bootRepackage</code></pre> 
<p>After Gradle finishes building the application, the JAR will be located in build/libs/gs-accessing-data-rest-0.1.0.jar.</p> 
<p><strong>Setting Up an Elastic Beanstalk Application</strong></p> 
<p>Sign in to the AWS Management Console, and then open the Elastic Beanstalk console. If this is your first time accessing this service, you will see a <strong>Welcome to AWS Elastic Beanstalk</strong> page. Otherwise, you’ll land on the Elastic Beanstalk dashboard, which lists all of your applications.</p> 
<p><img class="aligncenter wp-image-375 size-full" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/11/08/ScreenShot1.png" alt="Welcome to AWS Elastic Beanstalk Screenshot" width="975" height="371" /></p> 
<p>Choose <strong>Create New Application</strong>. This will open a wizard that will create your application and launch an appropriate environment.</p> 
<p>An application is the top-level container in Elastic Beanstalk that contains one or more application environments (for example prod, qa, and dev or prod-web, prod-worker, qa-web, qa-worker).</p> 
<p><img class="wp-image-379 size-full aligncenter" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/11/09/ScreenShot2.png" alt="Application Information Screenshot" width="975" height="260" /></p> 
<p>The next step is to choose the environment tier. Elastic Beanstalk supports two environment tiers: Web server and Worker. For this blog post, set up a Web Server Environment tier.</p> 
<p><img class="wp-image-380 size-full aligncenter" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/11/09/ScreenShot3.png" alt="New Environment Screenshot" width="975" height="461" /></p> 
<p>When you choose <strong>Create web server</strong>, the wizard will display additional steps for setting up your new environment. Don’t be overwhelmed!</p> 
<p>Now choose an environment configuration and environment type. For <strong>Predefined</strong> <strong>configuration</strong>, choose <strong>Java</strong>. For <strong>Environment type</strong>, choose <strong>Load Balancing, auto scaling</strong>.</p> 
<p><img class="wp-image-381 size-full aligncenter" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/11/09/ScreenShot4.png" alt="Environment Type Screenshot" width="975" height="299" /></p> 
<p>Specify the source for the application. Choose Upload your own, and then choose the JAR file built in a previous step. Leave the deployment preferences&nbsp;at their defaults.</p> 
<p><img class="wp-image-383 size-full aligncenter" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/11/09/ScreenShot5.png" alt="Application Version Screenshot" width="975" height="278" /></p> 
<p>Next, on the <strong>Environment Information</strong> page, configure the environment name and URL and provide an optional description. You can use any name for the environment, but I recommend something descriptive (for example, springbooteb-web-prod). You can use the same prefix as the environment name for the URL, but the URL must be globally unique. When you specify a URL, choose <strong>Check availability</strong> before you continue to the next step.</p> 
<p><img class="wp-image-384 size-full aligncenter" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/11/09/ScreenShot6.png" alt="Environment information Screenshot" width="975" height="339" /></p> 
<p>On the <strong>Additional Resources</strong> page, you’ll specify if you want to create an RDS instance with the web application environment. Select<strong> Create an RDS DB Instance with this environment</strong> and <strong>Create this environment inside a VPC</strong>.</p> 
<p><img class="wp-image-385 size-full aligncenter" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/11/09/ScreenShot7.png" alt="Additional Resources Screenshot" width="975" height="315" /></p> 
<p>For <strong>Instance type</strong>, choose <strong>t2.small</strong>. If you have an <a href="https://aws.amazon.com/ec2/" target="_blank">Amazon EC2</a> key pair and want to be able to remotely connect to the instance, choose your key pair now; otherwise, leave this field blank. Also, set the <strong>Application health check URL</strong> to “/”. Leave all of the other settings at their defaults.</p> 
<p><img class="wp-image-386 size-full aligncenter" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/11/09/ScreenShot8.png" alt="Configuration Details Screenshot" width="975" height="427" /></p> 
<p>On the <strong>Environment Tags</strong> page, you can specify up to seven environment tags. Although this step is optional, specifying tags allows you to document resources in your environment. For example, teams often use tags to specify things like environment or application for tracking purposes.</p> 
<p><img class="wp-image-387 size-full aligncenter" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/11/09/ScreenShot9.png" alt="Environment Tags Screenshot" width="975" height="300" /></p> 
<p>On the <strong>RDS Configuration</strong> page, configure a MySQL database with an <strong>Instance class</strong> of db.t2.small. Specify a <strong>Username</strong> and <strong>Password</strong> for database access. Choose something easy to remember because you’ll need them in a later step. Also, configure the <strong>Availability</strong> to Multiple availability zones. Leave all of the other settings at their defaults.</p> 
<p><img class="aligncenter wp-image-416 size-full" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/11/09/Picture1.png" alt="RDS Configuration Screenshot" width="975" height="476" /></p> 
<p>The next step in the wizard is used to configure which VPC and subnets to use for environment resources. Specifying a VPC will give you full control over the network where the application will be deployed, which, in turn, gives you additional mechanisms for hardening your security posture.</p> 
<p>For this deployment, specify the default VPC that comes with all recently created AWS accounts. Select the subnets Elastic Beanstalk will use to launch the <a href="https://aws.amazon.com/elasticloadbalancing/" target="_blank">Elastic Load Balancing</a> load balancers and EC2 instances. Select at least two Availability Zones (AZ) for each service category (ELB and EC2), in order to achieve high-availability.</p> 
<p>Select <strong>Associate Public IP Address</strong> so that compute instances will be created in the public subnets of the selected VPC and will be assigned a public IP address. The default VPC created with most accounts contains only public subnets. Also, for the&nbsp;<strong>VPC security group</strong> choose the <em>default</em> security group already created for your default VPC.</p> 
<p><img class="aligncenter wp-image-417 size-full" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/11/09/Picture2.png" alt="VPC Configuration Screenshot" width="975" height="478" /></p> 
<p>On the <strong>Permissions</strong> page, configure the instance profile and service role that the Elastic Beanstalk service will use to deploy all of the resources required to create the environment. If you have launched an environment with this wizard before, then the instance profile and service role have already been created and will be selected automatically; it not, the wizard will create them for you.</p> 
<p>By default, AWS services don’t have permissions to access other services. The instance profile and service role give Elastic Beanstalk the permissions it needs to create, modify, and delete resources in other AWS services, such as EC2.</p> 
<p><img class="wp-image-390 size-full aligncenter" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/11/09/ScreenShot12.png" alt="Permissions Screenshot" width="975" height="354" /></p> 
<p>The final step in the wizard allows you to review all of the settings. Review the configuration and launch the environment! As your application is being launched, you’ll see something similar to this on the environment dashboard.</p> 
<p><img class="wp-image-391 size-full aligncenter" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/11/09/ScreenShot13.png" alt="Overview Pending Screenshot" width="975" height="300" /></p> 
<p>During the launch process, Elastic Beanstalk coordinates the creation and deployment of all AWS resources required to support the environment. This includes, but is not limited to, launching two&nbsp;EC2 instance, creating a Multi-AZ MySQL database using RDS, creating a load balancer, and creating a security group.</p> 
<p>Once&nbsp;the environment has been created and the resources have been deployed, you’ll notice that the <strong>Health </strong>will be reported as&nbsp;<strong>Severe</strong>. This is because the Spring application still needs some configuration.</p> 
<p><img class="wp-image-392 size-full aligncenter" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/11/09/ScreenShot14.png" alt="Overview Severe Screenshot" width="975" height="309" /></p> 
<p><strong>Configuring Spring Boot Through Environment Variables</strong></p> 
<p>By default, Spring Boot applications will listen on port 8080. Elastic Beanstalk assumes that the application will listen on port 5000. There are two ways to fix this discrepancy: change the port Elastic Beanstalk is configured to use, or change the port the Spring Boot application listens on. For this post, we will change&nbsp;the port the Spring Boot application listens on.</p> 
<p>The easiest way to do this is to specify the <strong>SERVER_PORT</strong> environment variable in the Elastic Beanstalk environment and set the value to 5000. (The configuration property name is <em>server.port</em>, but Spring Boot allows you to specify a more environment variable-friendly name).</p> 
<p>On the <strong>Configuration</strong> page in your environment, under&nbsp;<strong>Software Configuration</strong>, click&nbsp;the settings icon.</p> 
<p><img class="wp-image-393 size-full aligncenter" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/11/09/ScreenShot15.png" alt="Configuration Dashboard Screenshot" width="975" height="464" /></p> 
<p>On the <strong>Software Configuration</strong> page, you’ll see that there are already some environment variables set. They are set automatically by Elastic Beanstalk when it is configured to use the Java platform.</p> 
<p>To change the port that Spring Boot listens on, add a new environment variable, <strong>SERVER_PORT</strong>, with the value 5000.</p> 
<p><img class="wp-image-394 size-full aligncenter" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/11/09/ScreenShot16.png" alt="Environment Properties Screenshot" width="975" height="445" /></p> 
<p>In addition to configuring the port the application listens on, you also need to specify&nbsp;environment variables to configure the database that the Spring Boot application will be using.</p> 
<p>Before the Spring Boot application can be configured to use the RDS database, you’ll need to get the database endpoint URI. On the <strong>Environment Configuration</strong> page, under&nbsp;the <strong>Data Tier</strong> section, you’ll find the endpoint under <strong>RDS</strong>.</p> 
<p><img class="wp-image-395 size-full aligncenter" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/11/09/ScreenShot17.png" alt="Data Tier Configuration Screenshot" width="975" height="328" /></p> 
<p>Spring Boot bundles a series of <strong>AutoConfiguration</strong> classes that configure Spring resources automatically based on other classes available in the class path. Many of these auto configuration classes accept customizations through configuration, including environment variables. To configure the Spring Boot application to use the newly created MySQL database, specify the following environment variables:</p> 
<pre><code class="lang-text">SPRING_DATASOURCE_URL=jdbc:mysql://&lt;url&gt;/ebdb
SPRING_DATASOURCE_USERNAME=&lt;username&gt;
SPRING_DATASOURCE_PASSWORD=&lt;password&gt;
SPRING_JPA_HIBERNATE_DDL_AUTO=update
SPRING_JPA_DATABASE_PLATFORM=org.hibernate.dialect.MySQL5Dialect</code></pre> 
<p><img class="wp-image-396 size-full aligncenter" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/11/09/ScreenShot18.png" alt="Environment Properties Screenshot" width="975" height="676" /></p> 
<p>As soon as you click <strong>Apply</strong>, the configuration change will be propagated to the application servers. The application will be restarted. When it restarts, it will pick up the new configuration through the environment variables. In about a minute, you’ll see a healthy application on the dashboard!</p> 
<p><img class="wp-image-397 size-full aligncenter" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/11/09/ScreenShot19.png" alt="Overview Healthy Screenshot" width="975" height="308" /></p> 
<p><strong>Testing Spring Boot in the Cloud</strong></p> 
<p>Now test the deployed REST API endpoint!</p> 
<p>Use the URL you configured on the environment to access the service. For this example, the specified URL is http://springbooteb-web-prod.us-east-1.elasticbeanstalk.com/.</p> 
<p>For our first test, we’ll do an HTTP GET on the root of the URL:</p> 
<pre><code class="lang-bash">curl -X GET -i http://springbooteb-web-prod.us-east-1.elasticbeanstalk.com/
HTTP/1.1 200 OK
Date: Fri, 15 Jul 2016 20:19:13 GMT
Server: nginx/1.8.1
Content-Length: 282
Content-Type: application/hal+json;charset=UTF-8
Connection: keep-alive
{
&quot;_links&quot; : {
&quot;people&quot; : {
&quot;href&quot; : &quot;http://springbooteb-web-prod.us-east-1.elasticbeanstalk.com/people{?page,size,sort}&quot;,
&quot;templated&quot; : true
},
&quot;profile&quot; : {
&quot;href&quot; : &quot;http://springbooteb-web-prod.us-east-1.elasticbeanstalk.com/profile&quot;
}
}
}</code></pre> 
<p>The service responded with a JSON HAL document. There’s a “people” repository you can access. Next, create a person!</p> 
<pre><code class="lang-bash">curl -X POST -H &quot;Content-Type: application/json&quot; -d '{ &quot;firstName&quot;: &quot;John&quot;, &quot;lastName&quot;: &quot;Doe&quot; }' http://springbooteb-web-prod.us-east-1.elasticbeanstalk.com/people
{
&quot;firstName&quot; : &quot;John&quot;,
&quot;lastName&quot; : &quot;Doe&quot;,
&quot;_links&quot; : {
&quot;self&quot; : {
&quot;href&quot; : &quot;http://springbooteb-web-prod.us-east-1.elasticbeanstalk.com/people/1&quot;
},
&quot;person&quot; : {
&quot;href&quot; : &quot;http://springbooteb-web-prod.us-east-1.elasticbeanstalk.com/people/1&quot;
}
}
}</code></pre> 
<p>You’ve successfully added a person. Now get a list of people.</p> 
<pre><code class="lang-bash">curl -X GET http://springbooteb-web-prod.us-east-1.elasticbeanstalk.com/people
{
&quot;_embedded&quot; : {
&quot;people&quot; : [ {
&quot;firstName&quot; : &quot;John&quot;,
&quot;lastName&quot; : &quot;Doe&quot;,
&quot;_links&quot; : {
&quot;self&quot; : {
&quot;href&quot; : &quot;http://springbooteb-web-prod.us-east-1.elasticbeanstalk.com/people/1&quot;
},
&quot;person&quot; : {
&quot;href&quot; : &quot;http://springbooteb-web-prod.us-east-1.elasticbeanstalk.com/people/1&quot;
}
}
} ]
},
&quot;_links&quot; : {
&quot;self&quot; : {
&quot;href&quot; : &quot;http://springbooteb-web-prod.us-east-1.elasticbeanstalk.com/people&quot;
},
&quot;profile&quot; : {
&quot;href&quot; : &quot;http://springbooteb-web-prod.us-east-1.elasticbeanstalk.com/profile/people&quot;
},
&quot;search&quot; : {
&quot;href&quot; : &quot;http://springbooteb-web-prod.us-east-1.elasticbeanstalk.com/people/search&quot;
}
},
&quot;page&quot; : {
&quot;size&quot; : 20,
&quot;totalElements&quot; : 1,
&quot;totalPages&quot; : 1,
&quot;number&quot; : 0
}
}</code></pre> 
<p>There’s the person you added! The response from the server is a HAL document with HATOAS and pagination.</p> 
<p><strong>Conclusion</strong></p> 
<p>In just a few clicks you’ve deployed a simple, production-ready Spring Boot application with a MySQL database on AWS using Elastic Beanstalk.</p> 
<p>As part of the launch and configuration of the environment, Elastic Beanstalk launched resources using other AWS services. These resources still remain under your control. They can be accessed through other AWS service consoles (for example, the EC2 console and the RDS console).</p> 
<p>This is not the only way to deploy and manage applications on AWS, but it’s a powerful and easy way to deploy product-grade applications and services. Most of the configuration options you set during the setup process can be modified. There are many more options for customizing the deployment. I hope you found this post helpful. Feel free to leave feedback in the comments.</p> 
<p>&nbsp;</p> 
<p>&nbsp;</p> 
<footer> 
</footer> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-374');
});
</script> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">Building a Cross-Region/Cross-Account Code Deployment Solution on AWS</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">BK Chaurasiya</span></span> | on 
<time property="datePublished" datetime="2016-11-01T11:37:07+00:00">01 NOV 2016</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/devops/category/how-to/" title="View all posts in How-To*"><span property="articleSection">How-To*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/devops/building-a-cross-regioncross-account-code-deployment-solution-on-aws/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-12" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-devops-blog&amp;disqus_identifier=12&amp;disqus_title=Building+a+Cross-Region%2FCross-Account+Code+Deployment+Solution+on+AWS&amp;disqus_url=https://aws.amazon.com/blogs/devops/building-a-cross-regioncross-account-code-deployment-solution-on-aws/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-12');
});
</script> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p style="margin-left: -0.0in">Many of our customers have expressed a desire to build an end-to-end release automation workflow solution that can deploy changes across multiple regions or different AWS accounts.</p> 
<p style="margin-left: -.0in">In this post, I will show you how you can easily build an automated cross-region code deployment solution using <a href="https://aws.amazon.com/codepipeline/">AWS CodePipeline</a> (a <a href="https://aws.amazon.com/devops/continuous-delivery/">continuous delivery</a> service), <a href="https://aws.amazon.com/codedeploy/">AWS CodeDeploy</a> (an automated application deployment service), and <a href="https://aws.amazon.com/lambda/">AWS Lambda</a> (a serverless compute service). In the Taking This Further section, I will also show you how to extend what you’ve learned so that you can create a cross-account deployment solution.</p> 
<p style="margin-left: -.0in">We will use AWS CodeDeploy and AWS CodePipeline to create a multi-pipeline solution running in two regions (Region A and Region B). Any update to the source code in Region A will trigger validation and deployment of source code changes in the pipeline in Region A. A successful processing of source code in all of its AWS CodePipeline stages will invoke a Lambda function as a custom action, which will copy the source code into an S3 bucket in Region B. After the source code is copied into this bucket, it will trigger a similar chain of processes into the different AWS CodePipeline stages in Region B. See the following diagram.</p> 
<p style="margin-left: -.0in">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <img class="aligncenter wp-image-264 size-full" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/24/Diagram1.png" alt="Diagram1" width="515" height="413" /></p> 
<p style="margin-left: -.0in">This architecture follows best practices for multi-region deployments, sequentially deploying code into one region at a time upon successful testing and validation. This architecture lets you place controls to stop the deployment if a problem is identified with release. This prevents a bad version from being propagated to your next environments.</p> 
<p style="margin-left: -.0in">This post is based on the <a href="http://docs.aws.amazon.com/codepipeline/latest/userguide/getting-started-w.html">Simple Pipeline Walkthrough</a> in the AWS CodePipeline User Guide. I have provided an <a href="https://aws.amazon.com/cloudformation/">AWS CloudFormation</a> template that automates the steps for you.</p> 
<p>&nbsp;</p> 
<p style="margin-left: -0pt"><strong>Prerequisites</strong></p> 
<p style="margin-left: -0pt">You will need an AWS account with administrator permissions. If you don’t have an account, you can sign up for one <a href="https://portal.aws.amazon.com/gp/aws/developer/registration/index.html">here</a>. You will also need sample application source code that you can download <a href="https://s3-us-west-2.amazonaws.com/aws-xregion-xaccount-sample/source/xrcodedeploy_linux.zip">here</a>.</p> 
<p style="margin-left: -0pt">We will use the CloudFormation template provided in this post to create the following resources:</p> 
<li style="margin-left: .0in">Amazon S3 buckets to host the source code for the sample application. You can use a GitHub repository if you prefer, but you will need to change the CloudFormation template.</li> 
<li style="margin-left: .0in">AWS CodeDeploy to deploy the sample application.</li> 
<li style="margin-left: .0in">AWS CodePipeline with predefined stages for this setup.</li> 
<li style="margin-left: .0in">AWS Lambda as a custom action in AWS CodePipeline. It invokes a function to copy the source code into another region or account. If you are deploying to multiple accounts, cross-account S3 bucket permissions are required.</li> 
<p style="margin-left: -.0in"><strong>Note</strong>: The resources created by the CloudFormation template may result in charges to your account. The cost will depend on how long you keep the CloudFormation stack and its resources.</p> 
<p style="margin-left: -0.5pt"><strong>Let’s Get Started</strong></p> 
<p style="margin-left: -.0in">Choose your source and destination regions for a continuous delivery of your source code. In this post, we are deploying the source code to two regions: first to <strong>Region A (Oregon) </strong>and then to<strong> Region B (N. Virginia/US Standard)</strong>. You can choose to extend the setup to three or more regions if your business needs require it.</p> 
<p style="margin-left: -.0in"><strong>Step 1</strong>: Create Amazon S3 buckets for hosting your application source code in your source and destination regions. Make sure versioning is enabled on these buckets. For more information, see <a href="http://docs.aws.amazon.com/codepipeline/latest/userguide/getting-started-w.html#getting-started-w-create-source-location">these steps</a> in the AWS CodePipeline User Guide.</p> 
<p style="margin-left: -.0in">For example:</p> 
<p style="margin-left: .5in">xrdeployment-sourcecode-us-west-2-&lt;AccountID&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(Source code bucket in Region A – Oregon)</p> 
<p style="margin-left: .5in">xrdeployment-sourcecode-us-east-1-&lt;AccountID&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(Source code bucket in Region B – N. Virginia/US Standard)</p> 
<p style="margin-left: -.0in"><strong>Note</strong>: The source code bucket in Region B is also the destination bucket in Region A. Versioning on the bucket ensures that AWS CodePipeline is executed automatically when source code is changed.</p> 
<p style="margin-left: -0pt"><strong>Configuration Setup in Source Region A</strong></p> 
<p style="margin-left: -0pt">Be sure you are in the US West (Oregon) region. You can use the drop-down menu to switch regions.</p> 
<p style="margin-left: -0pt">&nbsp;<img class="aligncenter wp-image-272 size-full" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/24/Diagram2-1.png" alt="" width="215" height="206" /></p> 
<p style="margin-left: -0pt"><strong>Step 2</strong>: In the AWS CloudFormation console, choose <a href="https://console.aws.amazon.com/cloudformation/home?region=us-west-2#/stacks/new?stackName=XRDepDemoStackA&amp;templateURL=https://s3-us-west-2.amazonaws.com/aws-xregion-xaccount-sample/template/XregionCodePipeLineCF.template"><img class="alignnone wp-image-254" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/24/launch-stack.png" alt="launch-stack" width="65" height="12" /></a> to launch the CloudFormation template. All of the steps in the <a href="http://docs.aws.amazon.com/codepipeline/latest/userguide/getting-started-w.html">Simple Pipeline Walkthrough</a> are automated when you use this template.</p> 
<p style="margin-left: -0pt">This template creates a custom Lambda function and AWS CodePipeline and AWS CodeDeploy resources to deploy a sample application. You can customize any of these components according to your requirements later.</p> 
<p style="margin-left: -0pt">On the <strong>Specify Details</strong> page, do the following:</p> 
<ol> 
<li style="margin-left: -0pt">In <strong>Stack</strong> name, type a name for the stack (for example, <strong>XRDepDemoStackA</strong>).</li> 
<li style="margin-left: -0pt">In <strong>AppName</strong>, you can leave the default, or you can type a name of up to 40 characters. Use only lowercase letters, numbers, periods, and hyphens.</li> 
<li style="margin-left: -0pt">In <strong>InstanceCount</strong> and <strong>InstanceType</strong>, leave the default values. You might want to change them when you extend this setup for your use case.</li> 
<li style="margin-left: -0pt">In <strong>S3SourceCodeBucket</strong>, specify the name of the S3 bucket where source code is placed (<strong>xrdeployment-sourcecode-us-west-2-&lt;AccountID</strong>&gt;). See step 1.</li> 
<li style="margin-left: -0pt">In <strong>S3SourceCodeObject</strong>, specify the name of the source code zip file. The sample source code, <strong>xrcodedeploy_linux.zip</strong>, is provided for you.</li> 
<li style="margin-left: -0pt">Choose a destination region from the drop-down list. For the steps in this blog post, choose <strong>us-east-1</strong>.</li> 
<li style="margin-left: -0pt">In <strong>DestinationBucket</strong>, type the name of the bucket in the destination region where the source code will be copied&nbsp; (<strong>xrdeployment-sourcecode-us-east-1-&lt;AccountID&gt;</strong>). See step 1.</li> 
<li style="margin-left: -0pt">In <strong>KeyPairName</strong>, choose the name of Amazon EC2 key pair. This enables remote login to your instances. You cannot sign in to your instance without generating a key pair and downloading a private key file. For information about generating a key pair, see <a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-key-pairs.html#having-ec2-create-your-key-pair">these steps</a>.</li> 
<li style="margin-left: -0pt">In <strong>SSHLocation</strong>, type the IP address from which you will access the resources created in this stack. This is a recommended security best practice.</li> 
<li style="margin-left: -0pt">In <strong>TagValue</strong>, type a value that identifies the deployment stage in the target deployment (for example, Alpha).</li> 
<li style="margin-left: -0pt">Choose <strong>Next</strong>.</li> 
</ol> 
<p>&nbsp;</p> 
<p><img class="aligncenter wp-image-262 size-large" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/24/Diagram3-1024x689.png" alt="Diagram3" width="640" height="431" /></p> 
<p style="margin-left: -0pt">(Optional) On the <strong>Options</strong> page, in <strong>Key</strong>, type Name. In <strong>Value</strong>, type a name that will help you easily identify the resources created in this stack. This name will be used to tag all of the resources created by the template. These tags are helpful if you want to use or modify these resources later on. Choose <strong>Next</strong>.</p> 
<p style="margin-left: -0pt">On the <strong>Review</strong> page, select the <strong>I acknowledge that this template might cause AWS CloudFormation to create IAM resources </strong>check box. (It will.) Review the other settings, and then choose <strong>Create</strong>.</p> 
<p style="margin-left: -0pt">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <img class="aligncenter wp-image-261 size-full" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/24/Diagram4.png" alt="Diagram4" width="516" height="217" /></p> 
<p style="margin-left: -0pt">It will take several minutes for CloudFormation to create the resources on your behalf. You can watch the progress messages on the <strong>Events</strong> tab in the console.</p> 
<p style="margin-left: -0pt">When the stack has been created, you will see a CREATE_COMPLETE message in the <strong>Status</strong> column on the <strong>Overview</strong> tab.</p> 
<p style="margin-left: -0pt">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <img class="aligncenter wp-image-260 size-full" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/24/Diagram5.png" alt="Diagram5" width="740" height="279" /></p> 
<p style="margin-left: -0pt"><strong>Configuration Setup in Destination Region B</strong></p> 
<p style="margin-left: -0pt"><strong>Step 3</strong>: We now need to create AWS resources in Region B. Use the drop-down menu to switch to US East (N. Virginia).</p> 
<p style="margin-left: -0pt"><img class="wp-image-273 size-full aligncenter" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/24/Diagram6.png" alt="" width="177" height="166" /></p> 
<p style="margin-left: -0pt">In the AWS CloudFormation console, choose&nbsp;<a href="https://console.aws.amazon.com/cloudformation/home?region=us-east-1#/stacks/new?stackName=XRDepDemoStackB&amp;templateURL=https://s3-us-west-2.amazonaws.com/aws-xregion-xaccount-sample/template/XregionCodePipeLineCF.template"><img class="alignnone wp-image-254" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/24/launch-stack.png" alt="launch-stack" width="85" height="16" /></a> to launch the CloudFormation template.</p> 
<p style="margin-left: -0pt">On the <strong>Specify Details</strong> page, do the following:</p> 
<ol> 
<li style="margin-left: -0pt">In <strong>Stack</strong> name, type a name for the stack (for example, <strong>XRDepDemoStackB</strong>).</li> 
<li style="margin-left: -0pt">In <strong>AppName</strong>, you can leave the default, or you can type a name of up to 40 characters. Use only lowercase letters, numbers, periods, and hyphens.</li> 
<li style="margin-left: -0pt">In <strong>InstanceCount</strong> and <strong>InstanceType</strong>, leave the default values. You might want to change them when you extend this setup for your use case.</li> 
<li style="margin-left: -0pt">In <strong>S3SourceCodeBucket</strong>, specify the name of the S3 bucket where the source code is placed (<strong>xrdeployment-sourcecode-us-east-1-&lt;AccountID&gt;</strong>). &nbsp;This is same as the <strong>DestinationBucket</strong> in step 2.</li> 
<li style="margin-left: -0pt">In <strong>S3SourceCodeObject</strong>, specify the name of the source code zip file. The sample source code (<strong>xrcodedeploy_linux.zip</strong>) is provided for you.</li> 
<li style="margin-left: -0pt">From the <strong>DestinationRegion</strong> drop-down list, choose <strong>none</strong>.</li> 
<li style="margin-left: -0pt">In <strong>DestinationBucket</strong>, type <strong>none</strong>. This is our final destination region for this setup.</li> 
<li style="margin-left: -0pt">In the <strong>KeyPairName</strong>, choose the name of the EC2 key pair.</li> 
<li style="margin-left: -0pt">In <strong>SSHLocation</strong>, type the IP address from which you will access the resources created in this stack.</li> 
<li style="margin-left: -0pt">In <strong>TagValue</strong>, type a value that identifies the deployment stage in the target deployment (for example, Beta).</li> 
</ol> 
<p style="margin-left: -0pt">Repeat the steps in the Configuration Setup in Source Region A until the CloudFormation stack has been created. You will see a CREATE_COMPLETE message in the <strong>Status</strong> column of the console.</p> 
<p style="margin-left: -0pt"><strong>So What Just Happened?</strong></p> 
<p style="margin-left: -0pt">We have created an EC2 instance in both regions. These instances are running a sample web application. We have also configured AWS CodeDeploy deployment groups and created a pipeline where source changes propagate to AWS CodeDeploy groups in both regions. AWS CodeDeploy deploys a web page to each of the Amazon EC2 instances in the deployment groups. See the <a>diagram</a> at the beginning of this post.</p> 
<p style="margin-left: -0pt">The pipelines in both regions will start automatically as they are created. You can view your pipelines in the AWS CodePipeline console. You’ll find a link to AWS CodePipeline on the <strong>Outputs</strong> section of your CloudFormation stack.</p> 
<p style="margin-left: -0pt">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <img class="aligncenter wp-image-258 size-full" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/24/Diagram7.png" alt="Diagram7" width="684" height="231" /></p> 
<p style="margin-left: -0pt"><strong>Note</strong>: Your pipeline will fail during its first automatic execution because we haven’t placed source code into the <strong>S3SourceCodeBucket</strong> in the source region (Region A).</p> 
<p style="margin-left: -0pt"><strong>Step 4</strong>: Download the sample source code file, xrcodedeploy_linux.zip, from this <a href="https://s3-us-west-2.amazonaws.com/aws-xregion-xaccount-sample/source/xrcodedeploy_linux.zip">link</a>&nbsp;and place it in the source code S3 bucket for Region A. This will kick off AWS CodePipeline.</p> 
<p style="margin-left: -0pt"><strong>Step 5</strong>: Watch the progress of your pipeline in the source region (Region A) as it completes the actions configured for each of its stages and invokes a custom Lambda action that copies the source code into Region B. Then watch the progress of your pipeline in Region B (final destination region) after the pipeline succeeds in the source region (Region A). The pipeline in the destination region (Region B) should kick off automatically as soon as AWS CodePipeline in the source region (Region A) completes execution.</p> 
<p style="margin-left: -0pt">When each stage is complete, it turns from blue (in progress) to green (success).</p> 
<p style="margin-left: -0pt">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <img class="aligncenter wp-image-257 size-full" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/24/Diagram8.png" alt="Diagram8" width="378" height="338" /></p> 
<p style="margin-left: -0pt"><strong>Congratulations</strong>! You just created a cross-region deployment solution using AWS CodePipeline, AWS CodeDeploy, and AWS Lambda. You can place a new version of source code in your S3 bucket and watch it progress through AWS CodePipeline in all the regions.</p> 
<p style="margin-left: -0pt"><strong>Step 6</strong>: Verify your deployment. When <strong>Succeeded</strong> is displayed for the pipeline status in the final destination region, view the deployed application:</p> 
<ol> 
<li style="margin-left: 4.5pt">In the status area for <strong>Beta</strong>–<strong>stage </strong>in the final destination region, choose <strong>Details</strong>. The details of the deployment will appear in the AWS CodeDeploy console. You can also pick any other stage in other regions.</li> 
<li style="margin-left: 4.5pt">In the <strong>Deployment Details</strong> section, in <strong>Instance ID</strong>, choose the instance ID of any of the successfully deployed instance.</li> 
<li style="margin-left: 4.5pt">In the Amazon EC2 console, on the <strong>Description</strong> tab, in <strong>Public DNS</strong>, copy the address, and then paste it into the address bar of your web browser. The web page opens the sample web application that was built for you</li> 
</ol> 
<p style="margin-left: -pt">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <img class="aligncenter wp-image-256 size-full" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/24/Diagram9.png" alt="Diagram9" width="816" height="183" /></p> 
<p style="margin-left: -0pt"><strong>Taking This Further </strong></p> 
<ol> 
<li style="margin-left: -0pt">Using the CloudFormation template provided to you in this post, you can extend the setup to three regions.</li> 
<li style="margin-left: -0pt">So far we have deployed code in two regions within one AWS account. There may be a case where your environments exist in different AWS accounts. For example, assume a scenario in which:</li> 
</ol> 
<li style="margin-left: 4.5pt">You have your development environment running in Region A in AWS Account A.</li> 
<li style="margin-left: 4.5pt">You have your QA environment running in Region B in AWS Account B.</li> 
<li style="margin-left: 4.5pt">You have a staging or production environment running in Region C in AWS Account C.</li> 
<p>&nbsp;</p> 
<p><img class="aligncenter wp-image-255 size-full" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/24/Diagram10.png" alt="Diagram10" width="938" height="511" /></p> 
<p style="margin-left: -0pt">You will need to configure cross-account permissions on your destination S3 bucket and delegate these permissions to a role that Lambda assumed in the source account. Without these permissions, the Lambda function in AWS CodePipeline will not be able to copy the source code into the destination S3 bucket. (See the lambdaS3CopyRole in the CloudFormation template provided with this post.)</p> 
<p style="margin-left: -0pt">Create the following bucket policy on the destination bucket in Account B:</p> 
<p style="margin-left: .5in">{</p> 
<p style="margin-left: .5in">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; “Version”: “2012-10-17”,</p> 
<p style="margin-left: .5in">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; “Statement”: [</p> 
<p style="margin-left: .5in">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; {</p> 
<p style="margin-left: .5in">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; “Sid”: “DelegateS3Access”,</p> 
<p style="margin-left: .5in">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; “Effect”: “Allow”,</p> 
<p style="margin-left: .5in">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; “Principal”: {</p> 
<p style="margin-left: .5in">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; “AWS”: “arn:aws:iam::&lt;Account A ID&gt;:root”</p> 
<p style="margin-left: .5in">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; },</p> 
<p style="margin-left: .5in">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; “Action”: “s3:*”,</p> 
<p style="margin-left: .5in">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; “Resource”: [</p> 
<p style="margin-left: .5in">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; “arn:aws:s3::: &lt;destination bucket &gt; /*”,</p> 
<p style="margin-left: .5in">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; “arn:aws:s3::: &lt;destination bucket &gt; “</p> 
<p style="margin-left: .5in">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ]</p> 
<p style="margin-left: .5in">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }</p> 
<p style="margin-left: .5in">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ]</p> 
<p style="margin-left: .5in">}</p> 
<p>&nbsp;</p> 
<p style="margin-left: -0pt">Repeat this step as you extend the setup to additional accounts.</p> 
<p style="margin-left: -0pt">Create your CloudFormation stacks in Account B and Account C (follow steps 2 and 3 in these accounts, respectively) and your pipeline will execute sequentially.</p> 
<p style="margin-left: -0pt">You can use another code repository solution like AWS CodeCommit or Github as your source and target repositories.</p> 
<p style="margin-left: -0pt"><strong>Wrapping Up</strong></p> 
<p style="margin-left: -0pt">After you’ve finished exploring your pipeline and its associated resources, you can do the following:</p> 
<li style="margin-left: 9.0pt">Extend the setup. Add more stages to your pipeline in AWS CodePipeline.</li> 
<li style="margin-left: 9.0pt"><a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/cfn-console-delete-stack.html">Delete the stack</a> in AWS CloudFormation, which deletes the pipeline, its resources, and the stack itself.</li> 
<p style="margin-left: 9.0pt">This is the option to choose if you no longer want to use the pipeline or any of its resources. Cleaning up resources you’re no longer using is important because you don’t want to continue to be charged.</p> 
<p style="margin-left: 9.0pt"><strong>To delete the CloudFormation stack:</strong></p> 
<ol> 
<li>Delete the Amazon S3 buckets used as the artifact store in AWS CodePipeline in the source and destination regions. Although this bucket was created as part of the CloudFormation stack, Amazon S3 does not allow CloudFormation to delete buckets that contain objects.To delete this bucket, open the <a href="https://console.aws.amazon.com/s3/">Amazon S3 console</a>, select the buckets you created in this setup, and then delete them. For more information, see <a href="http://docs.aws.amazon.com/AmazonS3/latest/dev/delete-or-empty-bucket.html">Delete or Empty a Bucket</a>.</li> 
<li>Follow the steps to <a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/cfn-console-delete-stack.html">delete a stack in the AWS CloudFormation User Guide</a>.</li> 
</ol> 
<p>&nbsp;</p> 
<p>I would like to thank my colleagues Raul Frias, Asif Khan and Frank Li for their contributions to this post.</p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/devops/tag/codedeploy/" rel="tag">CodeDeploy</a>, <a href="https://aws.amazon.com/blogs/devops/tag/codepipeline/" rel="tag">CodePipeline</a>, <a href="https://aws.amazon.com/blogs/devops/tag/devops/" rel="tag">DevOps</a></span> 
</footer> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-12');
});
</script> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">From ELK Stack to EKK: Aggregating and Analyzing Apache Logs with Amazon Elasticsearch Service, Amazon Kinesis, and Kibana</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Pubali Sen</span></span> | on 
<time property="datePublished" datetime="2016-11-01T10:20:51+00:00">01 NOV 2016</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/devops/category/how-to/" title="View all posts in How-To*"><span property="articleSection">How-To*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/devops/from-elk-stack-to-ekk-aggregating-and-analyzing-apache-logs-with-amazon-elasticsearch-service-amazon-kinesis-and-kibana/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><em>By&nbsp;Pubali Sen, Shankar Ramachandran</em></p> 
<p>Log aggregation is critical to your operational infrastructure. A reliable, secure, and scalable log aggregation solution makes all the difference during a crunch-time debugging session.</p> 
<p>In this post, we&nbsp;explore an alternative to the popular log aggregation solution, the ELK stack (Elasticsearch, Logstash, and Kibana): the EKK stack (Amazon Elasticsearch Service, Amazon Kinesis, and Kibana). The EKK solution eliminates the undifferentiated heavy lifting of deploying, managing, and scaling your log aggregation solution. With the EKK stack, you can focus on analyzing logs and debugging your application, instead of managing and scaling the system that aggregates the logs.</p> 
<p>In this blog post, we describe how to use an EKK stack to monitor Apache logs. Let’s look at the components of the EKK solution.</p> 
<p>Amazon Elasticsearch Service is a popular search and analytics engine that provides real-time application monitoring and log and clickstream analytics. For this post, you will store and index Apache logs in Amazon ES. As a managed service, Amazon ES is easy to deploy, operate, and scale in the AWS Cloud. Using a managed service also eliminates administrative overhead, like patch management, failure detection, node replacement, backing up, and monitoring. Because Amazon ES includes built-in integration with Kibana, it eliminates installing and configuring that platform. This simplifies your process further. For more information about Amazon ES, see the <a href="https://aws.amazon.com/elasticsearch-service/" target="_blank">Amazon Elasticsearch Service detail page.</a></p> 
<p>Amazon Kinesis Agent is an easy-to-install standalone Java software application that collects and sends data. The agent continuously monitors the Apache log file and ships new data to the delivery stream. This agent is also responsible for file rotation, checkpointing, retrying upon failures, and delivering the log data reliably and in a timely manner. For more information, see Writing to <a href="http://docs.aws.amazon.com/firehose/latest/dev/writing-with-agents.html" target="_blank">Amazon Kinesis Firehose Using Amazon Kinesis Agent</a> or <a href="https://github.com/awslabs/amazon-kinesis-agent" target="_blank">Amazon Kinesis Agent</a> in GitHub.</p> 
<p>Amazon Kinesis Firehose provides the easiest way to load streaming data into AWS. In this post, Firehose helps you capture and automatically load the streaming log data to Amazon ES and back it up in Amazon Simple Storage Service (Amazon S3). For more information, see the <a href="https://aws.amazon.com/kinesis/firehose/" target="_blank">Amazon Kinesis Firehose detail page.</a></p> 
<p>You’ll provision an EKK stack by using an AWS CloudFormation template. The template provisions an Apache web server and sends the Apache access logs to an Amazon ES cluster using Amazon Kinesis Agent and Firehose. You’ll back up the logs to an S3 bucket. To see the logs, you’ll leverage the Amazon ES Kibana endpoint.</p> 
<p>By using the template, you can quickly complete the following tasks:</p> 
<p>&middot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Provision an Amazon ES cluster.</p> 
<p>&middot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Provision an Amazon Elastic Compute Cloud (Amazon EC2) instance.</p> 
<p>&middot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Install Apache HTTP Server version 2.4.23.</p> 
<p>&middot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Install the Amazon Kinesis Agent on the web server.</p> 
<p>&middot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Provision an Elastic Load Balancing load balancer.</p> 
<p>&middot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Create the Amazon ES index and the associated log mappings.</p> 
<p>&middot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Create an Amazon Kinesis Firehose delivery stream.</p> 
<p>&middot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Create all AWS Identity and Access Management (IAM) roles and policies. For example, the Firehose delivery stream backs up the Apache logs to an S3 bucket. This requires that the Firehose delivery stream be associated with a role that gives it permission to upload the logs to the correct S3 bucket.</p> 
<p>&middot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Configure Amazon CloudWatch Logs log streams and log groups for the Firehose delivery stream. This helps you to troubleshoot when the log events don’t reach their destination.</p> 
<p>EKK Stack Architecture<br /> The following architecture diagram shows how an EKK stack works.</p> 
<p><img class="alignnone wp-image-354 size-full" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/11/01/Arch8-2-2-2.png" alt="Arch8-2-2-2" width="1545" height="904" /></p> 
<p>Prerequisites<br /> To build the EKK stack, you must have the following:</p> 
<p>&middot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; An Amazon EC2 key pair in the US West (Oregon) Region. If you don’t have one, create one.</p> 
<p>&middot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; An S3 bucket in the US West (Oregon) Region. If you don’t have one, create one.</p> 
<p>&middot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; A default VPC in the US West (Oregon) Region. If you have deleted the default VPC, request one.</p> 
<p>&middot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Administrator-level permissions in IAM to enable Amazon ES and Amazon S3 to receive the log data from the EC2 instance through Firehose.</p> 
<p>Getting Started<br /> Begin by launching the AWS CloudFormation template to create the stack.</p> 
<p>1.&nbsp;&nbsp;&nbsp;&nbsp; In the AWS CloudFormation console, choose &nbsp;to &nbsp; <a href="https://us-west-2.console.aws.amazon.com/cloudformation/home?region=us-west-2#/stacks/new?stackName=estemplatev4&amp;templateURL=https://s3.amazonaws.com/scriptdepot/es.template" target="_blank"><img class="alignnone size-full wp-image-254" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/24/launch-stack.png" alt="launch-stack" width="144" height="27" /></a>&nbsp;the AWS CloudFormation template. Make sure that you are in the US West (Oregon) region.</p> 
<p>Note: If you want to download the template to your computer and then upload it to AWS CloudFormation, you can do so from this Amazon S3 bucket. Save the template to a location on your computer that’s easy to remember.</p> 
<p>2.&nbsp;&nbsp;&nbsp;&nbsp; Choose Next.</p> 
<p>3.&nbsp;&nbsp;&nbsp;&nbsp; On the Specify Details page, provide the following:</p> 
<p><img class="alignnone wp-image-359 size-full" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/11/01/Screen-Shot-2016-11-01-at-9.44.20-AM.png" alt="Screen Shot 2016-11-01 at 9.44.20 AM" width="2548" height="1323" /></p> 
<p>a)&nbsp;&nbsp;&nbsp; Stack Name: A name for your stack.</p> 
<p>b)&nbsp;&nbsp;&nbsp; InstanceType: Select the instance family for the EC2 instance hosting the web server.</p> 
<p>c)&nbsp;&nbsp;&nbsp;&nbsp; KeyName: Select the Amazon EC2 key pair in the US West (Oregon) Region.</p> 
<p>d)&nbsp;&nbsp;&nbsp; SSHLocation: The IP address range that can be used to connect to the EC2 instance by using SSH. Accept the default, 0.0.0.0/0.</p> 
<p>e)&nbsp;&nbsp;&nbsp; WebserverPort: The TCP/IP port of the web server. Accept the default, 80.</p> 
<p>4.&nbsp;&nbsp;&nbsp;&nbsp; Choose Next.</p> 
<p>5.&nbsp;&nbsp;&nbsp;&nbsp; On the Options page, optionally specify tags for your AWS CloudFormation template, and then choose Next.</p> 
<p><img class="alignnone wp-image-181 size-full" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/17/createStack2.png" alt="createStack2" width="1013" height="623" /></p> 
<p>6.&nbsp;&nbsp;&nbsp;&nbsp; On the Review page, review your template details. Select the Acknowledgement checkbox, and then choose Create to create the stack.</p> 
<p>It takes about 10-15 minutes to create the entire stack.</p> 
<p>Configure the Amazon Kinesis Agent<br /> After AWS CloudFormation has created the stack, configure the Amazon Kinesis Agent.</p> 
<p>1.&nbsp;&nbsp;&nbsp;&nbsp; In the AWS CloudFormation console, choose the Resources tab to find the Firehose delivery stream name. You need this to configure the agent. Record this value because you will need it in step 3.</p> 
<p><img class="alignnone wp-image-182 size-full" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/17/createStack3.png" alt="createStack3" width="1013" height="589" /></p> 
<p>2.&nbsp;&nbsp;&nbsp;&nbsp; On the Outputs tab, find and record the public IP address of the web server. You need it to connect to the web server using SSH to configure the agent. For instructions on how to connect to an EC2 instance using SSH, see <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AccessingInstancesLinux.html" target="_blank">Connecting to Your Linux Instance Using SSH</a>.</p> 
<p><img class="alignnone wp-image-183 size-full" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/17/outputs.png" alt="outputs" width="910" height="404" /></p> 
<p>3. On the web server’s command line, run the following command:</p> 
<p>sudo vi /etc/aws-kinesis/agent.json</p> 
<p>This command opens the configuration file, agent.json, as follows.</p> 
<pre><em><code class="lang-json">{ &quot;cloudwatch.emitMetrics&quot;: true, &quot;firehose.endpoint&quot;: &quot;firehose.us-west-2.amazonaws.com&quot;, &quot;awsAccessKeyId&quot;: &quot;&quot;, &quot;awsSecretAccessKey&quot;: &quot;&quot;, &quot;flows&quot;: [ { &quot;filePattern&quot;: &quot;/var/log/httpd/access_log&quot;, &quot;deliveryStream&quot;: &quot;&quot;, &quot;dataProcessingOptions&quot;: [ { &quot;optionName&quot;: &quot;LOGTOJSON&quot;, &quot;logFormat&quot;: &quot;COMMONAPACHELOG&quot; } ] } ] } </code></em></pre> 
<p>4.&nbsp;&nbsp;&nbsp;&nbsp; For the deliveryStream key, type the value of the KinesisFirehoseDeliveryName that you retrieved from the stack’s Resources tab. After you type the value, save and terminate the agent.json file.</p> 
<p>5.&nbsp;&nbsp;&nbsp;&nbsp; Run the following command on the CLI:</p> 
<p>sudo service aws-kinesis-agent restart</p> 
<p>6. &nbsp; &nbsp; On the AWS CloudFormation console choose the resources tab and note the name of the Amazon ES cluster corresponding to the LogicalID&nbsp;ESDomain.</p> 
<p>7.&nbsp;&nbsp;&nbsp;&nbsp; Go to AWS Management Console, and choose Amazon Elasticsearch Service. Under My Domains, you can see the Amazon ES domain that the AWS CloudFormation template created.</p> 
<p><img class="alignnone wp-image-184 size-full" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/17/createStac5.png" alt="createStac5" width="910" height="474" /></p> 
<p>Configure Kibana and View Your Apache Logs<br /> Amazon ES provides a default installation of Kibana with every Amazon ES domain. You can find the Kibana endpoint on your domain dashboard in the Amazon ES console.</p> 
<p>1.&nbsp;&nbsp;&nbsp;&nbsp; In the Amazon ES console, choose the Kibana endpoint.</p> 
<p>2.&nbsp;&nbsp;&nbsp;&nbsp; In Kibana, for Index name or pattern, type logmonitor. logmonitor is the name of the AWS ES index that you created for the web server access logs. The health checks from Amazon Elastic Load Balancing generate access logs on the web server, which flow through the EKK pipeline to Kibana for discovery and visualization.</p> 
<p>3. &nbsp; &nbsp; In Time-field name, select datetime.</p> 
<p><img class="alignnone wp-image-185 size-full" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/17/kibana1.png" alt="kibana1" width="910" height="447" /></p> 
<p>4.&nbsp;&nbsp;&nbsp;&nbsp; On the Kibana console, choose the Discover tab to see the Apache logs.</p> 
<p><img class="alignnone wp-image-186 size-full" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/17/kibana3.png" alt="kibana3" width="910" height="505" /></p> 
<p>Use Kibana to visualize the log data by creating bar charts, line and scatter plots, histograms, pie charts, etc.</p> 
<p><img class="alignnone wp-image-187 size-full" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/17/Kibana4.png" alt="Kibana4" width="993" height="492" /></p> 
<p>Pie chart of IP addresses accessing the web server in the last 30 days</p> 
<p><img class="alignnone wp-image-188 size-full" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/17/Kibana5.png" alt="Kibana5" width="1013" height="492" /></p> 
<p>Bar chart of IP addresses accessing the web server in the last 5 minutes</p> 
<p>You can graph information about http response, bytes, or IP address to provide meaningful insights on the Apache logs. Kibana also facilitates making dashboards by combining graphs.</p> 
<p>Monitor Your Log Aggregator</p> 
<p>To monitor the Firehose delivery stream, navigate to the Firehose console. Choose the stream, and then choose the Monitoring tab to see the Amazon CloudWatch metrics for the stream.</p> 
<p><img class="alignnone wp-image-190 size-full" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/17/monito1.png" alt="monito1" width="994" height="499" /></p> 
<p>&nbsp;</p> 
<p>When log delivery fails, the Amazon S3 and Amazon ES logs help you troubleshoot. For example, the following screenshot shows logs when delivery to an Amazon ES destination fails because the date mapping on the index was not in line with the ingest log.</p> 
<p><img class="alignnone wp-image-191 size-full" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/17/monitor2.png" alt="monitor2" width="995" height="442" /></p> 
<p>Conclusion<br /> In this post, we showed how to ship Apache logs to Kibana by using Amazon Kinesis Agent, Amazon ES, and Firehose. It’s worth pointing out that Firehose automatically scales up or down based on the rate at which your application generates logs. To learn more about scaling Amazon ES clusters, see the <a href="http://docs.aws.amazon.com/elasticsearch-service/latest/developerguide/what-is-amazon-elasticsearch-service.html#concepts-scaling" target="_blank">Amazon Elasticsearch Service Developer Guide</a>.</p> 
<p>Managed services like Amazon ES and Amazon Kinesis Firehose simplify provisioning and managing a log aggregation system. The ability to run SQL queries against your streaming log data using Amazon Kinesis Analytics further strengthens the case for using an EKK stack. <a href="https://s3-us-west-2.amazonaws.com/scriptdepot/es.template" target="_blank">The AWS CloudFormation template</a> used in this post is available to extend and build your own EKK stack.</p> 
<p>&nbsp;</p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/devops/tag/amazon-elasticsearch/" rel="tag">Amazon Elasticsearch</a>, <a href="https://aws.amazon.com/blogs/devops/tag/amazon-kinesis-firehose/" rel="tag">Amazon Kinesis Firehose</a>, <a href="https://aws.amazon.com/blogs/devops/tag/cloudformation/" rel="tag">CloudFormation</a></span> 
</footer> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">Building End-to-End Continuous Delivery and Deployment Pipelines in AWS and TeamCity</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Balaji Iyer</span></span> | on 
<time property="datePublished" datetime="2016-10-31T12:14:54+00:00">31 OCT 2016</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/devops/category/how-to/" title="View all posts in How-To*"><span property="articleSection">How-To*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/devops/building-end-to-end-continuous-delivery-and-deployment-pipelines-in-aws-and-teamcity/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-206" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-devops-blog&amp;disqus_identifier=206&amp;disqus_title=Building+End-to-End+Continuous+Delivery+and+Deployment+Pipelines+in+AWS+and+TeamCity&amp;disqus_url=https://aws.amazon.com/blogs/devops/building-end-to-end-continuous-delivery-and-deployment-pipelines-in-aws-and-teamcity/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-206');
});
</script> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><em>By Balaji Iyer, Janisha Anand, and Frank Li</em></p> 
<p>Organizations that transform their applications to cloud-optimized architectures need a seamless, end-to-end continuous delivery and deployment workflow: from source code, to build, to deployment, to software delivery.</p> 
<p><strong>Continuous delivery</strong>&nbsp;is a&nbsp;<a href="https://aws.amazon.com/devops/">DevOps</a>&nbsp;software development practice where code changes are automatically built, tested, and prepared for a release to production. The practice expands on <a href="https://aws.amazon.com/devops/continuous-integration/">continuous integration</a>&nbsp;by deploying all code changes to a testing environment and/or a production environment after the build stage. When continuous delivery is implemented properly, developers will always have a deployment-ready build artifact that has undergone a standardized test process.</p> 
<p><strong>Continuous deployment</strong> is the process of deploying application revisions to a production environment automatically, without explicit approval from a developer. This process makes the entire software release process automated. Features are released as soon as they are ready, providing maximum value to customers.</p> 
<p>These two techniques enable development teams to deploy software rapidly, repeatedly, and reliably.</p> 
<p>In this post, we will build an end-to-end continuous deployment and delivery pipeline using <a href="http://aws.amazon.com/codepipeline">AWS CodePipeline</a>&nbsp;(a fully managed&nbsp;<a href="http://aws.amazon.com/devops/continuous-delivery/">continuous delivery</a>&nbsp;service), <a href="http://aws.amazon.com/codedeploy">AWS CodeDeploy</a>&nbsp;(an automated application deployment service), and TeamCity’s <a href="https://confluence.jetbrains.com/display/TW/AWS+CodePipeline+Plugin">AWS CodePipeline plugin</a>. We will use <a href="http://aws.amazon.com/cloudformation">AWS CloudFormation</a> to setup and configure the end-to-end infrastructure and application <a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/cfn-whatis-concepts.html#d0e3802">stacks</a>. The &shy;&shy;pipeline pulls source code from an Amazon S3 bucket, an AWS CodeCommit repository, or a GitHub repository. The source code will then be built and tested using TeamCity’s continuous integration server. Then AWS CodeDeploy will deploy the compiled and tested code to <a href="https://aws.amazon.com/ec2/">Amazon EC2</a> instances.</p> 
<p><strong>Prerequisites</strong></p> 
<p>You’ll need an AWS account, an <a href="https://aws.amazon.com/ec2/">Amazon EC2</a> key pair, and administrator-level permissions for AWS <a href="https://aws.amazon.com/iam/">Identity and Access Management (IAM)</a>, AWS CloudFormation, AWS CodeDeploy, AWS CodePipeline, Amazon EC2, and <a href="https://aws.amazon.com/s3/">Amazon S3</a>.</p> 
<p><strong>Overview</strong></p> 
<p>Here are the steps:</p> 
<ol> 
<li>Continuous integration server setup using TeamCity.</li> 
<li>Continuous deployment using AWS CodeDeploy.</li> 
<li>Building a delivery pipeline using AWS CodePipeline.</li> 
</ol> 
<p>In less than an hour, you’ll have an end-to-end, fully-automated continuous integration, continuous deployment, and delivery pipeline for your application. Let’s get started!</p> 
<p><span id="more-206"></span></p> 
<b>1. Continuous integration server setup using TeamCity</b> 
<p>Click here on this button <a href="https://console.aws.amazon.com/cloudformation/home?region=us-east-1#/stacks/new?stackName=TeamCityServer&amp;templateURL=https://s3.amazonaws.com/teamcity-aws-demo/TeamCity_Server_Template.cform"><img class="alignnone wp-image-254 size-full" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/24/launch-stack.png" alt="launch-stack" width="144" height="27" /></a>&nbsp;to launch an AWS CloudFormation stack to set up a TeamCity server. If you’re not already signed in to the AWS Management Console, you will be prompted to enter your AWS credentials. This stack provides an automated way to set up a TeamCity server based on the instructions <a href="https://confluence.jetbrains.com/display/TCD9/Installing+and+Configuring+the+TeamCity+Server">here</a>. You can download the template used for this setup from <a href="https://s3.amazonaws.com/teamcity-aws-demo/TeamCity_Server_Template.cform">here</a>.</p> 
<p>The CloudFormation template does the following:</p> 
<ol> 
<li>Installs and configures the TeamCity server and its dependencies in Linux.</li> 
<li>Installs the AWS CodePipeline <a href="https://confluence.jetbrains.com/display/TW/AWS+CodePipeline+Plugin">plugin</a> for TeamCity.</li> 
<li>Installs a <a href="https://github.com/awslabs/aws-demo-php-simple-app">sample application</a> with build configurations.</li> 
<li>Installs <a href="https://github.com/jetbrains/meta-runner-power-pack">PHP meta-runners</a> required to build the sample application.</li> 
<li>Redirects TeamCity port 8111 to 80.</li> 
</ol> 
<p>Choose the AWS region where the TeamCity server will be hosted. For this demo, choose <strong>US East (N. Virginia)</strong>.</p> 
<p><img style="width: 200px;height: 180px" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/24/Picture2-300x282.png" alt="Select a region" /></p> 
<p>On the <strong>Select Template </strong>page, choose <strong>Next</strong>.</p> 
<p>On the <strong>Specify Details</strong> page, do the following:</p> 
<ol> 
<li>In <strong>Stack name</strong>, enter a name for the stack. The name must be unique in the region in which you are creating the stack.</li> 
<li>In <strong>InstanceType</strong>, choose the instance type that best fits your requirements. The default value is t2.medium.</li> 
</ol> 
<p><strong>Note</strong>: The default instance type exceeds what’s included in the AWS Free Tier. If you use t2.medium, there will be charges to your account. The cost will depend on how long you keep the CloudFormation stack and its resources.</p> 
<ol start="3"> 
<li>In<strong> KeyName</strong>, choose the name of your Amazon EC2 key pair.</li> 
<li>In <strong>SSHLocation</strong>, enter the IP address range that can be used to connect through SSH to the EC2 instance. SSH and HTTP access is limited to this IP address range.</li> 
</ol> 
<p><strong>Note: </strong>You can use <a href="http://checkip.amazonaws.com/">checkip.amazonaws.com</a>&nbsp;or <a href="http://www.whatsmyip.org/">whatsmyip.org</a> to find your IP address. Remember to add&nbsp;<strong>/32</strong>&nbsp;to any single domain or, if you are representing a larger IP address space, use the correct CIDR block notation.</p> 
<p><img class="alignnone wp-image-239 size-full" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/24/Picture3.png" alt="Specify Details" width="975" height="540" /></p> 
<p>Choose <strong>Next</strong>.</p> 
<p>Although it’s optional, on the<strong> Options</strong>&nbsp;page, type TeamCityServer for the instance name. This is the name used in the CloudFormation template for the stack. It’s a best practice to name your instance, because it makes it easier to identify or modify resources later on.</p> 
<p>Choose&nbsp;<strong>Next</strong>.</p> 
<p>On the <strong>Review </strong>page, choose <strong>Create</strong> button. It will take several minutes for AWS CloudFormation to create the resources for you.</p> 
<p><img class="alignnone wp-image-240 size-full" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/24/Picture4.png" alt="Review" width="975" height="746" /></p> 
<p>When the stack has been created, you will see a <strong>CREATE_COMPLETE</strong> message on the <strong>Overview</strong> tab in the <strong>Status</strong> column.</p> 
<p><img class="alignnone wp-image-241 size-full" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/24/Picture5.png" alt="Events" width="975" height="517" /></p> 
<p>You have now successfully created a TeamCity server. To access the server, on the <a href="https://console.aws.amazon.com/ec2/v2/home?region=us-east-1#Instances:search=TeamCityServer">EC2 Instance page</a>, choose <strong>Public IP</strong> for the TeamCityServer instance.</p> 
<p><img class="alignnone wp-image-242 size-full" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/24/Picture6.png" alt="Public DNS" width="975" height="206" /></p> 
<p>On the <strong>TeamCity First Start</strong> page, choose <strong>Proceed</strong>.</p> 
<p><img class="alignnone wp-image-243 size-full" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/24/Picture7.png" alt="TeamCity First Start" width="975" height="544" /></p> 
<p>Although an internal database based on the HSQLDB database engine can be used for evaluation, TeamCity strongly recommends that you use an external database as a back-end TeamCity database in a production environment. An external database provides better performance and reliability. For more information, see the TeamCity <a href="https://confluence.jetbrains.com/display/TCD9/Setting+up+an+External+Database#SettingupanExternalDatabase-SelectingExternalDatabaseEngine">documentation</a>.</p> 
<p>On the <strong>Database connection setup</strong> page, choose<strong> Proceed</strong>.</p> 
<p><img class="alignnone wp-image-244 size-full" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/24/Picture8.png" alt="Database connection setup" width="975" height="397" /></p> 
<p>The TeamCity server will start, which can take several minutes.</p> 
<p><img class="alignnone wp-image-245 size-full" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/24/Picture9.png" alt="TeamCity is starting" width="975" height="247" /></p> 
<p>Review and Accept the TeamCity License Agreement, and then choose <strong>Continue</strong>.</p> 
<p>Next, create an Administrator account. Type a user name and password, and then choose <strong>Create Account</strong>.</p> 
<p>You can navigate to the demo project from <strong>Projects</strong> in the top-left corner.</p> 
<p><img class="alignnone wp-image-246 size-full" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/24/Picture10.png" alt="Projects" width="975" height="183" /></p> 
<p><strong>Note: </strong>You can create a project from a repository URL (the option used in this demo), or you can connect to your managed Git repositories, such as GitHub or BitBucket. The demo app used in this example can be found <a href="https://github.com/awslabs/aws-demo-php-simple-app">here</a>.</p> 
<p>We have already created a sample project configuration. Under <strong>Build</strong>, choose <strong>Edit Settings</strong>, and then review the settings.</p> 
<p><img class="alignnone wp-image-247 size-full" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/24/Picture11.png" alt="Demo App" width="975" height="392" /></p> 
<p>Choose <strong>Build Step: PHP – PHPUnit</strong>.</p> 
<p><img class="alignnone wp-image-248 size-full" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/24/Picture12.png" alt="Build Step" width="975" height="582" /></p> 
<p>The fields on the<strong> Build Step</strong> page are already configured.</p> 
<p><img class="alignnone wp-image-249 size-full" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/24/Picture13.png" alt="Build Step" width="975" height="706" /></p> 
<p>Choose <strong>Run </strong>to start the build.</p> 
<p><img class="alignnone wp-image-250 size-full" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/24/Picture14.png" alt="Run Test" width="975" height="222" /></p> 
<p>To review the tests that are run as part of the build, choose <strong>Tests</strong>.</p> 
<p><img src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/24/Picture15.png" alt="Build" width="777" height="348" /></p> 
<p><img class="alignnone wp-image-252 size-full" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/24/Picture16.png" alt="Build " width="975" height="395" /></p> 
<p>You can view any build errors by choosing <strong>Build log</strong> from the same drop-down list.</p> 
<p>Now that we have a successful build, we will use AWS CodeDeploy to set up a continuous deployment pipeline.</p> 
<b>2. Continuous deployment using AWS CodeDeploy</b> 
<p>Click here on this button <a href="https://console.aws.amazon.com/cloudformation/home?region=us-east-1#/stacks/new?stackName=DeploymentPipeline&amp;templateURL=https://s3.amazonaws.com/teamcity-aws-demo/CodeDeploy_Master_Template.cform"><img class="alignnone wp-image-254 size-full" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/24/launch-stack.png" alt="launch-stack" width="144" height="27" /></a> to launch an AWS CloudFormation stack that will use AWS CodeDeploy to set up a sample deployment pipeline. If you’re not already signed in to the AWS Management Console, you will be prompted to enter your AWS credentials.</p> 
<p>You can download the master template used for this setup from <a href="https://s3.amazonaws.com/teamcity-aws-demo/CodeDeploy_Master_Template.cform">here</a>. The template nests two CloudFormation templates to execute all dependent stacks cohesively.</p> 
<ol> 
<li>Template 1 creates a fleet of up to three EC2 instances (with a base operating system of Windows or Linux), associates an instance profile, and installs the AWS CodeDeploy agent. The CloudFormation template can be downloaded from <a href="https://s3.amazonaws.com/teamcity-aws-demo/CodeDeploy_Template.cform">here</a>.</li> 
<li>Template 2 creates an AWS CodeDeploy <a href="http://docs.aws.amazon.com/codedeploy/latest/userguide/how-to-create-deployment-group.html">deployment group</a> and then installs a sample application. The CloudFormation template can be downloaded from <a href="https://s3.amazonaws.com/teamcity-aws-demo/CodeDeploy_DeploymentGroup_Template.cform">here</a>.</li> 
</ol> 
<p>Choose the same AWS region you used when you created the TeamCity server (<strong>US East (N. Virginia)</strong>).</p> 
<p><strong>Note:</strong> The templates contain Amazon Machine Image (AMI) mappings for us-east-1, us-west-2, eu-west-1, and ap-southeast-2 only.</p> 
<p>On the <strong>Select Template </strong>page, choose <strong>Next</strong>.</p> 
<p><img class="alignnone wp-image-279 size-full" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/25/Picture17.png" alt="Picture17" width="975" height="546" /></p> 
<p>On the <strong>Specify Details </strong>page, in&nbsp;<strong>Stack name</strong>, type a name for the stack. In the <strong>Parameters </strong>section, do the following:</p> 
<ol> 
<li>In&nbsp;<strong>AppName</strong>, you can use the default, or you can type a name of your choice. The name must be between 2 and 15 characters long. It can contain lowercase and alphanumeric characters, hyphens (-), and periods (.), but the name must start with an alphanumeric character.</li> 
</ol> 
<ol start="2"> 
<li>In <strong>DeploymentGroupName</strong>, you can use the default, or you type a name of your choice. The name must be between 2 and 25 characters long. It can contain lowercase and alphanumeric characters, hyphens (-), and periods (.), but the name must start with an alphanumeric character.</li> 
</ol> 
<p><img class="alignnone wp-image-280 size-full" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/25/Picture18.png" alt="Picture18" width="975" height="297" /></p> 
<ol start="3"> 
<li>In <strong>InstanceType</strong>, choose the instance type that best fits the requirements of your application.</li> 
<li>In <strong>InstanceCount</strong>, type the number of EC2 instances (up to three) that will be part of the deployment group.</li> 
<li>For <strong>Operating System</strong>, choose <strong>Linux</strong> or <strong>Windows</strong>.</li> 
<li>Leave <strong>TagKey</strong> and <strong>TagValue</strong> at their defaults. AWS CodeDeploy will use this tag key and value to locate the instances during deployments. For information about Amazon EC2 instance tags, see <a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/Using_Tags.html#Using_Tags_Console">Working with Tags Using the Console</a>.<img class="alignnone wp-image-281 size-full" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/25/Picture19.png" alt="Picture19" width="975" height="398" /></li> 
<li>In S3Bucket and S3Key, type the bucket name and S3 key where the application is located. The default points to a sample application that will be deployed to instances in the deployment group. Based on what you selected in the OperatingSystem field, use the following values.<br /> <strong>Linux:</strong><br /> S3Bucket: aws-codedeploy<br /> S3Key: samples/latest/SampleApp_Linux.zip<br /> <strong>Windows:</strong><br /> S3Bucket: aws-codedeploy<br /> S3Key: samples/latest/SampleApp_Windows.zip</li> 
</ol> 
<ol start="8"> 
<li>In<strong> KeyName</strong>, choose the name of your Amazon EC2 key pair.</li> 
<li>In <strong>SSHLocation</strong>, enter the IP address range that can be used to connect through SSH/RDP to the EC2 instance.</li> 
</ol> 
<p><img class="alignnone wp-image-282 size-full" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/25/Picture20.png" alt="Picture20" width="975" height="433" /></p> 
<p><strong>Note: </strong>You can use <a href="http://checkip.amazonaws.com/">checkip.amazonaws.com</a>&nbsp;or <a href="http://www.whatsmyip.org/">whatsmyip.org</a> to find your IP address. Remember to add&nbsp;<strong>/32</strong>&nbsp;to any single domain or, if you are representing a larger IP address space, use the correct CIDR block notation.</p> 
<p>Follow the prompts, and then choose <strong>Next</strong>.</p> 
<p>On the&nbsp;<strong>Review</strong><strong>&nbsp;</strong>page, select the&nbsp;<strong>I acknowledge that this template might cause AWS CloudFormation to create IAM resources</strong>&nbsp;check box. Review the other settings, and then choose&nbsp;<strong>Create</strong>.</p> 
<p><img class="alignnone wp-image-283 size-full" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/25/Picture21.png" alt="Picture21" width="975" height="344" /></p> 
<p>It will take several minutes for CloudFormation to create all of the resources on your behalf. The nested stacks will be launched sequentially. You can view progress messages on the <strong>Events</strong> tab in the AWS CloudFormation console.</p> 
<p><img class="alignnone wp-image-284 size-full" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/25/Picture22.png" alt="Picture22" width="975" height="477" /></p> 
<p>You can see the newly created application and deployment groups in the AWS CodeDeploy console.</p> 
<p><img class="alignnone wp-image-285 size-full" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/25/Picture23.png" alt="Picture23" width="975" height="396" /></p> 
<p>To verify that your application was deployed successfully, navigate to the DNS address of one of the instances.</p> 
<p><img class="alignnone wp-image-286 size-full" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/25/Picture24.png" alt="Picture24" width="975" height="571" /></p> 
<p><img class="alignnone wp-image-287 size-full" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/25/Picture25.png" alt="Picture25" width="975" height="295" /></p> 
<p>Now that we have successfully created a deployment pipeline, let’s integrate it with AWS CodePipeline.</p> 
<b>3. Building a delivery pipeline using AWS CodePipeline</b> 
<p>We will now create a delivery pipeline in AWS CodePipeline with the <a href="https://confluence.jetbrains.com/display/TW/AWS+CodePipeline+Plugin">TeamCity AWS CodePipeline plugin</a>.</p> 
<ol> 
<li>Using AWS CodePipeline, we will build a new pipeline with Source and Deploy stages.</li> 
<li>Create a custom action for the TeamCity Build stage.</li> 
<li>Create an AWS CodePipeline action trigger in TeamCity.</li> 
<li>Create a Build stage in the delivery pipeline for TeamCity.</li> 
<li>Publish the build artifact for deployment.</li> 
</ol> 
<h3>Step 1: Build a new pipeline with Source and Deploy stages using AWS CodePipeline.</h3> 
<p>In this step, we will create an Amazon S3 bucket to use as the artifact store for this pipeline.</p> 
<ol> 
<li>Install and configure the <a href="http://docs.aws.amazon.com/streams/latest/dev/kinesis-tutorial-cli-installation.html">AWS CLI</a>.</li> 
</ol> 
<ol start="2"> 
<li>Create an Amazon S3 bucket that will host the build artifact. Replace <em>account-number</em> with your AWS account number in the following steps. <pre><code class="lang-bash">$ aws s3 mb s3://demo-app-build-account-number</code></pre> </li> 
</ol> 
<ol start="3"> 
<li>Enable bucket versioning <pre><code class="lang-bash">$ aws s3api put-bucket-versioning --bucket demo-app-build-account-number --versioning-configuration Status=Enabled</code></pre> </li> 
</ol> 
<ol start="4"> 
<li>Download the sample build artifact and upload it to the Amazon S3 bucket created in step 2.</li> 
</ol> 
<li><strong>OSX/Linux:</strong> <pre><code class="lang-bash">$ wget -qO- https://s3.amazonaws.com/teamcity-demo-app/Sample_Linux_App.zip | aws s3 cp - s3://demo-app-build-account-number/Sample_Linux_App.zip</code></pre> </li> 
<li><strong><strong>Windows:</strong></strong> <pre><code class="lang-code">$ wget -qO- https://s3.amazonaws.com/teamcity-demo-app/Sample_Windows_App.zip
$ aws s3 cp ./Sample_Windows_App.zip s3://demo-app-account-number</code></pre> </li> 
<p><strong>Note</strong>: You can use AWS CloudFormation to perform these steps in an automated way. When you choose <a href="https://console.aws.amazon.com/cloudformation/home?region=us-east-1#/stacks/new?stackName=S3BucketStack&amp;templateURL=https://s3.amazonaws.com/teamcity-aws-demo/S3_Bucket_Template.cform"><img class="alignnone wp-image-254 size-full" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/24/launch-stack.png" alt="launch-stack" width="144" height="27" /></a>, <a href="https://s3.amazonaws.com/teamcity-aws-demo/S3_Bucket_Template.cform">this template</a> will be used. Use the following commands to extract the Amazon S3 bucket name, enable versioning on the bucket, and copy over the sample artifact.</p> 
<pre><code class="lang-bash">$ export bucket-name =&quot;$(aws cloudformation describe-stacks --stack-name “S3BucketStack” --output text --query 'Stacks[0].Outputs[?OutputKey==`S3BucketName`].OutputValue')&quot;
$ aws s3api put-bucket-versioning --bucket $bucket-name --versioning-configuration Status=Enabled &amp;&amp; wget https://s3.amazonaws.com/teamcity-demo-app/Sample_Linux_App.zip &amp;&amp; aws s3 cp ./Sample_Linux_App.zip s3://$bucket-name</code></pre> 
<p>You can create a pipeline by using a CloudFormation stack or the AWS CodePipeline console.</p> 
<h4>Option 1: Use AWS CloudFormation to create a pipeline</h4> 
<p>We’re going to create a two-stage pipeline that uses a versioned Amazon S3 bucket and AWS CodeDeploy to release a sample application. (You can use an AWS CodeCommit repository or a GitHub repository as the source provider instead of Amazon S3.)</p> 
<p>Click here on this button <a href="https://console.aws.amazon.com/cloudformation/home?region=us-east-1#/stacks/new?stackName=DeliveryPipeline&amp;templateURL=https:%2F%2Fs3.amazonaws.com%2Fteamcity-aws-demo%2FCodePipeline_Template.cform"><img class="alignnone wp-image-254 size-full" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/24/launch-stack.png" alt="launch-stack" width="144" height="27" /></a>&nbsp;to launch an AWS CloudFormation stack to set up a new delivery pipeline using the application and deployment group created in an earlier step. If you’re not already signed in to the AWS Management Console, you will be prompted to enter your AWS credentials.</p> 
<p>Choose the <strong>US East (N. Virginia)</strong> region, and then choose <strong>Next</strong>.</p> 
<p>Leave the default options, and then choose <strong>Next</strong>.</p> 
<p><img class="alignnone wp-image-288 size-full" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/25/Picture26.png" alt="Picture26" width="975" height="682" /></p> 
<p>On the <strong>Options </strong>page, choose <strong>Next</strong>.</p> 
<p><img class="alignnone wp-image-289 size-full" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/25/Picture27.png" alt="Picture27" width="975" height="318" /></p> 
<p><strong>Select</strong> the<strong> I acknowledge that AWS CloudFormation might create IAM resources</strong> check box, and then choose <strong>Create</strong>. This will create the delivery pipeline in AWS CodePipeline.</p> 
<h4>Option 2: Use the AWS CodePipeline console to create a pipeline</h4> 
<p>On the <strong>Create pipeline</strong> page, in <strong>Pipeline name</strong>, type a name for your pipeline, and then choose <strong>Next step</strong>.<br /> <img class="alignnone wp-image-290 size-full" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/25/Picture28.png" alt="Picture28" width="975" height="386" /></p> 
<p>Depending on where your source code is located, you can choose Amazon S3, AWS CodeCommit, or GitHub as your<strong> Source provider</strong>. The pipeline will be triggered automatically upon every check-in to your GitHub or AWS CodeCommit repository or when an artifact is published into the S3 bucket. In this example, we will be accessing the product binaries from an Amazon S3 bucket.</p> 
<p>Choose <strong>Next step</strong>.<img class="alignnone wp-image-292 size-full" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/25/Picture29.png" alt="Picture29" width="975" height="628" /></p> 
<p>s3://demo-app-build-<em>account-number</em><em>/Sample_Linux_App.zip</em> (or) <em>Sample_Windows_App.zip</em></p> 
<p><strong>Note:</strong> AWS CodePipeline requires a versioned S3 bucket for source artifacts. <a href="http://docs.aws.amazon.com/AmazonS3/latest/UG/enable-bucket-versioning.html">Enable versioning</a> for the S3 bucket where the source artifacts will be located.</p> 
<p>On the <strong>Build </strong>page, choose <strong>No Build</strong>. We will update the build provider information later on.<img class="alignnone wp-image-293 size-full" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/25/Picture31.png" alt="Picture31" width="975" height="506" /></p> 
<p>For <strong>Deployment provider</strong>, choose <strong>CodeDeploy</strong>. For <strong>Application name </strong>and <strong>Deployment group</strong>, choose the application and deployment group we created in the deployment pipeline step, and then choose <strong>Next step</strong>.<img class="alignnone wp-image-294 size-full" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/25/Picture32.png" alt="Picture32" width="975" height="716" /></p> 
<p>An IAM role will provide the permissions required for AWS CodePipeline to perform the build actions and service calls.&nbsp; If you already have a role you want to use with the pipeline, choose it on the <strong>AWS Service Role</strong> page. Otherwise, type a name for your role, and then choose <strong>Create role</strong>.&nbsp; Review the predefined permissions, and then choose <strong>Allow</strong>. Then choose <strong>Next step</strong>.</p> 
<p>&nbsp;</p> 
<p>For information about AWS CodePipeline access permissions, see the&nbsp;<a href="http://docs.aws.amazon.com/codepipeline/latest/userguide/access-permissions.html">AWS CodePipeline Access Permissions Reference</a>.</p> 
<p><img class="alignnone wp-image-296 size-full" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/25/Picture34.png" alt="Picture34" width="975" height="403" /></p> 
<p>Review your pipeline, and then choose <strong>Create pipeline</strong></p> 
<p><img class="alignnone wp-image-297 size-full" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/25/Picture35.png" alt="Picture35" width="975" height="844" /></p> 
<p>This will trigger AWS CodePipeline to execute the Source and Beta steps. The source artifact will be deployed to the AWS CodeDeploy deployment groups.</p> 
<p><img class="alignnone wp-image-298 size-full" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/25/Picture36.png" alt="Picture36" width="515" height="822" /></p> 
<p>Now you can access the same DNS address of the AWS CodeDeploy instance to see the updated deployment. You will see the background color has changed to green and the page text has been updated.</p> 
<p><img class="alignnone wp-image-299 size-full" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/25/Picture37.png" alt="Picture37" width="975" height="326" /></p> 
<p>We have now successfully created a delivery pipeline with two stages and integrated the deployment with AWS CodeDeploy. Now let’s integrate the Build stage with TeamCity.</p> 
<h3>Step 2: Create a custom action for TeamCity Build stage</h3> 
<p>AWS CodePipeline includes a number of actions that help you configure build, test, and deployment resources for your automated release process. TeamCity is not included in the default actions, so we will create a <a href="http://docs.aws.amazon.com/codepipeline/latest/userguide/how-to-create-custom-action.html">custom action</a> and then include it in our delivery pipeline. TeamCity’s CodePipeline <a href="https://confluence.jetbrains.com/display/TW/AWS+CodePipeline+Plugin">plugin</a> will also create a job worker that will poll AWS CodePipeline for job requests for this custom action, execute the job, and return the status result to AWS CodePipeline.</p> 
<p>TeamCity’s custom action type (Build/Test categories) can be integrated with AWS CodePipeline. It’s similar to Jenkins and Solano CI custom actions. TeamCity’s CodePipeline <a href="https://confluence.jetbrains.com/display/TW/AWS+CodePipeline+Plugin">plugin</a> will also create a job worker that will poll AWS CodePipeline for job requests for this custom action, execute the job, and return the status result to AWS CodePipeline.</p> 
<p>The TeamCity AWS CodePipeline <a href="https://confluence.jetbrains.com/display/TW/AWS+CodePipeline+Plugin">plugin</a> is already installed on the TeamCity server we set up earlier. To learn more about installing TeamCity plugins, see <a href="https://confluence.jetbrains.com/display/TCDL/Installing+Additional+Plugins#InstallingAdditionalPlugins-InstallingTeamCityplugins">install the plugin</a>. We will now create a custom action to integrate TeamCity with AWS CodePipeline using a custom-action JSON file.</p> 
<p>Download this file locally: <a href="https://github.com/JetBrains/teamcity-aws-codepipeline-plugin/blob/master/custom-action.json">https://github.com/JetBrains/teamcity-aws-codepipeline-plugin/blob/master/custom-action.json</a></p> 
<p>Open a terminal session (Linux, OS X, Unix) or command prompt (Windows) on a computer where you have installed the AWS CLI. For information about setting up the AWS CLI, see <a href="http://docs.aws.amazon.com/cli/latest/userguide/cli-chap-getting-set-up.html">here</a>.</p> 
<p>Use the AWS CLI to run the <strong>aws codepipeline create-custom-action-type</strong> command, specifying the name of the JSON file you just created.</p> 
<p>For example, to create a build custom action:</p> 
<pre><code class="lang-bash">$ aws codepipeline create-custom-action-type --cli-input-json file://teamcity-custom-action.json</code></pre> 
<p>This should result in an output similar to this:</p> 
<pre><code class="lang-bash">{
&quot;actionType&quot;: {
&quot;inputArtifactDetails&quot;: {
&quot;maximumCount&quot;: 5,
&quot;minimumCount&quot;: 0
},
&quot;actionConfigurationProperties&quot;: [
{
&quot;description&quot;: &quot;The expected URL format is http[s]://host[:port]&quot;,
&quot;required&quot;: true,
&quot;secret&quot;: false,
&quot;key&quot;: true,
&quot;queryable&quot;: false,
&quot;name&quot;: &quot;TeamCityServerURL&quot;
},
{
&quot;description&quot;: &quot;Corresponding TeamCity build configuration external ID&quot;,
&quot;required&quot;: true,
&quot;secret&quot;: false,
&quot;key&quot;: true,
&quot;queryable&quot;: false,
&quot;name&quot;: &quot;BuildConfigurationID&quot;
},
{
&quot;description&quot;: &quot;Must be unique, match the corresponding field in the TeamCity build trigger settings, satisfy regular expression pattern: [a-zA-Z0-9_-]+] and have length &lt;= 20&quot;,
&quot;required&quot;: true,
&quot;secret&quot;: false,
&quot;key&quot;: true,
&quot;queryable&quot;: true,
&quot;name&quot;: &quot;ActionID&quot;
}
],
&quot;outputArtifactDetails&quot;: {
&quot;maximumCount&quot;: 5,
&quot;minimumCount&quot;: 0
},
&quot;id&quot;: {
&quot;category&quot;: &quot;Build&quot;,
&quot;owner&quot;: &quot;Custom&quot;,
&quot;version&quot;: &quot;1&quot;,
&quot;provider&quot;: &quot;TeamCity&quot;
},
&quot;settings&quot;: {
&quot;entityUrlTemplate&quot;: &quot;{Config:TeamCityServerURL}/viewType.html?buildTypeId={Config:BuildConfigurationID}&quot;,
&quot;executionUrlTemplate&quot;: &quot;{Config:TeamCityServerURL}/viewLog.html?buildId={ExternalExecutionId}&amp;tab=buildResultsDiv&quot;
}
}
}</code></pre> 
<p>Before you add the custom action to your delivery pipeline, make the following changes to the TeamCity build server. You can access the server by opening the <strong>Public IP</strong> of the TeamCityServer instance from the <a href="https://console.aws.amazon.com/ec2/v2/home?region=us-east-1#Instances:search=TeamCityServer">EC2 Instance page</a>.</p> 
<p><img class="alignnone wp-image-300 size-full" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/25/Picture38.png" alt="Picture38" width="975" height="206" /></p> 
<p>In TeamCity, choose <strong>Projects</strong>. Under <strong>Build Configuration Settings</strong>, choose <strong>Version Control Settings</strong>. You need to remove the version control trigger here so that the TeamCity build server will be triggered during the Source stage in AWS CodePipeline. Choose <strong>Detach</strong>.</p> 
<p><img class="alignnone wp-image-301 size-full" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/25/Picture39.png" alt="Picture39" width="975" height="361" /></p> 
<h3>Step 3: Create a new AWS CodePipeline action trigger in TeamCity</h3> 
<p>Now add a new AWS CodePipeline trigger in your build configuration. Choose <strong>Triggers</strong>, and then choose <strong>Add new trigger</strong></p> 
<p><strong><img class="alignnone wp-image-302 size-full" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/25/Picture40.png" alt="Picture40" width="975" height="355" /></strong></p> 
<p>From the drop-down menu, choose <strong>AWS CodePipeline Action</strong>.</p> 
<p><img class="alignnone wp-image-303 size-full" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/25/Picture41.png" alt="Picture41" width="975" height="511" /></p> 
<p>&nbsp;</p> 
<p>In the AWS CodePipeline console, choose the region in which you created your delivery pipeline. Enter your access key credentials, and for <strong>Action ID</strong>, type a unique name. You will need this ID when you add a TeamCity Build stage to the pipeline.</p> 
<p><img class="alignnone wp-image-304 size-full" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/25/Picture42.png" alt="Picture42" width="975" height="1032" /></p> 
<h3>Step 4: Create a new Build stage in the delivery pipeline for TeamCity</h3> 
<p>Add a stage to the pipeline and name it <strong>Build</strong>.</p> 
<p><img class="alignnone wp-image-305 size-large" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/25/Picture43-866x1024.png" alt="Picture43" width="640" height="757" /></p> 
<p>From the drop-down menu, choose <strong>Build</strong>. In <strong>Action name</strong>, type a name for the action. In <strong>Build provider</strong>, choose <strong>TeamCity</strong>, and then choose <strong>Add action</strong>.</p> 
<p>Select <strong>TeamCity</strong>, click <strong>Add action</strong></p> 
<p><img class="alignnone size-full wp-image-306" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/25/Picture44.png" alt="Picture44" width="975" height="781" /></p> 
<p>For <strong>TeamCity Action Configuration</strong>, use the following:</p> 
<p><strong>TeamCityServerURL</strong>:&nbsp; http://<em>&lt;Public DNS address of the TeamCity build server&gt;</em>[:port]</p> 
<p><img class="alignnone size-full wp-image-307" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/25/Picture45.png" alt="Picture45" width="831" height="638" /></p> 
<p><strong>BuildConfigurationID</strong>: In your TeamCity project, choose <strong>Build</strong>. You’ll find this ID (AwsDemoPhpSimpleApp_Build) under <strong>Build Configuration Settings</strong>.</p> 
<p><img class="alignnone size-full wp-image-308" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/25/Picture46.png" alt="Picture46" width="975" height="569" /></p> 
<p><strong>ActionID</strong>: In your TeamCity project, choose <strong>Build</strong>. You’ll find this ID under <strong>Build Configuration Settings</strong>. Choose <strong>Triggers</strong>, and then choose<strong> AWS CodePipeline Action</strong>.</p> 
<p><img class="alignnone size-full wp-image-309" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/25/Picture47.png" alt="Picture47" width="975" height="834" /></p> 
<p>Next, choose input and output artifacts for the Build stage, and then choose <strong>Add action</strong>.</p> 
<p><img class="alignnone size-full wp-image-310" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/25/Picture48.png" alt="Picture48" width="975" height="685" /></p> 
<p>We will now publish a new artifact to the Amazon S3 artifact bucket we created earlier, so we can see the deployment of a new app and its progress through the delivery pipeline. The demo app used in this artifact can be found <a href="https://github.com/awslabs/aws-demo-php-simple-app">here</a> for Linux or <a href="https://github.com/awslabs/AWSCodePipeline-S3-AWSCodeDeploy_Windows">here</a> for Windows.</p> 
<p>Download the sample build artifact and upload it to the Amazon S3 bucket created in step 2.</p> 
<p>OSX/Linux:</p> 
<pre><code class="lang-bash">$ wget -qO- https://s3.amazonaws.com/teamcity-demo-app/PhpArtifact.zip | aws s3 cp - s3://demo-app-build-account-number/PhpArtifact.zip</code></pre> 
<p>Windows:</p> 
<pre><code class="lang-code">$ wget -qO- https://s3.amazonaws.com/teamcity-demo-app/WindowsArtifact.zip
$ aws s3 cp ./WindowsArtifact.zip s3://demo-app-account-number
</code></pre> 
<p>From the AWS CodePipeline <a href="https://console.aws.amazon.com/codepipeline/home?region=us-east-1#/dashboard">dashboard</a>, under delivery-pipeline, choose <strong>Edit</strong>.<img style="width: 400px;height: 200px" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/25/Picture49.png" alt="Picture49" /></p> 
<p>Edit Source stage by choosing the edit icon on the right.</p> 
<p><strong>Amazon S3 location</strong>:</p> 
<p>Linux: s3://demo-app-<span style="color: #ff0000"><em>account-number</em></span><em>/PhpArtifact.zip</em></p> 
<p>Windows: s3://demo-app-<span style="color: #ff0000"><em>account-number</em></span><em>/WindowsArtifact.zip</em></p> 
<p>Under <strong>Output artifacts</strong>, make sure <strong>My App </strong>is displayed for<strong> Output artifact #1</strong>. This will be the input artifact for the Build stage.<img class="alignnone size-full wp-image-312" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/25/Picture50.png" alt="Picture50" width="975" height="666" /></p> 
<p>The output artifact of the Build stage should be the input artifact of the Beta deployment stage (in this case, <strong>MyAppBuild</strong>).<img class="alignnone size-full wp-image-313" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/25/Picture51.png" alt="Picture51" width="975" height="831" /></p> 
<p>Choose <strong>Update</strong>, and then choose <strong>Save pipeline changes</strong>. On the next page, choose <strong>Save and continue</strong>.</p> 
<h3>Step 5: Publish the build artifact for deployment<img class="alignnone size-full wp-image-314" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/25/Picture52.png" alt="Picture52" width="975" height="447" /></h3> 
<h4>Step (a)</h4> 
<p>In TeamCity, on the <strong>Build Steps</strong> page, for <strong>Runner type</strong>, choose <strong>Command Line</strong>, and then add the following custom script to copy the source artifact to the TeamCity <a href="https://confluence.jetbrains.com/display/TCD9/Build+Checkout+Directory">build checkout directory</a>.</p> 
<p><strong>Note:</strong> This step is required <em>only </em>if your AWS CodePipeline source provider is either AWS CodeCommit or Amazon S3. If your source provider is GitHub, this step is redundant, because the artifact is copied over automatically by the TeamCity AWS CodePipeline plugin.</p> 
<p>In <strong>Step name</strong>, enter a name for the Command Line runner to easily distinguish the context of the step.</p> 
<p>Syntax:</p> 
<pre><code class="lang-bash">$ cp -R %codepipeline.artifact.input.folder%/&lt;CodePipeline-Name&gt;/&lt;build-input-artifact-name&gt;/* % teamcity.build.checkoutDir%
$ unzip *.zip -d %teamcity.build.checkoutDir%
$ rm –rf %teamcity.build.checkoutDir%/*.zip</code></pre> 
<p>For <strong>Custom script</strong>, use the following commands:</p> 
<pre><code class="lang-bash">cp -R %codepipeline.artifact.input.folder%/delivery-pipeline/MyApp/* %teamcity.build.checkoutDir%
unzip *.zip -d %teamcity.build.checkoutDir%
rm –rf %teamcity.build.checkoutDir%/*.zip</code></pre> 
<p><img class="alignnone size-full wp-image-315" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/25/Picture53.png" alt="Picture53" width="975" height="674" /></p> 
<h4>Step (b):</h4> 
<p>For <strong>Runner type</strong>, choose <strong>Command Line</strong> runner type, and then add the following custom script to copy the build artifact to the output folder.</p> 
<p>For <strong>Step name</strong>, enter a name for the Command Line runner.</p> 
<p>Syntax:</p> 
<pre><code class="lang-bash">$ mkdir -p %codepipeline.artifact.output.folder%/&lt;CodePipeline-Name&gt;/&lt;build-output-artifact-name&gt;/
$ cp -R %codepipeline.artifact.input.folder%/&lt;CodePipeline-Name&gt;/&lt;build-input-artifact-name&gt;/* %codepipeline.artifact.output.folder%/&lt;CodePipeline-Name/&lt;build-output-artifact-name&gt;/
</code></pre> 
<p>For <strong>Custom script</strong>, use the following commands:</p> 
<pre><code class="lang-bash">$ mkdir -p %codepipeline.artifact.output.folder%/delivery-pipeline/MyAppBuild/
$ cp -R %codepipeline.artifact.input.folder%/delivery-pipeline/MyApp/* %codepipeline.artifact.output.folder%/delivery-pipeline/MyAppBuild/
</code></pre> 
<p><img class="alignnone size-full wp-image-340" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/25/CopyToOutputFolder.png" alt="CopyToOutputFolder" width="975" height="680" />In <strong>Build Steps</strong>, choose <strong>Reorder build steps </strong>to ensure the copying of the source artifact step is executed before the PHP – PHP Unit step.<img class="alignnone size-full wp-image-317" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/25/Picture54.png" alt="Picture54" width="975" height="575" /></p> 
<p>Drag and drop <strong>Copy Source Artifact To Build Checkout Directory</strong> to make it the first build step, and then choose <strong>Apply</strong>.<img class="alignnone size-full wp-image-318" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/25/Picture55.png" alt="Picture55" width="817" height="513" /></p> 
<p>Navigate to the AWS CodePipeline console. Choose the delivery pipeline, and then choose <strong>Release change</strong>. When prompted, choose <strong>Release</strong>.</p> 
<p>Choose<strong> Release </strong>on the next prompt.</p> 
<p><img class="alignnone size-full wp-image-319" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/25/Picture56.png" alt="Picture56" width="458" height="1209" /></p> 
<p>The most recent change will run through the pipeline again. It might take a few moments before the status of the run is displayed in the pipeline view.</p> 
<p>Here is what you’d see after AWS CodePipeline runs through all of the stages in the pipeline:<img class="alignnone size-full wp-image-320" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/25/Picture57.png" alt="Picture57" width="477" height="1135" /></p> 
<p>Let’s access one of the instances to see the new application deployment on the <a href="https://console.aws.amazon.com/ec2/v2/home?region=us-east-1#Instances:search=CodeDeployDemo">EC2 Instance page</a>.<img class="alignnone size-full wp-image-321" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/25/Picture58.png" alt="Picture58" width="975" height="571" /></p> 
<p>If your base operating system is Windows, accessing the public DNS address of one of the AWS CodeDeploy instances will result in the following page.</p> 
<blockquote> 
<pre>Windows: <em>http://public-dns/</em><img class="alignnone size-full wp-image-322" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/25/Picture59.png" alt="Picture59" width="975" height="201" /></pre> 
</blockquote> 
<p>If your base operating system is Linux, when we access the public DNS address of one of the AWS CodeDeploy instances, we will see the following test page, which is the sample application.</p> 
<blockquote> 
<pre>Linux: <em>http://public-dns/www/index.php</em><img class="alignnone size-full wp-image-323" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/25/Picture60.png" alt="Picture60" width="975" height="818" /></pre> 
</blockquote> 
<p>Congratulations! You’ve created an end-to-end deployment and delivery pipeline ─ from source code, to build, to deployment ─ in a fully automated way.</p> 
<b>Summary:</b> 
<p>In this post, you learned how to build an end-to-end delivery and deployment pipeline on AWS. Specifically, you learned how to build an end-to-end, fully automated, continuous integration, continuous deployment, and delivery pipeline for your application, at scale, using AWS deployment and management services. You also learned how AWS CodePipeline can be easily extended through the use of custom triggers to integrate other services like TeamCity.</p> 
<p>If you have questions or suggestions, please leave a comment below.</p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/devops/tag/best-practices/" rel="tag">Best practices</a>, <a href="https://aws.amazon.com/blogs/devops/tag/cloudformation/" rel="tag">CloudFormation</a>, <a href="https://aws.amazon.com/blogs/devops/tag/codecommit/" rel="tag">CodeCommit</a>, <a href="https://aws.amazon.com/blogs/devops/tag/codedeploy/" rel="tag">CodeDeploy</a>, <a href="https://aws.amazon.com/blogs/devops/tag/codepipeline/" rel="tag">CodePipeline</a>, <a href="https://aws.amazon.com/blogs/devops/tag/continuous-delivery/" rel="tag">Continuous Delivery</a>, <a href="https://aws.amazon.com/blogs/devops/tag/continuous-deployment/" rel="tag">Continuous Deployment</a>, <a href="https://aws.amazon.com/blogs/devops/tag/continuous-integration/" rel="tag">Continuous Integration</a>, <a href="https://aws.amazon.com/blogs/devops/tag/development/" rel="tag">Development</a>, <a href="https://aws.amazon.com/blogs/devops/tag/devops/" rel="tag">DevOps</a>, <a href="https://aws.amazon.com/blogs/devops/tag/how-to/" rel="tag">How-to</a>, <a href="https://aws.amazon.com/blogs/devops/tag/partners/" rel="tag">Partners</a>, <a href="https://aws.amazon.com/blogs/devops/tag/teamcity/" rel="tag">TeamCity</a>, <a href="https://aws.amazon.com/blogs/devops/tag/web-app/" rel="tag">Web app</a></span> 
</footer> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-206');
});
</script> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">AWS Config: Checking for Compliance with New Managed Rule Options</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Shawn O'Connor</span></span> | on 
<time property="datePublished" datetime="2016-10-26T09:12:14+00:00">26 OCT 2016</time> | 
<a href="https://aws.amazon.com/blogs/devops/aws-config-checking-for-compliance-with-new-managed-rule-options/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p>Change is the inherent nature of the Cloud. New ideas can immediately take shape through the provisioning of resources, projects will iterate and evolve, and sometimes we must go back to the drawing board. <a href="http://aws.amazon.com"> Amazon Web Services</a> accelerates this process by providing the ability to programmatically provision and de-provision resources. However, this freedom requires some responsibility on the part the organization in implementing consistent business and security policies.</p> 
<p><a href="https://aws.amazon.com/config/">AWS Config</a> enables AWS resource inventory and change management as well as Config Rules to confirm that resources are configured in compliance with policies that you define. <a href="https://aws.amazon.com/about-aws/whats-new/2016/10/8-new-config-rules-to-govern-the-configuration-of-critical-aws-resources/">New options</a> are now available for AWS Config managed rules, providing additional flexibility with regards to the type of rules and policies that can be created.</p> 
<li>AWS Config rules can now check that running instances are using approved <a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AMIs.html">Amazon Machine Images</a>, or AMIs. You can specify a list of approved AMI by ID or provide a tag to specify the list of AMI Ids.</li> 
<li>The Required-Tag managed rule can now require up to 6 tags with optional values in a single rule. Previously, each rule accepted only a single tag/value combo.</li> 
<li>Additionally, the Required-Tag managed rule now accepts a comma-separated list of values for each checked tag. This allows for a rule to be compliant if any one of a supplied list of tags is present on the resource.</li> 
<b>A Sample Policy</b> 
<p>Let’s explore how these new rule options can be incorporated into a broader compliance policy. A typical company’s policy might state that:</p> 
<li>All data must be encrypted at rest.</li> 
<li>The AWS IAM password policy must meet the corporate standard.</li> 
<li>Resources must be billed to the correct cost center.</li> 
<li>We want to know who owns a resource in case there is an issue or question about the resource.</li> 
<li>We want to identify whether a resource is a part of Dev, QA, Production, or staging so that we can apply the correct SLAs and make sure the appropriate teams have access.</li> 
<li>We need to identify any systems that handled privileged information such as Personally Identifiable Information (PII) or credit card data (PCI) as a part of our <a href="https://aws.amazon.com/compliance/">compliance</a> requirements.</li> 
<li>Our Ops teams regularly provides hardened images with the latest patches and required software (e.g. security and/or configuration management agents). We want to ensure that all Linux instances are built with these images. We do regular reviews to ensure our images are up to date.</li> 
<p>We see organizations implementing a variety of strategies like the one we have defined. <a href="https://d0.awsstatic.com/aws-answers/AWS_Tagging_Strategies.pdf">Tagging</a> is typically used to categorize and identify resources. We will be using tags and AWS Config managed rules to satisfy each of our policy requirements. In addition to the AWS Config managed rules, <a href="http://docs.aws.amazon.com/config/latest/developerguide/evaluate-config_develop-rules.html">custom compliance rules</a> can be developed using AWS Lambda functions.</p> 
<b>Implementation</b> 
<p>In the AWS Management console, we have built 5 rules.</p> 
<li>strong_password_policy – Checks that we have a Strong Password policy for AWS IAM Users</li> 
<li>only_encrypted_volumes – Checks that all attached EBS volumes are encrypted</li> 
<li>approved_ami_by_id – Checks that approved AMI IDs have been used</li> 
<li>approved_ami_by_tag – Check that AMIs tagged as <em>sec_approved</em> have been used</li> 
<li>ec2_required_tags – Check that all required tags have been applied to EC2 instances:<br /> 
<table> 
<thead> 
<tr> 
<th>Tag Name (Key)</th> 
<th>Tag Value(s)</th> 
<th>Description</th> 
</tr> 
</thead> 
<tbody> 
<tr> 
<td>Environment</td> 
<td>Prod / Dev / QA / Staging</td> 
<td>The environment in which the resource deployed</td> 
</tr> 
<tr> 
<td>Owner</td> 
<td>Joe, Steve, Anne</td> 
<td>Who is responsible?</td> 
</tr> 
<tr> 
<td>CostCenter</td> 
<td>General / Ops / Partner / Marketing</td> 
<td>Who is paying for the resource?</td> 
</tr> 
<tr> 
<td>LastReviewed</td> 
<td>Date (e.g. 09272016)</td> 
<td>Last time this instance was reviewed for compliance</td> 
</tr> 
<tr> 
<td>AuditLevel</td> 
<td>Normal / PII / PCI</td> 
<td>The required audit level for the instance</td> 
</tr> 
</tbody> 
</table> </li> 
<b>Strong Password Policy</b> 
<p>AWS Config has pre-built rules to check against the configured IAM password Policy. We have implemented this rule using the default configurations.</p> 
<p>We can see that our IAM password policy is <em>Compliant</em> with our managed rule.</p> 
<p><img class="alignnone wp-image-221 size-full" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/19/blog1.png" alt="blog1" width="1658" height="425" /></p> 
<b>Approved AMIs</b> 
<p>We have our hardened AMI from the Ops team. The image also includes encrypted EBS volumes. We have added a tag called <em>sec_approved</em> that we will use to test our image.</p> 
<p><img class="alignnone size-full wp-image-222" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/19/blog2.png" alt="blog2" width="1631" height="517" /></p> 
<p>We will create two additional rules to check that EC2 instances are launched with our approved AMIs. One will check that our <em>sec_approved</em> tag is present on the AMI. A second rule checks that the AMI ID (<strong>ami-1480c503</strong>) is included in a comma-separated list of approved images. Now we will launch two instances. One with a standard Amazon Linux AMI (<strong>i-019b0e790a67dd7f1</strong>) and one instance with our approved AMI (<strong>i-0caf40fcb4f48517c</strong>).</p> 
<p><img class="alignnone size-full wp-image-223" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/19/blog3.png" alt="blog3" width="1138" height="184" /></p> 
<p>If we look at the details of the <em>approved_amis_by_tag</em> and <em>approved_amis_by_id</em> rules, we see that the instance that was launched with the unapproved image (<strong>i-019b0e790a67dd7f1</strong>) has been marked <em>Noncompliant</em>. Our hardened instance (<strong>i-0caf40fcb4f48517c</strong>) is <em>Compliant</em>.</p> 
<p><img class="alignnone size-full wp-image-224" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/19/blog4.png" alt="blog4" width="1569" height="579" /></p> 
<p><img class="alignnone size-full wp-image-225" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/19/blog5.png" alt="blog5" width="1579" height="545" /></p> 
<b>Encrypted EBS Volumes</b> 
<p>In the EC2 Console we see the volumes attached to our instances. We can see that the EBS volumes created by our hardened AMI have been encrypted as configured. They are attached to instance <strong>i-0caf40fcb4f48517c</strong>.</p> 
<p><img class="alignnone size-full wp-image-226" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/19/blog6.png" alt="blog6" width="1762" height="264" /></p> 
<p>If we look at the details of the <em>only_encrypted_volumes</em> rule, we see that the instance that was launched with the unapproved image (<strong>i-019b0e790a67dd7f1</strong>) has been marked <em>Noncompliant</em>. Our hardened instance is <em>Compliant</em>.</p> 
<p><img class="alignnone size-full wp-image-227" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/19/blog7.png" alt="blog7" width="1583" height="694" /></p> 
<b>Required Tags</b> 
<p>Finally, let’s take a look at the <em>ec2_required_tags</em> rule. We have defined our required tags in our AWS Config Rule. Specific tag values are optional, but will be required if specified. Our hardened instance was configured with all required tags.</p> 
<p><img class="alignnone size-full wp-image-228" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/19/tags01.png" alt="tags01" width="999" height="716" /></p> 
<p><img class="alignnone size-full wp-image-229" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/19/tags2.png" alt="tags2" width="1334" height="388" /></p> 
<p>We can see that our tagged instance is compliant with our Required Tags Rule as well.</p> 
<p><img class="alignnone size-full wp-image-230" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/19/tags3.png" alt="tags3" width="1663" height="632" /></p> 
<footer> 
</footer> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">OpsWorks September 2016 Updates</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Daniel Huesch</span></span> | on 
<time property="datePublished" datetime="2016-09-20T12:33:44+00:00">20 SEP 2016</time> | 
<a href="https://aws.amazon.com/blogs/devops/opsworks-september-2016-updates/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-13" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-devops-blog&amp;disqus_identifier=13&amp;disqus_title=OpsWorks+September+2016+Updates&amp;disqus_url=https://aws.amazon.com/blogs/devops/opsworks-september-2016-updates/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-13');
});
</script> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p> Over the past few months, the AWS OpsWorks team has introduced several enhancements to existing features and added to support for new one. Let’s discuss some of these new capabilities.</p> 
<p style="margin-left:.25in"> &middot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <a href="https://console.aws.amazon.com/opsworks/home?region=us-east-1#/changelog/chef/12">Chef client 12.13.37</a> – Released a new AWS OpsWorks agent version for Chef 12 for Linux, enabling the latest enhancements from Chef. The OpsWorks console now shows the full history of enhancements to its agent software. Here’s an example of what the change log looks like:</p> 
<p style="margin-left:.25in"> <img alt="" src="https://dmhnzl5mp9mj6.cloudfront.net/application-management_awsblog/images/blog-post-september-01.png" /></p> 
<p style="margin-left:.25in"> &middot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <a href="https://nodejs.org/en/blog/release/v0.12.15/">Node.js 0.12.15</a> – Provided support for a new version of Node.js, in Chef 11.</p> 
<p style="margin-left:.75in"> –&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Fixes a bug in the read/write locks implementation for the Windows operating system.<br /> –&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Fixes a potential buffer overflow vulnerability.</p> 
<p style="margin-left:.25in"> &middot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <a href="https://www.ruby-lang.org/en/news/2016/04/26/ruby-2-3-1-released/">Ruby 2.3.1</a> – The built-in Chef 11 Ruby layer now supports Ruby 2.3.1, which includes these Ruby enhancements:</p> 
<p style="margin-left:.75in"> –&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Introduced a frozen string literal pragma.<br /> –&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Introduced a safe navigation operator (lonely operator).<br /> –&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Numerous performance improvements.</p> 
<p style="margin-left:.25in"> &middot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSVolumeTypes.html">Larger EBS volumes</a> – Following the recent announcement from <a href="https://aws.amazon.com/ebs/">Amazon EBS</a>, you can now use OpsWorks to create provisioned IOPS volumes that store up to 16 TB and process up to 20,000 IOPS, with a maximum throughput of 320 MBps. You can also create general purpose volumes that store up to 16 TB and process up to 10,000 IOPS, with a maximum throughput of 160 MBps.</p> 
<p style="margin-left:.25in"> &middot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <a href="https://docs.aws.amazon.com/opsworks/latest/userguide/workinginstances-os-linux.html">New Linux operating systems</a> – OpsWorks continues to enhance its operating system support and now offers:</p> 
<p style="margin-left:.75in"> –&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Amazon Linux 2016.03 (Amazon Linux 2016.09 support will be available soon)<br /> –&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Ubuntu 16.04<br /> –&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; CentOS 7</p> 
<p style="margin-left:.25in"> &middot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <a href="http://docs.aws.amazon.com/opsworks/latest/userguide/workinginstances-add.html">Instance tenancy</a> – You can provision dedicated instances through OpsWorks. Dedicated instances are <a href="https://aws.amazon.com/ec2/">Amazon EC2</a> instances that run in a virtual private cloud (VPC) on hardware that’s dedicated to a single customer. Your dedicated instances are physically isolated at the host hardware level from instances that belong to other AWS accounts.</p> 
<p style="margin-left:.25in"> <img alt="" src="https://dmhnzl5mp9mj6.cloudfront.net/application-management_awsblog/images/blog-post-september-02.png" /></p> 
<p style="margin-left:.25in"> &middot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSVolumeTypes.html">Define root volumes</a> – You can define the size of the root volume of your EBS-backed instances directly from the OpsWorks console. Choose from a variety of volume types: <strong>General Purpose (SSD)</strong>, <strong>Provisioned IOPS (SSD)</strong>, and <strong>Magnetic</strong>.</p> 
<p style="margin-left:.25in"> <img alt="" src="https://dmhnzl5mp9mj6.cloudfront.net/application-management_awsblog/images/blog-post-september-03.png" /></p> 
<p style="margin-left:.25in"> &middot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Instance page – The OpsWorks instance page now displays a summary bar that indicates the aggregated state of all the instances in a selected stack. Summary fields include total instance count, online instances, instances that are in the setting-up stage, instances that are in the shutting-down stage, stopped instances, and instances in an error state.</p> 
<p style="margin-left:.25in"> <img alt="" src="https://dmhnzl5mp9mj6.cloudfront.net/application-management_awsblog/images/blog-post-september-04.png" /></p> 
<p style="margin-left:.25in"> &middot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Service role regeneration – You can now use the OpsWorks console to recreate your IAM service role if it was deleted.</p> 
<p style="margin-left:.25in"> <strong>Recreate IAM service role</strong></p> 
<p style="margin-left:.25in"> <img alt="" src="https://dmhnzl5mp9mj6.cloudfront.net/application-management_awsblog/images/blog-post-september-05.png" /></p> 
<p style="margin-left:.25in"> <strong>Confirmation of IAM service role creation</strong></p> 
<p style="margin-left:.25in"> <img alt="" src="https://dmhnzl5mp9mj6.cloudfront.net/application-management_awsblog/images/blog-post-september-06.png" /></p> 
<p style="margin-left:.25in"> As always, we welcome your feedback about features you’re using in OpsWorks. Be sure to visit the <a href="https://forums.aws.amazon.com/forum.jspa?forumID=153">OpsWorks user forums</a>, and check out the <a href="https://aws.amazon.com/documentation/opsworks/">documentation</a>.</p> 
<p> &nbsp;</p> 
<p> &nbsp;</p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/devops/tag/opsworks/" rel="tag">OpsWorks</a></span> 
</footer> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-13');
});
</script> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">Secure AWS CodeCommit with Multi-Factor Authentication</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Steffen Grunwald</span></span> | on 
<time property="datePublished" datetime="2016-09-02T08:26:18+00:00">02 SEP 2016</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/devops/category/how-to/" title="View all posts in How-To*"><span property="articleSection">How-To*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/devops/secure-aws-codecommit-with-multi-factor-authentication/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-14" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-devops-blog&amp;disqus_identifier=14&amp;disqus_title=Secure+AWS+CodeCommit+with+Multi-Factor+Authentication&amp;disqus_url=https://aws.amazon.com/blogs/devops/secure-aws-codecommit-with-multi-factor-authentication/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-14');
});
</script> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p> This blog post shows you how to set up <a href="https://aws.amazon.com/codecommit/">AWS CodeCommit</a> if you want to enforce multi-factor authentication (MFA) for your repository users. One of the most common reasons for using MFA for your AWS CodeCommit repository is to secure sensitive data or prevent accidental pushes to the repository that could trigger a sensitive change process.</p> 
<p> By using the MFA capabilities of <a href="https://aws.amazon.com/iam/">AWS Identity and Access Management</a> (IAM) you can add an extra layer of protection to sensitive code in your AWS CodeCommit repository. AWS Security Token Service (STS) and IAM allow you to stretch the period during which the authentication is valid from 15 minutes to 36 hours, depending on your needs. AWS CLI profile configuration and the AWS CodeCommit credential helper transparently use the MFA information as soon as it has been issued, so you can work with MFA with minimal impact to your daily development process.</p> 
<b> Solution Overview</b> 
<p> AWS CodeCommit currently provides two communication protocols and authentication methods:</p> 
<li> <strong>SSH</strong> authentication uses keys configured in IAM user profiles.</li> 
<li> <strong>HTTPS</strong> authentication uses IAM keys or temporary security credentials retrieved when assuming an IAM role.</li> 
<p> It is possible to use SSH in a manner that incorporates multiple factors. An SSH private key can be considered <em>something you have</em> and its passphrase <em>something you know</em>. However, the passphrase cannot technically be enforced on the client side. Neither is it issued on an independent device.</p> 
<p> That is why the solution described in this post uses the <a href="http://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-cli.html">assumption of IAM roles</a> to enforce MFA. STS can <a href="http://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_mfa_configure-api-require.html">validate MFA</a> information from devices that issue time-based one-time passwords (TOTPs).</p> 
<p> A typical scenario involves the use of multiple AWS accounts (for example, Dev and Prod). One account is used for authentication and another contains the resource to be accessed (in this case, your AWS CodeCommit repository). You could also apply this solution to a single account.</p> 
<p> This is what the workflow looks like:</p> 
<p> <img alt="Overview" src="https://dmhnzl5mp9mj6.cloudfront.net/application-management_awsblog/images/CodeCommit_BlogPost.png" style="height: 350px;border-width: 0px;border-style: solid;width: 624px" /></p> 
<ol> 
<li> A user authenticates with IAM keys and a token from her MFA device and retrieves temporary credentials from STS. Temporary credentials consist of an access key ID, a secret access key, and a session token. The expiration of these keys can be configured with a duration of up to 36 hours.</li> 
<li> To access the resources in a different account, <a href="http://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_terms-and-concepts.html">role delegation</a> comes into play. The local Git repository is configured to use the temporary credentials to assume an IAM role that has access to the AWS CodeCommit repository. Here again, STS provides temporary credentials, but they are valid for a maximum of one hour.</li> 
<li> When Git is calling AWS CodeCommit, the credentials retrieved in step 2 are used to authenticate the requests. When the credentials expire, they are reissued with the credentials from step 1.</li> 
</ol> 
<p> You could use permanent IAM keys to directly assume the role in step 2 without the temporary credentials from step 1. The process reduces the frequency with which a developer needs to use MFA by increasing the lifetime of the temporary credentials.</p> 
<b> Account Setup Tasks</b> 
<p> The tasks to set up the MFA scenario are as follows:</p> 
<ol> 
<li> Create a <strong>repository</strong> in AWS CodeCommit.</li> 
<li> Create a <strong>role that is used to access the repository</strong>.</li> 
<li> Create a <strong>group allowed to assume the role</strong>.</li> 
<li> Create a <strong>user with an MFA device</strong> who belongs to the group.</li> 
</ol> 
<p> The following steps assume that you have <a href="http://docs.aws.amazon.com/cli/latest/userguide/installing.html">set up the AWS CLI</a> and <a href="http://docs.aws.amazon.com/cli/latest/userguide/cli-chap-getting-started.html">configured it with the keys</a> of users who have the required permissions to IAM and AWS CodeCommit in two accounts. Following the workflow, we will create the following admin users and AWS CLI profiles:</p> 
<li> <strong>admin-account-a</strong> needs permissions to administer IAM (built-in policy <code>IAMFullAccess</code>)</li> 
<li> <strong>admin-account-b</strong> needs permissions to administer IAM and AWS CodeCommit (built-in policies <code>IAMFullAccess</code> and <code>AWSCodeCommitFullAccess</code>)</li> 
<p> At the time of this writing, AWS CodeCommit is available in <code>us-east-1</code> only, so use that region for the <code>region</code> profile attribute for account B.</p> 
<p> The following scripts work for Linux and Mac OS. For readability, line breaks are separated by back slashes. If you want to run these scripts on Microsoft Windows, you will need to adapt them or run them on an emulation layer (for example, Cygwin).</p> 
<p> Replace placeholders like <code>&lt;XXXX&gt;</code> before issuing the commands.</p> 
<h3> Task 1: Create a repository in AWS CodeCommit</h3> 
<p> Create an AWS CodeCommit repository in Account B:</p> 
<pre>
aws codecommit create-repository 
--repository-name myRepository 
--repository-description &quot;My Repository&quot; 
--profile admin-account-b</pre> 
<h3> Task 2: Create a role that is used to access the repository</h3> 
<ol> 
<li> <p> Create an IAM policy that grants access to the repository in Account B. Name it <em>MyRepositoryContributorPolicy</em>.</p> <p> Here is the MyRepositoryContributorPolicy.json policy document:</p> 
<pre>
{
&quot;Version&quot;: &quot;2012-10-17&quot;,
&quot;Statement&quot;: [
{
&quot;Effect&quot;: &quot;Allow&quot;,
&quot;Action&quot;: [
&quot;codecommit:CreateBranch&quot;,
&quot;codecommit:GetBlob&quot;,
&quot;codecommit:GetBranch&quot;,
&quot;codecommit:GetObjectIdentifier&quot;,
&quot;codecommit:GetRepository&quot;,
&quot;codecommit:GetTree&quot;,
&quot;codecommit:GitPull&quot;,
&quot;codecommit:GitPush&quot;,
&quot;codecommit:ListBranches&quot;
],
&quot;Resource&quot;: [
&quot;arn:aws:codecommit:&lt;ACCOUNT_B_REGION&gt;:&lt;ACCOUNT_B_ID&gt;:myRepository&quot;
]
}
]
}</pre> 
<p></p> 
<pre>
aws iam create-policy 
--policy-name MyRepositoryContributorPolicy 
--policy-document file://./MyRepositoryContributorPolicy.json 
--profile admin-account-b</pre> 
<p></p> 
<li> <p> Create a <em>MyRepositoryContributorRole</em> role that has the <em>MyRepositoryContributorPolicy</em> attached in Account B.</p> <p> Here is the MyRepositoryContributorTrustPolicy.json trust policy document:</p> 
<pre>
{
&quot;Version&quot;: &quot;2012-10-17&quot;,
&quot;Statement&quot;: [
{
&quot;Effect&quot;: &quot;Allow&quot;,
&quot;Principal&quot;: {
&quot;AWS&quot;: &quot;arn:aws:iam::&lt;ACCOUNT_A_ID&gt;:root&quot;
},
&quot;Action&quot;: &quot;sts:AssumeRole&quot;
}
]
}</pre> 
<p></p> 
<pre>
aws iam create-role 
--role-name MyRepositoryContributorRole 
--assume-role-policy-document file://./MyRepositoryContributorTrustPolicy.json 
--profile admin-account-b</pre> 
<p></p> 
<pre>
aws iam attach-role-policy 
--role-name MyRepositoryContributorRole 
--policy-arn arn:aws:iam::&lt;ACCOUNT_B_ID&gt;:policy/MyRepositoryContributorPolicy 
--profile admin-account-b</pre> 
<p></p> 
</ol> 
<h3> Task 3: Create a group allowed to assume the role</h3> 
<ol> 
<li> <p> Create a <em>MyRepositoryContributorAssumePolicy</em> policy for users who are allowed to assume the role in Account A.</p> <p> Here is the MyRepositoryContributorAssumePolicy.json policy document:</p> 
<pre>
{
&quot;Version&quot;: &quot;2012-10-17&quot;,
&quot;Statement&quot;: [
{
&quot;Effect&quot;: &quot;Allow&quot;,
&quot;Action&quot;: [
&quot;sts:AssumeRole&quot;
],
&quot;Resource&quot;: [
&quot;arn:aws:iam::&lt;ACCOUNT_B_ID&gt;:role/MyRepositoryContributorRole&quot;
],
&quot;Condition&quot;: {
&quot;NumericLessThan&quot;: {
&quot;aws:MultiFactorAuthAge&quot;: &quot;86400&quot;
}
}
}
]
}</pre> 
<p></p> 
<pre>
aws iam create-policy 
--policy-name MyRepositoryContributorAssumePolicy 
--policy-document file://./MyRepositoryContributorAssumePolicy.json 
--profile admin-account-a</pre> 
<p></p> 
<li> <p> Create the group for all users who need access to the repository:</p> 
<pre>
aws iam create-group 
--group-name MyRepositoryContributorGroup 
--profile admin-account-a</pre> 
<p></p> 
<li> <p> Attach the policy to the group:</p> 
<pre>
aws iam attach-group-policy 
--group-name MyRepositoryContributorGroup 
--policy-arn arn:aws:iam::&lt;ACCOUNT_A_ID&gt;:policy/MyRepositoryContributorAssumePolicy 
--profile admin-account-a</pre> 
<p></p> 
</ol> 
<h3> Task 4: Create a <strong>user with an MFA device</strong> who belongs to the group</h3> 
<ol> 
<li> <p> Create an IAM user in Account A:</p> 
<pre>
aws iam create-user 
--user-name MyRepositoryUser 
--profile admin-account-a</pre> 
<p></p> 
<li> <p> Add the user to the IAM group:</p> 
<pre>
aws iam add-user-to-group 
--group-name MyRepositoryContributorGroup 
--user-name MyRepositoryUser 
--profile admin-account-a</pre> 
<p></p> 
<li> <p> Create a virtual MFA device for the user. You can use the AWS CLI, but in this case it is easier to <a href="http://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_mfa_enable_virtual.html#enable-virt-mfa-for-iam-user">create one in the AWS Management Console</a>.</p> </li> 
<li> <p> Create IAM access keys for the user. Make note of the output of <code>AccessKeyId</code> and <code>SecretAccessKey</code>. They will be referenced as <code>&lt;ACCESS_KEY_ID&gt;</code> and <code>&lt;SECRET_ACCESS&gt;</code> later in this post.</p> 
<pre>
aws iam create-access-key 
--user-name MyRepositoryUser 
--profile admin-account-a</pre> 
<p></p> 
</ol> 
<p> You’ve now completed the account setup. To create more users, repeat task 4. Now we can continue to the local setup of the contributor’s environment.</p> 
<b> Initialize the Contributor’s Environment</b> 
<p> Each contributor must perform the setup in order to have access to the repository.</p> 
<p> Setup Tasks:</p> 
<ol> 
<li> Create a profile for the IAM user who fetches temporary credentials.</li> 
<li> Create a profile that is used to access the repository.</li> 
<li> Populate the role assuming profile with temporary credentials.</li> 
</ol> 
<h3> Task 1: Create a profile for the IAM user who fetches temporary credentials</h3> 
<p> By default, the AWS CLI maintains <a href="http://docs.aws.amazon.com/cli/latest/userguide/cli-chap-getting-started.html#cli-config-files">two files</a> in <code>~/.aws/</code> that contain per-profile settings. One is <code>credentials</code>, which stores sensitive information for means of authentication (for example, the secret access keys). The other is <code>config</code>, which defines all other settings, such as the region or the MFA device to use.</p> 
<p> Add the IAM keys for <em>MyRepositoryUser</em> that you created in Account Setup task 4 to <code>~/.aws/credentials</code>:</p> 
<pre>
[FetchMfaCredentials]
aws_access_key_id=&lt;ACCESS_KEY_ID&gt;
aws_secret_access_key=&lt;SECRET_ACCESS&gt;</pre> 
<p> Add the following lines to <code>~/.aws/config</code>:</p> 
<pre>
[profile FetchMfaCredentials]
mfa_serial=arn:aws:iam::&lt;ACCOUNT_A_ID&gt;:mfa/MyRepositoryUser
get_session_token_duration_seconds=86400</pre> 
<p> <code>get_session_token_duration_seconds</code> is a custom attribute that is used later by a script. It must not exceed the value of <code>aws:MultiFactorAuthAge</code> that we used in the assume policy.</p> 
<h3> Task 2: Create a profile that is used to access the repository</h3> 
<p> Add the following lines to <code>~/.aws/config</code>:</p> 
<pre>
[profile MyRepositoryContributor]
region=&lt;ACCOUNT_B_REGION&gt;
role_arn=arn:aws:iam::&lt;ACCOUNT_B_ID&gt;:role/MyRepositoryContributorRole
source_profile=MyRepositoryAssumer
</pre> 
<p> When the <em>MyRepositoryContributor</em> profile is used, the MyRepositoryContributorRole is assumed with credentials of the <em>MyRepositoryAssumer</em> profile. You may have noticed that we have not put <em>MyRepositoryAssumer</em> in the <code>credentials</code> file yet. The following task shows how the file is populated.</p> 
<h3> Task 3: Populate the role assuming profile with temporary credentials</h3> 
<ol> 
<li> <p> Create the populateSessionTokenProfile.sh script in your home directory or any other location:</p> 
<pre>
#!/bin/bash
# Parameter 1 is the name of the profile that is populated
# with keys and tokens.
KEY_PROFILE=&quot;$1&quot;
# Parameter 2 is the name of the profile that calls the
# session token service.
# It must contain IAM keys and mfa_serial configuration
# The STS response contains an expiration date/ time.
# This is checked to only set the keys if they are expired.
EXPIRATION=$(aws configure get expiration --profile &quot;$1&quot;)
RELOAD=&quot;true&quot;
if [ -n &quot;$EXPIRATION&quot; ];
then
# get current time and expiry time in seconds since 1-1-1970
NOW=$(date -u +&quot;%Y-%m-%dT%H:%M:%SZ&quot;)
# if tokens are set and have not expired yet
if [[ &quot;$EXPIRATION&quot; &gt; &quot;$NOW&quot; ]];
then
echo &quot;Will not fetch new credentials. They expire at (UTC) $EXPIRATION&quot;
RELOAD=&quot;false&quot;
fi
fi
if [ &quot;$RELOAD&quot; = &quot;true&quot; ];
then
echo &quot;Need to fetch new STS credentials&quot;
MFA_SERIAL=$(aws configure get mfa_serial --profile &quot;$2&quot;)
DURATION=$(aws configure get get_session_token_duration_seconds --profile &quot;$2&quot;)
read -p &quot;Token for MFA Device ($MFA_SERIAL): &quot; TOKEN_CODE
read -r AWS_SECRET_ACCESS_KEY AWS_SESSION_TOKEN EXPIRATION AWS_ACCESS_KEY_ID &lt; &lt;(aws sts get-session-token 
--profile &quot;$2&quot; 
--output text 
--query 'Credentials.*' 
--serial-number $MFA_SERIAL 
--duration-seconds $DURATION 
--token-code $TOKEN_CODE)
aws configure set aws_secret_access_key &quot;$AWS_SECRET_ACCESS_KEY&quot; --profile &quot;$KEY_PROFILE&quot;
aws configure set aws_session_token &quot;$AWS_SESSION_TOKEN&quot; --profile &quot;$KEY_PROFILE&quot;
aws configure set aws_access_key_id &quot;$AWS_ACCESS_KEY_ID&quot; --profile &quot;$KEY_PROFILE&quot;
aws configure set expiration &quot;$EXPIRATION&quot; --profile &quot;$1&quot;
fi</pre> 
<p></p> 
<li> <p> Run the script once. You might need to set execution permission (for example, <code>chmod 755</code>) before you run it.</p> 
<pre>
~/populateSessionTokenProfile.sh MyRepositoryAssumer FetchMfaCredentials
Need to fetch new STS credentials
Token for MFA Device (arn:aws:iam::&lt;ACCOUNT_A_ID&gt;:mfa/MyRepositoryUser): XXXXXX</pre> 
<p></p> 
<li> <p> Clone the repository, configure Git to use temporary credentials, and create an alias to renew MFA credentials:</p> 
<pre>
git clone --config 'credential.helper=!aws codecommit 
--profile MyRepositoryContributor 
credential-helper $@' 
--config 'credential.UseHttpPath=true' 
--config 'alias.mfa=!~/populateSessionTokenProfile.sh 
MyRepositoryAssumer FetchMfaCredentials' 
$(aws codecommit get-repository 
--repository-name myRepository 
--profile MyRepositoryContributor 
--output text 
--query repositoryMetadata.cloneUrlHttp)</pre> 
<p></p> 
<pre>
A client error (ExpiredToken) occurred when calling the AssumeRole operation:
The security token included in the request is expired</pre> 
<p></p> 
<pre>
git mfa</pre> 
<p></p> 
</ol> 
<p> We hope you find the steps for enforcing MFA for your repository users helpful. Feel free to leave your feedback in the comments.</p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/devops/tag/aws-codecommit/" rel="tag">AWS CodeCommit</a></span> 
</footer> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-14');
});
</script> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">Introducing Application Load Balancer – Unlocking and Optimizing Architectures</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">George Huang</span></span> | on 
<time property="datePublished" datetime="2016-08-19T00:16:41+00:00">19 AUG 2016</time> | 
<a href="https://aws.amazon.com/blogs/devops/introducing-application-load-balancer-unlocking-and-optimizing-architectures/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-15" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-devops-blog&amp;disqus_identifier=15&amp;disqus_title=Introducing+Application+Load+Balancer+%26%238211%3B+Unlocking+and+Optimizing+Architectures&amp;disqus_url=https://aws.amazon.com/blogs/devops/introducing-application-load-balancer-unlocking-and-optimizing-architectures/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-15');
});
</script> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p> <strong><i>This is a guest blog post by&nbsp;</i><em>Felix Candelario &amp; Benjamin F., AWS Solutions Architects.</em></strong></p> 
<p> This blog post will focus on architectures you can unlock with the recently launched <em>Application Load Balancer</em> and compare them with the implementations that use what we now refer to as the Classic Load Balancer. An Application Load Balancer operates at the application layer and makes routing and load-balancing decisions on application traffic using HTTP and HTTPS.</p> 
<p> There are several features to help you unlock new workloads:</p> 
<li> Content-based routing<p></p> 
<li> Allows you to define rules that route traffic to different target groups based on the path of a URL. The target group typically represents a service in a customer’s architecture.</li> 
</ul> </li> 
<li> Container support<p></p> 
<li> Provides the ability to load-balance across multiple ports on the same <a href="https://aws.amazon.com/ec2/">Amazon EC2</a> instance. This functionality specifically targets the use of containers and is integrated into <a href="https://aws.amazon.com/ecs/">Amazon ECS</a>.</li> 
</ul> </li> 
<li> Application monitoring<p></p> 
<li> Allows you to monitor and associate health checks per target group.</li> 
</ul> </li> 
<b> Service Segmentation Using Subdomains</b> 
<p> Our customers often need to break big, monolithic applications into smaller service-oriented architectures while hosting this functionality under the same domain name.</p> 
<p> In the example.com architecture shown here, a customer has decided to segment services such as processing orders, serving images, and processing registrations. Each function represents a discrete collection of instances. Each collection of instances host several applications that provide a service.</p> 
<p> <img alt="" src="https://dmhnzl5mp9mj6.cloudfront.net/application-management_awsblog/images/img1.png" style="width: 624px;height: 525px" /></p> 
<p> Using a classic load balancer, the customer has to deploy several load balancers. Each load balancer points to the instances that represent and front the service by using a subdomain.</p> 
<p> With the introduction of content-based routing on the new application load balancers, customers can reduce the number of load balancers required to accomplish the segmentation.</p> 
<p> Application Load Balancers introduce the concept of rules, targets, and target groups. Rules determine how to route requests. Each rule specifies a target group, a condition, and a priority. An action is taken when the conditions on a rule are matched. Targets are endpoints that can be registered as a member of a target group. Target groups are used to route requests to registered targets as part of the action for a rule. Each target group specifies a protocol and target port. You can define health checks per target group and you can route to multiple target groups from each Application Load Balancer.</p> 
<p> A new architecture shown here accomplishes with a single load balancer what previously required three. Here we’ve configured a single Application Load Balancer with three rules.</p> 
<p> <img alt="" src="https://dmhnzl5mp9mj6.cloudfront.net/application-management_awsblog/images/img2.png" style="width: 624px;height: 516px" /></p> 
<p> Let’s walk through the first rule in depth. To configure the Application Load Balancer to route traffic destined to <a href="http://www.example.com/orders/">www.example.com/orders/</a>, we must complete five tasks.</p> 
<ol> 
<li> Create the Application Load Balancer.</li> 
<li> Create a target group.</li> 
<li> Register targets with the target group.</li> 
<li> Create a listener with the default rule that forwards requests to the default target group.</li> 
<li> Create a listener that forwards requests to the previously created target group.</li> 
</ol> 
<p> To create the Application Load Balancer, we must provide a name for it and a minimum of two subnets.</p> 
<p style="margin-left:.5in"> <span style="font-family:courier new,courier,monospace">aws elbv2 create-load-balancer –name example-loadbalancer –subnets &quot;subnet-9de127c4&quot; &quot;subnet-0b1afc20&quot;</span></p> 
<p> To create a target group, we must specify a name, protocol, port, and vpc-id. Based on the preceding figure, we execute the following command to create a target group for the instances that represent the order-processing functionality.</p> 
<p> <span style="font-family:courier new,courier,monospace">aws elbv2 create-target-group –name order-instances –protocol HTTP –port 80 –vpc vpc-85a268e0</span></p> 
<p> After the target group has been created, we can either add instances manually or through the use of an Auto Scaling group. To add an Auto Scaling group, we use the Auto Scaling group name and the generated target group ARN:</p> 
<p> <span style="font-family:courier new,courier,monospace">aws autoscaling attach-load-balancer-target-groups –auto-scaling-group-name order_autoscaling_group –target-group-arns &quot;arn:aws:elasticloadbalancing:us-west-2:007038732177:targetgroup/order-instances/f249f89ef5899de1&quot;</span></p> 
<p> If we want to manually add instances, we would supply a list of instances and the generated target group ARN to register the instances associated with the order-processing functionality:</p> 
<p> <span style="font-family:courier new,courier,monospace">aws elbv2 register-targets –target-group-arn &quot;arn:aws:elasticloadbalancing:us-west-2:007038732177:targetgroup/order-instances/f249f89ef5899de1&quot; –targets Id=i-01cb16f914ec4714c,Port=80</span></p> 
<p> After the instances have been registered with the target group, we create a listener with a default rule that forwards requests to the first target group. For the sake of this example, we’ll assume that the orders target group is the default group:</p> 
<p style="margin-left:.5in"> <span style="font-family:courier new,courier,monospace">aws elb create-listener –load-balancer-arn &quot;arn:aws:elasticloadbalancing:us-west-2:007038732177:targetgroup/order-instances/f249f89ef5899de1&quot; &nbsp;–protocol HTTP –port 80 –default-actions Type=forward,TargetGroupArn=&quot;arn:aws:elasticloadbalancing:us-east-1:007038732177:targetgroup/orders-instances/e53f8f9dfaf230c8&quot;</span></p> 
<p> Finally, we create a rule that forwards a request to the target group to which the order instances are registered when the condition of a path-pattern (in this case, ‘/orders/*’) is met:</p> 
<p> <span style="font-family:courier new,courier,monospace">aws elbv2 create-rule –listener-arn &quot;arn:aws:elasticloadbalancing:us-west-2:007038732177:listener/app/example-loadbalancer/6bfa6ad4a2dd7925/6f916335439e2735&quot; –conditions Field=path-pattern,Values=’/orders/*’ –priority 20 –actions Type=forward,TargetGroupArn=&quot;arn:aws:elasticloadbalancing:us-west-2:007038732177:targetgroup/order-instances/f249f89ef5899de1&quot;</span></p> 
<p> We repeat this process (with the exception of creating the default listener) for the images and registration functionality.</p> 
<p> With this new architecture, we can move away from segmenting functionality based on subdomains and rely on paths. In this way, we preserve the use of a single subdomain, www, throughout the entire user experience. This approach reduces the number of Elastic Load Balancing load balancers required, which results in costs savings. It also reduces the operational overheard required for monitoring and maintaining additional elements in the application architecture.</p> 
<p> <strong>Important</strong> The move from subdomain segmentation to path segmentation requires you to rewrite code to accommodate the new URLs.</p> 
<b> Service Segmentation Using a Proxy Layer</b> 
<p> A proxy layer pattern is used when customers want to use a single subdomain, such as www, while still segmenting functionality by grouping back-end servers. The following figure shows a common implementation of this pattern using the popular open source package NGINX.</p> 
<p> In this implementation, the subdomain of <a href="http://www.example.com/">www.example.com</a> is associated with a top-level external load balancer. This load balancer is configured so that traffic is distributed to a group of instances running NGINX. Each instance running NGINX is configured with rules that direct traffic to one of the three internal load balancers based on the path in the URL.</p> 
<p> <img alt="" src="https://dmhnzl5mp9mj6.cloudfront.net/application-management_awsblog/images/img3.png" style="width: 624px;height: 526px" /></p> 
<p> For example, when a user browses to <a href="http://www.example.com/amazingbrand/">www.example.com/amazingbrand/</a>, the external Elastic Load Balancing load balancer sends all traffic to the NGINX layer. All three of the NGINX installations are configured in the same way. When one of the NGINX instances receives the request, it parses the URL, matches a location for “/amazing”, and sends traffic to the server represented by the internal load balancer fronting the group of servers providing the Amazing Brand functionality.</p> 
<p> It’s important to consider the impact of failed health checks. Should one of the NGINX instances fail health checks generated by the external load balancer, this load balancer will stop sending traffic to that newly marked unhealthy host. In this scenario, all of the discrete groups of functionality would be affected, making troubleshooting and maintenance more complex.</p> 
<p> The following figure shows how customers can achieve segmentation while preserving a single subdomain without having to deploy a proxy layer.</p> 
<p> <img alt="" src="https://dmhnzl5mp9mj6.cloudfront.net/application-management_awsblog/images/img4.png" style="width: 624px;height: 385px" /></p> 
<p> In this implementation, both the proxy layer and the internal load balancers can be removed now that we can use the content-based routing associated with the new application load balancers. Using the previously demonstrated rules functionality, we can create three rules that point to different target groups based on different path conditions.</p> 
<p> For this implementation, you’ll need to create the application load balancer, create a target group, register targets to the target group, create the listener, and create the rules.</p> 
<p> 1. Create the application load balancer.</p> 
<p> <span style="font-family:courier new,courier,monospace">aws elbv2 create-load-balancer –name example2-loadbalancer –subnets &quot;subnet-fc02b18b&quot; &quot;subnet-63029106&quot;</span></p> 
<p> 2. Create three target groups.</p> 
<p> <span style="font-family:courier new,courier,monospace">aws elbv2 create-target-group –name amazing-instances –protocol HTTP –port 80 –vpc vpc-85a268e0</span></p> 
<p> <span style="font-family:courier new,courier,monospace">aws elbv2 create-target-group –name stellar-instances –protocol HTTP –port 80 –vpc vpc-85a268e0</span></p> 
<p> <span style="font-family:courier new,courier,monospace">aws elbv2 create-target-group –name awesome-instances –protocol HTTP –port 80 –vpc vpc-85a268e0</span></p> 
<p> 3. Register targets with each target group.</p> 
<p> <span style="font-family:courier new,courier,monospace">aws elbv2 register-targets –target-group-arn &quot;arn:aws:elasticloadbalancing:us-west-2:007038732177:targetgroup/amazing-instances/ad4a2174e7cc314c&quot; –targets Id=i-072db711f70c36961,Port=80</span></p> 
<p> <span style="font-family:courier new,courier,monospace">aws elbv2 register-targets –target-group-arn &quot;arn:aws:elasticloadbalancing:us-west-2:007038732177:targetgroup/stellar-instances/ef828b873624ba7a&quot; –targets Id=i-08def6cbea7584481,Port=80</span></p> 
<p> <span style="font-family:courier new,courier,monospace">aws elbv2 register-targets –target-group-arn &quot;arn:aws:elasticloadbalancing:us-west-2:007038732177:targetgroup/awesome-instances/116b2df4cd7fcc5c&quot; –targets Id=i-0b9dba5b06321e6fe,Port=80</span></p> 
<p> 4. Create a listener with the default rule that forwards requests to the default target group.</p> 
<p> <span style="font-family:courier new,courier,monospace">aws elbv2 create-listener –load-balancer-arn &quot;arn:aws:elasticloadbalancing:us-west-2:007038732177:loadbalancer/app/example2-loadbalancer/a685c68b17dfd091&quot; –protocol HTTP –port 80 –default-actions Type=forward,TargetGroupArn=&quot;arn:aws:elasticloadbalancing:us-west-2:007038732177:targetgroup/amazing-instances/ad4a2174e7cc314c&quot;</span></p> 
<p> 5. &nbsp;Create a listener that forwards requests for each path to each target group. You need to make sure that every priority is unique.</p> 
<p style="margin-left:.5in"> <span style="font-family:courier new,courier,monospace">aws elbv2 create-rule –listener-arn &quot;arn:aws:elasticloadbalancing:us-west-2:007038732177:listener/app/example2-loadbalancer/a685c68b17dfd091/546af7daf3bd913e&quot; –conditions Field=path-pattern,Values=’/amazingbrand/*’ –priority 20 –actions Type=forward,TargetGroupArn=&quot;arn:aws:elasticloadbalancing:us-west-2:007038732177:targetgroup/amazing-instances/ad4a2174e7cc314c&quot;</span></p> 
<p style="margin-left:.5in"> &nbsp;</p> 
<p style="margin-left:.5in"> <span style="font-family:courier new,courier,monospace">aws elbv2 create-rule –listener-arn &quot;arn:aws:elasticloadbalancing:us-west-2:007038732177:listener/app/example2-loadbalancer/a685c68b17dfd091/546af7daf3bd913e&quot; –conditions Field=path-pattern,Values=’/stellarbrand/*’ –priority 40 –actions Type=forward,TargetGroupArn=&quot;arn:aws:elasticloadbalancing:us-west-2:007038732177:targetgroup/stellar-instances/ef828b873624ba7a&quot;</span></p> 
<p style="margin-left:.5in"> &nbsp;</p> 
<p style="margin-left:.5in"> <span style="font-family:courier new,courier,monospace">aws elbv2 create-rule –listener-arn &quot;arn:aws:elasticloadbalancing:us-west-2:007038732177:listener/app/example2-loadbalancer/a685c68b17dfd091/546af7daf3bd913e&quot; –conditions Field=path-pattern,Values=’/awesomebrand/*’ –priority 60 –actions Type=forward,TargetGroupArn=&quot;arn:aws:elasticloadbalancing:us-west-2:007038732177:targetgroup/awesome-instances/116b2df4cd7fcc5c&quot;</span></p> 
<p> This implementation not only saves you the costs associated with running instances that support a proxy layer and an additional layer of load balancers. It also increases robustness as a result of application monitoring. In the Classic Load Balancer implementation of a proxy pattern, the failure of a single instance hosting NGINX impacts all of the other discrete functionality represented by the grouping of instances. In the application load balancer implementation, health checks are now associated with a single target group only. Failures and performance are now segmented from each other.</p> 
<p> Run the following command to verify the health of the registered targets in the Amazing Brands target group:</p> 
<p> <span style="font-family:courier new,courier,monospace">aws elbv2 describe-target-health –target-group-arn &quot;arn:aws:elasticloadbalancing:us-west-2:007038732177:targetgroup/amazing-instances/ad4a2174e7cc314c&quot;</span></p> 
<p> If the instances in this target group were marked as unhealthy, you would see the following output:</p> 
<p> <span style="font-family:courier new,courier,monospace">{</span></p> 
<p> <span style="font-family:courier new,courier,monospace">&nbsp;&nbsp;&nbsp; &quot;TargetHealthDescriptions&quot;: [</span></p> 
<p> <span style="font-family:courier new,courier,monospace">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; {</span></p> 
<p> <span style="font-family:courier new,courier,monospace">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;HealthCheckPort&quot;: &quot;80&quot;,</span></p> 
<p> <span style="font-family:courier new,courier,monospace">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;Target&quot;: {</span></p> 
<p> <span style="font-family:courier new,courier,monospace">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;Id&quot;: &quot;i-072db711f70c36961&quot;,</span></p> 
<p> <span style="font-family:courier new,courier,monospace">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;Port&quot;: 80</span></p> 
<p> <span style="font-family:courier new,courier,monospace">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; },</span></p> 
<p> <span style="font-family:courier new,courier,monospace">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;TargetHealth&quot;: {</span></p> 
<p> <span style="font-family:courier new,courier,monospace">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;State&quot;: &quot;unhealthy&quot;,</span></p> 
<p> <span style="font-family:courier new,courier,monospace">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;Reason&quot;: &quot;Target.Timeout&quot;,</span></p> 
<p> <span style="font-family:courier new,courier,monospace">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;Description&quot;: &quot;Request timed out&quot;</span></p> 
<p> <span style="font-family:courier new,courier,monospace">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }</span></p> 
<p> <span style="font-family:courier new,courier,monospace">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }</span></p> 
<p> <span style="font-family:courier new,courier,monospace">&nbsp;&nbsp;&nbsp; ]</span></p> 
<p> <span style="font-family:courier new,courier,monospace">}</span></p> 
<b> Service Segmentation Using Containers</b> 
<p> Increasingly, customers are using containers as a way to package and isolate applications. Instead of grouping functionality by instances, customers are providing an even more granular collection of computing resources by using containers.</p> 
<p> When you use Classic load balancers, you create a fixed relationship between the load balancer port and the container instance port. For example, it is possible to map the load balancer port 80 to the container instance port 3030 and the load balancer port 4040 to the container instance port 4040. However, it is not possible to map the load balancer port 80 to port 3030 on one container instance and port 4040 on another container instance.</p> 
<p> The following figure illustrates this limitation. It also points out a pattern of using a proxy container to represent other containers operating on different ports. Logically, this implementation is similar to the proxy segmentation implementation described earlier.</p> 
<p> <img alt="" src="https://dmhnzl5mp9mj6.cloudfront.net/application-management_awsblog/images/img5.png" style="width: 624px;height: 413px" /></p> 
<p> <em>Figure 5 Classic load balancer container based segmentation</em></p> 
<p> Enhanced container support is one of the major features of the Application Load Balancer. It makes it possible to load-balance across multiple ports on the same EC2 instance. The following figure shows how this capability removes the need to run containers that proxy access to other containers.</p> 
<p> <img alt="" src="https://dmhnzl5mp9mj6.cloudfront.net/application-management_awsblog/images/img6.png" style="width: 624px;height: 586px" /></p> 
<p> To integrate containers, you only need to register the targets in the target group, which the Amazon ECS scheduler handles automatically. The following command configures /cart as illustrated in the preceding figure.</p> 
<p> <span style="font-family:courier new,courier,monospace">aws elbv2 register-targets –-target-group-arn &quot;arn:aws:elasticloadbalancing:us-west-2:007038732177:targetgroup/cart-instances/ad4a2174e7cc314c&quot; –-targets Id=i-84ri3a2c6dcd16b9c,Port=90 Id=i-83fc3a2c6dcd16b9c,Port=90 Id=i-qy342a2c6dcd16b9c,Port=100</span></p> 
<b> A/B Testing</b> 
<p> A/B testing is a term used for randomized experiments of two separate website experiences to test and gather data that will be helpful in decision-making. To facilitate this type of testing, you need to redirect a percentage of traffic to the secondary stack.</p> 
<p> By using Classic Load Balancers, you can conduct these experiments by grouping the different experiences under separate load balancers. By using <a href="https://aws.amazon.com/route53/">Amazon Route 53</a>, you can then leverage a group of weighted resource record sets that point to the CNAMEs provided by the Classic Load Balancer. By modifying the weight of a given record, you can then move a random sampling of customers to a different website experience represented by the instances behind the Classic Load Balancer.</p> 
<p> <img alt="" src="https://dmhnzl5mp9mj6.cloudfront.net/application-management_awsblog/images/img7.png" style="width: 624px;height: 547px" /></p> 
<p> The introduction of the application load balancer optimizes A/B testing in a couple of ways. In the following figure, you can see the same grouping of instances that represent the two different website experiences (the A and the B experience shown in the preceding figure). The major differences here are one less load balancer, which reduces costs and configuration, and a new mechanism, rules, to control the switch from the A to the B experience. In this configuration, the logic for redirecting a percentage of traffic must be done at the application level, not the DNS level, by rewriting URLs that point to the B stack instead of the default A stack. The benefits of this approach are that specific users are targeted based on criteria that the application is aware of (random users, geographies, users’ history or preferences). There is also no need to rely on DNS for redirecting some traffic, so the control of who is directed to stack B is much more fine-grained. This mechanism also allows for a more immediate transitioning of users from the A to the B experience because there is no delay associated with DNS records having to be flushed for user cache.</p> 
<p> <img alt="" src="https://dmhnzl5mp9mj6.cloudfront.net/application-management_awsblog/images/img8.png" style="width: 624px;height: 533px" /></p> 
<b> Conclusion</b> 
<p> The launch of the application load balancer provides significant optimization in segmentation techniques and A/B testing. These two use cases represent only a subset, but they illustrate how you can leverage the new features associated with this launch. Feel free to leave your feedback in the comments.</p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/devops/tag/application-load-balancer/" rel="tag">application load balancer</a></span> 
</footer> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-15');
});
</script> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">Building a Microsoft BackOffice Server Solution on AWS with AWS CloudFormation</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Bill Jacobi</span></span> | on 
<time property="datePublished" datetime="2016-08-18T01:26:52+00:00">18 AUG 2016</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/devops/category/how-to/" title="View all posts in How-To*"><span property="articleSection">How-To*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/devops/building-a-microsoft-backoffice-server-solution-on-aws-with-aws-cloudformation/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-16" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-devops-blog&amp;disqus_identifier=16&amp;disqus_title=Building+a+Microsoft+BackOffice+Server+Solution+on+AWS+with+AWS+CloudFormation&amp;disqus_url=https://aws.amazon.com/blogs/devops/building-a-microsoft-backoffice-server-solution-on-aws-with-aws-cloudformation/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-16');
});
</script> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p> Last month, AWS released the <a href="http://docs.aws.amazon.com/quickstart/latest/accelerator-msservers/welcome.html">AWS Enterprise Accelerator: Microsoft Servers on the AWS Cloud</a> along with a <a href="https://s3.amazonaws.com/quickstart-reference/enterprise-accelerator/msservers/latest/doc/microsoft-servers-on-the-aws-cloud.pdf">deployment guide</a> and <a href="https://s3.amazonaws.com/quickstart-reference/enterprise-accelerator/msservers/latest/templates/msservers-master.template">CloudFormation template</a>. This blog post will explain how to deploy complex Windows workloads and how <a href="https://aws.amazon.com/cloudformation/">AWS CloudFormation</a> solves the problems related to server dependencies.</p> 
<p> This AWS Enterprise Accelerator solution deploys the four most requested Microsoft servers ─ SQL Server, Exchange Server, Lync Server, and SharePoint Server ─ in a highly available, multi-AZ architecture on AWS. It includes Active Directory Domain Services as the foundation. By following the steps in the solution, you can take advantage of the email, collaboration, communications, and directory features provided by these servers on the AWS IaaS platform. &nbsp;</p> 
<p> There are a number of dependencies between the servers in this solution, including:</p> 
<li> Active Directory</li> 
<li> Internet access</li> 
<li> Dependencies within server clusters, such as needing to create the first server instance before adding additional servers to the cluster.</li> 
<li> Dependencies on AWS infrastructure, such as sharing a common VPC, NAT gateway, Internet gateway, DNS, routes, and so on.</li> 
<p> The infrastructure and servers are built in three logical layers. The Master template orchestrates the stack builds with one stack per Microsoft server and manages inter-stack dependencies. Each of the CloudFormation stacks uses PowerShell to stand up the Microsoft servers at the OS level. Before it configures the OS, CloudFormation configures the AWS infrastructure required by each Windows server. Together, CloudFormation and PowerShell create a quick, repeatable deployment pattern for the servers. The solution supports 10,000 users. Its modularity at both the infrastructure and application level enables larger user counts.</p> 
<p> <img alt="MSServers Solution - 6 CloudFormation Stacks" src="https://dmhnzl5mp9mj6.cloudfront.net/application-management_awsblog/images/MSServers%20Solution%20Stack.png" style="width: 624px;height: 262px;float: left" /></p> 
<b> Managing Stack Dependencies</b> 
<p> To explain how we enabled the dependencies between the stacks, the SQLStack is dependent on ADStack since SQL Server is dependent on Active Directory; and, similarly, SharePointStack is dependent on SQLStack, both as required by Microsoft. Lync is dependendent on Exchange since both servers must extend the AD schema independently. In Master, these server dependencies are coded in CloudFormation as follows:</p> 
<p> <span style="font-family:monospace">&quot;<span style="color:#008000">Resources</span>&quot;: {<br /> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;<span style="color:#008000">ADStack</span>&quot;: …AWS::CloudFormation::Stack…<br /> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;<span style="color:#ff0000">SQLStack</span>&quot;: {<br /> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;<span style="color:#008000">Type</span>&quot;: &quot;<span style="color:#0000ff">AWS::CloudFormation::Stack</span>&quot;,<br /> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;<span style="color:#ff0000">DependsOn</span>&quot;: &quot;<span style="color:#0000ff">ADStack</span>&quot;,</span><br /> <span style="font-family: monospace">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&quot;</span><span>Properties</span><span style="font-family: monospace">&quot;: …</span><br /> <span style="font-family: monospace">&nbsp; &nbsp; &nbsp; &nbsp;}</span><br /> and<br /> <span style="font-family: monospace">&quot;</span><span>Resources</span><span style="font-family: monospace">&quot;: {</span><br /> <span style="font-family: monospace">&nbsp; &nbsp; &nbsp; &nbsp;&quot;</span><span>ADStack</span><span style="font-family: monospace">&quot;: …AWS::CloudFormation::Stack…</span><br /> <span style="font-family: monospace">&nbsp; &nbsp; &nbsp; &nbsp;&quot;</span><span>SQLStack</span><span style="font-family: monospace">&quot;: {</span><br /> <span style="font-family: monospace">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&quot;</span><span>Type</span><span style="font-family: monospace">&quot;: &quot;</span><span>AWS::CloudFormation::Stack</span><span style="font-family: monospace">&quot;,</span><br /> <span style="font-family: monospace">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&quot;</span><span>DependsOn</span><span style="font-family: monospace">&quot;: &quot;</span><span>ADStack</span><span style="font-family: monospace">&quot;,</span><br /> <span style="font-family: monospace">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&quot;</span><span>Properties</span><span style="font-family: monospace">&quot;: …</span><br /> <span style="font-family: monospace">&nbsp; &nbsp; &nbsp; &nbsp;},</span><br /> <span style="font-family: monospace">&nbsp; &nbsp; &nbsp; &nbsp;&quot;</span><span style="color:#ff0000"><span style="font-family: monospace">SharePointStack</span></span><span style="font-family: monospace">&quot;: {</span><br /> <span style="font-family: monospace">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;</span><span>Type</span><span style="font-family: monospace">&quot;: &quot;<span style="color:#0000ff">A</span></span><span style="color:#0000ff"><span style="font-family: monospace">W</span></span><span>S::CloudFormation::Stack</span><span style="font-family: monospace">&quot;,</span><br /> <span style="font-family: monospace">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;</span><span style="color:#ff0000"><span style="font-family: monospace">DependsOn</span></span><span style="font-family: monospace">&quot;: &quot;</span><span>SQLStack</span><span style="font-family: monospace">&quot;,</span><br /> <span style="font-family: monospace">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;</span><span>Properties</span><span style="font-family: monospace">&quot;: …</span><br /> <span style="font-family: monospace">&nbsp; &nbsp; &nbsp; &nbsp;}</span></p> 
<p> The “DependsOn” statements in the stack definitions forces the order of stack execution to match the diagram. Lower layers are executed and successfully completed before the upper layers. If you do not use “DependsOn”, CloudFormation will execute your stacks in parallel. An example of parallel execution is what happens after ADStack returns SUCCESS. The two higher-level stacks, SQLStack and ExchangeStack, are executed in parallel at the next level (layer 2). &nbsp;SharePoint and Lync are executed in parallel at layer 3. The arrows in the diagram indicate stack dependencies.</p> 
<b> Passing Parameters Between Stacks</b> 
<p> If you have concerns about how to pass infrastructure parameters between the stack layers, let’s use an example in which we want to pass the same VPCCIDR to all of the stacks in the solution. VPCCIDR is defined as a parameter in Master as follows:</p> 
<p> <span style="font-family:monospace">&quot;<span style="color:#008000">VPCCIDR</span>&quot;: {</span><br /> <span style="font-family: monospace">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;</span><span>AllowedPattern</span><span style="font-family: monospace">&quot;: &quot;</span><span>[a-zA-Z0-9]+\..+</span><span style="font-family: monospace">&quot;,</span><br /> <span style="font-family: monospace">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;</span><span>Default</span><span style="font-family: monospace">&quot;: &quot;</span><span>10.0.0.0/16</span><span style="font-family: monospace">&quot;,</span><br /> <span style="font-family: monospace">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;</span><span>Description</span><span style="font-family: monospace">&quot;: &quot;</span><span>CIDR Block for the VPC</span><span style="font-family: monospace">&quot;,</span><br /> <span style="font-family: monospace">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;</span><span>Type</span><span style="font-family: monospace">&quot;: &quot;</span><span>String</span><span style="font-family: monospace">&quot;</span><br /> <span style="font-family: monospace">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;}</span></p> 
<p> By defining VPCCIDR in Master and soliciting user input for this value, this value is then <em>passed</em> to ADStack by the use of an identically named and typed parameter between Master and the stack being called.</p> 
<p> <span style="font-family:monospace">&quot;<span style="color:#008000">VPCCIDR</span>&quot;: {</span><br /> <span style="font-family: monospace">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;</span><span>Description</span><span style="font-family: monospace">&quot;: &quot;</span><span>CIDR Block for the VPC</span><span style="font-family: monospace">&quot;,</span><br /> <span style="font-family: monospace">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;</span><span>Type</span><span style="font-family: monospace">&quot;: &quot;</span><span>String</span><span style="font-family: monospace">&quot;,</span><br /> <span style="font-family: monospace">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;</span><span>Default</span><span style="font-family: monospace">&quot;: &quot;</span><span>10.0.0.0/16</span><span style="font-family: monospace">&quot;,</span><br /> <span style="font-family: monospace">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;</span><span>AllowedPattern</span><span style="font-family: monospace">&quot;: &quot;</span><span>[a-zA-Z0-9]+\..+</span><span style="font-family: monospace">&quot;</span><br /> <span style="font-family: monospace">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;}</span></p> 
<p> After Master defines VPCCIDR, ADStack can use “Ref”: “VPCCIDR” in any resource (such as the security group, <em>DomainController1SG</em>) that needs the VPC CIDR range of the first domain controller. Instead of passing commonly-named parameters between stacks, another option is to pass outputs from one stack as inputs to the next. For example, if you want to pass VPCID between two stacks, you could accomplish this as follows. Create an output like VPCID in the first stack:</p> 
<p> <span style="font-family:monospace">“<span style="color:#008000">Outputs</span>”&nbsp; : {<br /> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; “<span style="color:#008000">VPCID</span>” : {<br /> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; “<span style="color:#008000">Value</span>” : “ {<span style="color:#008000">“Ref”</span> : <span style="color:#0000ff">“VPC”</span>},<br /> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; “<span style="color:#008000">Description</span>” : <span style="color:#0000ff">“VPC ID”</span><br /> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }, …<br /> }</span></p> 
<p> In the second stack, create a parameter with the same name and type:</p> 
<p> <span style="font-family:monospace">“<span style="color:#008000">Parameters</span>” : {</span><br /> <span style="font-family: monospace">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;“</span><span>VPCID</span><span style="font-family: monospace">” : {</span><br /> <span style="font-family: monospace">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; “</span><span>Type</span><span style="font-family: monospace">” : “</span><span>AWS::EC2::VPC::Id</span><span style="font-family: monospace">”,</span><br /> <span style="font-family: monospace">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;}, …</span><br /> <span style="font-family: monospace">}</span></p> 
<p> When the first template calls the second template, VPCID is passed as an output of the first template to become an input (parameter) to the second.</p> 
<b> Managing Dependencies Between Resources Inside a Stack</b> 
<p> All of the dependencies so far have been between stacks. Another type of dependency is one between resources within a stack. In the Microsoft servers case, an example of an intra-stack dependency is the need to create the first domain controller, DC1, before creating the second domain controller, DC2.</p> 
<p> DC1, like many cluster servers, must be fully created first so that it can replicate common state (domain objects) to DC2.&nbsp; In the case of the Microsoft servers in this solution, all of the servers require that a single server (such as DC1 or Excb) must be fully created to define the cluster or farm configuration used on subsequent servers.</p> 
<p> Here’s another intra-stack dependency example: The Microsoft servers must fully configure the Microsoft software on the <a href="https://aws.amazon.com/ec2/">Amazon EC2</a> instances before those instances can be used. So there is a dependency on software completion within the stack after successful creation of the instance, before the rest of stack execution (such as deploying subsequent servers) can continue. These intra-stack dependencies like “software is fully installed” are managed through the use of <em>wait conditions</em>. Wait conditions are CloudFormation resources just like EC2 instances and allow the “DependsOn” attribute mentioned earlier to manage dependencies inside a stack. For example, to pause the creation of DC2 until DC1 is complete, we configured the following “DependsOn” attribute using a wait condition. See (1) in the following diagram:</p> 
<p> <span style="font-family:monospace">&quot;<span style="color:#008000">DomainController1</span>&quot;: {</span><br /> <span style="font-family: monospace">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;</span><span>Type</span><span style="font-family: monospace">&quot;: &quot;AWS::EC2::Instance&quot;,</span><br /> <span style="font-family: monospace">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;</span><span>DependsOn</span><span style="font-family: monospace">&quot;: &quot;NATGateway1&quot;,</span><br /> <span style="font-family: monospace">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;</span><span>Metadata</span><span style="font-family: monospace">&quot;: {</span><br /> <span style="font-family: monospace">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</span><span>&quot;AWS::CloudFormation::Init&quot;</span><span style="font-family: monospace">: {</span><br /> <span style="font-family: monospace">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;</span><span>configSets</span><span style="font-family: monospace">&quot;: {</span><br /> <span style="font-family: monospace">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;</span><span>config</span><span style="font-family: monospace">&quot;: [</span><br /> <span style="font-family: monospace">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;</span><span>setup</span><span style="font-family: monospace">&quot;,</span><br /> <span style="font-family: monospace">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;</span><span>rename</span><span style="font-family: monospace">&quot;,</span><br /> <span style="font-family: monospace">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;</span><span>installADDS</span><span style="font-family: monospace">&quot;,</span><br /> <span style="font-family: monospace">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;</span><span>configureSites</span><span style="font-family: monospace">&quot;,</span><br /> <span style="font-family: monospace">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;</span><span>installADCS</span><span style="font-family: monospace">&quot;,</span><br /> <span style="font-family: monospace">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;</span><span>finalize</span><span style="font-family: monospace">&quot;</span><br /> <span style="font-family: monospace">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ]</span><br /> <span style="font-family: monospace">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }, …</span><br /> <span style="font-family: monospace">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;},</span><br /> <span style="font-family: monospace">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&quot;</span><span>Properties</span><span style="font-family: monospace">&quot; : …</span><br /> <span style="font-family: monospace">},</span><br /> <span style="font-family: monospace">&quot;</span><span style="color:#ff0000"><span style="font-family: monospace">DomainController2</span></span><span style="font-family: monospace">&quot;: {</span><br /> <span style="font-family: monospace">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&quot;</span><span>Type</span><span style="font-family: monospace">&quot;: &quot;</span><span>AWS::EC2::Instance</span><span style="font-family: monospace">&quot;,</span><br /> <span>[1]</span><span style="font-family: monospace">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;</span><span style="color:#ff0000"><span style="font-family: monospace">DependsOn</span></span><span style="font-family: monospace">&quot;: &quot;</span><span>DomainController1WaitCondition</span><span style="font-family: monospace">&quot;,</span><br /> <span style="font-family: monospace">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&quot;</span><span>Metadata</span><span style="font-family: monospace">&quot;: …,</span><br /> <span style="font-family: monospace">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&quot;</span><span>Properties</span><span style="font-family: monospace">&quot; : …</span><br /> <span style="font-family: monospace">},</span></p> 
<p> <span style="font-family:monospace">The WaitCondition (2) uses on a CloudFormation resource called a WaitConditionHandle (3), which receives a SUCCESS or FAILURE signal from the creation of the first domain controller:</span></p> 
<p> <span style="font-family:monospace">&quot;<span style="color:#ff0000">DomainController1WaitCondition</span>&quot;: {</span><br /> <span style="font-family: monospace">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;</span><span>Type</span><span style="font-family: monospace">&quot;: &quot;</span><span>AWS::CloudFormation::WaitCondition</span><span style="font-family: monospace">&quot;,</span><br /> <span style="font-family: monospace">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;</span><span style="color:#ff0000"><span style="font-family: monospace">DependsOn</span></span><span style="font-family: monospace">&quot;: &quot;</span><span>DomainController1</span><span style="font-family: monospace">&quot;,</span><br /> <span style="font-family: monospace">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;</span><span>Properties</span><span style="font-family: monospace">&quot;: {</span><br /> <span style="font-family: monospace">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;</span><span>Handle</span><span style="font-family: monospace">&quot;: {</span><br /> <span>[2] </span><span style="font-family: monospace">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&quot;</span><span style="color:#008000"><span style="font-family: monospace">Ref</span></span><span style="font-family: monospace">&quot;: &quot;</span><span>DomainController1WaitHandle</span><span style="font-family: monospace">&quot;</span><br /> <span style="font-family: monospace">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; },</span><br /> <span style="font-family: monospace">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;</span><span>Timeout</span><span style="font-family: monospace">&quot;: &quot;</span><span>3600</span><span style="font-family: monospace">&quot;</span><br /> <span style="font-family: monospace">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }</span><br /> <span style="font-family: monospace">&nbsp; &nbsp; &nbsp;</span><span style="font-family: monospace">},</span><br /> <span style="font-family: monospace">&nbsp; &nbsp; &nbsp;&quot;</span><span>DomainController1WaitHandle</span><span style="font-family: monospace">&quot;: {</span><br /> <span>[3] &nbsp;</span><span style="font-family: monospace"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&quot;</span><span>Type</span><span style="font-family: monospace">&quot;: &quot;</span><span>AWS::CloudFormation::WaitConditionHandle</span><span style="font-family: monospace">&quot;</span><br /> <span style="font-family: monospace">&nbsp; &nbsp; &nbsp;}</span></p> 
<p> SUCCESS is signaled in (4) by cfn-signal.exe –exit-code 0 during the “finalize” step of DC1, which enables CloudFormation to execute DC2 as an EC2 resource via the wait condition.</p> 
<p> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;<span style="color:#008000">finalize</span>&quot;: {<br /> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&quot;<span>commands</span>&quot;: {<br /> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&quot;<span>a-signal-success</span>&quot;: {<br /> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&quot;<span>command</span>&quot;: {<br /> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&quot;<span>Fn::Join</span>&quot;: [<br /> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&quot;&quot;,<br /> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;[<br /> <span>[4] </span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&quot;<span>cfn-signal.exe -e 0 &quot;&quot;</span>,<br /> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;{<br /> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&quot;<span style="color:#008000">Ref</span>&quot;: &quot;<span>DomainController1WaitHandle</span>&quot;</p> 
<p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;},<br /> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&quot;&quot;&quot;<br /> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;]<br /> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;]<br /> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;}<br /> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;}<br /> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;}<br /> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;}<br /> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;}</p> 
<p> If the timeout had been reached in step (2), this would have automatically signaled a FAILURE and stopped stack execution of ADStack and the Master stack.</p> 
<p> As we have seen in this blog post, you can create both nested stacks and nested dependencies and can pass parameters between stacks by passing standard parameters or by passing outputs. Inside a stack, you can configure resources that are dependent on other resources through the use of wait conditions and the cfn-signal infrastructure. The AWS Enterprise Accelerator solution uses both techniques to deploy multiple Microsoft servers in a single VPC for a Microsoft BackOffice solution on AWS. &nbsp;</p> 
<p> In a future blog post, we will illustrate how PowerShell can be used to bootstrap and configure Windows instances with downloaded cmdlets, all integrated into CloudFormation stacks.</p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/devops/tag/automation/" rel="tag">Automation</a>, <a href="https://aws.amazon.com/blogs/devops/tag/best-practices/" rel="tag">Best practices</a>, <a href="https://aws.amazon.com/blogs/devops/tag/cloudformation/" rel="tag">CloudFormation</a>, <a href="https://aws.amazon.com/blogs/devops/tag/dependencies/" rel="tag">Dependencies</a>, <a href="https://aws.amazon.com/blogs/devops/tag/dependson/" rel="tag">DependsOn</a>, <a href="https://aws.amazon.com/blogs/devops/tag/devops/" rel="tag">DevOps</a>, <a href="https://aws.amazon.com/blogs/devops/tag/microsoft/" rel="tag">Microsoft</a>, <a href="https://aws.amazon.com/blogs/devops/tag/new-stuff/" rel="tag">New stuff</a>, <a href="https://aws.amazon.com/blogs/devops/tag/servers/" rel="tag">Servers</a>, <a href="https://aws.amazon.com/blogs/devops/tag/waitcondition/" rel="tag">WaitCondition</a>, <a href="https://aws.amazon.com/blogs/devops/tag/windows/" rel="tag">Windows</a></span> 
</footer> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-16');
});
</script> 
</article> 
<p>
© 2017, Amazon Web Services, Inc. or its affiliates. All rights reserved.
</p>

    </div>
  </div>
</div>


    <div id="footer" class="navigation hidden-print">
      <div class="container">
        <div class="row">
          <div class="col-xs-12">
            <ul class="footer-links nav navbar-nav">
              <li><a href="../aws.html">AWS</a></li>
              <li><a href="../linux.html">Linux</a></li>
              <li><a href="../docker.html">Docker</a></li>
              <li><a href="../ibmpower.html">IBM Power</a></li>
              <li><a href="blogsataws1.html">Blogs@AWS (Kindle Friendly)</a></li>
            </ul>
            <ul class="footer-links nav navbar-nav navbar-right">
              <li><a href="../comments.html">Comments?</a></li>
            </ul>
          </div>
        </div>
      </div>
    </div>
  </body>
</html>
