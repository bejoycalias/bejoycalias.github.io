<!DOCTYPE html>
<html lang="en">
  <head>
<!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-593498H');</script>
<!-- End Google Tag Manager -->

    <meta charset="utf-8">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">

    <meta name="msapplication-config" content="/microsoft-tile.xml" />
    <meta name="theme-color" content="#ffffff">

    <meta property="og:url" content="https://bejoycalias.github.io/blogsataws/apnblogs1.html" />
    <meta property="og:site_name" content="Bejoy's TechNotes"/>
    <meta property="og:title" content="Bejoy's TechNotes - Kindle Friendly AWS APN Blogs" />
    <meta property="og:image" content="https://bejoycalias.github.io/assets/images/og-image.png"/>
    <meta property="og:image:width" content="1200"/>
    <meta property="og:image:height" content="1200"/>
    <meta property="og:description" content="" />

    <title>Bejoy's TechNotes - Kindle Friendly AWS APN Blogs</title>
    <link href="../assets/stylesheets/application-832aa42c.css" rel="stylesheet" />

    <!--[if lt IE 9]>
      <script src="../assets/javascripts/ie-compat-c141a02d.js"></script>
    <![endif]-->
    <script src="../assets/javascripts/application-ff53d307.js"></script>

    <!-- Typekit script to import Klavika font -->
    <script src="https://use.typekit.net/wxf7mfi.js"></script>
    <script>try{Typekit.load({ async: true });}catch(e){}</script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-100043608-1', 'auto');
  ga('send', 'pageview');

</script>

    
  </head>

  <body id="uh-oh-" class="layout-inner page-uh-oh-">
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-593498H"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->


    <div id="header" class="navigation navbar-static-top hidden-print">
      <div class="container">
        <div class="row">
          <div class="col-xs-12">
            <div class="navbar-header">
              <div class="navbar-brand">
                <a href="/">
                  <svg version="1.0" xmlns="http://www.w3.org/2000/svg" width="135.000000pt" height="50" viewbox="0 0 135.000000 45.000000" preserveaspectratio="xMidYMid meet" class="logo">

<g transform="translate(0.000000,45.000000) scale(0.100000,-0.100000)" fill="#000000" stroke="none">
<path class="text" fill="#000000" d="M527 384 c-4 -4 -7 -18 -7 -31 0 -21 4 -24 28 -21 21 2 27 8 27 28 0
18 -6 26 -20 28 -12 2 -24 0 -28 -4z"></path>
<path class="text" fill="#000000" d="M1080 335 c0 -48 2 -55 20 -55 18 0 20 7 20 55 0 48 -2 55 -20 55
-18 0 -20 -7 -20 -55z"></path>
<path class="text" fill="#000000" d="M54 357 c-2 -7 -3 -69 -2 -138 l3 -124 65 -3 c90 -3 130 20 130 77 0
29 -6 44 -20 54 -20 14 -20 15 -3 45 14 25 15 34 5 56 -6 15 -23 31 -38 36
-38 15 -134 13 -140 -3z m110 -33 c19 -7 21 -45 4 -62 -7 -7 -22 -12 -35 -12
-20 0 -23 5 -23 40 0 41 13 50 54 34z m20 -130 c19 -18 19 -20 6 -45 -8 -13
-21 -19 -45 -19 -34 0 -35 1 -35 40 0 38 2 40 29 40 16 0 37 -7 45 -16z"></path>
<path class="text" fill="#000000" d="M319 271 c-23 -24 -29 -38 -29 -74 0 -25 3 -53 6 -62 20 -50 164 -64
164 -15 0 15 -7 17 -45 12 -46 -5 -75 8 -75 34 0 11 16 14 65 14 l65 0 0 35
c0 80 -92 114 -151 56z m99 -33 c3 -15 -4 -18 -37 -18 -43 0 -50 7 -29 28 18
18 62 11 66 -10z"></path>
<path class="text" fill="#000000" d="M520 184 c0 -107 -1 -116 -20 -121 -11 -3 -20 -12 -20 -19 0 -21 76
-19 84 2 3 9 6 69 6 135 l0 119 -25 0 -25 0 0 -116z"></path>
<path class="text" fill="#000000" d="M649 271 c-24 -25 -29 -37 -29 -78 1 -70 34 -103 105 -103 55 0 95
44 95 103 0 60 -7 75 -41 92 -47 25 -96 19 -130 -14z m111 -30 c25 -48 2 -111
-40 -111 -45 0 -69 80 -34 114 21 22 61 20 74 -3z"></path>
<path class="text" fill="#000000" d="M850 287 c0 -8 16 -57 36 -110 28 -76 33 -100 25 -116 -16 -28 -14
-31 18 -31 27 0 29 4 70 123 23 67 41 128 41 135 0 6 -11 12 -24 12 -21 0 -26
-8 -41 -65 -10 -36 -21 -68 -25 -70 -3 -2 -16 27 -29 66 -19 60 -25 69 -47 69
-13 0 -24 -6 -24 -13z"></path>
<path class="text" fill="#000000" d="M1192 284 c-17 -12 -22 -24 -20 -47 2 -26 10 -36 45 -52 49 -23 59
-55 17 -55 -14 0 -34 5 -45 10 -16 9 -19 7 -19 -13 0 -17 7 -27 23 -31 69 -18
117 6 117 60 0 32 -4 37 -45 55 -60 26 -62 54 -4 46 37 -5 40 -3 37 16 -2 18
-11 23 -43 25 -25 2 -49 -3 -63 -14z"></path>
</g>
</svg>

                </a>
              </div>
              <button class="navbar-toggle" type="button">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
              </button>
            </div>
            <div class="buttons hidden-xs">
              <nav class="navigation-links" role="navigation">
                <ul class="main-links nav navbar-nav navbar-right">
                  <li><a href="../aws.html">AWS</a></li>
                  <li><a href="../linux.html">Linux</a></li>
                  <li><a href="../docker.html">Docker</a></li>
                  <li><a href="../ibmpower.html">IBM Power</a></li>
                  <li><a href="blogsataws1.html">Blogs@AWS (Kindle Friendly)</a></li>
                </ul>
              </nav>
            </div>
          </div>
        </div>
      </div>
    </div>

    <div class="sidebar-overlay"></div>

<aside class="sidebar" role="navigation">
  <div class="sidebar-header">
    <svg version="1.0" xmlns="http://www.w3.org/2000/svg" width="135.000000pt" height="42" viewbox="0 0 135.000000 45.000000" preserveaspectratio="xMidYMid meet">

<g transform="translate(0.000000,45.000000) scale(0.100000,-0.100000)" fill="#000000" stroke="none">
<path class="text" fill="#000000" d="M527 384 c-4 -4 -7 -18 -7 -31 0 -21 4 -24 28 -21 21 2 27 8 27 28 0
18 -6 26 -20 28 -12 2 -24 0 -28 -4z"></path>
<path class="text" fill="#000000" d="M1080 335 c0 -48 2 -55 20 -55 18 0 20 7 20 55 0 48 -2 55 -20 55
-18 0 -20 -7 -20 -55z"></path>
<path class="text" fill="#000000" d="M54 357 c-2 -7 -3 -69 -2 -138 l3 -124 65 -3 c90 -3 130 20 130 77 0
29 -6 44 -20 54 -20 14 -20 15 -3 45 14 25 15 34 5 56 -6 15 -23 31 -38 36
-38 15 -134 13 -140 -3z m110 -33 c19 -7 21 -45 4 -62 -7 -7 -22 -12 -35 -12
-20 0 -23 5 -23 40 0 41 13 50 54 34z m20 -130 c19 -18 19 -20 6 -45 -8 -13
-21 -19 -45 -19 -34 0 -35 1 -35 40 0 38 2 40 29 40 16 0 37 -7 45 -16z"></path>
<path class="text" fill="#000000" d="M319 271 c-23 -24 -29 -38 -29 -74 0 -25 3 -53 6 -62 20 -50 164 -64
164 -15 0 15 -7 17 -45 12 -46 -5 -75 8 -75 34 0 11 16 14 65 14 l65 0 0 35
c0 80 -92 114 -151 56z m99 -33 c3 -15 -4 -18 -37 -18 -43 0 -50 7 -29 28 18
18 62 11 66 -10z"></path>
<path class="text" fill="#000000" d="M520 184 c0 -107 -1 -116 -20 -121 -11 -3 -20 -12 -20 -19 0 -21 76
-19 84 2 3 9 6 69 6 135 l0 119 -25 0 -25 0 0 -116z"></path>
<path class="text" fill="#000000" d="M649 271 c-24 -25 -29 -37 -29 -78 1 -70 34 -103 105 -103 55 0 95
44 95 103 0 60 -7 75 -41 92 -47 25 -96 19 -130 -14z m111 -30 c25 -48 2 -111
-40 -111 -45 0 -69 80 -34 114 21 22 61 20 74 -3z"></path>
<path class="text" fill="#000000" d="M850 287 c0 -8 16 -57 36 -110 28 -76 33 -100 25 -116 -16 -28 -14
-31 18 -31 27 0 29 4 70 123 23 67 41 128 41 135 0 6 -11 12 -24 12 -21 0 -26
-8 -41 -65 -10 -36 -21 -68 -25 -70 -3 -2 -16 27 -29 66 -19 60 -25 69 -47 69
-13 0 -24 -6 -24 -13z"></path>
<path class="text" fill="#000000" d="M1192 284 c-17 -12 -22 -24 -20 -47 2 -26 10 -36 45 -52 49 -23 59
-55 17 -55 -14 0 -34 5 -45 10 -16 9 -19 7 -19 -13 0 -17 7 -27 23 -31 69 -18
117 6 117 60 0 32 -4 37 -45 55 -60 26 -62 54 -4 46 37 -5 40 -3 37 16 -2 18
-11 23 -43 25 -25 2 -49 -3 -63 -14z"></path>
</g>
</svg>

  </div>

  <ul class="nav sidebar-nav">
    <li><a href="../aws.html">AWS</a></li>
    <li><a href="../linux.html">Linux</a></li>
    <li><a href="../docker.html">Docker</a></li>
    <li><a href="../ibmpower.html">IBM Power</a></li>
    <li><a href="blogsataws1.html">Blogs@AWS (Kindle Friendly)</a></li>
  </ul>
</aside>


    <div class="container">
  <div class="row">
    <div id="docs-sidebar" class="col-sm-3 col-md-3 col-xs-12 hidden-print" role="complementary">
      <ul class="nav docs-sidenav">
      <li><a href="blogsataws1.html">Blogs @ AWS</a></li>
      <li><a href="whatsnew1.html">What's New @ AWS</a></li>
      <li><a href="mgmtblogs1.html">Management Tools Blogs @ AWS</a></li>
      <li><a href="computeblogs1.html">Compute Blogs @ AWS</a></li>
      <li><a href="devopsblogs1.html">DevOps Blogs @ AWS</a></li>
      <li><a href="secblogs1.html">Security Blogs @ AWS</a></li>
      <li class="active"><a href="apnblogs1.html">APN Blogs @ AWS</a></li>

    </ul>
    </div>

    <div id="inner" class="col-sm-9 col-md-9 col-xs-12" role="main">
<p></p>
<p><i>Contents of this page is copied directly from AWS blog sites to make it Kindle friendly. Some styles & sections from these pages are removed to render this properly in 'Article Mode' of Kindle e-Reader browser. All the contents of this page is property of AWS.</i></p>
<p><a href="apnblogs1.html">Page 1</a>|<a href="apnblogs2.html">Page 2</a>|<a href="apnblogs3.html">Page 3</a>|<a href="apnblogs4.html">Page 4</a></p>
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<meta property="image" content="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/15/SaaS-Factory_feature.jpg" /> 
<b class="lb-b blog-post-title" property="name headline">Architecting Multi-Region SaaS Solutions on AWS</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Tod Golding</span></span> | on 
<time property="datePublished" datetime="2018-03-26T11:11:46+00:00">26 MAR 2018</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/apn/category/aws-partner-network/" title="View all posts in AWS Partner Network*"><span property="articleSection">AWS Partner Network*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/software/" title="View all posts in Software*"><span property="articleSection">Software*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/apn/architecting-multi-region-saas-solutions-on-aws/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-6570" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-apn-blog&amp;disqus_identifier=6570&amp;disqus_title=Architecting+Multi-Region+SaaS+Solutions+on+AWS&amp;disqus_url=https://aws.amazon.com/blogs/apn/architecting-multi-region-saas-solutions-on-aws/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-6570');
});
</script> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><em>By Tod Golding, Partner Solutions Architect at AWS</em></p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/15/SaaS-Factory_embed-1-300x105.jpg" />As software-as-a-service (SaaS) organizations grow and begin to extend their global reach, they must consider how their larger geographic footprint will shape and influence the architecture of their systems. Operations, deployment, agility, security, and scale all can be impacted by the move to a geographically distributed SaaS model.</p> 
<p>This move to a multi-region model often represents a major shift for SaaS organizations. The more complexity that is added to a system’s operational and deployment profile, the more challenging it becomes to maintain the agility goals that are often associated SaaS delivery models.</p> 
<p>This challenge of embracing the need for multi-region distribution while remaining responsive to your market is the focus of this blog post. The goal here is to explore the factors that are often behind a SaaS organization’s adoption of a multi-region strategy. With this motivation as a backdrop, we can dig into the architectural patterns and strategies that are commonly used when building, deploying, and managing multi-region SaaS environments.</p> 
<b>Scoping the Multi-Region Problem</b> 
<p>The topic of multi-region architecture is very broad, covering a wide range of architectural considerations that can influence many dimensions of your system’s architecture. AWS has a collection of useful resources that provide good general guidance on multi-region architecture. There are blog posts and whitepapers that look at the multi-region capabilities of individual services, networking models, and general failover patterns. A sampling of multi-region reference materials are included at the end of this post.</p> 
<p>For the purposes of our discussion, it makes more sense to focus on the nuances and motivations associated with multi-region SaaS environments. This guidance, paired with the broader coverage of multi-region strategies, should equip you with a foundational set of considerations that can be factored into your overall multi-region strategy.</p> 
<b>What’s Behind the Move to Multi-Region SaaS?</b> 
<p>Before we look at multi-region architecture, let’s start by understanding the dynamics that push some SaaS providers to a multi-region model.&nbsp;In many cases, SaaS ISVs can address basic geographic challenges through classic, edge-based content distribution strategies. <a href="https://aws.amazon.com/cloudfront/">Amazon CloudFront</a>, for example, can be used to solve the latency issues that are often associated with geographic distribution.</p> 
<p>There is a point at which this problem moves away from static content distribution and becomes more focused on availability, performance, and regional considerations. In these cases, you must introduce new and often custom mechanisms to achieve your multi-region goals. Below is a list of the common factors that often motivate a SaaS provider’s move toward a multi-region model.</p> 
<li><strong>Failover: </strong>The ability to withstand regional system failures, enabling part or all of a system to effectively transition load to an alternate region.</li> 
<li><strong>Latency:</strong> The need to process and serve non-static data without incurring the overhead of long network hops.</li> 
<li><strong>Compliance:</strong> Variations in regional compliance requirements means data and services must be regionally hosted.</li> 
<p>Failover is a fairly broad multi-region topic that is often more about adopting a disaster recovery model that can withstand regionalized application issues. In this mode, SaaS providers are often looking at ways to replicate some or all of their environment to another region. In the event of a failure, their system can gracefully redirect traffic to another region.</p> 
<p>Failover can be implemented in a number of <a href="http://d36cz9buwru1tt.cloudfront.net/AWS_Disaster_Recovery.pdf">different models</a> and at varying levels of granularity in your solution. The approach you choose here would be driven by the nature of your architecture and the decomposition of your system. It can also be influenced by the replication capabilities of the various tools and services you are using in your solution. Having a robust failover strategy may be of particular interest to SaaS providers where all of a region’s customers could be hosted in a single, shared infrastructure footprint. In this model, you may opt to for a cross-region model to limit the blast radius of a region-centric application issue.</p> 
<p>Latency and compliance, on the other hand, are more common drivers of multi-region adoption by SaaS providers. For some global SaaS providers, the access patterns and general usage models for their applications make housing their solution in a single region challenging. While edge-based content can help, there are some application flows that may not be adequately covered by a content delivery network (CDN). You may have aspects of your application that are transacting data that must be served directly by one or more application services. In these cases, you may quickly reach a tipping point where it becomes natural to deploy some or all of your application directly into a region. If, for example, you were building an ad serving platform that required millisecond rendering of ads, you may find that serving content from a single region may not be adequate.</p> 
<p>Compliance is often driven by the regional regulations that govern data privacy. Data sovereignty and <a href="https://www.eugdpr.org/">General Data Protection Regulation</a> (GDPR) requirements will often impose restrictions that can only be successfully addressed through some flavor of a multi-region strategy. Even in these scenarios, there may be an option to pick and choose those parts of your application that are subject to the regional compliance issues. In these cases, you may find yourself balancing the complexity of deploying and managing a more complex architectural footprint. Typically, in these scenarios, SaaS providers prefer to move their entire solution into a region.</p> 
<b>The Impact of a Multi-Region Model</b> 
<p>Now that we have a good handle on some of the common themes that can push a SaaS provider toward a multi-region model, let’s look at how the adoption of a multi-region model impacts the design, architecture, operations, and agility of your SaaS solution.&nbsp;The over-arching goal here is to find to a way to introduce the notion of multi-region without completely compromising the agility goals that are fundamental to most SaaS solutions.</p> 
<p>The following sections highlight some of the key areas that require consideration as you move to a multi-region SaaS model. This is not a comprehensive list, but it does represent some of the common challenges that are confronted by SaaS organizations.</p> 
<h3>Tenant Onboarding</h3> 
<p>Providing a frictionless onboarding experience is essential to SaaS organizations. The goal here is to streamline the process of acquiring and provisioning new customer environments. Of course, if your solution is hosted in multiple regions, this can add a wrinkle to your onboarding process.</p> 
<p><em>Figure 1</em>&nbsp;provides an illustration of one approach to take when onboarding tenants in a multi-region model. You’ll notice we have a group of new tenants signing up for our SaaS solution in a number of regions. In this model, the tenants provide data during the signup process that distinguishes their target region.&nbsp;A shared onboarding service would then be responsible for orchestrating the provisioning of the new tenants in their designated regions.</p> 
<img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/15/Shared-Onboarding.jpg" /> 
<p class="wp-caption-text"><em>Figure 1 –&nbsp;A centralized onboarding model.</em></p> 
<p>This model attempts to centralize the onboarding process in a single region. This simplifies and streamlines the process, but it can also present a challenge in terms of compliance. By collecting a users’ information outside each region, it’s likely you will violate the sovereignty requirements of a given region. However, if you are not facing compliance issues, then you could find the approach appealing.</p> 
<p>The alternative to this strategy&nbsp;is to decentralize some aspects of your onboarding process.&nbsp;<em>Figure 2</em> represents an alternated approach to this problem that distributes the onboarding process to each region.</p> 
<img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/15/Landing-Routing-Page.jpg" /> 
<p class="wp-caption-text"><em>Figure 2 – A decentralized onboarding model.</em></p> 
<p>The basic difference is that the onboarding experience is now hosted in each region, allowing you to ensure any data collected about the tenant is managed within the scope of the region. The main challenge of this model is determining how tenants will be redirected to each regional onboarding experience. In this case, we introduced a landing/routing page that allows users to opt into the region of their choosing. This is just one option, and each solution may take a different approach to landing their tenants in the correct region. They key takeaway is that the actual onboarding and collection of a tenant’s data is localized to a region.</p> 
<p>In this more distributed model, you do add some complexity to your deployment model and lose the ability to manage and deploy a centralized experience. Still, if you are deploying into regions with GDPR or general data sovereignty requirements, this is often your only option.</p> 
<b>Multi-Region Identity</b> 
<p>Once you’ve successfully onboarded a tenant, you still have to decide how your multi-region environment will support authentication. While it would be nice to have a centralized model identity provider for all of your users, the centralization of this data does not align with any of the fundamental data sovereignty requirements that govern the management of personal information.</p> 
<p>With this in mind, your approach to identity&nbsp;should&nbsp;focus on the tenant experience and the introduction of a mechanism that can effectively route your identity management to each region. In many respects, the challenges outlined here overlap with the onboarding discussion above. Now, however, you must have a non-invasive model for routing users to a region-centric authentication experience.</p> 
<p>Ideally, you would like this to be a relatively seamless experience for your tenants where the routing to a given region is mostly transparent. One common approach to resolving this is to embed tenant context in the URL of your application.&nbsp;<em>Figure 3</em> provides a sample of what this might look like in practice.</p> 
<img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/15/Tenant-Routing.jpg" /> 
<p class="wp-caption-text"><em>Figure 3 –&nbsp;Using URLs to route tenant authentication.</em></p> 
<p>With this model, each tenant is assigned a unique URL that was provisioned as part of their onboarding experience. In this example, we have created subdomains that prepend the tenant scope to the application’s URL. This subdomain uses traditional DNS routing (shown as <a href="https://aws.amazon.com/route53/?nc2=h_m1">Amazon Route 53</a>&nbsp;in <em>Figure 3</em>) to direct each tenant to the appropriate region.</p> 
<p>Once you are routed to the appropriate region, your SaaS solution relies on a regionally hosted identity provider&nbsp;to manage and authenticate users of your system. In this case, we’ve shown <a href="https://aws.amazon.com/cognito/">Amazon Cognito</a> as the identity provider for each region.</p> 
<p>While this model adds a configuration element and more moving parts to your tenant provisioning process, it also yields a much more intuitive experience for end users. It’s also important to note the tenant identifier that was prepended to the subdomain should never map directly to any internal representation you might have of your actual tenant identifier. Instead, this surfaces as a unique subdomain that only serves the purpose of routing users to their regions.</p> 
<p>There are some scenarios where your application may need to rely on the tenant to select a target region or environment before they can authenticate. This shows up in cases where a user may have the option to have accounts in multiple regions. In these cases, surfacing the region as part of the authentication experience may be unavoidable.</p> 
<p>For some solutions, you may be required to support identity portability where a user wants to move their existing identity from one region to another. This, too, may require additional workflows in your user management system to enable transfers of this nature. It also has the potential to challenge compliance regulations.</p> 
<b>Management and Monitoring</b> 
<p>Even as you distribute customer environments to individual regions, you’d still prefer to have a centralized model for managing and monitoring the overall health of tenants. In fact, as you move to a more distributed multi-region model, the need for robust operational tooling becomes more pronounced. The key is to put in place a mechanism that efficiently scales your operational footprint, allowing you to observe the regional and global health of your SaaS environments through a centralized experience.</p> 
<p>There are a number&nbsp;of different approaches that can be taken to centrally aggregate the data from each of your regions. The model you choose will be driven by the stack and tooling that best fits your application. Some solutions, for example, capture data locally then replicates it across regions. Others might stream log data directly to some centralized repository.</p> 
<p>Fortunately, the APN Partner community includes a number of different solutions in the management monitoring domain that can simplify your path to multi-region monitoring. <a href="https://aws.amazon.com/partners/find/partnerdetails/?n=Sumo%20Logic&amp;id=001E000000Rl0y6IAB">Sumologic</a>, <a href="https://aws.amazon.com/partners/find/partnerdetails/?n=New%20Relic&amp;id=001E000000Rl12lIAB">New Relic</a>, <a href="https://aws.amazon.com/partners/find/partnerdetails/?n=Datadog%20Inc&amp;id=001E000000Rp57sIAB">Datadog</a>, and <a href="https://aws.amazon.com/partners/find/partnerdetails/?n=Dynatrace&amp;id=001E000000texmiIAA">Dynatrace</a> are among the rich collection of monitoring Partner solutions you may want to consider. Each of these products has its own model for capturing and analyzing multi-region environments.</p> 
<p>AWS also has networking constructs that can be useful in building out your management environment. Cross-region VPC peering, for example, is used by some organizations to manage distributed environments. This can add security to your management footprint and may simplify the automation and deployment experience. As you might suspect, you will need to factor GDPR into your monitoring strategy. In some cases, you may need to ensure the data you’re logging is completely sanitized and complies with the requirements outlined in GDPR regulations.</p> 
<b>Deployment Automation</b> 
<p>Agility is one of the driving forces behind the adoption of a SaaS delivery model. However, as you move to a multi-region footprint, this has the potential to add complexity to your environment&nbsp;and undermine agility goals. Deployment, for example, becomes a much more involved process as you consider the automation and DevOps pipeline implications associated with releasing your product in multiple regions.</p> 
<p>The key to maintaining agility in a multi-region model is to limit the amount of variation that is introduced for each deployment. This is really just an extension of core DevOps tenets with additional emphasis on creating automated, repeatable deployment processes that manage all aspects of configuration through code.</p> 
<p><em>Figure 4</em>&nbsp;provides a conceptual view of a multi-region pipeline. The goal here&nbsp;is to view each regional deployment as a clone of the environment that might have originally been hosted in a single region. As you move to a multi-region model, the pipeline must deploy each change (in this case, each microservice) to the target region with the hope that the service requires minimal region-specific changes. Ultimately, the more universal your footprint across&nbsp;all regions, the more likely you’ll be able to release new features without&nbsp;feeling the multi-region model is hindering your agility.</p> 
<img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/15/Multi-Region-Pipeline.jpg" /> 
<p class="wp-caption-text"><em>Figure 4 –&nbsp;Multi-region deployment authentication.</em></p> 
<p>While&nbsp;our&nbsp;goal here is to minimize variation, it’s also possible that some region-specific requirements could add new elements to your pipeline. It would not be uncommon, for example, to see downstream steps added to your pipeline in each region responsible for performing compliance validation. There may nuances based on AWS service variations that could introduce regional configuration and deployment variations, but the goal would still be to view these as extensions of your overall pipeline.</p> 
<b>Billing</b> 
<p>Like management and monitoring, billing is a service that should be implemented using a centralized model. Ultimately, you’d like to have one experience that manages SaaS customer accounts, policies, and billing activity. The idea is that metering and activity data needed&nbsp;to generate a SaaS bill should be published from each region to a centralized system that is responsible for aggregating the information and generating a bill. This same system would be responsible for pushing updates to customers’ status, policies, and configuration to each region.</p> 
<p>Of course, while this is the preferred state, it is also complicated by compliance and regulations. In situations where you face sovereignty or GDPR requirements, you need to build a more decentralized billing model that prevents customer information from leaving a region. So, while the mechanics of billing would be the same across all regions, you would still be required to have each region generate its own bill. This obviously adds complexity and inefficiency to your billing process but may be unavoidable.</p> 
<b>Multi-Region or Multi-Availability Zone</b> 
<p>The move to a multi-region model often represents a natural progression for SaaS organizations that face regionalized latency and compliance hurdles. However, when multi-region is adopted purely as a failover strategy, the discussion gets more complicated. In some instances, you may find that a multi-Availability Zone approach will satisfy the failover requirements of your solution without requiring you to absorb the added overhead of a multi-region model.</p> 
<p>Ultimately, this comes down to having a firm handle on the factors driving your need for multi-region adoption. As you look at your options,&nbsp;weigh the impact these choices will have on the overall complexity and agility of your solution.</p> 
<b>Making the Move</b> 
<p>The move to a multi-region model is no trivial undertaking. As you can see from the items covered above, there are a number of factors&nbsp;to consider when thinking about how&nbsp;to deliver SaaS solutions in a multi-region environment. Onboarding, identity, operations—all of these areas require specific architectural strategies that address the requirements imposed by a multi-region model. In making this transition, you must remain focused on creating a seamless experience for customers.</p> 
<p>Multi-region environments also have the potential to impact the agility of your organization. It is essential that your multi-region approach places an even higher premium on your ability to automate and manage your solution to ensure you can continue to release features and functionality at a rapid pace.</p> 
<b>Additional Resources and Next Steps</b> 
<li><a href="https://aws.amazon.com/answers/networking/aws-multiple-region-multi-vpc-connectivity/">Multi-Region Multi-VPC Connectivity</a></li> 
<li><a href="https://www.youtube.com/watch?v=RMrfzR4zyM4">VIDEO: How to Design a Multi-Region Active-Active Architecture</a></li> 
<li><a href="https://aws.amazon.com/blogs/compute/building-a-multi-region-serverless-application-with-amazon-api-gateway-and-aws-lambda/">Building a Multi-region Serverless Application with Amazon API Gateway and AWS Lambda</a></li> 
<li><a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/crr.html">Amazon S3 Cross Region Replication</a></li> 
<li><a href="https://aws.amazon.com/dynamodb/global-tables/">Global DynamoDB Tables</a></li> 
<li><a href="https://aws.amazon.com/about-aws/whats-new/2016/06/amazon-aurora-now-supports-cross-region-replication/">Amazon Aurora Cross-Region Replication</a></li> 
<b>About AWS SaaS Factory</b> 
<p><a href="https://aws.amazon.com/partners/saas-on-aws/technical-enablement/">AWS SaaS Factory</a>&nbsp;provides AWS Partner Network (APN) Partners with resources that help accelerate and guide their adoption of a SaaS delivery model.&nbsp;SaaS Factory includes reference architectures for building SaaS solutions on AWS; Quick Starts that automate deployments for key workloads on AWS; and exclusive training opportunities&nbsp;for building a SaaS business on AWS. APN Technology Partners who develop SaaS Solutions are encouraged to join the program!</p> 
<p><strong><a href="https://aws.amazon.com/partners/saas-on-aws/technical-enablement/">Learn more about AWS SaaS Factory &gt;&gt;</a></strong></p> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-6570');
});
</script> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<meta property="image" content="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/23/Migration-2.jpg" /> 
<b class="lb-b blog-post-title" property="name headline">Migrating a Mainframe to AWS in 5 Steps</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Phil de Valence</span></span> | on 
<time property="datePublished" datetime="2018-03-23T12:08:29+00:00">23 MAR 2018</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/apn/category/aws-partner-network/" title="View all posts in AWS Partner Network*"><span property="articleSection">AWS Partner Network*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/migration/" title="View all posts in Migration*"><span property="articleSection">Migration*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/apn/migrating-a-mainframe-to-aws-in-5-steps/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-6007" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-apn-blog&amp;disqus_identifier=6007&amp;disqus_title=Migrating+a+Mainframe+to+AWS+in+5+Steps&amp;disqus_url=https://aws.amazon.com/blogs/apn/migrating-a-mainframe-to-aws-in-5-steps/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-6007');
});
</script> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><em>By Craig Marble, Vice President, Legacy Modernization Services at Astadia</em></p> 
<p>If you have a Mainframe, you have invested in building a reliable platform and application portfolio that has served as the backbone of your business. But the technology landscape of today requires more flexibility and agility at a lower cost than Mainframes can provide.</p> 
<p>At <a href="https://aws.amazon.com/partners/find/partnerdetails/?n=Astadia&amp;id=001E000000UfZWOIA3">Astadia</a>, an AWS Partner Network (APN) Standard Consulting Partner, we have found that customers are turning to Amazon Web Services (AWS) as a modern and flexible option for running Mainframe application workloads, and they are leveraging past investments in Mainframe applications and data.</p> 
<p>When carefully planned, managed, and executed, the rewards of moving Mainframe workloads to AWS are numerous. Besides the cost savings of the pay-as-you-go model, once your Mainframe application set has been fully deployed on AWS, you will have the freedom to integrate proven business logic with modern technologies for data analytics or mobile enablement, expanding your business to new markets, customers, and partners. With that in mind, migrating Mainframe applications to the cloud seems more like a necessity than a luxury.</p> 
<p>In this post, I will walk through a five-step methodology we have found helpful to moving Mainframe applications to AWS.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/01/15/Unisys-to-AWS-in-5-Steps-1024x674.jpg" /></p> 
<p>We recommend you&nbsp;reuse the original application source code and data, and to migrate them to modern AWS services. Mainframe migration enablement tools can keep existing code intact, but you should also expect to replace some components and rethink data storage.</p> 
<p>A least-change approach like this reduces project cost and risk compared to manual rewrites or package replacements, and reaps the benefits of integration with new technologies to exploit new markets while leveraging a 20- or 30-year investment. Once migrated, the application will resemble its old self enough for existing staff to maintain its modern incarnation; they have years of valuable knowledge they can use and pass on to new developers.</p> 
<b>Step 1: Discover</b> 
<p>The first thing you need to do is catalog and analyze all applications, languages, databases, networks, platforms, and processes in your environment. Document the interrelationships between applications and all external integration points. Use as much automated analysis as possible, and feed everything into a central repository.</p> 
<p>Astadia employs a combination of commercial analysis tools, like Micro Focus Enterprise Analyzer, and our own specially-developed parsers, to analyze legacy code quickly and efficiently. This analysis output is used to establish migration rules that are fed into Astadia Code Transformation Engine. These rules get updated and refined throughout the project.</p> 
<b>Step 2: Design</b> 
<p>After analyzing all of the source code, data structures, and end-state requirements, it is time to design and architect the solution. The design should include the following details:</p> 
<li><strong>AWS instance details:</strong> For instance types, in most cases, general purpose M instances are suitable for production, pre-production, and performance environments, while general purpose T instances fit the development, test, or integration environments.</li> 
<li><strong>Transaction loads:</strong> Non-functional requirements in general, performance requirements such as high transactions per second, or quick response times are often critical for Mainframe workloads execution. This implies careful design and sizing of the underlying network, storage, and computing.</li> 
<li><strong>Batch requirements:</strong> Almost every Mainframe runs Batch applications which are typically I/O intensive and require very low latency from storage or data stores. Because this can be a challenge for distributed systems, Batch infrastructure needs to be designed and tested early.</li> 
<li><strong>Programming language conversions and replacements:</strong> Some languages which may not be supported or available on the target components can be converted with tools or replaced by newer functions.</li> 
<li><strong>Integration with external systems:</strong>&nbsp;Mainframes are commonly the back-end or system of record for satellite or partner systems, and integration must be preserved after migration. This includes protocols, interfaces, latency, bandwidth, and more.</li> 
<li><strong>Third-party software requirements:</strong> Each Independent Software Vendor (ISV) may or may not have a functionally equivalent software available on AWS, consequently needing a specific migration path definition.</li> 
<li><strong>Planning for future requirements:</strong> Business and IT strategies and priorities dictate architecture decisions, especially around addressing future performance and integration capabilities.</li> 
<p>Source code may include MAPPER, LINC, COBOL, or Batch Control Language. Data stores may include networked, hierarchical,&nbsp;relational, or file-based data stores.</p> 
<img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/22/AWS-Mainframe-Migration-1024x374.jpg" /> 
<p class="wp-caption-text"><em>Figure 2 – The core component of the Mainframe migration architecture is the Mainframe Cloud Framework that uses a suite of emulators and utilities to execute the legacy code.</em></p> 
<p>The core component of the architecture in <em>Figure 2</em> is the Mainframe Cloud Framework, which uses a suite of emulators and utilities to execute the legacy code. OpenMCS is Astadia’s Message Control System that provides the necessary transaction processing features of COMS to support migrated code. This Mainframe Cloud Framework runs on <a href="https://aws.amazon.com/ec2/">Amazon Elastic Compute Cloud</a> (Amazon EC2) for compute resources.</p> 
<p>In most cases, Mainframe hierarchical and flat file data structures will be migrated to Relational Database Management Systems (RDBMS) solutions within <a href="https://aws.amazon.com/rds/">Amazon Relational Database Service</a> (Amazon RDS). Elasticity of the solution is facilitated by <a href="https://aws.amazon.com/elasticloadbalancing/">Elastic Load Balancing</a>&nbsp;(ELB) with the Network Load Balancer (NLB) along with Auto Scaling Groups.</p> 
<p>You’ll want to select which Mainframe migration tools you want to use; we recommend choosing ones that require you to make the least amount of change since it greatly reduces project costs and risks. For example, Astadia normally uses Micro Focus Visual COBOL for development and Astadia’s OpenMCS for emulating transaction monitors. This combination allows migrating COBOL applications to Windows and Linux with minimum change to the original source.</p> 
<p>However, you will need to design custom-developed solutions to meet requirements that aren’t met by emulation tools. COBOL is almost always migrated, but programs written in languages like Algol and MASM will need to be rewritten because they are not supported by the target emulating environment.</p> 
<p>Some program functions may be replaced by the target operating system or other target-platform components, so do a little analysis to find the gaps. Some legacy Assembler sort functions, for example, may be replaced by RDBMS SQL clauses. This is also where you will need to define your data migration strategy. You can keep flat files in their same legacy flat form, but it’s best to convert them to relational in order to facilitate integration with modern SQL-based tools, and to facilitate scalability with proven RDBMS. Hierarchical data should be converted to relational data using conversions tools or extract-transform-load (ETL) programs.</p> 
<b>Step 3: Modernize</b> 
<p>This is an iterative, automated process utilizing Astadia Code Transformation Engine to make mass changes to source code. If the modified code compiles, it’s ready for unit testing. If it doesn’t, developers should review the errors, find a fix, update the migration rules, and run the program(s) through the engine again. Many times, error fixes in one program may be applied en masse to fix the same errors in other programs, giving you the ability to leverage economies of scale.</p> 
<img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/01/15/Astadia-Code-Transformation-Engine-1-1024x990.jpg" /> 
<p class="wp-caption-text"><em>Figure 3 – As you go through the modernization process, the Astadia Code Transformation Engine with improved migration rules gets faster and more accurate for migrating follow-on source code.</em></p> 
<p>As you go through the modernization process, with more source code files, the Code Transformation Engine with improved migration rules gets faster and more accurate for migrating follow-on source code. This is because source code files tend to repeat the same coding patterns requiring the same transformation rules. This is also when developers write source to replace those legacy components that will not migrate to AWS.</p> 
<p>This step also includes building out and validating the new databases. To make this easier, Astadia has developed a DDL conversion tool that analyzes legacy data file layouts and database schemas, and then generates flat file and relational schemas for the target databases, as well as ETL programs, to migrate the data. Once the target file and database environment has been validated, static data can be migrated in parallel with code migration and development activities.</p> 
<p>Dynamic data—data that changes frequently—will be migrated during cutover to production.</p> 
<b>Step 4: Test</b> 
<p>The good news about testing is that you mostly need to focus on the code that has been changed. You may decide not to unit test every line of code since most of it hasn’t changed, but testing should focus on:</p> 
<li>Integration</li> 
<li>Data accesses</li> 
<li>Sorting routines that may be affected by using ASCII vs. EBCDIC</li> 
<li>Code modifications to accommodate data type changes</li> 
<li>Newly developed code</li> 
<p>Any Continuous Integration/Continuous Deployment (CI/CD) pipeline test which executes from a non-mainframe platform (such as from a T27 client platform) can be kept unchanged and follow DevOps best practices.</p> 
<p>Because many legacy applications have few, if any, test scripts and documentation, you will likely need to spend time and resources to develop test scripts. We recommend investing the time in developing the proper test procedures to make your applications more robust on AWS. You will also need to perform load and stress tests to ensure your applications are prepared to handle high volumes.</p> 
<b>Step 5: Implement</b> 
<p>When migrated applications have been tested, verified, and optimized, the process of deploying those applications can begin. In reality, many deployment activities are initiated in parallel with earlier phases—things like creating and configuring AWS instances, installing and configuring Mainframe emulation software (e.g. Astadia OpenMCS), migrating static data, and other infrastructure or framework activities.</p> 
<p>In some cases, environments may be replicated to achieve this, or existing environments may be repurposed. Such replications are typically facilitated by automation tools such as <a href="https://aws.amazon.com/cloudformation">AWS CloudFormation</a> or <a href="https://aws.amazon.com/opsworks/">AWS OpsWorks</a>. The specifics of this may depend upon application and data characteristics and any company standards or preferences you might have. After dynamic data is migrated and validated, cutover to production mode can be completed.</p> 
<b>Additional Resources for Mainframe Migration</b> 
<p>Every Mainframe system is unique with specific languages, subsystems, versions, and data stores. Moreover, every shop has unique functional and non-functional requirements and standards. Astadia can tailor and refine the above steps to your specific needs and leverage our unique proprietary toolset to make your Mainframe migration to AWS successful.</p> 
<p>Learn more about Astadia’s unique capabilities and the&nbsp;Mainframe to AWS References Architectures <a href="https://cloudgps.astadia.com/ibm-mainframe-to-aws-reference-architecture">here</a>&nbsp;and <a href="https://cloudgps.astadia.com/unisys-to-aws-reference-architecture">here</a>.</p> 
<p>For more information on legacy modernization, visit <a href="https://cloudgps.astadia.com/">astadia.com/insights</a>.</p> 
<hr /> 
<h6><em>The content and opinions in this blog are those of the third party author and AWS is not responsible for the content or accuracy of this post.</em></h6> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-6007');
});
</script> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<meta property="image" content="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/22/Connect-2.jpg" /> 
<b class="lb-b blog-post-title" property="name headline">AWS Solution Space Expands with Solutions for Amazon Connect</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Derek Belt</span></span> | on 
<time property="datePublished" datetime="2018-03-23T11:44:52+00:00">23 MAR 2018</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/apn/category/contact-center/amazon-connect/" title="View all posts in Amazon Connect*"><span property="articleSection">Amazon Connect*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/aws-partner-network/" title="View all posts in AWS Partner Network*"><span property="articleSection">AWS Partner Network*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/contact-center/" title="View all posts in Contact Center*"><span property="articleSection">Contact Center*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/apn/aws-solution-space-expands-with-solutions-for-amazon-connect/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-6720" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-apn-blog&amp;disqus_identifier=6720&amp;disqus_title=AWS+Solution+Space+Expands+with+Solutions+for+Amazon+Connect&amp;disqus_url=https://aws.amazon.com/blogs/apn/aws-solution-space-expands-with-solutions-for-amazon-connect/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-6720');
});
</script> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><a href="https://aws.amazon.com/connect/">Amazon Connect</a><a href="https://aws.amazon.com/solutionspace/contact-center/"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/22/Connect-2-300x150.jpg" /></a> is a self-service, cloud-based contact center service that makes it easy for any business to deliver better customer service at lower cost. Amazon Connect is based on the same contact center technology used by Amazon customer service associates around the world to power millions of customer conversations.</p> 
<p>With seven new integrations launched on <strong>AWS Solution Space</strong>, you can optimize your customer experience and contact center efficiency with pre-integrated solutions and pre-defined consulting services from <a href="https://aws.amazon.com/partners/">AWS Partner Network</a> (APN) Partners with validated capabilities in this area.</p> 
<p>Solution Space&nbsp;allows&nbsp;APN Partners&nbsp;to showcase customer-ready solutions&nbsp;that are quick, cost effective, and repeatable. Each solution is based on architectures validated by AWS and are meant to create new business opportunities for customers, leading to production workloads on AWS.</p> 
<p><strong><a href="https://aws.amazon.com/solutionspace/contact-center/">Visit the Contact Center&nbsp;page on AWS Solution Space &gt;&gt;&nbsp;</a></strong></p> 
<b>What’s New in this Expansion?</b> 
<p>The contact center solutions we just launched include integrations in sales and service, workforce optimization, speech analysis, fraud detection, and messaging. In addition, customers can find consulting offers from validated Amazon Connect partners.</p> 
<h3>Sales and Service</h3> 
<li><strong><a href="https://aws.amazon.com/solutionspace/contact-center/amazon-connect-aria-toolkit/">Aria Solutions Toolkit for Salesforce and Amazon Connect</a></strong><br /> <strong>Aria Solutions</strong>, Standard Consulting Partner</li> 
<li><strong><a href="https://aws.amazon.com/solutionspace/contact-center/amazon-connect-freshdesk/">Customer Support with Freshdesk and Amazon Connect</a></strong><br /> <strong>Freshworks</strong>, Advanced Technology Partner, AWS Marketing &amp; Commerce Competency</li> 
<h3>Workforce Optimization</h3> 
<li><strong><a href="https://aws.amazon.com/solutionspace/contact-center/amazon-connect-verint/">Verint Workforce Optimization</a></strong><br /> <strong>Verint</strong>, Advanced Technology Partner</li> 
<h3>Speech Analytics</h3> 
<li><strong><a href="https://aws.amazon.com/solutionspace/contact-center/amazon-connect-voicebase/">VoiceBase Speech Recognition and Analysis</a></strong><br /> <strong>VoiceBase</strong>, Standard Technology Partner</li> 
<li><strong><a href="https://aws.amazon.com/solutionspace/contact-center/amazon-connect-dialogtech/">DialogTech Speech Recognition and Analysis</a></strong><br /> <strong>DialogTech</strong>, Standard Technology Partner</li> 
<h3>Fraud Detection</h3> 
<li><strong><a href="https://aws.amazon.com/solutionspace/contact-center/amazon-connect-pindrop/">Pindrop Fraud Detection</a></strong><br /> <strong>Pindrop</strong>, Standard Technology Partner</li> 
<h3>Messaging</h3> 
<li><strong><a href="https://aws.amazon.com/solutionspace/contact-center/amazon-connect-webtext/">Webtext Messaging with Amazon Connect</a></strong><br /> <strong>Webtext</strong>, Standard Technology Partner</li> 
<b>Getting Involved and Next Steps</b> 
<p>APN Partners are encouraged to&nbsp;<a href="https://aws.au1.qualtrics.com/jfe/form/SV_b9Ih30HkcJqX3a5">nominate their solutions for AWS Solution Space via this online application &gt;&gt;</a></p> 
<p>If you have questions about Solution Space or want to discuss whether your solution is a good fit, please contact your Partner Development Manager. To learn more and see each customer-ready solution, visit the&nbsp;<a href="https://aws.amazon.com/solutionspace/">AWS Solution Space website</a>.</p> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-6720');
});
</script> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<meta property="image" content="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/15/SaaS-Factory_feature.jpg" /> 
<b class="lb-b blog-post-title" property="name headline">Enabling New SaaS Strategies with AWS PrivateLink</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Tod Golding</span></span> | on 
<time property="datePublished" datetime="2018-03-21T12:20:38+00:00">21 MAR 2018</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/apn/category/aws-partner-network/" title="View all posts in AWS Partner Network*"><span property="articleSection">AWS Partner Network*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/networking-content-delivery/" title="View all posts in Networking &amp; Content Delivery*"><span property="articleSection">Networking &amp; Content Delivery*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/software/" title="View all posts in Software*"><span property="articleSection">Software*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/apn/enabling-new-saas-strategies-with-aws-privatelink/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-6587" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-apn-blog&amp;disqus_identifier=6587&amp;disqus_title=Enabling+New+SaaS+Strategies+with+AWS+PrivateLink&amp;disqus_url=https://aws.amazon.com/blogs/apn/enabling-new-saas-strategies-with-aws-privatelink/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-6587');
});
</script> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><em>By Tod Golding, Partner Solutions Architect at AWS</em></p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/15/SaaS-Factory_embed-1-300x105.jpg" />Networking is&nbsp;an area that doesn’t always jump out as a hot topic for teams designing and building software-as-a-service (SaaS) solutions. Instead, networking is often viewed as a foundational element of a system’s architecture. The reality is there are plenty of scenarios where the networking footprint of a SaaS application can influence the functionality, extensibility, and management profile of your SaaS environment.</p> 
<p>While there are plenty of creative ways developers leverage Amazon Web Service (AWS) networking constructs to refine SaaS solutions, the introduction of <a href="https://aws.amazon.com/about-aws/whats-new/2017/11/introducing-aws-privatelink-for-aws-services/">AWS PrivateLink</a>&nbsp;adds new opportunities in the SaaS networking landscape. PrivateLink equips architects with a seamless experience for integrating with SaaS environments, enabling a new model and mindset to expose secure entry points into SaaS applications.</p> 
<p>In this post, I will dig into the specifics of the PrivateLink model and identify areas where PrivateLink has the potential to impact the architecture, integration model, and compliance footprint of your SaaS solution.</p> 
<b>The AWS PrivateLink Story</b> 
<p>To understand the value proposition of AWS PrivateLink, we must first start by examining some of the fundamentals that influenced its introduction. Let’s look at a common network configuration for applications that are running on AWS.&nbsp;<em>Figure 1 </em>represents a simple case where a service is running on an <a href="https://aws.amazon.com/ec2/">Amazon Elastic Compute Cloud</a> (Amazon EC2) instance hosted in an <a href="https://aws.amazon.com/vpc/">Amazon Virtual Private Cloud</a> (Amazon VPC).</p> 
<img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/19/PrivateLink-Figure-1.jpg" /> 
<p class="wp-caption-text"><em>Figure 1 – Accessing AWS services with the Internet Gateway or VPC endpoints.</em></p> 
<p>This example represents a common scenario where your application services may require access to an AWS managed service (in this example, <a href="https://aws.amazon.com/s3/?nc2=h_m1">Amazon Simple Storage Service</a>, or Amazon S3). AWS provides two paths to these services. Traditionally, to access Amazon S3 from within a VPC, you have to pass through an Internet gateway to get to Amazon S3 since it wasn’t part of your VPC. The need to pass through the Internet to access AWS services was less than ideal and, ultimately, led to the introduction of VPC endpoints&nbsp;that allow you to connect to a service like Amazon S3 from your VPC without leaving the AWS network.</p> 
<p>The diagram in <em>Figure 1</em> illustrates both of these access scenarios. Along the top, you’ll see where our VPC router is sending traffic through the Internet Gateway to the internet. From there, you can access Amazon S3. The alternate path here (at the bottom of the diagram) illustrates the use of a VPC endpoint. With the VPC endpoint exposed by Amazon S3, the service can interact directly with Amazon S3 service without leaving the AWS network.</p> 
<b>Taking VPC Endpoints to the Next Level</b> 
<p>Endpoints solved an important problem for AWS developers. They also exposed developers to an integration model that opened the door to a whole new set of possibilities. With endpoints, developers saw the value of exposing and accessing services in a more seamless model. It was only natural they would see the power of this construct and begin to wonder how they could leverage this same mechanism to enable access to their own services. If developers could somehow create entry points into their own VPCs using the endpoint model, they would be able to support new strategies for safely exposing application services within their environments.</p> 
<p>This, of course, is precisely the mindset that drove the introduction of what is now known as AWS PrivateLink. This new networking construct is focused on extending the capabilities of VPC endpoints, allowing developers to expose native services via VPC endpoints.&nbsp;<em>Figure 2</em> provides a high-level view of a PrivateLink implementation.</p> 
<img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/19/PrivateLink-Figure-2.jpg" /> 
<p class="wp-caption-text"><em>Figure 2 – Exposing native services via VPC endpoints.</em></p> 
<p>You’ll notice that in <em>Figure 2</em> we have a SaaS solution that is hosted in an AWS account on the right-hand side of the diagram. This SaaS provider has their own account and a collection of services running in a VPC. Let’s presume these services provide functionality that the provider would like to make available for consumption by environments that are running in other AWS accounts or businesses. They would like to achieve this without opening a public interface&nbsp;and prefer that traffic remain within the confines of the AWS networking infrastructure.</p> 
<p>This is now directly in the sweet spot of the problem that PrivateLink solves. With PrivateLink, we can put a <a href="https://aws.amazon.com/elasticloadbalancing/">Network Load Balancer</a> (NLB) in front of our services and attach a VPC endpoint to the load balancer. This configuration assigns a private IP address to the endpoint that can be accessed by external consumers without touching the public network. In fact, these endpoints will appear as if they reside directly in the consumer VPC.</p> 
<p>While the power of PrivateLink has merits in any number of scenarios, it’s of particular interest to SaaS organizations. Through PrivateLink, SaaS providers see new and creative opportunities to use this networking construct to enhance and expand the architectural and business models of their solutions. The sections that follow highlight some of the common ways SaaS providers are employing PrivateLink in their offerings.</p> 
<b>Enabling Third-Party Integrations</b> 
<p>Many SaaS providers support integrations with third-party solutions that are also hosted on AWS. In many cases, SaaS providers are extending the capabilities and value proposition of their products through third-party integrations. Without PrivateLink, of course, tackling these integrations meant exposing a public network paths between these systems—even when they all reside with the same AWS infrastructure.</p> 
<p>PrivateLink reduces the risk and efficiency of these integrations, providing a natural and more secure mechanism for connecting SaaS environments. In many respects, consuming the capabilities of another SaaS provider becomes like consuming other native services on the AWS network. In fact, a PrivateLink-based solution that has been vetted and published on <a href="https://aws.amazon.com/marketplace">AWS Marketplace</a> can be whitelisted and appear in the console alongside other AWS services.</p> 
<p><em>Figure 3</em>&nbsp;provides a high-level view of the integration model that SaaS providers might employ to enable third-party integrations.</p> 
<img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/19/PrivateLink-Figure-3.jpg" /> 
<p class="wp-caption-text"><em>Figure 3 – Using AWS PrivateLink to promote SaaS integrations.</em></p> 
<p>Here, we have examples of three separate SaaS integrations. The first SaaS provider on the left has used PrivateLink to create an integration with another SaaS solution (SaaS Solution 2). This provider has also relied on an integration of its own with yet another SaaS provider (SaaS solution 3).</p> 
<p>On the surface, this may seem like a less than monumental achievement. Certainly, SaaS providers have been creating models for integration long before the introduction of PrivateLink. What’s new here is the idea that these integrations are being achieved without any reliance on public network exposure. They cross account boundaries and integrate more seamlessly, benefiting from all the perks that come with staying in the confines of the AWS network infrastructure.</p> 
<p>By relying on PrivateLink for integrations, these services inherit all the AWS-supported mechanisms for controlling and constraining the accessibility. PrivateLink supports the application of <a href="https://aws.amazon.com/iam/">AWS Identity and Access Management</a> (IAM) policies to restrict access to endpoints. SaaS providers can configure their endpoints to require consent from both parties before enabling opening any connection between the parties. This added level of control is essential in multi-tenant SaaS environments where there is a premium on preventing any form of cross-tenant access to resources.</p> 
<b>Frictionless Onboarding with AWS Marketplace</b> 
<p>Once you have added PrivateLink support to your SaaS application, you’ll want to promote the availability of this option to prospects and customers. AWS Marketplace provides you with just such a vehicle. You&nbsp;can list your SaaS solutions on AWS Marketplace along with other SaaS providers, increasing your ability to promote this option and drive new and, potentially, unanticipated business relationships.</p> 
<p>Through AWS Marketplace, you’ll be able to create a frictionless experience that will streamline the provisioning and configuration of PrivateLink connections. In fact, SaaS providers that use PrivateLink&nbsp;can use their own DNS names to brand and simplify the naming of their endpoints. Learn more about <a href="https://aws.amazon.com/marketplace/saas/privatelink">PrivateLink on&nbsp;AWS Marketplace</a>.</p> 
<b>On-Premises Integration</b> 
<p>Some SaaS providers rely on a hybrid delivery model, where portions of their applications are hosted on-premises. Implementing solutions of this nature can be challenging and undermine the agility of your SaaS architecture. The network constructs used to support this model can also add layers of complexity to your SaaS environment.</p> 
<p>PrivateLink provides a new option that significantly reduces the complexity of these environments.&nbsp;<em>Figure 4</em> illustrates how you can use PrivateLink to simplify the networking model of SaaS solutions that rely on a partial on-premises footprint.</p> 
<img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/19/PrivateLink-Figure-4.jpg" /> 
<p class="wp-caption-text"><em>Figure 4 – Using AWS PrivateLink to access services from on-premises environments.</em></p> 
<p>You can see that our SaaS provider has a collection of services running on AWS. This could represent a scenario where you’ve only hosted a specific feature of your product in the cloud. Or, it could be that your system is in a transitional state where the services of your application are currently split between AWS and on-premises environments. It could also be that requirements of your domain simply require some aspects of your SaaS solution to remain on-premises.</p> 
<p>The beauty of this model is that PrivateLink makes integrations relatively straightforward. The services that are exposed in your AWS environment will be able to participate as first-class citizens in your on-premises environment, removing much of the complexity and streamlining the fundamentals of your integration.</p> 
<b>Control Plane for Tenant VPCs</b> 
<p>Some SaaS providers deliver solutions in what’s referred to as a silo model. In siloed environments, each SaaS tenant is provisioned and deployed into its own VPC with its own dedicated infrastructure stack. This model is often the byproduct of specific regulatory or domain considerations.</p> 
<p>Managing and operating siloed environments can be particularly challenging. Ultimately, you’d like to have a single control plane that spans all the individual VPCs, providing a single operational and management experience for tenants. Some have addressed this issue through a combination of security groups, IP restrictions, and other measures that control the public accessibility of your VPCs. Others have relied on <a href="https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/vpc-peering.html">VPC peering</a> to address this need. However, this adds a layer of complexity to IP addressing schemes of tenant VPCs. Both strategies are valid; they simply require an added level of care and forethought.</p> 
<p>As you can imagine, PrivateLink represents a compelling alternative for managing multi-VPC environments.&nbsp;<em>Figure 5</em> provides a high-level view of how this control plane might be implemented with PrivateLink.</p> 
<img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/19/PrivateLink-Figure-5.jpg" /> 
<p class="wp-caption-text"><em>Figure 5 – Using AWS PrivateLink to build a multi-VPC control plane.</em></p> 
<p>Here you’ll notice that we’ve introduced two VPCs on the right-hand side the diagram the represent the individual tenant VPCs. Now, to enable management and configuration of these tenant environments, we have created a separate VPC that hosts our management service (on the left-hand side). This management service uses PrivateLink to invoke management operations on each of the tenant VPC environments. It achieves all of this without leaving the AWS network, adding a layer of efficiency and control to the management profile of your environment.</p> 
<p>This model certainly overcomes many of the challenges associated with VPC peering. It also tends to meet a higher security threshold than any of the mechanisms that rely on exposing public entry points to your VPCs.</p> 
<b>Improving the Compliance Footprint</b> 
<p>Compliance represents a significant challenge many SaaS providers—especially those relying on integrations or interactions that require them to interact with external environments. For these solutions, any attempt to move data across a public network path must be given careful scrutiny. To make this work, SaaS providers often employ a range of a security measures (keys, encryption, etc.) to satisfy compliance requirements of their domain.</p> 
<p>PrivateLink provides a natural fit for SaaS solutions that have a heavy compliance footprint. Since all the traffic that flows through a PrivateLink endpoint remains on the AWS network, this traffic inherits the security and compliance features that are already supported by AWS. This allows your solution to piggyback on the compliance models that are directly supported by AWS, such as PCI-DSS, HIPAA, GLBA, and FISMA.</p> 
<p>These compliance considerations can add immediate value to the integrations you might create with other SaaS vendors. This added level of compliance and security can promote integrations with your product and, potentially, drive new integrations you may not have previously considered.</p> 
<b>The Cost Model</b> 
<p>As you consider the integration model for PrivateLink, you must consider how you will manage cost as part of this experience. With PrivateLink, the cost of adding an endpoint to your solution is viewed as separate from the cost of enabling a new connection between a given consumer and your PrivateLink endpoint. Each separate connection that is made to a PrivateLink endpoint incurs its own cost.</p> 
<p>This cost model raises interesting questions for SaaS providers. If, for example, the integration is requested by a SaaS tenant, these costs could be passed along directly to the tenant that has enabled the integration. There will also be scenarios where SaaS providers want to limit a tenant’s awareness of these costs, but in this model a SaaS provider&nbsp;has to provision the connection using thier own account and absorb this as part of their AWS costs.</p> 
<p>The key here is that you should factor the cost model into your design. If you expect to make costs transparent to you tenants, you’ll want to determine how this might influence your overall SaaS tiering and cost model.</p> 
<b>One-Way Flow</b> 
<p>In looking at the scenarios described in this post, you’ll notice that each of the diagrams represent the network flow as a one-way path into PrivateLink. This is intentional and fundamental to achieving the goals of PrivateLink. However, it’s important to note that some integration patterns you may be considering could rely on a two-way integration model.</p> 
<b>Getting Started</b> 
<p>Hopefully, this post gives you a good sense of some of the key areas where AWS PrivateLink can influence the architecture and integration models of your SaaS solutions. The simplicity, enhanced security, performance, and compliance aspects of PrivateLink open up new models for discovering and integrating SaaS solutions on AWS.</p> 
<p>For some, PrivateLink will solve fundamental integration and management problems. For others, it may also represent an opportunity to create a more appealing model for building integrations with other SaaS products that, previously, may not have been achievable.</p> 
<b>About AWS SaaS Factory</b> 
<p><a href="https://aws.amazon.com/partners/saas-on-aws/technical-enablement/">AWS SaaS Factory</a>&nbsp;provides AWS Partner Network (APN) Partners with resources that help accelerate and guide their adoption of a SaaS delivery model.&nbsp;SaaS Factory includes reference architectures for building SaaS solutions on AWS; Quick Starts that automate deployments for key workloads on AWS; and exclusive training opportunities&nbsp;for building a SaaS business on AWS.</p> 
<p>APN Technology Partners who develop SaaS Solutions are encouraged to join the program!</p> 
<p><strong><a href="https://aws.amazon.com/partners/saas-on-aws/technical-enablement/">Learn more about AWS SaaS Factory &gt;&gt;</a></strong></p> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-6587');
});
</script> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<meta property="image" content="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/12/28/VMware-Cloud-on-AWS.jpg" /> 
<b class="lb-b blog-post-title" property="name headline">Understanding Amazon VPC from a VMware NSX Engineer’s Perspective</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Anuj Dewangan</span></span> | on 
<time property="datePublished" datetime="2018-03-21T10:18:02+00:00">21 MAR 2018</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/apn/category/compute/amazon-vpc/" title="View all posts in Amazon VPC*"><span property="articleSection">Amazon VPC*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/aws-partner-network/" title="View all posts in AWS Partner Network*"><span property="articleSection">AWS Partner Network*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/apn/understanding-amazon-vpc-from-a-vmware-nsx-engineers-perspective/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-6537" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-apn-blog&amp;disqus_identifier=6537&amp;disqus_title=Understanding+Amazon+VPC+from+a+VMware+NSX+Engineer%26%238217%3Bs+Perspective&amp;disqus_url=https://aws.amazon.com/blogs/apn/understanding-amazon-vpc-from-a-vmware-nsx-engineers-perspective/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-6537');
});
</script> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><em>By Anuj Dewangan, Solutions Architect at AWS</em></p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/12/28/VMware-Cloud-on-AWS-300x150.jpg">VMware Cloud on AWS</a>, you can deploy applications in a fully-managed VMware environment that runs on the Software-Defined Data Center (SDDC) stack directly on bare-metal Amazon Web Services (AWS) infrastructure.</p> 
<p>Organizations can simplify their hybrid IT operations by using the same VMware technologies—including vSphere, vSAN, NSX, and vCenter—across their on-premises datacenters and on the AWS cloud.</p> 
<p>VMware Cloud on AWS also brings native integration with AWS infrastructure and platform capabilities such as <a href="https://aws.amazon.com/ec2/">Amazon Elastic Compute Cloud</a> (Amazon EC2), <a href="https://aws.amazon.com/kinesis/">Amazon Kinesis</a>, and <a href="https://aws.amazon.com/redshift/">Amazon Redshift</a>, among others. I recommend reviewing <a href="https://aws.amazon.com/blogs/apn/securing-workloads-on-vmware-cloud-on-aws-using-native-aws-services/">this blog post</a> to understand native integration of AWS services with workloads deployed in VMware Cloud on AWS for centralized access, security, content acceleration, and data analytics.</p> 
<p>If you are looking to integrate native AWS services with your enterprise applications, knowledge of <a href="https://aws.amazon.com/vpc/">Amazon Virtual Private Cloud</a> (Amazon VPC) networking becomes especially important.</p> 
<p>In this post, and my follow-up, I will explain the major components of Amazon VPC for engineers and architects who build and operate VMware NSX networks, and who are building solutions on VMware Cloud on AWS. I will explain VPC in terminology and concepts that are familiar to you as NSX experts. If you come from an NSX background like me and are new to Amazon VPC, please read on!</p> 
<p>If you&nbsp;have a traditional network engineering background and would like to learn more about Amazon VPC, I recommend <a href="https://aws.amazon.com/blogs/apn/amazon-vpc-for-on-premises-network-engineers-part-one/">reading this blog series first</a>.</p> 
<b>Amazon VPC and VMware NSX</b> 
<p>Through Amazon VPC,&nbsp;you can launch AWS resources in a virtual network in AWS regions. On the other hand, <a href="https://www.vmware.com/products/nsx.html">VMware NSX</a>—starting with on-premises datacenters and now with <a href="https://aws.amazon.com/vmware/">VMware Cloud on AWS</a>—enables a software-defined networking (SDN) solution to seamlessly extend on-premises networks to AWS. This allows VMware customers to migrate applications to AWS, create a disaster recovery solution, or extend the capacity of their datacenters.</p> 
<p>Let’s look at the physical and logical components in an Amazon VPC, including the forwarding, control, and management planes.</p> 
<b>Physical Infrastructure: AWS Regions and Availability Zones</b> 
<p>NSX Transport Zones (TZs) determine the physical scope of networking components like Logical Switches and Distributed Logical Routers (DLRs) in an NSX network. TZs can include multiple vSphere clusters, such as compute and edge clusters. An NSX Transport Zone with multiple clusters is shown in <em>Figure 1</em>.</p> 
<img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/14/NSX-Transport-Zone.jpg" /> 
<p class="wp-caption-text"><em>Figure 1 – NSX Transport Zone with compute and edge clusters.</em></p> 
<p>A Logical Switch created in the Transport Zone will span all the vSphere hosts that are part of the clusters associated with the TZ. Similarly, a DLR associated with Logical Switches in this TZ will create a DLR instance on each of the vSphere hosts in the cluster.</p> 
<p>As with NSX Transport Zones, while understanding the logical components in an Amazon VPC, it’s important&nbsp;to understand the physical scope of their existence within the <a href="https://aws.amazon.com/about-aws/global-infrastructure/">AWS global infrastructure</a>. Region and Availability Zone (AZ) constructs govern the physical scope of Amazon VPC components like ENI, subnets, route tables, security groups, VPC Gateways, and Network ACLs.&nbsp;<em>Figure 2</em> shows the relationship between AWS Regions and AZs.</p> 
<img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/14/AWS-Regions.jpg" /> 
<p class="wp-caption-text"><em>Figure 2 –&nbsp;AWS Regions and Availability Zones (AZs).</em></p> 
<p>Each AWS Region is built in a separate geographic area and is completely independent from all other Regions. Each region has multiple, isolated locations known as Availability Zones, and each AZ has one or more physical datacenters that are fault isolated from all other AZs in the region. The AZs within a Region are connected through low-latency networking links. To achieve high availability, an application is deployed across multiple AZs.</p> 
<b>Tenant’s Logical Network: Amazon VPC</b> 
<p>For NSX, a logically isolated network for a tenant is characterized by one or more dedicated Logical Switches, typically one DLR and one or more Edge Service Gateways (ESGs).&nbsp;<em>Figure 3</em> shows switching and routing plane components of the NSX network for a three-tier application deployment.</p> 
<img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/14/Plane-Components.jpg" /> 
<p class="wp-caption-text"><em>Figure 3 –&nbsp;NSX logical network for a three-tier application.</em></p> 
<p>An Amazon VPC represents a virtual isolated network in the AWS cloud, and encapsulates all the networking components required to make communication possible within the VPC. <em>Figure 4</em> shows an Amazon VPC and related components for a three-tier application deployment, and represents an equivalent construct to a tenant network.</p> 
<img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/22/VPC-Architecture-1.jpg" /> 
<p class="wp-caption-text"><em>Figure 4 – A three-tier application deployed in an Amazon VPC.</em></p> 
<p>Just like an NSX tenant network can contain multiple subnets, Amazon VPC is also a container for multiple subnets. The scope of a VPC is a single AWS Region and spans all the AZs in that Region. Each Region in your AWS account gets a default VPC. You can also create your own VPC as <a href="https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Scenarios.html">described in this post</a>.</p> 
<p>You can use <a href="http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Internet_Gateway.html">Internet connectivity</a>, <a href="https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/vpn-connections.html">virtual private network</a> (VPN), and <a href="http://aws.amazon.com/directconnect">AWS Direct Connect</a> to connect your VPC networks to networks outside of AWS. <a href="http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/vpc-peering.html">VPC peering</a> allows you to connect to other VPCs in your AWS account or other AWS accounts. Amazon VPC also provides private connectivity to several AWS and Partner services through <a href="https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/vpc-endpoints.html">VPC endpoints</a>, allowing you to connect to these services without the need for Internet connectivity.</p> 
<p>Additionally, Amazon VPC infrastructure includes a <a href="https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/vpc-dns.html">VPC DNS server</a>—available at the second IPv4 address of the primary <a href="http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Subnets.html">Classless Inter-Domain Routing</a> (CIDR) range—to resolve both private and public hostnames. Having a built-in DNS server reduces the administrative burden for deploying workloads in an Amazon VPC.</p> 
<b>VPC Addressing</b> 
<p>An Amazon VPC is associated with a primary IPv4 CIDR, and you can add additional IPv4 CIDRs to extend the addressing space. Unlike IPv4 addresses in an NSX network, which can be Internet routable or private, all IPv4 addresses in an Amazon VPC are private and need to be mapped to public IPv4 addresses for Internet connectivity. You can still use IPv4 CIDRs outside RFC 1918/6598 address space in your Amazon VPC, but IPv4 CIDR addresses are never used to directly communicate with the Internet. IPv4 addresses need to have Network Address Translation (NAT) between private IPv4 addresses and <a href="https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/vpc-ip-addressing.html#vpc-public-ipv4-addresses">public IPv4 addresses</a> to enable IPv4 based Internet connectivity.</p> 
<p>You can also add an IPv6 CIDR to your Amazon VPC. With IPv6, AWS assigns a globally routable /56 prefix to the Amazon VPC.</p> 
<b>VPC Subnets</b> 
<p>In an NSX network, an NSX Logical Switch represents a Layer 2 network and is associated with a subnet in the tenant network. In an Amazon VPC, you directly create <a href="http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Subnets.html">subnets</a>&nbsp;and the VPC control and forwarding planes enable communication between the subnet’s network interfaces. Amazon VPC users do not directly work with the underlying components which enable traffic flow within a subnet. The section in this post about Amazon VPC forwarding and control planes provides more details on forwarding architecture.</p> 
<p>While creating a subnet, you will assign a unique IPv4 and optionally an IPv6 CIDR from the VPC CIDR range. The scope of a subnet in a VPC is within an Availability Zone, and there can be multiple subnets per AZ per VPC. From a workload perspective, for higher availability, application tiers are deployed across multiple subnets and multiple AZs, as is shown in <em>Figure 4</em>.</p> 
<p>Subnets can be public or private. A public subnet has direct access to the Internet via a route to the <a href="http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Internet_Gateway.html">Internet Gateway</a>, while network interfaces in public subnets are mapped to public IPv4 addresses using the built-in 1:1 stateless NAT of the Internet Gateway. A private subnet does not have direct access to the Internet―it can connect to on-premises datacenters through the use of VPN/Direct Connect or to the Internet using VPC-based NAT. We will learn more about external connectivity for a VPC&nbsp;in my next post.</p> 
<p>In the three-tier application shown in <em>Figure 4</em>, the web, app, and database tiers are deployed in private subnets, whereas the nodes for the <a href="https://docs.aws.amazon.com/elasticloadbalancing/latest/userguide/what-is-load-balancing.html">Elastic Load Balancer</a> (ELB) are deployed in public subnets, enabling direct access of incoming Internet traffic to the ELB nodes. Public subnets associated with the ELB nodes are not shown in <em>Figure 4</em> for simplicity.</p> 
<b>Elastic Network Interfaces (ENI)</b> 
<p>Once you have created a subnet in the VPC, you can create and associate <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-eni.html">Elastic Network Interfaces</a> (ENI) with the subnet. Because an ENI is associated with a subnet, the scope of the ENI is the same as that of the subnet, which is the AZ in which the subnet is created.</p> 
<p>An ENI is conceptually similar to a VMware virtual network interface card (vnic). Just like vnics are associated with VMware Virtual Machines (VMs), ENIs are associated with <a href="https://aws.amazon.com/documentation/ec2/">Amazon Elastic Compute Cloud (Amazon EC2) instances</a>,&nbsp;<a href="https://aws.amazon.com/documentation/elastic-load-balancing/">Load Balancer nodes</a>, <a href="https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/vpce-interface.html">VPC interface endpoints</a>, and instances of managed services like <a href="https://aws.amazon.com/documentation/rds/">Amazon RDS</a>.</p> 
<p>VMware vnics, in an NSX network, are associated with VXLAN-backed distributed port groups which link to a Logical Switch. This, in turn, represents a network subnet. Similarly, each ENI is associated with exactly one subnet, and the ENI borrows its IP addresses from the subnet CIDR block.</p> 
<p>Unlike vnics, ENIs encapsulate Layer 3 properties of the network interface. You can auto or manually assign IPv4 and IPv6 addresses to an ENI. You can also configure secondary IP addresses on an ENI—all IP addresses configured on an ENI must be in the same CIDR range as the associated subnet. These IP addresses remain assigned to the ENIs for the lifetime of the ENIs.</p> 
<p>Another difference from vnics is that ENIs can exist independent of their association with instances. An ENI can be created through the&nbsp;<a href="https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_CreateNetworkInterface.html">AWS API</a>, <a href="https://docs.aws.amazon.com/cli/latest/reference/ec2/create-network-interface.html">AWS Command Line Interface</a> (CLI), or the <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-eni.html#create_eni">AWS Management Console</a>. ENIs can then be associated or disassociated with an instance. You can associate multiple ENIs with an instance and move an ENI to another instance as well. This is where the “elasticity” of the network interface becomes evident.</p> 
<p>Each IPv4 address in an ENI can be mapped with a public or Elastic IP address if the ENIs are in a public subnet and need to exchange traffic directly with the Internet. <a href="https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/vpc-ip-addressing.html#vpc-public-ipv4-addresses">Public IP address</a> and <a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/elastic-ip-addresses-eip.html">Elastic IP address</a> are Internet-routable IPv4 addresses that allow an instance with a private IP address to communicate with the Internet. <span style="color: #000000">Because the IPv6 CIDRs are publicly routable, there is no need for&nbsp;any IP&nbsp;address mapping. As long as the subnet is public, IPv6 Internet connectivity will work.</span></p> 
<p>Once an instance is associated with an ENI, the operating system running on the instances receive IPv4 and IPv6 address for the associated network interfaces using Dynamic Host Configuration Protocol (DHCP). IP addresses received by the instance are the addresses associated with the ENI. DHCP also provides the instance with a default gateway, IP addresses of DNS servers, DNS domain, and other parameters like Network Time Protocol (NTP) servers. DHCP parameters are configured at a VPC level. <a href="http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_DHCP_Options.html">This documentation</a> provides more details on DHCP parameters.</p> 
<p>The Amazon VPC network provides the DHCP server in the virtualization infrastructure, and the DHCP packets are handled locally without any broadcasts. So as a network engineer, you don’t need to think about how broadcast packets will be handled on the physical network, as Amazon VPC takes care of it.</p> 
<b>Route Tables</b> 
<p>Similar to NSX—where you create DLRs to enable Layer 3 routing between the Logical Switches and, consequently, enable routing for the related subnets—in Amazon VPC you associate VPC subnets with <a href="https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Route_Tables.html">VPC route tables</a>.</p> 
<p>Each subnet within a VPC is associated with exactly one route table, which determines the Layer 3 forwarding rules for all packets originating from ENIs associated with the subnet. Each route table can be associated with multiple subnets of the VPC, and route tables have a scope of the entire VPC. Hence, you can associate a Route Table with any subnet of the VPC, irrespective of what Availability Zone the subnet is created in.</p> 
<p>Each VPC can have multiple route tables to govern different forwarding behavior for various subnets of the VPC. For example, private subnets might have route tables with a default route to an&nbsp;<a href="http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/vpc-nat-gateway.html">NAT Gateway</a>, and public subnets might be associated with route tables with a default route to the VPC Internet Gateway. This is analogous to having multiple DLRs in an NSX tenant network to govern different routing behavior for traffic from different logical switches.</p> 
<p>A route table in a VPC thus represents a logical router which performs packet forwarding for all subnets associated with it. Just like the DLRs, the route table function is embedded in the virtualization infrastructure and can handle traffic sent to the default gateway of the VPC subnets.</p> 
<p>In the three-tier application shown in <em>Figure 4,</em> the web, app, and database tiers are deployed in private subnets. By definition, the route table associated with these private subnets (route table 2) does not have a route to the Internet Gateway, and the application instances in these tiers do not have direct access to the Internet. Similarly, packets from the Internet cannot directly reach the application instances. On the other hand, ELB nodes are deployed in public subnets which are associated with a route table (route table 1) that has a route to the Internet Gateway, providing access to the ELB nodes.</p> 
<p>An important distinction from NSX-based networking topologies is that each route table always has a local route to the VPC CIDR and this route cannot be removed or modified. Longest prefix match (LPM) rules do not apply to the VPC CIDR route.</p> 
<p>Consequently, all traffic in the VPC with Layer 3 destinations in the VPC CIDR are always forwarded directly to the destination. This is applicable to all traffic destined to IP addresses of the interfaces associated with instances, Internet, and VPN Gateway, or VPC interface endpoints. This means that for the three-tier application in <em>Figure 4</em>, despite being associated with different route tables, the ELB nodes and instances deployed in the web, app, and database tiers can communicate with each other. This enables normal application traffic flow from the Internet to the ELB nodes, and from the ELB nodes to the instances in the web tier, and vice versa.</p> 
<p>You can still use <a href="https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_SecurityGroups.html">VPC security groups</a> to segment traffic within a VPC subnet and VPC Network ACLs to filter traffic to/from a VPC subnet. However, you cannot insert a firewall appliance or load balancer appliance as a next-hop for any traffic between interfaces in the VPC.</p> 
<p>Another point of note is that the same route table can handle both IPv4 and IPv6 routes. You can modify the forwarding behavior for the route table by adding static routes to it. As I discussed previously, the static routes cannot conflict with the VPC CIDR. It is possible to route traffic for destination prefixes to next-hops within the VPC, like Internet Gateway (IGW), VPN Gateway, VPC endpoints, VPC peers, or other ENIs in the VPC. We will discuss many of these VPC components in my next blog post.</p> 
<b>Under the Hood: Amazon VPC Forwarding and Control Planes</b> 
<p>So how does the forwarding and control plane for Amazon VPC work? The AWS re:Invent session titled <a href="https://www.youtube.com/watch?v=8gc2DgBqo9U">Another Day, Another Billion Flows</a>&nbsp;describes the control and forwarding planes of VPC, interaction of VPC with external networks,&nbsp;and&nbsp;flow tracking capabilities implemented within a VPC.</p> 
<p>All communication within the VPC is unicast. Similar to the Address Resolution Protocol (ARP) suppression mechanism in NSX Logical Switches, all ARP requests are suppressed and replied to locally in Amazon VPC. Again, just like how DHCP packets are handled, you don’t need to think about how ARP broadcast packets will be handled on the physical network.</p> 
<p>The VPC forwarding mechanism looks up the packet from the ENIs and, using the Mapping Service, makes a forwarding decision to the destination. Like the NSX controllers, the Mapping Service holds the forwarding information used by VPC forwarding components in the virtualization infrastructure. All packets are encapsulated using VPC encapsulation at the virtualization layer. The VPC encapsulation carries additional information like source and destination ENIs and VPC ID to the encapsulated packet.</p> 
<p>You can now relate to the control, forwarding, and encapsulation techniques used in Amazon VPC. Suddenly, VPC networking looks much familiar, doesn’t it?</p> 
<b>Amazon VPC Management Plane</b> 
<p>NSX networks are managed through VMware NSX Manager APIs and through the Networking and Security plugin within vCenter. Similarly, management of Amazon VPC is programmatic and API-driven as well. Amazon VPCs are managed using the AWS Management Console, <a href="https://docs.aws.amazon.com/AWSEC2/latest/APIReference/Welcome.html">Amazon VPC APIs</a>, and&nbsp;<a href="https://aws.amazon.com/tools/#sdk">AWS Software Development Kits</a> (SDKs). AWS has region-specific HTTPS API endpoints available for managing Amazon VPC and its components.</p> 
<b>Conclusion</b> 
<p>Now that you have a good understanding of the major VPC components, I recommend you create a VPC from scratch using the <a href="https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/working-with-vpcs.html">documentation here</a>, which will help you consolidate many of the concepts introduced in this blog.</p> 
<p>In my next post, I will discuss external connectivity options for connecting services deployed within a VPC to the Internet, corporate networks using VPN technologies, other VPCs using VPC peering, and to AWS and other partner services using VPC endpoints. I will also discuss security components within a VPC.</p> 
<p>See you next time!</p> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-6537');
});
</script> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<meta property="image" content="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/02/13/Training-and-Certification-1.jpg" /> 
<b class="lb-b blog-post-title" property="name headline">New AWS Solutions Training for Partners: Desktop and Application Streaming</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Andrew Kloman</span></span> | on 
<time property="datePublished" datetime="2018-03-16T08:35:40+00:00">16 MAR 2018</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/apn/category/aws-partner-network/" title="View all posts in AWS Partner Network*"><span property="articleSection">AWS Partner Network*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/desktop-app-streaming/" title="View all posts in Desktop &amp; App Streaming*"><span property="articleSection">Desktop &amp; App Streaming*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/apn/new-aws-solutions-training-for-partners-desktop-and-application-streaming/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-6564" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-apn-blog&amp;disqus_identifier=6564&amp;disqus_title=New+AWS+Solutions+Training+for+Partners%3A+Desktop+and+Application+Streaming&amp;disqus_url=https://aws.amazon.com/blogs/apn/new-aws-solutions-training-for-partners-desktop-and-application-streaming/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-6564');
});
</script> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><em>By Andrew Kloman,&nbsp;Partner Solutions Architect at AWS focused on End User Computing</em></p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/02/13/Training-and-Certification-1-300x150.jpg">AWS Partner Network</a> (APN) Partners—Amazon Desktop and Application Streaming for Technical and Business Professionals.</p> 
<p>These courses are intended for APN Partners who work with desktop applications hosted on Amazon Web Services (AWS). The courses are delivered through a mix of web-based training and demonstrations of product features and functionality, and includes an assessment to validate what was covered.</p> 
<b>Register (Partner Central login required)</b> 
<li><a href="https://www.aws.training/learningobject/curriculum?id=18554"><strong>AWS Solutions Training for Partners: Desktop and Application Streaming – Technical &gt;&gt;</strong></a></li> 
<li><strong><a href="https://www.aws.training/learningobject/curriculum?id=18414">AWS Solutions Training for Partners: Desktop and Application Streaming – Business &gt;&gt;</a></strong></li> 
<b>About the Training</b> 
<h3><strong>Desktop and Application Streaming – Technical</strong></h3> 
<p>This course teaches you about the capabilities of <a href="https://aws.amazon.com/workspaces/">Amazon WorkSpaces </a>and <a href="https://aws.amazon.com/appstream2/">Amazon AppStream 2.0</a>, guiding you to set up the solution within your AWS account. You will learn the technical details of provisioning, configuring, and managing Amazon WorkSpaces and AppStream2.0.</p> 
<p>This course covers:</p> 
<li>Introduction to Amazon WorkSpaces and AppStream 2.0</li> 
<li>Features and benefits of Amazon WorkSpaces and AppStream 2.0</li> 
<li>Considerations for networking, security, image/bundle management, and governance.</li> 
<li>Prerequisites for deploying each solution within your AWS account.</li> 
<li>Deep dive into the features of Amazon WorkSpaces and AppStream 2.0</li> 
<li>Demonstrations of deploying Amazon WorkSpaces and AppStream 2.0 in your AWS account.</li> 
<p><a href="https://www.aws.training/learningobject/curriculum?id=18554"><strong>Register for the Technical training here &gt;&gt;</strong></a></p> 
<h3><strong>Desktop and Application Streaming – Business</strong></h3> 
<p>This covers the following concepts:</p> 
<li>Overview of End User Computing on AWS and the market opportunity</li> 
<li>Identifying opportunities and building an End User Computing practice on AWS</li> 
<li>Understanding pricing models</li> 
<li>Positioning AWS for customers’ needs</li> 
<li>Use cases and case studies</li> 
<p><strong><a href="https://partnercentral.awspartner.com/LmsSsoRedirect?RelayState=%2flearningobject%2fcurriculum%3fid%3d18414">Register for the Business training here &gt;&gt;</a></strong></p> 
<b>Prerequisites</b> 
<p>We recommend that attendees have the following prerequisites before registering for the new Desktop and Application Streaming courses:</p> 
<li>Familiarity with desktop application management and cloud computing concepts</li> 
<li><a href="https://aws.amazon.com/partners/training/accreditation/#AWS_Business_Professional">AWS Business Professional</a> and <a href="https://aws.amazon.com/partners/training/accreditation/#AWS_Technical_Professional">AWS Technical Professional</a> training</li> 
<li><a href="https://aws.amazon.com/partners/training/accreditation/#AWS_TCO_Economics">AWS Total Cost of Ownership (TCO) and Cloud Economics</a></li> 
<li>AWS Solutions Training for Partners: 
<li><a href="https://partnercentral.awspartner.com/LmsSsoRedirect?RelayState=%2flearningobject%2fcurriculum%3fid%3d11644">AWS for Windows Business</a> (Online)</li> 
<li><a href="https://partnercentral.awspartner.com/LmsSsoRedirect?RelayState=%2flearningobject%2fcurriculum%3fid%3d13965">AWS for Windows Technical</a>&nbsp;(Online)</li> 
<li><a href="https://partnercentral.awspartner.com/LmsSsoRedirect?RelayState=%2flearningobject%2fcurriculum%3fid%3d14875">Best Practices: Well-Architected</a></li> 
</ul> </li> 
<b>Learn More About the AWS Partner Network (APN)</b> 
<p>The APN is the global partner program for AWS and is focused on helping APN Partners build successful AWS-based businesses or solutions. As an APN Partner, you will receive business, technical, sales, and marketing resources to help you grow your business and better support your customers.</p> 
<p><strong><a href="https://aws.amazon.com/partners/">See all the benefits of being an APN Partner &gt;&gt;</a></strong></p> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-6564');
});
</script> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<meta property="image" content="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/02/07/Say-Hello.jpg" /> 
<b class="lb-b blog-post-title" property="name headline">Say Hello to 10 New and 9 Renewed AWS Competency Partners Added in February</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Stephanie Lawson</span></span> | on 
<time property="datePublished" datetime="2018-03-12T15:24:56+00:00">12 MAR 2018</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/apn/category/aws-partner-network/" title="View all posts in AWS Partner Network*"><span property="articleSection">AWS Partner Network*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/awsquest/" title="View all posts in AWS Quest*"><span property="articleSection">AWS Quest*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/apn/say-hello-to-10-new-and-9-renewed-aws-competency-partners-added-in-february/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-6517" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-apn-blog&amp;disqus_identifier=6517&amp;disqus_title=Say+Hello+to+10+New+and+9+Renewed+AWS+Competency+Partners+Added+in+February&amp;disqus_url=https://aws.amazon.com/blogs/apn/say-hello-to-10-new-and-9-renewed-aws-competency-partners-added-in-february/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-6517');
});
</script> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><em>By Stephanie Lawson, Partner Program Marketing Manager at AWS</em></p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/02/07/AWS-Competency_thumbnail-300x150.png">AWS Competency Program</a> admitted 10 new AWS Partner Network (APN) Partners in February—spanning workload, solution, and industry designations. Please join us in welcoming our newest AWS Competency Partners!</p> 
<p>The AWS Competency Program provides customers with highlighted APN Partners that have demonstrated technical proficiency through an AWS Technical Validation and proven customer success in specialized solution areas.</p> 
<p><a href="https://aws.amazon.com/partners/competencies/">View all AWS Competencies and designated APN Partners &gt;&gt;</a></p> 
<b><a href="https://aws.amazon.com/devops/partner-solutions/">AWS DevOps Competency</a></b> 
<h3><em>Consulting Partners</em></h3> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/12/Classmethod-Logo-150x150.jpg" /></p> 
<h3><a href="https://aws.amazon.com/partners/find/partnerdetails/?n=Classmethod&amp;id=001E000000Rl0wJIAR">Classmethod</a></h3> 
<p>Headquartered in Japan, Classmethod helps clients establish DevOps processes for source code management, testing, deployment, and more. With their extensive experience, they help customers choose the right tools and get managed services up and running.</p> 
<p><a href="https://classmethod.jp/services/members/aws-consulting/">DevOps Practice</a> |&nbsp;<a href="https://classmethod.jp/cases/bamiyan-app/">Customer Success</a> |&nbsp;<a href="https://pages.awscloud.com/partner-connect.html?partner-name=001E000000Rl0wJIAR">Contact</a></p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/12/eCloudValley-Logo-150x150.jpg" /></p> 
<h3><a href="https://aws.amazon.com/partners/find/partnerdetails/?n=Ecloudvalley&amp;id=001E000000jD1zaIAC&amp;t=psf-overview">eCloudvalley</a></h3> 
<p>As a born-in-the-cloud APN Premier Consulting Partner, eCloudvalley focuses on AWS and has&nbsp;more than 100 AWS certifications.&nbsp;Their team of experts helps customers launch successful cloud initiatives to quicken go-to-market speeds, automate and strengthen security, increase stakeholder value, improve customer experiences, and lower costs.</p> 
<p><a href="https://www.ecloudvalley.com/">Practice Overview</a> | <a href="https://pages.awscloud.com/partner-connect.html?partner-name=001E000000jD1zaIAC">Contact</a></p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/12/JHC-Technology-Logo-150x150.jpg" /></p> 
<h3><a href="https://aws.amazon.com/partners/find/partnerdetails/?n=JHC%20Technology%2C%20Inc.&amp;id=001E000000Rl0x6IAB">JHC Technology Inc.</a></h3> 
<p>JHC offers faster feature delivery by shrinking the developer feedback loop, quick responses to stakeholder requirements and feedback, improved quality control with automated build, test, and deployment pipeline; and auto scaling, self-healing infrastructure.</p> 
<p><a href="http://www.jhctechnology.com/what-we-do/agile-devops-orchestration/">Practice Overview</a> | <a href="http://www.jhctechnology.com/wp-content/uploads/2018/01/TNTP_CaseStudy_021017.pdf">Customer Success</a> | <a href="https://pages.awscloud.com/partner-connect.html?partner-name=001E000000Rl0x6IAB">Contact</a></p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/12/Polar-Seven-Logo-150x150.jpg" /></p> 
<h3><a href="https://aws.amazon.com/partners/find/partnerdetails/?n=PolarSeven&amp;id=001E000000Xd2auIAB">PolarSeven</a></h3> 
<p>PolarSeven excels in DevOps, a proven method wherein software developers collaborate closely with operations. By working together on the entire product lifecycle, these teams create a quicker, more agile, and more competitive IT delivery.</p> 
<p><a href="https://polarseven.com/what-we-do/devops/">Practice Overview</a> | <a href="https://polarseven.com/success-stories/hey-case-study/">Customer Success</a> | <a href="https://pages.awscloud.com/partner-connect.html?partner-name=001E000000Xd2auIAB">Contact</a></p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/12/RightCloud-Logo-150x150.jpg" /></p> 
<h3><a href="https://aws.amazon.com/partners/find/partnerdetails/?n=RightCloud%20Pte%20Ltd&amp;id=001E000001KbrhpIAB">RightCloud</a></h3> 
<p>Leveraging Agile and DevOps methodologies, cultures, and principles to boost productivity, RightCloud provides a set of flexible services designed to enable customers to more rapidly and reliably build and deliver products using DevOps practices.</p> 
<p><a href="http://www.rightcloud.asia/devops.html">DevOps on AWS</a> | <a href="http://www.rightcloud.asia/jollibees-devops-journey.html">Customer Reference</a> | <a href="https://pages.awscloud.com/partner-connect.html?partner-name=001E000001KbrhpIAB">Contact</a></p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/12/Storm-Reply-Logo-150x150.jpg" /></p> 
<h3><a href="https://aws.amazon.com/partners/find/partnerdetails/?n=Storm%20Reply&amp;id=001E000000NaBI4IAN">Storm Reply</a></h3> 
<p>Storm Reply uses automation tools and best practices as a core service for Managed Service Provider solutions. They manage applications on customers’ behalf using a DevOps approach to speed up operations.</p> 
<p><a href="http://www.reply.com/storm-reply/en/#/storm-reply/en/content/automated-operation">DevOps Practice</a> | <a href="http://www.reply.com/en/lavazza-highly-scalable-ecommerce-platform">Customer Reference</a> | <a href="https://pages.awscloud.com/partner-connect.html?partner-name=001E000000NaBI4IAN">Contact</a></p> 
<b><a href="https://aws.amazon.com/government-education/partner-solutions/">AWS&nbsp;Government Competency</a></b> 
<h3><em>Consulting Partners</em></h3> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/12/General-Dynamics-IT-Logo-150x150.jpg" /></p> 
<h3><a href="https://aws.amazon.com/partners/find/partnerdetails/?n=General%20Dynamics%20Information%20Technology&amp;id=001E000000gL3HHIA0">General Dynamics Information Technology</a></h3> 
<p>As a trusted systems integrator for more than 50 years, GDIT provides technology services to customers across U.S. federal, state, and commercial sectors. They deliver large scale enterprise solutions and service support&nbsp;for the AWS Cloud.</p> 
<p><a href="http://www.gdit.com/cloudsolutions">Practice Overview</a> | <a href="https://pages.awscloud.com/partner-connect.html?partner-name=001E000000gL3HHIA0">Contact</a></p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/12/Cloudten-Logo-150x150.jpg" /></p> 
<h3><a href="https://aws.amazon.com/partners/find/partnerdetails/?n=Cloudten%20Industries&amp;id=001E000000yQVaCIAW">Cloudten Industries</a></h3> 
<p>Cloudten’s AWS-certified staff are specialists in all aspects of cloud architecture, including security and application integration. Working closely with AWS and leading vendors, Cloudten delivers end-to-end competencies to help organizations build flexible, highly available, resilient, and efficient cloud environments.</p> 
<p><a href="http://www.cloudten.com.au/government">Practice Overview</a> | <a href="https://pages.awscloud.com/partner-connect.html?partner-name=001E000000yQVaCIAW">Contact</a></p> 
<b><a href="https://aws.amazon.com/partners/competencies/sap/">AWS&nbsp;SAP Competency</a></b> 
<h3><em>Consulting Partners</em></h3> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/12/BNW-Logo-150x150.jpg" /></p> 
<h3><a href="https://aws.amazon.com/partners/find/partnerdetails/?n=BNW%20Consulting%20Pty%20Ltd&amp;id=0010L00001kW0R9QAK">BNW Consulting</a></h3> 
<p>BNW delivers consulting, managed services, and software solutions to customers in the enterprise as well as SMB market. They have been doing SAP technology projects since 1996 and delivered more than 200 SAP migrations to the cloud.</p> 
<p><a href="https://www.bnwconsulting.com.au/">Practice Overview</a> | <a href="https://aws.amazon.com/solutions/case-studies/visy/">Customer Success</a> | <a href="https://pages.awscloud.com/partner-connect.html?partner-name=0010L00001kW0R9QAK">Contact</a></p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/12/Velocity-Logo-150x150.jpg" /></p> 
<h3><a href="https://aws.amazon.com/partners/find/partnerdetails/?n=Velocity%20Technology%20Solutions&amp;id=001E000001N7nNJIAZ">Velocity Technology Solutions</a></h3> 
<p>Velocity hosts and manages customers’ SAP systems,&nbsp;offering reliable and secure performance, up-to-date SAP applications, and a solution customized for their business requirements. Velocity provides customers with rapid implementation of the latest software releases.</p> 
<p><a href="https://velocitycloud.com/expertise/sap">Practice Overview</a> | <a href="https://velocitycloud.com/press/bcbg-and-velocity-complete-sap-cloud-services-expansion">Customer Success</a> | <a href="https://pages.awscloud.com/partner-connect.html?partner-name=001E000001N7nNJIAZ">Contact</a></p> 
<hr /> 
<b>Renewed AWS Competency Partners in February</b> 
<b><a href="https://aws.amazon.com/big-data/partner-solutions/">AWS&nbsp;Big Data Competency</a></b> 
<h3><em>Consulting Partners</em></h3> 
<li><a href="https://aws.amazon.com/partners/find/partnerdetails/?n=CloudMas&amp;id=001E000000UfZqHIAV">CloudMas</a></li> 
<li><a href="https://aws.amazon.com/partners/find/partnerdetails/?n=Onica&amp;id=001E000000heMPCIA2">Onica</a></li> 
<li><a href="https://aws.amazon.com/partners/find/partnerdetails/?n=Pariveda%20Solutions%20Inc.&amp;id=001E000000NaBHsIAN">Pariveda</a></li> 
<li><a href="https://aws.amazon.com/partners/find/partnerdetails/?n=Storm%20Reply&amp;id=001E000000NaBI4IAN">Storm Reply</a></li> 
<li><a href="https://aws.amazon.com/partners/find/partnerdetails/?n=TO%20THE%20NEW&amp;id=001E000000dHs9dIAC">TO THE NEW</a></li> 
<h3><em>Technology Partners</em></h3> 
<li><a href="https://aws.amazon.com/partners/find/partnerdetails/?n=Looker&amp;id=001E000000kC9lnIAC">Looker</a></li> 
<li><a href="https://aws.amazon.com/partners/find/partnerdetails/?n=Treasure%20Data&amp;id=001E000000Rp5OSIAZ">Treasure Data</a></li> 
<li><a href="https://aws.amazon.com/partners/find/partnerdetails/?n=TIBCO&amp;id=001E000000Rl0y8IAB">TIBCO</a></li> 
<li><a href="https://aws.amazon.com/partners/competencies/sap/">SAP</a></li> 
<hr /> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/14/aws_partner_network_blog_01-1024x21.png" /></p> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-6517');
});
</script> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<meta property="image" content="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/11/14/AWS-Marketplace_border.png" /> 
<b class="lb-b blog-post-title" property="name headline">See What’s New for AWS Marketplace Sellers</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Brad Lyman</span></span> | on 
<time property="datePublished" datetime="2018-03-09T15:08:57+00:00">09 MAR 2018</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/apn/category/software/aws-marketplace/" title="View all posts in AWS Marketplace*"><span property="articleSection">AWS Marketplace*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/aws-partner-network/" title="View all posts in AWS Partner Network*"><span property="articleSection">AWS Partner Network*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/apn/see-whats-new-for-aws-marketplace-sellers/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-6497" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-apn-blog&amp;disqus_identifier=6497&amp;disqus_title=See+What%26%238217%3Bs+New+for+AWS+Marketplace+Sellers&amp;disqus_url=https://aws.amazon.com/blogs/apn/see-whats-new-for-aws-marketplace-sellers/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-6497');
});
</script> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><em>By Brad Lyman, Principal Product Manager at AWS</em></p> 
<p><strong><a href="https://aws.amazon.com/marketplace"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/11/14/AWS-Marketplace_border-300x150.png">AWS Marketplace</a> released more than a dozen major features in 2017, as well as many other enhancements and updates. These releases make it easier for Amazon Web Services (AWS) customers to discover and procure software, and for Independent Software Vendors (ISVs) to sell their products on AWS Marketplace.</p> 
<p>AWS Marketplace currently offers more than 4,200 software listings from nearly 1,300 ISVs spanning 35 categories. More than 160,000 active AWS customers use 481 million hours a month of <a href="https://aws.amazon.com/ec2/">Amazon Elastic Compute Cloud</a> (Amazon EC2) for AWS Marketplace products. That’s a lot of activity, and I will describe how&nbsp;our new features enable you, as a seller, to enhance your offerings to AWS customers.</p> 
<p>Did you know we continually update our documentation, including the <a href="http://awsmp-loadforms.s3.amazonaws.com/AWS_Marketplace_-_Seller_Guide.pdf">AWS Marketplace Seller Guide</a>? Or that we&nbsp;post new announcements on the <a href="https://aws.amazon.com/marketplace/management/">AWS Marketplace Management Portal</a> (AMMP)?&nbsp;In case you missed any announcements,&nbsp;here’s a&nbsp;recap of new features that are relevant to ISVs and AWS Partner Network (APN) Partners.</p> 
<p>This post also assumes you have access to AMMP as a registered seller. If not and you want to become a registered seller, here’s how to <a href="https://aws.amazon.com/marketplace/management/register/">begin the registration process</a>.</p> 
<b>Global AWS Marketplace Metering Service Availability</b> 
<p>When we launched the AWS Marketplace Metering Service (MMS) in 2016, we focused on just a few regions. Last year, we completed our global rollout so you can send metering records for Amazon Machine Images (AMIs) or software-as-a-service (SaaS) products to any public AWS region. If you were already sending metering records, this feature was automatically enabled.</p> 
<b>Self-Service Listings for Editing Existing Products</b> 
<p>We have enabled you to edit many of your existing products using self-service tools within AMMP. Previously, you had to use a spreadsheet to upload or modify products. To access Self-Service Listings, log in to AMMP and choose the Listings tab.</p> 
<b>Tax Calculation Service</b> 
<p>This feature enables AWS to calculate and collect sales and use tax on your behalf. Log in to AMMP to take advantage of this feature; under the Settings tab, choose Tax Calculation Service. Once configured, we automatically calculate and collect sales and use tax based on your customers’ location, and provide you with tax data through the U.S. Sales Tax Report.</p> 
<b>SaaS Contracts</b> 
<p>We announced SaaS Contracts during the AWS Summit in San Francisco. This feature enables customers to enter into long-term (monthly, 1-, 2-, or 3-year) contracts for SaaS products. Customers can increase the size of their contract, and AWS Marketplace automatically calculates the prorated upgrade price. It’s also easy for customers to agree to automatic renewals. Check details using <a href="https://aws.amazon.com/documentation/marketplace/">AWS Marketplace APIs</a>, and for more information see our SaaS Onboarding Guide, available in AMMP.</p> 
<b>Log Metering Records with AWS CloudTrail</b> 
<p>We heard from SaaS sellers that you need better visibility into the metering records you send to MMS. That’s why we integrated MMS with AWS CloudTrail, so now every successful metering record is logged and stored using <a href="http://aws.amazon.com/cloudtrail">AWS CloudTrail</a>. If you are a SaaS seller that has enabled CloudTrail, this feature was automatically enabled. Learn more about our <a href="https://docs.aws.amazon.com/marketplacemetering/latest/APIReference/Welcome.html">AWS Marketplace Metering Service API</a>.</p> 
<b>Self-Service Listings for SaaS Products</b> 
<p>When we launched SaaS Contracts, sellers still had to rely on a spreadsheet for uploading product details. Self-Service Listings enables you to take advantage of self-service tools to manage listings. You can find more by logging into AMMP and choosing the Listings tab.</p> 
<b>GovCloud Deployments</b> 
<p>In 2017, we launched support for GovCloud deployments. <a href="https://docs.aws.amazon.com/govcloud-us/latest/UserGuide/welcome.html">AWS GovCloud (US)</a> is an isolated AWS region designed to allow U.S. government agencies and customers to move sensitive workloads into the cloud by addressing specific regulatory and compliance requirements. This feature enables sellers to offer products to GovCloud users by simplifying the discovery of GovCloud-accessible products and easing the deployment of these into the region. To take advantage of this feature, you must show that your product has the proper clearance. For more information, read our <a href="http://docs.aws.amazon.com/govcloud-us/latest/UserGuide/govcloud-us-ug.pdf">AWS GovCloud (US) User Guide</a>.</p> 
<b>Cost and Budgets Support for AWS Marketplace</b> 
<p>As customers move more of their workloads to the cloud, it’s important to understand how budgets are being used. Customers can now visualize their AWS Marketplace costs and usage in <a href="https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/cost-explorer-what-is.html">Cost Explorer</a>, dive deeper into usage patterns using <a href="https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/billing-reports-costusage.html">Cost and Usage Reporting</a>, and set budgets on their AWS Marketplace costs and usage. This feature is automatically available for your products and requires no additional work from you. Customers received this feature automatically at no charge.</p> 
<b>Multi-AMI Solutions</b> 
<p>This feature enables you to offer solutions that contain multiple AMIs. Customers will be able to browse your multi-AMI solutions on AWS Marketplace, subscribe with one click, and deploy using <a href="http://aws.amazon.com/cloudformation">AWS CloudFormation</a> templates that you provide. For customers, subscribing to a single solution entitles them to use all AMIs contained in that solution and pay based on the pricing model set for each AMI. More information is available in the guide for <a href="https://s3.amazonaws.com/awsmp-loadforms/awsmp-ami-delivery-using-cloudformation.pdf">AMI-Based Product Delivery Using AWS CloudFormation</a>.</p> 
<b>Seller Private Offers</b> 
<p>This feature enables you to offer products on AWS Marketplace with customer-specific pricing and legal terms. Using a public product as a starting point, you can change prices and upload a PDF of the legal terms for a specific purchase. This feature is only available for sellers in the <a href="https://s3.amazonaws.com/awsmp-loadforms/guides/AWS-Marketplace-Enhanced-Data-Sharing-Program-Guide.pdf">AWS Marketplace Enhanced Data Sharing Program</a>, which is reserved for sellers who compensate their salespeople for AWS Marketplace purchases.</p> 
<b>AWS PrivateLink on AWS Marketplace</b> 
<p><a href="https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/vpce-interface.html">AWS PrivateLink</a> enables customers to pass data to a SaaS application without ever leaving the Amazon network. AWS Marketplace makes it easier for customers to find your products that support AWS PrivateLink, and configure a PrivateLink connection by providing seller-specified DNS names. This feature requires you to configure your SaaS application for PrivateLink. Learn more in the <a href="http://awsmp-loadforms.s3.amazonaws.com/AWS_Marketplace_-_Seller_Guide.pdf">AWS Marketplace Seller Guide</a>.</p> 
<b>Seller Reporting Enhancements</b> 
<p>We have made several enhancements to AWS Marketplace seller reporting. This includes reporting updates for new features types, such as adding support for Multi-AMI Solutions, SaaS Contracts, and Private Offers. We also made updates to the reports we offer for registered Channel Partners. This additional information is automatically available through seller reports. To view your reports, log in to AMMP and choose the Reports tab. Documentation for each report is available in the <a href="http://aws-marketplace-reports.s3.amazonaws.com/reports-data-dictionary.pdf">Data Dictionary</a>.</p> 
<b>Managed Rulesets on AWS Marketplace</b> 
<p>When AWS launched <a href="https://docs.aws.amazon.com/waf/latest/developerguide/what-is-aws-waf.html">AWS WAF</a>, a web application firewall that lets you monitor HTTP and HTTPS requests, AWS Marketplace added support for Managed WAF Rulesets. Sellers on AWS Marketplace can now provide customers with rulesets that are deployed directly in a customer’s fully managed solution. Learn more about how to vend a managed ruleset at <a href="https://docs.aws.amazon.com/waf/latest/developerguide/waf-managed-rule-groups.html">AWS Marketplace Rule Groups</a>.</p> 
<b>Enhanced Product Detail Page</b> 
<p>We added support for rich media content on our product detail page, including adding up to five videos and/or screenshots for helping customers understand your product. The rich media features are currently limited to sellers participating in the beta program, as it requires sellers to provide additional content. The self-service tools are in development and the feature will be available to all AWS Marketplace vendors once the toolset is finalized.</p> 
<p>All in all,&nbsp;we have launched a host&nbsp;of new features and enhancements for AWS Marketplace customers and sellers. Let us know if there are features you’d like to learn more about or if you have an idea for a feature we should consider adding. The AWS Marketplace team is already hard at work on the features we’ve heard our customers want to see in 2018.</p> 
<p>Stay tuned for more announcements!</p> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-6497');
});
</script> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<meta property="image" content="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/08/Batch.jpg" /> 
<b class="lb-b blog-post-title" property="name headline">How to Migrate Mainframe Batch to Cloud Microservices with Blu Age and AWS</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Phil de Valence</span></span> | on 
<time property="datePublished" datetime="2018-03-09T09:08:46+00:00">09 MAR 2018</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/apn/category/application-services/amazon-api-gateway-application-services/" title="View all posts in Amazon API Gateway*"><span property="articleSection">Amazon API Gateway*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/database/amazon-aurora/" title="View all posts in Amazon Aurora*"><span property="articleSection">Amazon Aurora*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/database/amazon-elasticache/" title="View all posts in Amazon ElastiCache*"><span property="articleSection">Amazon ElastiCache*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/storage/amazon-glacier/" title="View all posts in Amazon Glacier*"><span property="articleSection">Amazon Glacier*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/analytics/amazon-kinesis/" title="View all posts in Amazon Kinesis*"><span property="articleSection">Amazon Kinesis*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/storage/amazon-simple-storage-services-s3/" title="View all posts in Amazon Simple Storage Services (S3)*"><span property="articleSection">Amazon Simple Storage Services (S3)*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/compute/aws-lambda/" title="View all posts in AWS Lambda*"><span property="articleSection">AWS Lambda*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/management-tools/aws-managed-services/" title="View all posts in AWS Managed Services*"><span property="articleSection">AWS Managed Services*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/aws-partner-network/" title="View all posts in AWS Partner Network*"><span property="articleSection">AWS Partner Network*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/migration/" title="View all posts in Migration*"><span property="articleSection">Migration*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/serverless/" title="View all posts in Serverless*"><span property="articleSection">Serverless*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/apn/how-to-migrate-mainframe-batch-to-cloud-microservices-with-blu-age-and-aws/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-6474" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-apn-blog&amp;disqus_identifier=6474&amp;disqus_title=How+to+Migrate+Mainframe+Batch+to+Cloud+Microservices+with+Blu+Age+and+AWS&amp;disqus_url=https://aws.amazon.com/blogs/apn/how-to-migrate-mainframe-batch-to-cloud-microservices-with-blu-age-and-aws/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-6474');
});
</script> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><em>By Alexis Henry, Chief Technology Officer at Blu Age</em></p> 
<p><a href="https://aws.amazon.com/partners/find/partnerdetails/?n=BluAge&amp;id=0010L00001kWbLPQA0"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/08/Batch-300x150.jpg">Blu Age</a> discovered that Batch can be a very complex aspect of a mainframe migration to Amazon Web Services (AWS). It often dictates whether a mainframe migration is successful or not. To succeed in a transition to microservices, it is critical to design your AWS architecture to account for the key Batch stringent performance requirements such as intensive I/Os, large datasets, and short durations.</p> 
<p>In this post, I will describe how to migrate mainframe Batch to AWS microservices using Blu Age automated transformation technology.</p> 
<p>Customers choose microservices aiming for more agility, innovation, quality, scalability, and availability. Despite all these advantages, a microservices approach introduces operational complexity. AWS has a number of offerings that address important challenges of microservices architectures: <a href="https://aws.amazon.com/managed-services/">Managed Services</a>, service orientation, programming languages polyglot, on-demand resources, infrastructure as code, and continuous delivery, among others.</p> 
<p>Experience is still growing on microservices topics. Much of the existing technical literature describe microservices in the context of new applications or peeling monoliths, such as transitioning Java or client/server applications. However, most of the existing worldwide IT relies on mainframe monoliths. Many corporations and public agencies are looking for strategies to migrate their mainframe to cloud microservices, minimizing project risk, duration, and cost.</p> 
<b>Mainframe Batch</b> 
<p>Batch processing usually involves bulk processing of data&nbsp;that could not be processed in real-time due to the limited capabilities of transactional engines at the time of their initial design and implementation. Batch software design was predicated on the constraints and assumptions of the mainframe environment, such as high CPU power for mono thread application, locking of I/O to data storage—which prevents concurrent processing of Batch and transaction—and higher Total Cost of Ownership (TCO) for provisioning nightly CPU peaks. Those constraints are still directly influencing Million Instructions Per Second (MIPS) estimation, cost, and operational model.</p> 
<p>A more efficient and cost optimized architecture is now available with AWS. It can be achieved by transforming legacy Batch processes to real-time microservices, leveraging <a href="https://aws.amazon.com/kinesis">Amazon Kinesis</a> for data streaming, <a href="https://aws.amazon.com/api-gateway">Amazon API Gateway</a> for service invocation, and <a href="http://aws.amazon.com/lambda">AWS Lambda</a> and serverless computing for compute and storage.</p> 
<p>In the following example, I will explain how to transition a typical retail banking mainframe application from the dual Online/Batch model toward real-time microservices combining AWS services and Blu Age modernization technology.</p> 
<b>Example: Mainframe Legacy Batch Architecture</b> 
<p>In <em>Figure 1</em>, we use an example mainframe Batch architecture that we will transform into a microservice architecture in later sections. This typical scenario shows a mainframe legacy system using z/OS CICS, JCL, Cobol, DB2, VSAM files, GDG files, and tapes.</p> 
<img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/07/Mainframe-Legacy-Batch-Architecture-1024x881.jpg" /> 
<p class="wp-caption-text"><em>Figure 1 – Mainframe legacy Batch architecture example.</em></p> 
<p>The Batch programs have been designed to avoid multiple user locking and waiting for transaction responses. During the day, loan request transactions append transaction data to a temporary file, with one file per physical office. At night, CICS transactions that share data with Batches are switched off to avoid concurrency, locks, and consistency issues.</p> 
<h3>There are three Batch programs:</h3> 
<ol> 
<li>Every five minutes, the Upload Batch program sends all temporary files to the Batch region via message queuing.</li> 
<li>Every night, the Loan Batch program is triggered by the scheduler. It executes the following logic: 
<li>All files are merged into one</li> 
<li>The merged file is then sorted to improve performance and prepare the next processing steps</li> 
<li>Each record in the sorted file are processed for enrichment (personal information about credit history and other loans are collected from DB2 and injected into the enriched record)</li> 
<li>Each record is enriched a second time by injecting risk assessment information from a VSAM file, resulting in an enriched file with all the information required to perform risk analysis and grant or reject loan request</li> 
<li>Each record in previous output file is processed, and eventually COBOL programs create three outputs: A copy of unprocessed/rejected records which will need further processing (parsing error, missing elements, fails); an update of records in a DB2 table for each customer requesting a loan with current status (rejected, approved, pending) and loan proposal only for approved requests (rates, duration, etc.); and audit information (who, what, when, where) is traced into mainframe Generation Data Groups (GDG) files.</li> 
</ul> </li> 
<li>Every week, the Archiving Batch is triggered to save some GDG data to tape devices (for legal reasons), and to prune GDG (removal of files sent to tapes).</li> 
</ol> 
<b>Transforming Batch Logic to Microservices with Blu Age Velocity</b> 
<p>Blu Age technology accelerates legacy application modernization with automation for both reverse-engineering of the legacy procedural mainframe applications (code + data) as well as forward-engineering to new microservice-ready object-oriented applications.</p> 
<p>When modernizing from mainframe monoliths toward AWS, both the transformation and the definition of the target architecture are automated and standardized for AWS by <a href="https://www.bluage.com/products/blu-age-velocity">Blu Age Velocity</a> transformation technology. This execution environment is available off-the-shelf and relies upon two components:</p> 
<li><strong>Blu Age Velocity Framework</strong> brings all utilities and services to get rid of former system specificities and anti-patterns: Go To removal, data memory model, execution model, data access model, sort and file management utilities, and more.</li> 
<li><strong>BluSam Server</strong> can be seen as a full stack microservice container. Any number of containers may be deployed, with each being the execution unit for locally deployed services and data access service. Each former Batch program becomes a Spring Boot autonomous executable. Microservice containers are distributed. Programs are freely deployed. Data is freely deployed. In-memory read/write cache may be enable on demand or at start-up. All services are available as REST API. All services are registered into a service directory automatically.</li> 
<img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/07/Blu-Age-Velocity-Microservice-1024x483.jpg" /> 
<p class="wp-caption-text"><em>Figure 2 – Blu Age Velocity microservice design.</em></p> 
<p>Our recommendation for a successful mainframe to microservices project is to separate the technical stack transformation phase from the business split transformation phase in order to keep the microservices transformation complexity manageable for each phase and minimize project risks.</p> 
<p>With such an approach, the first technical stack transformation phase focuses on the application code and data isofunctional migration, keeping the same application model with mostly infrastructure teams from both the mainframe and the AWS sides. The later business split transformation phase focuses on creating domain model boundaries for each microservice and will not involve a mainframe team. It does require participants from the Line of Business with an understanding of the business functions and processes.</p> 
<p>For the technical stack microservice transformation phase, the mainframe Batch architecture is automatically refactored with Blu Age Velocity in the following way:</p> 
<li><strong>REST APIs:</strong> Each service has its REST APIs available and deployed. This enables remote call capability for both business logic services and data access services. Typical integration strategy is made with Kinesis, Lambda, and API Gateway.</li> 
<li><strong>Java Programs:</strong> All former programs and scripts (COBOL programs, JCLs, CICS transactions, BMS maps) are transformed into single executables. BMS maps are transformed into Angular single-page application, while server-side services are transformed into Java Spring Boot applications. Each may be freely deployed to the BluSam server of your choice. They show in the Java Information Control System (JICS) layer of the above picture.</li> 
<li><strong>Cache:</strong> Persisted data may be loaded into the in-memory cache for optimization of performance. The cache supports write-behind and relies on <a href="http://aws.amazon.com/elasticache">Amazon ElastiCache</a>. This increases both read and write performance in bulk mode as well. Native write-through is designed for read access but cause delays when refreshing data into the database, while write-behind allows optimal performance in all scenario.</li> 
<li><strong>Persistence Data Layer:</strong> Persisted data is managed by BluSam I/O. Any former data storage (VSAM, GDG, DB2 z/OS tables, etc) is now stored in a persistence data store. Any prior data access mode (sequential, indexed sequential, hierarchical, relational) is refactored to fit with a new database.</li> 
<li><strong>Persistence Data Store:</strong> Typically, as detailed later, <a href="https://aws.amazon.com/rds/aurora/">Amazon Aurora</a> is the relational data store of choice for data persistence. Now each BluSam Server has the flexibility to operate its own database choice (relational, Key Value store, No SQL, Graph database).</li> 
<li><strong>Service Directory:</strong> All deployed services are published into a central directory for location lookup and integration across microservices.</li> 
<p>For the business split transformation phase, a Domain-Driven Design approach is recommended to identify each microservice scope with a Bounded Context. Blu Age Analyzer automates domain discovery by analyzing data and call dependencies between legacy programs. Domain decomposition refactoring using functional input is supported as well by Blu Age Analyzer. Decomposition strategy produced by Blu Age Analyzer is then driving the modernization transformations.</p> 
<p>To learn more about this approach, see details about <a href="https://www.bluage.com/products/blu-age-analyzer">Blu Age Analyzer</a>, <a href="https://martinfowler.com/tags/domain%20driven%20design.html">Martin Fowler Domain Driven Design</a>, <a href="https://martinfowler.com/bliki/BoundedContext.html">Bounded Context</a>, and <a href="https://en.wikipedia.org/wiki/Domain-driven_design">Wikipedia Domain Driven Design</a>. Once the microservices scope and Bounded Context have been defined, Blu Age automation can quickly re-factor the application code to separate and create the new microservices application packages.</p> 
<b>Example: Resulting Real-Time Microservices</b> 
<p>Getting back to our mainframe legacy Batch example, application owners decide to modernize the mainframe with two main goals in mind:</p> 
<ol> 
<li>Enhance customer experience and satisfaction with answers for loan applications in minutes, rather than the following day once the nightly Batch is complete. Enable self-service and loan notifications to mobile application users.</li> 
<li>Agility and the ability to introduce new features or changes with a better time to market by refactoring all business logic.</li> 
</ol> 
<p>For this purpose, executives decide to transform their mainframe Batch leveraging Blu Age technology as described in the preceding section. We now detail the resulting real-time microservices architecture on AWS. This example microservices Bounded Contexts split is as follows:</p> 
<li><strong>Retail Banking SPA Portal Microservice:</strong> This is a distributed UI system which is localized per region/country (languages, legal specifics).</li> 
<li><strong>Loan Risk Assessment Microservice:</strong> This service is in charge of assessing the risk of granting loans and sending a rate and duration proposal based on customer profile, credit history, and risk assessment rules.</li> 
<li><strong>Transactional Retail Microservice:</strong> This service handles checks, credit card, and all former desk-facing simple operations.</li> 
<li><strong>Long-term Data Storage Microservice:</strong> This becomes a service of its own, which other microservices do not have to be aware of (i.e. they do not have to trigger or do service composition with).</li> 
<img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/07/Real-Time-Microservices-Architecture-1024x532.jpg" /> 
<p class="wp-caption-text"><em>Figure 3 – Real-time microservices architecture with Blu Age Velocity and AWS.</em></p> 
<p>We now describe components of this real-time microservices architecture.</p> 
<h3>Angular Front End</h3> 
<p>Angular enriches user experience while ensuring users of the legacy mainframe application do not require retraining for using the modernized system. All surface behaviors of the former mainframe system are mimicked with user experience related processes and screens transformed into a portal.</p> 
<p>This architecture automatically distributes user connections to different containers and regions for better availability and reliability. It distributes the local versions of retail application in various countries and offices as well (because of various languages and legislation). As soon as a user submits a request, the Angular single-page application emits data into Kinesis to route and process this request in real-time.</p> 
<h3>Amazon Kinesis</h3> 
<p>Kinesis is the unified data hub for the real-time system, also called the data transport layer. Requests are pushed into Kinesis, which acts as a central, fast, and robust streaming hub. In addition to basic message queuing, Kinesis continuously sends data in the stream and allows data replay and broadcasting.</p> 
<p>Kinesis is fully managed, which means you do not have to manage the infrastructure nor the configuration to adapt to burst or capacity variations. Even though data will be processed on the fly, Kinesis provides a buffer if needed. This is beneficial for mainframe Batch when there is a need to replay or reject prior data processing. Furthermore, Kinesis is used to support the <a href="http://microservices.io/patterns/data/database-per-service.html">Database per Service design pattern</a> as per <a href="https://martinfowler.com/articles/microservices.html">Martin Fowler’s microservices description</a>.</p> 
<h3>Amazon API Gateway</h3> 
<p>API Gateway identifies which API or service to map to the incoming Kinesis data. It is the perfect fit as the central hub to access all your microservices, whatever their underlying technology and locations. Moreover, API Gateway serves as a service locator to call appropriate microservices, and enables service versioning and Canary deployment strategy. This&nbsp;allows reducing the risk of introducing a new software version in production by slowly rolling out the change to a small subset of users before rolling it out to the entire infrastructure and making it available to everybody.</p> 
<p>Another reason for using API Gateway as a Canary strategy is when different business versions exist because large banks typically operate in many countries with different regulations. Using microservices through API Gateway, both solve multichannel and multi regulation issues.</p> 
<h3>AWS Lambda</h3> 
<p>API Gateway uses Lambda as a proxy to call microservices. Lambda initiates context and parameter values injected into the remote service. In the legacy system, JCL receives parameter values from a scheduler or programmatically defined variables. In such context, those parameters are used to set up the Batch runtime environment with the name of the dataset, version of deployed programs, execute Batch in production or test partition.</p> 
<p>In the new paradigm, Lambda is used to keep this runtime parameter capability, which the client should not do for decoupling reasons, and triggers the appropriate Groovy script (which replaces z/OS JCL after being transformed with Blu Age). Groovy is preferred to Java to be modified without compilation while sharing the same JVM as the Java classes to be run.</p> 
<p>Therefore, mainframe Batch job steps or run units may be reproduced, and modification can be done to Batch setup without compilation. Groovy and Java classes are called via REST and may be either synchronous or asynchronous. Asynchronous is preferred in case of long processing time. Indeed, Lambda lifetime must be kept below 500 seconds, and in such case detached services is the right pattern.</p> 
<h3>Amazon ElastiCache</h3> 
<p>One specificity of mainframe system is I/O capabilities provided both by the underlying file system and non-relational databases built on top of it. Among those, VSAM relies on indexed sequential data store for which modern databases (RDBMS, graph database, column database) do not provide equivalent indexing, at least not preserving performance for all features. Blu Age BluSam uses ElastiCache (Redis implementation) in order to bring equivalent performance while supporting necessary I/O capabilities features:</p> 
<li><strong>In Memory Indexes:</strong> VSAM indexes are stored in ElastiCache to support fast and full featured indexed sequential logic.</li> 
<li><strong>Index Persistence:</strong> Indexes are saved in real-time to an underlying database to provide the required availability requirements. The default configuration stores into Aurora. BluSam allows using any RDBMS or Key/Value store as well.</li> 
<li><strong>Record Caching:</strong>&nbsp;Mainframe dataset records may be uploaded to cache, either at BluSam Server startup using bulk cache insert or on the fly as requests hit the cache.</li> 
<li><strong>Write-behind:</strong> In addition to write-through, BluSam adds persistence-specific services to support write-behind. Write-through induces a delay (database acknowledgement), which may cause a performance slowdown when doing bulk processing. For this reason, write-behind has been added to manage transactions only at the cache level. The cache manages persistence to the underlying database with a first-of strategy (first of N-record changed and elapsed time since the last cache saving). This write-behind feature is available for both indexes and individual records.</li> 
<li><strong>Managed Service:</strong> ElastiCache is a fully managed service that enables transparent scaling. Even large mainframe Batch systems requiring processing of terabytes of business records per day are handled by ElastiCache with no need to manage capacity or scaling. Data may be uploaded into the cache in burst mode to process reliably any bulk data (warming cache and processing in memory is typically a good strategy for bulk processing).</li> 
<h3>Amazon Aurora</h3> 
<p>Aurora is the preferred target AWS database for mainframe modernization because of its performance and equivalence. Legacy mainframe applications rely mostly on VSAM and SQL I/O capabilities, and changing to another data access type such as put/get of a document&nbsp;could be risky and time-consuming as it involves a major rewrite of the application logic disconnecting it from the data access APIs. However, using Aurora with BluSam and ElastiCache allows preserving transformation automation and performance with no need for refactoring for both VSAM’s like indexes (permanent storage in Aurora; live indexes in ElastiCache), and native SQL support.</p> 
<p>Scalability is also important when modernizing mainframe because legacy application usage varies over time. For example, payroll systems or tax payment systems have a peak of activity every month/quarter. Aurora is a managed database with storage that can automatically grow to 64 TB per instance.</p> 
<p>One challenge with microservices is the Database per Service design pattern. This pattern creates a need for data synchronization within the constraints of the CAP theorem because data is distributed. While specific patterns exist to handle the trade-off between eventual consistency, rollback mechanism, and transactional delay, they were all designed for online transactions. Each of these suffer, however, from network and transactional delay which do not fit with the mainframe Batch latency requirements. This includes a commit time within one milliseconds, whereas patterns such as Saga or API Composition introduce up to 100 milliseconds delay.</p> 
<p>Aurora brings a simple yet effective capability for data synchronization with native Lambda integration. Whenever a record is modified, then a Lambda is triggered. The Lambda is used to stream into Kinesis which delivers to API Gateway. Kinesis allows having multiple subscribers to propagate the data change to their local data store, while API Gateway allows doing API management for each domain. Then, all domains are synchronized simultaneously while each implements its private synchronization APIs based on its private choice of languages and databases</p> 
<p>Aurora Serverless opens new strategies to achieve high performance&nbsp;and behaves like the regular Aurora service but automatically scales up or down based on your application’s needs while preserving ACID transactions. Because of the rapid scaling, Aurora Serverless is a cost-effective solution for Batch, burst, bulk data transfers, data consolidation, reducing elapse time for long processes such as payroll Batches.</p> 
<b>Data Storage Microservice</b> 
<p>In the mainframe system, long-term data storage was handled at the application level, with several Batch jobs being responsible for archiving, back up, and pruning. Furthermore, the mainframe&nbsp;archival is costly and complex because it relies on generational GDG files on mainframe itself, and on tapes shipped to off-site storage.</p> 
<p>With AWS, the long-term data storage microservice is built with a single Lambda function leveraging lower cost storage like <a href="http://aws.amazon.com/s3">Amazon Simple Storage Service</a> (Amazon S3) and <a href="http://aws.amazon.com/glacier">Amazon Glacier</a>.</p> 
<img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/07/Long-Term-Data-Storage-Microservice-1024x373.jpg" /> 
<p class="wp-caption-text"><em>Figure 4 – Long-term data storage microservice.</em></p> 
<p>Preserving the overall defined architecture, Kinesis and API Gateway remain the central data hub. <a href="http://aws.amazon.com/batch">AWS Batch</a> is used to schedule data storage actions through a Lambda function. The Lambda function copies Aurora data into Amazon S3 with a command similar to the following:</p> 
<blockquote> 
<p>SELECT INTO OUTFILE S3 <strong>&lt;sql statement&gt;</strong>, where <strong>sql statement</strong> selects data to be stored externally to the application database.</p> 
</blockquote> 
<p>Amazon S3 functionalities replace z/OS GDG features, local copies of data, audit trails, medium term archiving and pruning of data, and extra backups. For long-term data archival and to satisfy regulatory requirements, the data is later moved from Amazon S3 into Amazon Glacier based on a Lifecycle Rule.</p> 
<h3>Customer Benefits</h3> 
<p>Blu Age Velocity is a ready-to-use solution that accelerates the migration of mainframe Batch to AWS microservices. Because it is a packaged solution, it minimizes project risk and costs. There are savings coming from transitioning from a mainframe MIPS cost structure to pay-as-you-go AWS Managed Services. Such savings typically finance the modernization project in a short time period and allow for a quicker return on investment.</p> 
<p>The target architecture uses AWS Managed Services and serverless technology. As such, each microservice is elastic and minimizes system administrator tasks. It adapts to the client demand, automatically ensuring availability and performance of services while only paying for what you use.</p> 
<p>From a design perspective, mainframe Batch applications are migrated to real-time, which improves customer experience and satisfaction. Batch applications are also transformed into microservices&nbsp;that benefit from more flexibility, increased agility, independent business domains, deployment automation, and safe deployment strategy. In short: better, faster, safer capability to deliver and implement new features.</p> 
<b>Learn More About Blu Age Velocity</b> 
<p>Blu Age Velocity can be used by any customer in any industry, for any mainframe executing languages such as COBOL (including most of its various flavors), JCL, and subsystems such as CICS, IMS, and VSAM. Blu Age Velocity accelerates both the code automated modernization&nbsp;and the target architecture definition.</p> 
<p>Blu Age also facilitates the necessary activities from legacy code base inventory and analysis to control of like-for-like business logic testing and compliance with the latest development standards. Blu Age recommends performing a Proof of Concept with the most complex Batch jobs. This proves the technology robustness and minimizes risk for the other jobs or programs.</p> 
<p><strong><a href="https://aws.amazon.com/marketplace/pp/B078Z1R93R">Visit&nbsp;our Blu Genius listing on AWS Marketplace to access your free sandbox&nbsp;&gt;&gt;</a></strong></p> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-6474');
});
</script> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<meta property="image" content="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/01/Video.jpg" /> 
<b class="lb-b blog-post-title" property="name headline">Using the New Amazon EC2 G3 Instances to Playout an IP-Based Ultra High Definition Channel on AWS</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Mark Stephens</span></span> | on 
<time property="datePublished" datetime="2018-03-06T09:51:52+00:00">06 MAR 2018</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/apn/category/compute/amazon-ec2/" title="View all posts in Amazon EC2*"><span property="articleSection">Amazon EC2*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/storage/amazon-elastic-block-storage-ebs/" title="View all posts in Amazon Elastic Block Storage (EBS)*"><span property="articleSection">Amazon Elastic Block Storage (EBS)*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/analytics/amazon-elasticsearch-service/" title="View all posts in Amazon Elasticsearch Service*"><span property="articleSection">Amazon Elasticsearch Service*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/software/aws-marketplace/" title="View all posts in AWS Marketplace*"><span property="articleSection">AWS Marketplace*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/aws-partner-network/" title="View all posts in AWS Partner Network*"><span property="articleSection">AWS Partner Network*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/apn/using-the-new-amazon-ec2-g3-instances-to-playout-an-ip-based-ultra-high-definition-channel-on-aws/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-6389" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-apn-blog&amp;disqus_identifier=6389&amp;disqus_title=Using+the+New+Amazon+EC2+G3+Instances+to+Playout+an+IP-Based+Ultra+High+Definition+Channel+on+AWS&amp;disqus_url=https://aws.amazon.com/blogs/apn/using-the-new-amazon-ec2-g3-instances-to-playout-an-ip-based-ultra-high-definition-channel-on-aws/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-6389');
});
</script> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><em>By Michael Jacobs, Software as a Service Manager at Cinegy</em></p> 
<p><a href="https://aws.amazon.com/marketplace/pp/B0754S2MNK?qid=1513079044259&amp;sr=0-1&amp;ref_=srh_res_product_title"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/01/Video-300x150.jpg" /></a>Whether you are a content creator, delivery platform provider, or somewhere in between, playout from the cloud is likely a subject of discussion in your organization. More and more companies are looking to the cloud for expansion and the offering of new services, but cloud playout brings its own set of challenges such as&nbsp;knowing which compute resource you will need to run your channels.</p> 
<p><a href="https://aws.amazon.com/partners/find/partnerdetails/?n=Cinegy&amp;id=001E000001FgUVtIAN">Cinegy</a>, an Amazon Web Services (AWS) Standard Technology Partner, has long been an advocate of IP-based video workflows. We understand that maintaining visual quality whilst reducing bandwidth consumption is an ongoing challenge with the increasing data requirements of formats such as Ultra High Definition (UHD). We address this by leveraging the power of NVIDIA’s hardware-based h.264 and h.265 (HEVC) encoding engines instead of using CPU.</p> 
<p>In this post, I will demonstrate how to deploy a fully-functional playout engine using <a href="https://aws.amazon.com/ec2/">Amazon Elastic Compute Cloud</a>&nbsp;(Amazon EC2)&nbsp;resources and the Cinegy Amazon Machine Image (AMI) to deliver a UHD TV channel with graphics.</p> 
<b>Channel in the Cloud</b> 
<p>Some time ago, Cinegy saw the power of CPUs was not increasing at the pace it previously had. We noted, however, that GPUs were still doubling their power every year&nbsp;and decided to invest in leveraging the increasing processing power. We implemented support for NVIDIA encoding and decoding into our products, and this allows video to be offloaded to an available and supported NVIDIA card while keeping the load on the CPU to a minimum.</p> 
<p>Our <strong>Channel in the Cloud bundle</strong>&nbsp;has been&nbsp;<a href="https://aws.amazon.com/marketplace/pp/B0754S2MNK?qid=1519760199294&amp;sr=0-1&amp;ref_=srh_res_product_title">available on AWS Marketplace</a>&nbsp;for some time and has historically deployed on the Amazon EC2 G2 instance family. With the introduction of the G3 instance family, we created a new bundle with better graphic and video format capabilities, such as UHD and multi HD channel support. The new NVIDIA-backed G3 range of instances gives us access to a modern NVIDIA Tesla-based GPU&nbsp;and features such as Enhanced Networking and <a href="https://aws.amazon.com/ebs/">Amazon Elastic Block Service</a>&nbsp;(Amazon EBS)&nbsp;volumes.</p> 
<p>Due to the encoding of the video being carried out by the powerful NVIDIA GPU in the new G3 instance types, it is now possible to playout a UHD-quality video channel, add graphics branding, and monitor the output as well. The latest&nbsp;Channel in the Cloud bundle runs on any of the G3 instance sizes&nbsp;and contains our playout and control software (Cinegy Air PRO) as well as our monitoring software (Cinegy Multiviewer).</p> 
<b>Deploying the Cinegy Software</b> 
<p>The first step is to launch the Cinegy AMI from AWS Marketplace, which has the playout engine configured with channels that are also set to be monitored with the Cinegy Multiviewer application. If you require more in-depth instructions on how to use our software, visit our <a href="https://open.cinegy.com/products/air/11/">Cinegy Air 11</a>&nbsp;and <a href="https://open.cinegy.com/products/multiviewer/12/">Cinegy Multiviewer</a>&nbsp;sections of our document website.</p> 
<p>Making use of the available NVIDIA graphics card with the Cinegy Playout Engine software is relatively straightforward. Let’s go through setting up a single UHD TV channel for RTP output and then look at the load placed upon the instance.</p> 
<p>In addition to the deployed instance, you will need access to the video assets you wish to playout. The media needs to be available on either a locally-attached volume or via UNC path. Alternatively, the video could be an incoming IP stream to the Amazon EC2 instance. Delivery of your generated IP stream will be via your chosen platform, such as over the Internet or satellite uplink location.</p> 
<b>Cinegy Playout Engine – Playback Settings</b> 
<p>To access these settings once you have logged into the instance, right-click the icon in the taskbar to use the configuration utility:</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/02/27/Cinegy-Configuration-Utility.jpg" /></p> 
<p>As you can see in the screenshot below, we have gone into the Playback tab and the channel mode is set to UHD at 25Hz. We will also use the available NVIDIA Tesla M60 in the G3 instance for any graphics rendering on the channel. We added an RTP/UDP output device using the ‘Add device’ button and this will be configured next.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/02/27/Cinegy-Add-Device.jpg" /></p> 
<b>Cinegy Playout Engine – RTP/UDP Settings</b> 
<p>The following screenshot shows the IP output from the engine is set to be encoded using H.264 on the NVIDIA GPU at a bit rate of 100Mbps. We will also be using a constant bit rate and a mostly I-frame mode.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/02/27/Cinegy-IP-Output.jpg" /></p> 
<b>Cinegy Playout Engine – Audio Settings</b> 
<p>After hitting the ‘Next’ button, we can set the audio stream format we wish to use. This has been set to AAC-LC running at 192 kbit/s.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/02/27/Cinegy-Audio-Settings.jpg" /></p> 
<p>Using the above settings on the smallest of the GPU instances, a g3.4xlarge, 1-playout channel configured to output UHD at 25 fps (offloaded to the NVIDIA GPU for H.264 encoding) via RTP at 100Mbps with AAC-LC audio included uses less than 30 percent of the available CPU and less than 10 percent of available RAM.</p> 
<p><span style="color: #ff0000"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/01/Cinegy-Task-Manager-1.jpg" /></span></p> 
<p>If we add some graphics branding to the output, this increases the load on the CPU to about 65 percent when the engine first engages, but then the CPU returns to a slightly increased level, until the graphics sequence is finished.</p> 
<p>If you&nbsp;want to add graphics to your TV channel’s output using Cinegy software, please refer to the <a href="https://open.cinegy.com/products/air/11/titler/">Cinegy Titler manual</a>&nbsp;along with the Handling Items-Secondary Events section of the <a href="https://open.cinegy.com/products/air/11/air/user-manual/handling-items/secondary-events/">Cinegy Air 11 user manual</a>. You can also check out&nbsp;the <a href="https://open.cinegy.com/products/air/11/playout/user-manual/configuration/cg/">Cinegy Playout Engine manual</a>&nbsp;to learn more.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/01/Cinegy-Task-Manager-2.jpg" /></p> 
<p>GPU loading is still very light even when running the additional graphics, with a maximum load of 19 percent being recorded using the <strong>nvidia-smi</strong> command line tool.</p> 
<p>The Cinegy Playout Engine application also includes CPU and memory utilisation graphs for ease of reference.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/02/27/Cinegy-Playout-Dashboard.jpg" /></p> 
<b>Monitoring of Output</b> 
<p>We include our Multiviewer application with the AWS Marketplace offering to give customers the ability to monitor standard broadcast parameters of the output from the Playout Engine, such as Audio Clipping and Video Black. These alerts can be notified to the operators via various mechanisms such as file, SNMP traps, and email, if a problem is detected.</p> 
<p>In addition, Multiviewer alert notifications can be sent as telemetry data to either Cinegy’s or your own <a href="https://aws.amazon.com/elasticsearch-service/">Amazon Elasticsearch Service</a> cluster for visualisation and trend analysis.</p> 
<b>Storage Volumes</b> 
<p>UHD video assets are generally four times larger than the HD equivalent using the same encapsulation and, therefore, also requires four times the bandwidth. By attaching Amazon EBS volumes to the instance, a highly-performant and resilient storage device can be added and used to store media assets. This ensures the critical files required for playback will persist if the instance stops running and has increased availability against single component hardware failure.</p> 
<p>Amazon EBS volumes also provide the flexibility to increase their size and IOPS capacity dynamically on a live system to ensure continued operation.</p> 
<p>The g3.4xlarge instance is an Amazon EBS-optimized instance type. This&nbsp;means it has dedicated bandwidth to communicate with the Amazon EBS service and is separated from any network traffic. The instance size has the capability of having up to 3,500 Mbps of bandwidth available to Amazon EBS, if required.</p> 
<p>As an example, a 1TB-sized general performance SSD (gp2) volume provisioned as a second volume on this instance type would provide 3,000 IOPS of performance and peak throughput of 160 MiB/s.</p> 
<b>Conclusion</b> 
<p>As you can see, the GPU and CPU power available with the Amazon EC2 G3 instances allows you to playout UHD content with graphics branding and be confident you still have some headroom available.</p> 
<p>Combining our Cinegy Air PRO bundle with a G3 instance gives you the capability to achieve UHD playout from the cloud with ease, and provides all the benefits of Amazon EC2, including scalability, monitoring, and dynamic resource allocation. So whether you need to run a single channel for a few hours on a weekend or multiple 24&times;7 channels with redundancy, we encourage you to dive into our solution.</p> 
<p>To take Cinegy for a test run, visit AWS Marketplace and&nbsp;<strong><a href="https://aws.amazon.com/marketplace/pp/B0754S2MNK?qid=1513079044259&amp;sr=0-1&amp;ref_=srh_res_product_title">start enjoying the benefits of UHD cloud playout &gt;&gt;</a></strong></p> 
<hr /> 
<h6><em>The content and opinions in this blog are those of the third party author and AWS is not responsible for the content or accuracy of this post.</em></h6> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-6389');
});
</script> 
</article> 
<p>
© 2018 Amazon Web Services, Inc. or its affiliates. All rights reserved.
</p>

    </div>
  </div>
</div>


    <div id="footer" class="navigation hidden-print">
      <div class="container">
        <div class="row">
          <div class="col-xs-12">
            <ul class="footer-links nav navbar-nav">
              <li><a href="../aws.html">AWS</a></li>
              <li><a href="../linux.html">Linux</a></li>
              <li><a href="../docker.html">Docker</a></li>
              <li><a href="../ibmpower.html">IBM Power</a></li>
              <li><a href="blogsataws1.html">Blogs@AWS (Kindle Friendly)</a></li>
            </ul>
            <ul class="footer-links nav navbar-nav navbar-right">
              <li><a href="../comments.html">Comments?</a></li>
            </ul>
          </div>
        </div>
      </div>
    </div>
  </body>
</html>
