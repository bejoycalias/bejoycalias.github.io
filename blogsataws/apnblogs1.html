<!DOCTYPE html>
<html lang="en">
  <head>
<!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-593498H');</script>
<!-- End Google Tag Manager -->

    <meta charset="utf-8">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">

    <meta name="msapplication-config" content="/microsoft-tile.xml" />
    <meta name="theme-color" content="#ffffff">

    <meta property="og:url" content="https://bejoycalias.github.io/blogsataws/apnblogs1.html" />
    <meta property="og:site_name" content="Bejoy's TechNotes"/>
    <meta property="og:title" content="Bejoy's TechNotes - Kindle Friendly AWS APN Blogs" />
    <meta property="og:image" content="https://bejoycalias.github.io/assets/images/og-image.png"/>
    <meta property="og:image:width" content="1200"/>
    <meta property="og:image:height" content="1200"/>
    <meta property="og:description" content="" />

    <title>Bejoy's TechNotes - Kindle Friendly AWS APN Blogs</title>
    <link href="../assets/stylesheets/application-832aa42c.css" rel="stylesheet" />

    <!--[if lt IE 9]>
      <script src="../assets/javascripts/ie-compat-c141a02d.js"></script>
    <![endif]-->
    <script src="../assets/javascripts/application-ff53d307.js"></script>

    <!-- Typekit script to import Klavika font -->
    <script src="https://use.typekit.net/wxf7mfi.js"></script>
    <script>try{Typekit.load({ async: true });}catch(e){}</script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-100043608-1', 'auto');
  ga('send', 'pageview');

</script>

    
  </head>

  <body id="uh-oh-" class="layout-inner page-uh-oh-">
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-593498H"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->


    <div id="header" class="navigation navbar-static-top hidden-print">
      <div class="container">
        <div class="row">
          <div class="col-xs-12">
            <div class="navbar-header">
              <div class="navbar-brand">
                <a href="/">
                  <svg version="1.0" xmlns="http://www.w3.org/2000/svg" width="135.000000pt" height="50" viewbox="0 0 135.000000 45.000000" preserveaspectratio="xMidYMid meet" class="logo">

<g transform="translate(0.000000,45.000000) scale(0.100000,-0.100000)" fill="#000000" stroke="none">
<path class="text" fill="#000000" d="M527 384 c-4 -4 -7 -18 -7 -31 0 -21 4 -24 28 -21 21 2 27 8 27 28 0
18 -6 26 -20 28 -12 2 -24 0 -28 -4z"></path>
<path class="text" fill="#000000" d="M1080 335 c0 -48 2 -55 20 -55 18 0 20 7 20 55 0 48 -2 55 -20 55
-18 0 -20 -7 -20 -55z"></path>
<path class="text" fill="#000000" d="M54 357 c-2 -7 -3 -69 -2 -138 l3 -124 65 -3 c90 -3 130 20 130 77 0
29 -6 44 -20 54 -20 14 -20 15 -3 45 14 25 15 34 5 56 -6 15 -23 31 -38 36
-38 15 -134 13 -140 -3z m110 -33 c19 -7 21 -45 4 -62 -7 -7 -22 -12 -35 -12
-20 0 -23 5 -23 40 0 41 13 50 54 34z m20 -130 c19 -18 19 -20 6 -45 -8 -13
-21 -19 -45 -19 -34 0 -35 1 -35 40 0 38 2 40 29 40 16 0 37 -7 45 -16z"></path>
<path class="text" fill="#000000" d="M319 271 c-23 -24 -29 -38 -29 -74 0 -25 3 -53 6 -62 20 -50 164 -64
164 -15 0 15 -7 17 -45 12 -46 -5 -75 8 -75 34 0 11 16 14 65 14 l65 0 0 35
c0 80 -92 114 -151 56z m99 -33 c3 -15 -4 -18 -37 -18 -43 0 -50 7 -29 28 18
18 62 11 66 -10z"></path>
<path class="text" fill="#000000" d="M520 184 c0 -107 -1 -116 -20 -121 -11 -3 -20 -12 -20 -19 0 -21 76
-19 84 2 3 9 6 69 6 135 l0 119 -25 0 -25 0 0 -116z"></path>
<path class="text" fill="#000000" d="M649 271 c-24 -25 -29 -37 -29 -78 1 -70 34 -103 105 -103 55 0 95
44 95 103 0 60 -7 75 -41 92 -47 25 -96 19 -130 -14z m111 -30 c25 -48 2 -111
-40 -111 -45 0 -69 80 -34 114 21 22 61 20 74 -3z"></path>
<path class="text" fill="#000000" d="M850 287 c0 -8 16 -57 36 -110 28 -76 33 -100 25 -116 -16 -28 -14
-31 18 -31 27 0 29 4 70 123 23 67 41 128 41 135 0 6 -11 12 -24 12 -21 0 -26
-8 -41 -65 -10 -36 -21 -68 -25 -70 -3 -2 -16 27 -29 66 -19 60 -25 69 -47 69
-13 0 -24 -6 -24 -13z"></path>
<path class="text" fill="#000000" d="M1192 284 c-17 -12 -22 -24 -20 -47 2 -26 10 -36 45 -52 49 -23 59
-55 17 -55 -14 0 -34 5 -45 10 -16 9 -19 7 -19 -13 0 -17 7 -27 23 -31 69 -18
117 6 117 60 0 32 -4 37 -45 55 -60 26 -62 54 -4 46 37 -5 40 -3 37 16 -2 18
-11 23 -43 25 -25 2 -49 -3 -63 -14z"></path>
</g>
</svg>

                </a>
              </div>
              <button class="navbar-toggle" type="button">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
              </button>
            </div>
            <div class="buttons hidden-xs">
              <nav class="navigation-links" role="navigation">
                <ul class="main-links nav navbar-nav navbar-right">
                  <li><a href="../aws.html">AWS</a></li>
                  <li><a href="../linux.html">Linux</a></li>
                  <li><a href="../docker.html">Docker</a></li>
                  <li><a href="../ibmpower.html">IBM Power</a></li>
                  <li><a href="blogsataws1.html">Blogs@AWS (Kindle Friendly)</a></li>
                </ul>
              </nav>
            </div>
          </div>
        </div>
      </div>
    </div>

    <div class="sidebar-overlay"></div>

<aside class="sidebar" role="navigation">
  <div class="sidebar-header">
    <svg version="1.0" xmlns="http://www.w3.org/2000/svg" width="135.000000pt" height="42" viewbox="0 0 135.000000 45.000000" preserveaspectratio="xMidYMid meet">

<g transform="translate(0.000000,45.000000) scale(0.100000,-0.100000)" fill="#000000" stroke="none">
<path class="text" fill="#000000" d="M527 384 c-4 -4 -7 -18 -7 -31 0 -21 4 -24 28 -21 21 2 27 8 27 28 0
18 -6 26 -20 28 -12 2 -24 0 -28 -4z"></path>
<path class="text" fill="#000000" d="M1080 335 c0 -48 2 -55 20 -55 18 0 20 7 20 55 0 48 -2 55 -20 55
-18 0 -20 -7 -20 -55z"></path>
<path class="text" fill="#000000" d="M54 357 c-2 -7 -3 -69 -2 -138 l3 -124 65 -3 c90 -3 130 20 130 77 0
29 -6 44 -20 54 -20 14 -20 15 -3 45 14 25 15 34 5 56 -6 15 -23 31 -38 36
-38 15 -134 13 -140 -3z m110 -33 c19 -7 21 -45 4 -62 -7 -7 -22 -12 -35 -12
-20 0 -23 5 -23 40 0 41 13 50 54 34z m20 -130 c19 -18 19 -20 6 -45 -8 -13
-21 -19 -45 -19 -34 0 -35 1 -35 40 0 38 2 40 29 40 16 0 37 -7 45 -16z"></path>
<path class="text" fill="#000000" d="M319 271 c-23 -24 -29 -38 -29 -74 0 -25 3 -53 6 -62 20 -50 164 -64
164 -15 0 15 -7 17 -45 12 -46 -5 -75 8 -75 34 0 11 16 14 65 14 l65 0 0 35
c0 80 -92 114 -151 56z m99 -33 c3 -15 -4 -18 -37 -18 -43 0 -50 7 -29 28 18
18 62 11 66 -10z"></path>
<path class="text" fill="#000000" d="M520 184 c0 -107 -1 -116 -20 -121 -11 -3 -20 -12 -20 -19 0 -21 76
-19 84 2 3 9 6 69 6 135 l0 119 -25 0 -25 0 0 -116z"></path>
<path class="text" fill="#000000" d="M649 271 c-24 -25 -29 -37 -29 -78 1 -70 34 -103 105 -103 55 0 95
44 95 103 0 60 -7 75 -41 92 -47 25 -96 19 -130 -14z m111 -30 c25 -48 2 -111
-40 -111 -45 0 -69 80 -34 114 21 22 61 20 74 -3z"></path>
<path class="text" fill="#000000" d="M850 287 c0 -8 16 -57 36 -110 28 -76 33 -100 25 -116 -16 -28 -14
-31 18 -31 27 0 29 4 70 123 23 67 41 128 41 135 0 6 -11 12 -24 12 -21 0 -26
-8 -41 -65 -10 -36 -21 -68 -25 -70 -3 -2 -16 27 -29 66 -19 60 -25 69 -47 69
-13 0 -24 -6 -24 -13z"></path>
<path class="text" fill="#000000" d="M1192 284 c-17 -12 -22 -24 -20 -47 2 -26 10 -36 45 -52 49 -23 59
-55 17 -55 -14 0 -34 5 -45 10 -16 9 -19 7 -19 -13 0 -17 7 -27 23 -31 69 -18
117 6 117 60 0 32 -4 37 -45 55 -60 26 -62 54 -4 46 37 -5 40 -3 37 16 -2 18
-11 23 -43 25 -25 2 -49 -3 -63 -14z"></path>
</g>
</svg>

  </div>

  <ul class="nav sidebar-nav">
    <li><a href="../aws.html">AWS</a></li>
    <li><a href="../linux.html">Linux</a></li>
    <li><a href="../docker.html">Docker</a></li>
    <li><a href="../ibmpower.html">IBM Power</a></li>
    <li><a href="blogsataws1.html">Blogs@AWS (Kindle Friendly)</a></li>
  </ul>
</aside>


    <div class="container">
  <div class="row">
    <div id="docs-sidebar" class="col-sm-3 col-md-3 col-xs-12 hidden-print" role="complementary">
      <ul class="nav docs-sidenav">
      <li><a href="blogsataws1.html">Blogs @ AWS</a></li>
      <li><a href="whatsnew1.html">What's New @ AWS</a></li>
      <li><a href="mgmtblogs1.html">Management Tools Blogs @ AWS</a></li>
      <li><a href="computeblogs1.html">Compute Blogs @ AWS</a></li>
      <li><a href="devopsblogs1.html">DevOps Blogs @ AWS</a></li>
      <li><a href="secblogs1.html">Security Blogs @ AWS</a></li>
      <li class="active"><a href="apnblogs1.html">APN Blogs @ AWS</a></li>

    </ul>
    </div>

    <div id="inner" class="col-sm-9 col-md-9 col-xs-12" role="main">
<p></p>
<p><i>Contents of this page is copied directly from AWS blog sites to make it Kindle friendly. Some styles & sections from these pages are removed to render this properly in 'Article Mode' of Kindle e-Reader browser. All the contents of this page is property of AWS.</i></p>
<p><a href="apnblogs1.html">Page 1</a>|<a href="apnblogs2.html">Page 2</a>|<a href="apnblogs3.html">Page 3</a>|<a href="apnblogs4.html">Page 4</a></p>
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<meta property="image" content="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/02/07/Say-Hello.jpg" /> 
<b class="lb-b blog-post-title" property="name headline">Say Hello to 10 New and 9 Renewed AWS Competency Partners Added in February</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Stephanie Lawson</span></span> | on 
<time property="datePublished" datetime="2018-03-12T15:24:56+00:00">12 MAR 2018</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/apn/category/aws-partner-network/" title="View all posts in AWS Partner Network*"><span property="articleSection">AWS Partner Network*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/awsquest/" title="View all posts in AWS Quest*"><span property="articleSection">AWS Quest*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/apn/say-hello-to-10-new-and-9-renewed-aws-competency-partners-added-in-february/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-6517" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-apn-blog&amp;disqus_identifier=6517&amp;disqus_title=Say+Hello+to+10+New+and+9+Renewed+AWS+Competency+Partners+Added+in+February&amp;disqus_url=https://aws.amazon.com/blogs/apn/say-hello-to-10-new-and-9-renewed-aws-competency-partners-added-in-february/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-6517');
});
</script> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><em>By Stephanie Lawson, Partner Program Marketing Manager at AWS</em></p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/02/07/AWS-Competency_thumbnail-300x150.png">AWS Competency Program</a> admitted 10 new AWS Partner Network (APN) Partners in February—spanning workload, solution, and industry designations. Please join us in welcoming our newest AWS Competency Partners!</p> 
<p>The AWS Competency Program provides customers with highlighted APN Partners that have demonstrated technical proficiency through an AWS Technical Validation and proven customer success in specialized solution areas.</p> 
<p><a href="https://aws.amazon.com/partners/competencies/">View all AWS Competencies and designated APN Partners &gt;&gt;</a></p> 
<b><a href="https://aws.amazon.com/devops/partner-solutions/">AWS DevOps Competency</a></b> 
<h3><em>Consulting Partners</em></h3> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/12/Classmethod-Logo-150x150.jpg" /></p> 
<h3><a href="https://aws.amazon.com/partners/find/partnerdetails/?n=Classmethod&amp;id=001E000000Rl0wJIAR">Classmethod</a></h3> 
<p>Headquartered in Japan, Classmethod helps clients establish DevOps processes for source code management, testing, deployment, and more. With their extensive experience, they help customers choose the right tools and get managed services up and running.</p> 
<p><a href="https://classmethod.jp/services/members/aws-consulting/">DevOps Practice</a> |&nbsp;<a href="https://classmethod.jp/cases/bamiyan-app/">Customer Success</a> |&nbsp;<a href="https://pages.awscloud.com/partner-connect.html?partner-name=001E000000Rl0wJIAR">Contact</a></p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/12/eCloudValley-Logo-150x150.jpg" /></p> 
<h3><a href="https://aws.amazon.com/partners/find/partnerdetails/?n=Ecloudvalley&amp;id=001E000000jD1zaIAC&amp;t=psf-overview">eCloudvalley</a></h3> 
<p>As a born-in-the-cloud APN Premier Consulting Partner, eCloudvalley focuses on AWS and has&nbsp;more than 100 AWS certifications.&nbsp;Their team of experts helps customers launch successful cloud initiatives to quicken go-to-market speeds, automate and strengthen security, increase stakeholder value, improve customer experiences, and lower costs.</p> 
<p><a href="https://www.ecloudvalley.com/">Practice Overview</a> | <a href="https://pages.awscloud.com/partner-connect.html?partner-name=001E000000jD1zaIAC">Contact</a></p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/12/JHC-Technology-Logo-150x150.jpg" /></p> 
<h3><a href="https://aws.amazon.com/partners/find/partnerdetails/?n=JHC%20Technology%2C%20Inc.&amp;id=001E000000Rl0x6IAB">JHC Technology Inc.</a></h3> 
<p>JHC offers faster feature delivery by shrinking the developer feedback loop, quick responses to stakeholder requirements and feedback, improved quality control with automated build, test, and deployment pipeline; and auto scaling, self-healing infrastructure.</p> 
<p><a href="http://www.jhctechnology.com/what-we-do/agile-devops-orchestration/">Practice Overview</a> | <a href="http://www.jhctechnology.com/wp-content/uploads/2018/01/TNTP_CaseStudy_021017.pdf">Customer Success</a> | <a href="https://pages.awscloud.com/partner-connect.html?partner-name=001E000000Rl0x6IAB">Contact</a></p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/12/Polar-Seven-Logo-150x150.jpg" /></p> 
<h3><a href="https://aws.amazon.com/partners/find/partnerdetails/?n=PolarSeven&amp;id=001E000000Xd2auIAB">PolarSeven</a></h3> 
<p>PolarSeven excels in DevOps, a proven method wherein software developers collaborate closely with operations. By working together on the entire product lifecycle, these teams create a quicker, more agile, and more competitive IT delivery.</p> 
<p><a href="https://polarseven.com/what-we-do/devops/">Practice Overview</a> | <a href="https://polarseven.com/success-stories/hey-case-study/">Customer Success</a> | <a href="https://pages.awscloud.com/partner-connect.html?partner-name=001E000000Xd2auIAB">Contact</a></p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/12/RightCloud-Logo-150x150.jpg" /></p> 
<h3><a href="https://aws.amazon.com/partners/find/partnerdetails/?n=RightCloud%20Pte%20Ltd&amp;id=001E000001KbrhpIAB">RightCloud</a></h3> 
<p>Leveraging Agile and DevOps methodologies, cultures, and principles to boost productivity, RightCloud provides a set of flexible services designed to enable customers to more rapidly and reliably build and deliver products using DevOps practices.</p> 
<p><a href="http://www.rightcloud.asia/devops.html">DevOps on AWS</a> | <a href="http://www.rightcloud.asia/jollibees-devops-journey.html">Customer Reference</a> | <a href="https://pages.awscloud.com/partner-connect.html?partner-name=001E000001KbrhpIAB">Contact</a></p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/12/Storm-Reply-Logo-150x150.jpg" /></p> 
<h3><a href="https://aws.amazon.com/partners/find/partnerdetails/?n=Storm%20Reply&amp;id=001E000000NaBI4IAN">Storm Reply</a></h3> 
<p>Storm Reply uses automation tools and best practices as a core service for Managed Service Provider solutions. They manage applications on customers’ behalf using a DevOps approach to speed up operations.</p> 
<p><a href="http://www.reply.com/storm-reply/en/#/storm-reply/en/content/automated-operation">DevOps Practice</a> | <a href="http://www.reply.com/en/lavazza-highly-scalable-ecommerce-platform">Customer Reference</a> | <a href="https://pages.awscloud.com/partner-connect.html?partner-name=001E000000NaBI4IAN">Contact</a></p> 
<b><a href="https://aws.amazon.com/government-education/partner-solutions/">AWS&nbsp;Government Competency</a></b> 
<h3><em>Consulting Partners</em></h3> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/12/General-Dynamics-IT-Logo-150x150.jpg" /></p> 
<h3><a href="https://aws.amazon.com/partners/find/partnerdetails/?n=General%20Dynamics%20Information%20Technology&amp;id=001E000000gL3HHIA0">General Dynamics Information Technology</a></h3> 
<p>As a trusted systems integrator for more than 50 years, GDIT provides technology services to customers across U.S. federal, state, and commercial sectors. They deliver large scale enterprise solutions and service support&nbsp;for the AWS Cloud.</p> 
<p><a href="http://www.gdit.com/cloudsolutions">Practice Overview</a> | <a href="https://pages.awscloud.com/partner-connect.html?partner-name=001E000000gL3HHIA0">Contact</a></p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/12/Cloudten-Logo-150x150.jpg" /></p> 
<h3><a href="https://aws.amazon.com/partners/find/partnerdetails/?n=Cloudten%20Industries&amp;id=001E000000yQVaCIAW">Cloudten Industries</a></h3> 
<p>Cloudten’s AWS-certified staff are specialists in all aspects of cloud architecture, including security and application integration. Working closely with AWS and leading vendors, Cloudten delivers end-to-end competencies to help organizations build flexible, highly available, resilient, and efficient cloud environments.</p> 
<p><a href="http://www.cloudten.com.au/government">Practice Overview</a> | <a href="https://pages.awscloud.com/partner-connect.html?partner-name=001E000000yQVaCIAW">Contact</a></p> 
<b><a href="https://aws.amazon.com/partners/competencies/sap/">AWS&nbsp;SAP Competency</a></b> 
<h3><em>Consulting Partners</em></h3> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/12/BNW-Logo-150x150.jpg" /></p> 
<h3><a href="https://aws.amazon.com/partners/find/partnerdetails/?n=BNW%20Consulting%20Pty%20Ltd&amp;id=0010L00001kW0R9QAK">BNW Consulting</a></h3> 
<p>BNW delivers consulting, managed services, and software solutions to customers in the enterprise as well as SMB market. They have been doing SAP technology projects since 1996 and delivered more than 200 SAP migrations to the cloud.</p> 
<p><a href="https://www.bnwconsulting.com.au/">Practice Overview</a> | <a href="https://aws.amazon.com/solutions/case-studies/visy/">Customer Success</a> | <a href="https://pages.awscloud.com/partner-connect.html?partner-name=0010L00001kW0R9QAK">Contact</a></p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/12/Velocity-Logo-150x150.jpg" /></p> 
<h3><a href="https://aws.amazon.com/partners/find/partnerdetails/?n=Velocity%20Technology%20Solutions&amp;id=001E000001N7nNJIAZ">Velocity Technology Solutions</a></h3> 
<p>Velocity hosts and manages customers’ SAP systems,&nbsp;offering reliable and secure performance, up-to-date SAP applications, and a solution customized for their business requirements. Velocity provides customers with rapid implementation of the latest software releases.</p> 
<p><a href="https://velocitycloud.com/expertise/sap">Practice Overview</a> | <a href="https://velocitycloud.com/press/bcbg-and-velocity-complete-sap-cloud-services-expansion">Customer Success</a> | <a href="https://pages.awscloud.com/partner-connect.html?partner-name=001E000001N7nNJIAZ">Contact</a></p> 
<hr /> 
<b>Renewed AWS Competency Partners in February</b> 
<b><a href="https://aws.amazon.com/big-data/partner-solutions/">AWS&nbsp;Big Data Competency</a></b> 
<h3><em>Consulting Partners</em></h3> 
<li><a href="https://aws.amazon.com/partners/find/partnerdetails/?n=CloudMas&amp;id=001E000000UfZqHIAV">CloudMas</a></li> 
<li><a href="https://aws.amazon.com/partners/find/partnerdetails/?n=Onica&amp;id=001E000000heMPCIA2">Onica</a></li> 
<li><a href="https://aws.amazon.com/partners/find/partnerdetails/?n=Pariveda%20Solutions%20Inc.&amp;id=001E000000NaBHsIAN">Pariveda</a></li> 
<li><a href="https://aws.amazon.com/partners/find/partnerdetails/?n=Storm%20Reply&amp;id=001E000000NaBI4IAN">Storm Reply</a></li> 
<li><a href="https://aws.amazon.com/partners/find/partnerdetails/?n=TO%20THE%20NEW&amp;id=001E000000dHs9dIAC">TO THE NEW</a></li> 
<h3><em>Technology Partners</em></h3> 
<li><a href="https://aws.amazon.com/partners/find/partnerdetails/?n=Looker&amp;id=001E000000kC9lnIAC">Looker</a></li> 
<li><a href="https://aws.amazon.com/partners/find/partnerdetails/?n=Treasure%20Data&amp;id=001E000000Rp5OSIAZ">Treasure Data</a></li> 
<li><a href="https://aws.amazon.com/partners/find/partnerdetails/?n=TIBCO&amp;id=001E000000Rl0y8IAB">TIBCO</a></li> 
<li><a href="https://aws.amazon.com/partners/competencies/sap/">SAP</a></li> 
<hr /> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/14/aws_partner_network_blog_01-1024x21.png" /></p> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-6517');
});
</script> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<meta property="image" content="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/02/13/Training-and-Certification-1.jpg" /> 
<b class="lb-b blog-post-title" property="name headline">New AWS Solutions Training for Partners: Desktop and Application Streaming</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Andrew Kloman</span></span> | on 
<time property="datePublished" datetime="2018-03-16T08:35:40+00:00">16 MAR 2018</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/apn/category/aws-partner-network/" title="View all posts in AWS Partner Network*"><span property="articleSection">AWS Partner Network*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/desktop-app-streaming/" title="View all posts in Desktop &amp; App Streaming*"><span property="articleSection">Desktop &amp; App Streaming*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/apn/new-aws-solutions-training-for-partners-desktop-and-application-streaming/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-6564" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-apn-blog&amp;disqus_identifier=6564&amp;disqus_title=New+AWS+Solutions+Training+for+Partners%3A+Desktop+and+Application+Streaming&amp;disqus_url=https://aws.amazon.com/blogs/apn/new-aws-solutions-training-for-partners-desktop-and-application-streaming/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-6564');
});
</script> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><em>By Andrew Kloman,&nbsp;Partner Solutions Architect at AWS focused on End User Computing</em></p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/02/13/Training-and-Certification-1-300x150.jpg">AWS Partner Network</a> (APN) Partners—Amazon Desktop and Application Streaming for Technical and Business Professionals.</p> 
<p>These courses are intended for APN Partners who work with desktop applications hosted on Amazon Web Services (AWS). The courses are delivered through a mix of web-based training and demonstrations of product features and functionality, and includes an assessment to validate what was covered.</p> 
<b>Register (Partner Central login required)</b> 
<li><a href="https://partnercentral.awspartner.com/LmsSsoRedirect?RelayState=%2flearningobject%2fcurriculum%3fid%3d18414"><strong>AWS Solutions Training for Partners: Desktop and Application Streaming – Technical &gt;&gt;</strong></a></li> 
<li><strong><a href="https://www.aws.training/learningobject/curriculum?id=18414">AWS Solutions Training for Partners: Desktop and Application Streaming – Business &gt;&gt;</a></strong></li> 
<b>About the Training</b> 
<h3><strong>Desktop and Application Streaming – Technical</strong></h3> 
<p>This course teaches you about the capabilities of <a href="https://aws.amazon.com/workspaces/">Amazon WorkSpaces </a>and <a href="https://aws.amazon.com/appstream2/">Amazon AppStream 2.0</a>, guiding you to set up the solution within your AWS account. You will learn the technical details of provisioning, configuring, and managing Amazon WorkSpaces and AppStream2.0.</p> 
<p>This course covers:</p> 
<li>Introduction to Amazon WorkSpaces and AppStream 2.0</li> 
<li>Features and benefits of Amazon WorkSpaces and AppStream 2.0</li> 
<li>Considerations for networking, security, image/bundle management, and governance.</li> 
<li>Prerequisites for deploying each solution within your AWS account.</li> 
<li>Deep dive into the features of Amazon WorkSpaces and AppStream 2.0</li> 
<li>Demonstrations of deploying Amazon WorkSpaces and AppStream 2.0 in your AWS account.</li> 
<p><a href="https://partnercentral.awspartner.com/LmsSsoRedirect?RelayState=%2flearningobject%2fcurriculum%3fid%3d18554"><strong>Register here &gt;&gt;</strong></a></p> 
<h3><strong>Desktop and Application Streaming – Business</strong></h3> 
<p>This covers the following concepts:</p> 
<li>Overview of End User Computing on AWS and the market opportunity</li> 
<li>Identifying opportunities and building an End User Computing practice on AWS</li> 
<li>Understanding pricing models</li> 
<li>Positioning AWS for customers’ needs</li> 
<li>Use cases and case studies</li> 
<p><strong><a href="https://partnercentral.awspartner.com/LmsSsoRedirect?RelayState=%2flearningobject%2fcurriculum%3fid%3d18414">Register here &gt;&gt;</a></strong></p> 
<b>Prerequisites</b> 
<p>We recommend that attendees have the following prerequisites before registering for the new Desktop and Application Streaming courses:</p> 
<li>Familiarity with desktop application management and cloud computing concepts</li> 
<li><a href="https://aws.amazon.com/partners/training/accreditation/#AWS_Business_Professional">AWS Business Professional</a> and <a href="https://aws.amazon.com/partners/training/accreditation/#AWS_Technical_Professional">AWS Technical Professional</a> training</li> 
<li><a href="https://aws.amazon.com/partners/training/accreditation/#AWS_TCO_Economics">AWS Total Cost of Ownership (TCO) and Cloud Economics</a></li> 
<li>AWS Solutions Training for Partners: 
<li><a href="https://partnercentral.awspartner.com/LmsSsoRedirect?RelayState=%2flearningobject%2fcurriculum%3fid%3d11644">AWS for Windows Business</a> (Online)</li> 
<li><a href="https://partnercentral.awspartner.com/LmsSsoRedirect?RelayState=%2flearningobject%2fcurriculum%3fid%3d13965">AWS for Windows Technical</a>&nbsp;(Online)</li> 
<li><a href="https://partnercentral.awspartner.com/LmsSsoRedirect?RelayState=%2flearningobject%2fcurriculum%3fid%3d14875">Best Practices: Well-Architected</a></li> 
</ul> </li> 
<b>Learn More About the AWS Partner Network (APN)</b> 
<p>The APN is the global partner program for AWS and is focused on helping APN Partners build successful AWS-based businesses or solutions. As an APN Partner, you will receive business, technical, sales, and marketing resources to help you grow your business and better support your customers.</p> 
<p><strong><a href="https://aws.amazon.com/partners/">See all the benefits of being an APN Partner &gt;&gt;</a></strong></p> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-6564');
});
</script> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<meta property="image" content="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/11/14/AWS-Marketplace_border.png" /> 
<b class="lb-b blog-post-title" property="name headline">See What’s New for AWS Marketplace Sellers</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Brad Lyman</span></span> | on 
<time property="datePublished" datetime="2018-03-09T15:08:57+00:00">09 MAR 2018</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/apn/category/software/aws-marketplace/" title="View all posts in AWS Marketplace*"><span property="articleSection">AWS Marketplace*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/aws-partner-network/" title="View all posts in AWS Partner Network*"><span property="articleSection">AWS Partner Network*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/apn/see-whats-new-for-aws-marketplace-sellers/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-6497" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-apn-blog&amp;disqus_identifier=6497&amp;disqus_title=See+What%26%238217%3Bs+New+for+AWS+Marketplace+Sellers&amp;disqus_url=https://aws.amazon.com/blogs/apn/see-whats-new-for-aws-marketplace-sellers/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-6497');
});
</script> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><em>By Brad Lyman, Principal Product Manager at AWS</em></p> 
<p><strong><a href="https://aws.amazon.com/marketplace"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/11/14/AWS-Marketplace_border-300x150.png">AWS Marketplace</a> released more than a dozen major features in 2017, as well as many other enhancements and updates. These releases make it easier for Amazon Web Services (AWS) customers to discover and procure software, and for Independent Software Vendors (ISVs) to sell their products on AWS Marketplace.</p> 
<p>AWS Marketplace currently offers more than 4,200 software listings from nearly 1,300 ISVs spanning 35 categories. More than 160,000 active AWS customers use 481 million hours a month of <a href="https://aws.amazon.com/ec2/">Amazon Elastic Compute Cloud</a> (Amazon EC2) for AWS Marketplace products. That’s a lot of activity, and I will describe how&nbsp;our new features enable you, as a seller, to enhance your offerings to AWS customers.</p> 
<p>Did you know we continually update our documentation, including the <a href="http://awsmp-loadforms.s3.amazonaws.com/AWS_Marketplace_-_Seller_Guide.pdf">AWS Marketplace Seller Guide</a>? Or that we&nbsp;post new announcements on the <a href="https://aws.amazon.com/marketplace/management/">AWS Marketplace Management Portal</a> (AMMP)?&nbsp;In case you missed any announcements,&nbsp;here’s a&nbsp;recap of new features that are relevant to ISVs and AWS Partner Network (APN) Partners.</p> 
<p>This post also assumes you have access to AMMP as a registered seller. If not and you want to become a registered seller, here’s how to <a href="https://aws.amazon.com/marketplace/management/register/">begin the registration process</a>.</p> 
<b>Global AWS Marketplace Metering Service Availability</b> 
<p>When we launched the AWS Marketplace Metering Service (MMS) in 2016, we focused on just a few regions. Last year, we completed our global rollout so you can send metering records for Amazon Machine Images (AMIs) or software-as-a-service (SaaS) products to any public AWS region. If you were already sending metering records, this feature was automatically enabled.</p> 
<b>Self-Service Listings for Editing Existing Products</b> 
<p>We have enabled you to edit many of your existing products using self-service tools within AMMP. Previously, you had to use a spreadsheet to upload or modify products. To access Self-Service Listings, log in to AMMP and choose the Listings tab.</p> 
<b>Tax Calculation Service</b> 
<p>This feature enables AWS to calculate and collect sales and use tax on your behalf. Log in to AMMP to take advantage of this feature; under the Settings tab, choose Tax Calculation Service. Once configured, we automatically calculate and collect sales and use tax based on your customers’ location, and provide you with tax data through the U.S. Sales Tax Report.</p> 
<b>SaaS Contracts</b> 
<p>We announced SaaS Contracts during the AWS Summit in San Francisco. This feature enables customers to enter into long-term (monthly, 1-, 2-, or 3-year) contracts for SaaS products. Customers can increase the size of their contract, and AWS Marketplace automatically calculates the prorated upgrade price. It’s also easy for customers to agree to automatic renewals. Check details using <a href="https://aws.amazon.com/documentation/marketplace/">AWS Marketplace APIs</a>, and for more information see our SaaS Onboarding Guide, available in AMMP.</p> 
<b>Log Metering Records with AWS CloudTrail</b> 
<p>We heard from SaaS sellers that you need better visibility into the metering records you send to MMS. That’s why we integrated MMS with AWS CloudTrail, so now every successful metering record is logged and stored using <a href="http://aws.amazon.com/cloudtrail">AWS CloudTrail</a>. If you are a SaaS seller that has enabled CloudTrail, this feature was automatically enabled. Learn more about our <a href="https://docs.aws.amazon.com/marketplacemetering/latest/APIReference/Welcome.html">AWS Marketplace Metering Service API</a>.</p> 
<b>Self-Service Listings for SaaS Products</b> 
<p>When we launched SaaS Contracts, sellers still had to rely on a spreadsheet for uploading product details. Self-Service Listings enables you to take advantage of self-service tools to manage listings. You can find more by logging into AMMP and choosing the Listings tab.</p> 
<b>GovCloud Deployments</b> 
<p>In 2017, we launched support for GovCloud deployments. <a href="https://docs.aws.amazon.com/govcloud-us/latest/UserGuide/welcome.html">AWS GovCloud (US)</a> is an isolated AWS region designed to allow U.S. government agencies and customers to move sensitive workloads into the cloud by addressing specific regulatory and compliance requirements. This feature enables sellers to offer products to GovCloud users by simplifying the discovery of GovCloud-accessible products and easing the deployment of these into the region. To take advantage of this feature, you must show that your product has the proper clearance. For more information, read our <a href="http://docs.aws.amazon.com/govcloud-us/latest/UserGuide/govcloud-us-ug.pdf">AWS GovCloud (US) User Guide</a>.</p> 
<b>Cost and Budgets Support for AWS Marketplace</b> 
<p>As customers move more of their workloads to the cloud, it’s important to understand how budgets are being used. Customers can now visualize their AWS Marketplace costs and usage in <a href="https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/cost-explorer-what-is.html">Cost Explorer</a>, dive deeper into usage patterns using <a href="https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/billing-reports-costusage.html">Cost and Usage Reporting</a>, and set budgets on their AWS Marketplace costs and usage. This feature is automatically available for your products and requires no additional work from you. Customers received this feature automatically at no charge.</p> 
<b>Multi-AMI Solutions</b> 
<p>This feature enables you to offer solutions that contain multiple AMIs. Customers will be able to browse your multi-AMI solutions on AWS Marketplace, subscribe with one click, and deploy using <a href="http://aws.amazon.com/cloudformation">AWS CloudFormation</a> templates that you provide. For customers, subscribing to a single solution entitles them to use all AMIs contained in that solution and pay based on the pricing model set for each AMI. More information is available in the guide for <a href="https://s3.amazonaws.com/awsmp-loadforms/awsmp-ami-delivery-using-cloudformation.pdf">AMI-Based Product Delivery Using AWS CloudFormation</a>.</p> 
<b>Seller Private Offers</b> 
<p>This feature enables you to offer products on AWS Marketplace with customer-specific pricing and legal terms. Using a public product as a starting point, you can change prices and upload a PDF of the legal terms for a specific purchase. This feature is only available for sellers in the <a href="https://s3.amazonaws.com/awsmp-loadforms/guides/AWS-Marketplace-Enhanced-Data-Sharing-Program-Guide.pdf">AWS Marketplace Enhanced Data Sharing Program</a>, which is reserved for sellers who compensate their salespeople for AWS Marketplace purchases.</p> 
<b>AWS PrivateLink on AWS Marketplace</b> 
<p><a href="https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/vpce-interface.html">AWS PrivateLink</a> enables customers to pass data to a SaaS application without ever leaving the Amazon network. AWS Marketplace makes it easier for customers to find your products that support AWS PrivateLink, and configure a PrivateLink connection by providing seller-specified DNS names. This feature requires you to configure your SaaS application for PrivateLink. Learn more in the <a href="http://awsmp-loadforms.s3.amazonaws.com/AWS_Marketplace_-_Seller_Guide.pdf">AWS Marketplace Seller Guide</a>.</p> 
<b>Seller Reporting Enhancements</b> 
<p>We have made several enhancements to AWS Marketplace seller reporting. This includes reporting updates for new features types, such as adding support for Multi-AMI Solutions, SaaS Contracts, and Private Offers. We also made updates to the reports we offer for registered Channel Partners. This additional information is automatically available through seller reports. To view your reports, log in to AMMP and choose the Reports tab. Documentation for each report is available in the <a href="http://aws-marketplace-reports.s3.amazonaws.com/reports-data-dictionary.pdf">Data Dictionary</a>.</p> 
<b>Managed Rulesets on AWS Marketplace</b> 
<p>When AWS launched <a href="https://docs.aws.amazon.com/waf/latest/developerguide/what-is-aws-waf.html">AWS WAF</a>, a web application firewall that lets you monitor HTTP and HTTPS requests, AWS Marketplace added support for Managed WAF Rulesets. Sellers on AWS Marketplace can now provide customers with rulesets that are deployed directly in a customer’s fully managed solution. Learn more about how to vend a managed ruleset at <a href="https://docs.aws.amazon.com/waf/latest/developerguide/waf-managed-rule-groups.html">AWS Marketplace Rule Groups</a>.</p> 
<b>Enhanced Product Detail Page</b> 
<p>We added support for rich media content on our product detail page, including adding up to five videos and/or screenshots for helping customers understand your product. The rich media features are currently limited to sellers participating in the beta program, as it requires sellers to provide additional content. The self-service tools are in development and the feature will be available to all AWS Marketplace vendors once the toolset is finalized.</p> 
<p>All in all,&nbsp;we have launched a host&nbsp;of new features and enhancements for AWS Marketplace customers and sellers. Let us know if there are features you’d like to learn more about or if you have an idea for a feature we should consider adding. The AWS Marketplace team is already hard at work on the features we’ve heard our customers want to see in 2018.</p> 
<p>Stay tuned for more announcements!</p> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-6497');
});
</script> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<meta property="image" content="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/08/Batch.jpg" /> 
<b class="lb-b blog-post-title" property="name headline">How to Migrate Mainframe Batch to Cloud Microservices with Blu Age and AWS</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Phil de Valence</span></span> | on 
<time property="datePublished" datetime="2018-03-09T09:08:46+00:00">09 MAR 2018</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/apn/category/application-services/amazon-api-gateway-application-services/" title="View all posts in Amazon API Gateway*"><span property="articleSection">Amazon API Gateway*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/database/amazon-aurora/" title="View all posts in Amazon Aurora*"><span property="articleSection">Amazon Aurora*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/database/amazon-elasticache/" title="View all posts in Amazon ElastiCache*"><span property="articleSection">Amazon ElastiCache*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/storage/amazon-glacier/" title="View all posts in Amazon Glacier*"><span property="articleSection">Amazon Glacier*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/analytics/amazon-kinesis/" title="View all posts in Amazon Kinesis*"><span property="articleSection">Amazon Kinesis*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/storage/amazon-simple-storage-services-s3/" title="View all posts in Amazon Simple Storage Services (S3)*"><span property="articleSection">Amazon Simple Storage Services (S3)*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/compute/aws-lambda/" title="View all posts in AWS Lambda*"><span property="articleSection">AWS Lambda*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/management-tools/aws-managed-services/" title="View all posts in AWS Managed Services*"><span property="articleSection">AWS Managed Services*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/aws-partner-network/" title="View all posts in AWS Partner Network*"><span property="articleSection">AWS Partner Network*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/migration/" title="View all posts in Migration*"><span property="articleSection">Migration*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/serverless/" title="View all posts in Serverless*"><span property="articleSection">Serverless*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/apn/how-to-migrate-mainframe-batch-to-cloud-microservices-with-blu-age-and-aws/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-6474" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-apn-blog&amp;disqus_identifier=6474&amp;disqus_title=How+to+Migrate+Mainframe+Batch+to+Cloud+Microservices+with+Blu+Age+and+AWS&amp;disqus_url=https://aws.amazon.com/blogs/apn/how-to-migrate-mainframe-batch-to-cloud-microservices-with-blu-age-and-aws/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-6474');
});
</script> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><em>By Alexis Henry, Chief Technology Officer at Blu Age</em></p> 
<p><a href="https://aws.amazon.com/partners/find/partnerdetails/?n=BluAge&amp;id=0010L00001kWbLPQA0"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/08/Batch-300x150.jpg">Blu Age</a> discovered that Batch can be a very complex aspect of a mainframe migration to Amazon Web Services (AWS). It often dictates whether a mainframe migration is successful or not. To succeed in a transition to microservices, it is critical to design your AWS architecture to account for the key Batch stringent performance requirements such as intensive I/Os, large datasets, and short durations.</p> 
<p>In this post, I will describe how to migrate mainframe Batch to AWS microservices using Blu Age automated transformation technology.</p> 
<p>Customers choose microservices aiming for more agility, innovation, quality, scalability, and availability. Despite all these advantages, a microservices approach introduces operational complexity. AWS has a number of offerings that address important challenges of microservices architectures: <a href="https://aws.amazon.com/managed-services/">Managed Services</a>, service orientation, programming languages polyglot, on-demand resources, infrastructure as code, and continuous delivery, among others.</p> 
<p>Experience is still growing on microservices topics. Much of the existing technical literature describe microservices in the context of new applications or peeling monoliths, such as transitioning Java or client/server applications. However, most of the existing worldwide IT relies on mainframe monoliths. Many corporations and public agencies are looking for strategies to migrate their mainframe to cloud microservices, minimizing project risk, duration, and cost.</p> 
<b>Mainframe Batch</b> 
<p>Batch processing usually involves bulk processing of data&nbsp;that could not be processed in real-time due to the limited capabilities of transactional engines at the time of their initial design and implementation. Batch software design was predicated on the constraints and assumptions of the mainframe environment, such as high CPU power for mono thread application, locking of I/O to data storage—which prevents concurrent processing of Batch and transaction—and higher Total Cost of Ownership (TCO) for provisioning nightly CPU peaks. Those constraints are still directly influencing Million Instructions Per Second (MIPS) estimation, cost, and operational model.</p> 
<p>A more efficient and cost optimized architecture is now available with AWS. It can be achieved by transforming legacy Batch processes to real-time microservices, leveraging <a href="https://aws.amazon.com/kinesis">Amazon Kinesis</a> for data streaming, <a href="https://aws.amazon.com/api-gateway">Amazon API Gateway</a> for service invocation, and <a href="http://aws.amazon.com/lambda">AWS Lambda</a> and serverless computing for compute and storage.</p> 
<p>In the following example, I will explain how to transition a typical retail banking mainframe application from the dual Online/Batch model toward real-time microservices combining AWS services and Blu Age modernization technology.</p> 
<b>Example: Mainframe Legacy Batch Architecture</b> 
<p>In <em>Figure 1</em>, we use an example mainframe Batch architecture that we will transform into a microservice architecture in later sections. This typical scenario shows a mainframe legacy system using z/OS CICS, JCL, Cobol, DB2, VSAM files, GDG files, and tapes.</p> 
<img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/07/Mainframe-Legacy-Batch-Architecture-1024x881.jpg" /> 
<p class="wp-caption-text"><em>Figure 1 – Mainframe legacy Batch architecture example.</em></p> 
<p>The Batch programs have been designed to avoid multiple user locking and waiting for transaction responses. During the day, loan request transactions append transaction data to a temporary file, with one file per physical office. At night, CICS transactions that share data with Batches are switched off to avoid concurrency, locks, and consistency issues.</p> 
<h3>There are three Batch programs:</h3> 
<ol> 
<li>Every five minutes, the Upload Batch program sends all temporary files to the Batch region via message queuing.</li> 
<li>Every night, the Loan Batch program is triggered by the scheduler. It executes the following logic: 
<li>All files are merged into one</li> 
<li>The merged file is then sorted to improve performance and prepare the next processing steps</li> 
<li>Each record in the sorted file are processed for enrichment (personal information about credit history and other loans are collected from DB2 and injected into the enriched record)</li> 
<li>Each record is enriched a second time by injecting risk assessment information from a VSAM file, resulting in an enriched file with all the information required to perform risk analysis and grant or reject loan request</li> 
<li>Each record in previous output file is processed, and eventually COBOL programs create three outputs: A copy of unprocessed/rejected records which will need further processing (parsing error, missing elements, fails); an update of records in a DB2 table for each customer requesting a loan with current status (rejected, approved, pending) and loan proposal only for approved requests (rates, duration, etc.); and audit information (who, what, when, where) is traced into mainframe Generation Data Groups (GDG) files.</li> 
</ul> </li> 
<li>Every week, the Archiving Batch is triggered to save some GDG data to tape devices (for legal reasons), and to prune GDG (removal of files sent to tapes).</li> 
</ol> 
<b>Transforming Batch Logic to Microservices with Blu Age Velocity</b> 
<p>Blu Age technology accelerates legacy application modernization with automation for both reverse-engineering of the legacy procedural mainframe applications (code + data) as well as forward-engineering to new microservice-ready object-oriented applications.</p> 
<p>When modernizing from mainframe monoliths toward AWS, both the transformation and the definition of the target architecture are automated and standardized for AWS by <a href="https://www.bluage.com/products/blu-age-velocity">Blu Age Velocity</a> transformation technology. This execution environment is available off-the-shelf and relies upon two components:</p> 
<li><strong>Blu Age Velocity Framework</strong> brings all utilities and services to get rid of former system specificities and anti-patterns: Go To removal, data memory model, execution model, data access model, sort and file management utilities, and more.</li> 
<li><strong>BluSam Server</strong> can be seen as a full stack microservice container. Any number of containers may be deployed, with each being the execution unit for locally deployed services and data access service. Each former Batch program becomes a Spring Boot autonomous executable. Microservice containers are distributed. Programs are freely deployed. Data is freely deployed. In-memory read/write cache may be enable on demand or at start-up. All services are available as REST API. All services are registered into a service directory automatically.</li> 
<img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/07/Blu-Age-Velocity-Microservice-1024x483.jpg" /> 
<p class="wp-caption-text"><em>Figure 2 – Blu Age Velocity microservice design.</em></p> 
<p>Our recommendation for a successful mainframe to microservices project is to separate the technical stack transformation phase from the business split transformation phase in order to keep the microservices transformation complexity manageable for each phase and minimize project risks.</p> 
<p>With such an approach, the first technical stack transformation phase focuses on the application code and data isofunctional migration, keeping the same application model with mostly infrastructure teams from both the mainframe and the AWS sides. The later business split transformation phase focuses on creating domain model boundaries for each microservice and will not involve a mainframe team. It does require participants from the Line of Business with an understanding of the business functions and processes.</p> 
<p>For the technical stack microservice transformation phase, the mainframe Batch architecture is automatically refactored with Blu Age Velocity in the following way:</p> 
<li><strong>REST APIs:</strong> Each service has its REST APIs available and deployed. This enables remote call capability for both business logic services and data access services. Typical integration strategy is made with Kinesis, Lambda, and API Gateway.</li> 
<li><strong>Java Programs:</strong> All former programs and scripts (COBOL programs, JCLs, CICS transactions, BMS maps) are transformed into single executables. BMS maps are transformed into Angular single-page application, while server-side services are transformed into Java Spring Boot applications. Each may be freely deployed to the BluSam server of your choice. They show in the Java Information Control System (JICS) layer of the above picture.</li> 
<li><strong>Cache:</strong> Persisted data may be loaded into the in-memory cache for optimization of performance. The cache supports write-behind and relies on <a href="http://aws.amazon.com/elasticache">Amazon ElastiCache</a>. This increases both read and write performance in bulk mode as well. Native write-through is designed for read access but cause delays when refreshing data into the database, while write-behind allows optimal performance in all scenario.</li> 
<li><strong>Persistence Data Layer:</strong> Persisted data is managed by BluSam I/O. Any former data storage (VSAM, GDG, DB2 z/OS tables, etc) is now stored in a persistence data store. Any prior data access mode (sequential, indexed sequential, hierarchical, relational) is refactored to fit with a new database.</li> 
<li><strong>Persistence Data Store:</strong> Typically, as detailed later, <a href="https://aws.amazon.com/rds/aurora/">Amazon Aurora</a> is the relational data store of choice for data persistence. Now each BluSam Server has the flexibility to operate its own database choice (relational, Key Value store, No SQL, Graph database).</li> 
<li><strong>Service Directory:</strong> All deployed services are published into a central directory for location lookup and integration across microservices.</li> 
<p>For the business split transformation phase, a Domain-Driven Design approach is recommended to identify each microservice scope with a Bounded Context. Blu Age Analyzer automates domain discovery by analyzing data and call dependencies between legacy programs. Domain decomposition refactoring using functional input is supported as well by Blu Age Analyzer. Decomposition strategy produced by Blu Age Analyzer is then driving the modernization transformations.</p> 
<p>To learn more about this approach, see details about <a href="https://www.bluage.com/products/blu-age-analyzer">Blu Age Analyzer</a>, <a href="https://martinfowler.com/tags/domain%20driven%20design.html">Martin Fowler Domain Driven Design</a>, <a href="https://martinfowler.com/bliki/BoundedContext.html">Bounded Context</a>, and <a href="https://en.wikipedia.org/wiki/Domain-driven_design">Wikipedia Domain Driven Design</a>. Once the microservices scope and Bounded Context have been defined, Blu Age automation can quickly re-factor the application code to separate and create the new microservices application packages.</p> 
<b>Example: Resulting Real-Time Microservices</b> 
<p>Getting back to our mainframe legacy Batch example, application owners decide to modernize the mainframe with two main goals in mind:</p> 
<ol> 
<li>Enhance customer experience and satisfaction with answers for loan applications in minutes, rather than the following day once the nightly Batch is complete. Enable self-service and loan notifications to mobile application users.</li> 
<li>Agility and the ability to introduce new features or changes with a better time to market by refactoring all business logic.</li> 
</ol> 
<p>For this purpose, executives decide to transform their mainframe Batch leveraging Blu Age technology as described in the preceding section. We now detail the resulting real-time microservices architecture on AWS. This example microservices Bounded Contexts split is as follows:</p> 
<li><strong>Retail Banking SPA Portal Microservice:</strong> This is a distributed UI system which is localized per region/country (languages, legal specifics).</li> 
<li><strong>Loan Risk Assessment Microservice:</strong> This service is in charge of assessing the risk of granting loans and sending a rate and duration proposal based on customer profile, credit history, and risk assessment rules.</li> 
<li><strong>Transactional Retail Microservice:</strong> This service handles checks, credit card, and all former desk-facing simple operations.</li> 
<li><strong>Long-term Data Storage Microservice:</strong> This becomes a service of its own, which other microservices do not have to be aware of (i.e. they do not have to trigger or do service composition with).</li> 
<img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/07/Real-Time-Microservices-Architecture-1024x532.jpg" /> 
<p class="wp-caption-text"><em>Figure 3 – Real-time microservices architecture with Blu Age Velocity and AWS.</em></p> 
<p>We now describe components of this real-time microservices architecture.</p> 
<h3>Angular Front End</h3> 
<p>Angular enriches user experience while ensuring users of the legacy mainframe application do not require retraining for using the modernized system. All surface behaviors of the former mainframe system are mimicked with user experience related processes and screens transformed into a portal.</p> 
<p>This architecture automatically distributes user connections to different containers and regions for better availability and reliability. It distributes the local versions of retail application in various countries and offices as well (because of various languages and legislation). As soon as a user submits a request, the Angular single-page application emits data into Kinesis to route and process this request in real-time.</p> 
<h3>Amazon Kinesis</h3> 
<p>Kinesis is the unified data hub for the real-time system, also called the data transport layer. Requests are pushed into Kinesis, which acts as a central, fast, and robust streaming hub. In addition to basic message queuing, Kinesis continuously sends data in the stream and allows data replay and broadcasting.</p> 
<p>Kinesis is fully managed, which means you do not have to manage the infrastructure nor the configuration to adapt to burst or capacity variations. Even though data will be processed on the fly, Kinesis provides a buffer if needed. This is beneficial for mainframe Batch when there is a need to replay or reject prior data processing. Furthermore, Kinesis is used to support the <a href="http://microservices.io/patterns/data/database-per-service.html">Database per Service design pattern</a> as per <a href="https://martinfowler.com/articles/microservices.html">Martin Fowler’s microservices description</a>.</p> 
<h3>Amazon API Gateway</h3> 
<p>API Gateway identifies which API or service to map to the incoming Kinesis data. It is the perfect fit as the central hub to access all your microservices, whatever their underlying technology and locations. Moreover, API Gateway serves as a service locator to call appropriate microservices, and enables service versioning and Canary deployment strategy. This&nbsp;allows reducing the risk of introducing a new software version in production by slowly rolling out the change to a small subset of users before rolling it out to the entire infrastructure and making it available to everybody.</p> 
<p>Another reason for using API Gateway as a Canary strategy is when different business versions exist because large banks typically operate in many countries with different regulations. Using microservices through API Gateway, both solve multichannel and multi regulation issues.</p> 
<h3>AWS Lambda</h3> 
<p>API Gateway uses Lambda as a proxy to call microservices. Lambda initiates context and parameter values injected into the remote service. In the legacy system, JCL receives parameter values from a scheduler or programmatically defined variables. In such context, those parameters are used to set up the Batch runtime environment with the name of the dataset, version of deployed programs, execute Batch in production or test partition.</p> 
<p>In the new paradigm, Lambda is used to keep this runtime parameter capability, which the client should not do for decoupling reasons, and triggers the appropriate Groovy script (which replaces z/OS JCL after being transformed with Blu Age). Groovy is preferred to Java to be modified without compilation while sharing the same JVM as the Java classes to be run.</p> 
<p>Therefore, mainframe Batch job steps or run units may be reproduced, and modification can be done to Batch setup without compilation. Groovy and Java classes are called via REST and may be either synchronous or asynchronous. Asynchronous is preferred in case of long processing time. Indeed, Lambda lifetime must be kept below 500 seconds, and in such case detached services is the right pattern.</p> 
<h3>Amazon ElastiCache</h3> 
<p>One specificity of mainframe system is I/O capabilities provided both by the underlying file system and non-relational databases built on top of it. Among those, VSAM relies on indexed sequential data store for which modern databases (RDBMS, graph database, column database) do not provide equivalent indexing, at least not preserving performance for all features. Blu Age BluSam uses ElastiCache (Redis implementation) in order to bring equivalent performance while supporting necessary I/O capabilities features:</p> 
<li><strong>In Memory Indexes:</strong> VSAM indexes are stored in ElastiCache to support fast and full featured indexed sequential logic.</li> 
<li><strong>Index Persistence:</strong> Indexes are saved in real-time to an underlying database to provide the required availability requirements. The default configuration stores into Aurora. BluSam allows using any RDBMS or Key/Value store as well.</li> 
<li><strong>Record Caching:</strong>&nbsp;Mainframe dataset records may be uploaded to cache, either at BluSam Server startup using bulk cache insert or on the fly as requests hit the cache.</li> 
<li><strong>Write-behind:</strong> In addition to write-through, BluSam adds persistence-specific services to support write-behind. Write-through induces a delay (database acknowledgement), which may cause a performance slowdown when doing bulk processing. For this reason, write-behind has been added to manage transactions only at the cache level. The cache manages persistence to the underlying database with a first-of strategy (first of N-record changed and elapsed time since the last cache saving). This write-behind feature is available for both indexes and individual records.</li> 
<li><strong>Managed Service:</strong> ElastiCache is a fully managed service that enables transparent scaling. Even large mainframe Batch systems requiring processing of terabytes of business records per day are handled by ElastiCache with no need to manage capacity or scaling. Data may be uploaded into the cache in burst mode to process reliably any bulk data (warming cache and processing in memory is typically a good strategy for bulk processing).</li> 
<h3>Amazon Aurora</h3> 
<p>Aurora is the preferred target AWS database for mainframe modernization because of its performance and equivalence. Legacy mainframe applications rely mostly on VSAM and SQL I/O capabilities, and changing to another data access type such as put/get of a document&nbsp;could be risky and time-consuming as it involves a major rewrite of the application logic disconnecting it from the data access APIs. However, using Aurora with BluSam and ElastiCache allows preserving transformation automation and performance with no need for refactoring for both VSAM’s like indexes (permanent storage in Aurora; live indexes in ElastiCache), and native SQL support.</p> 
<p>Scalability is also important when modernizing mainframe because legacy application usage varies over time. For example, payroll systems or tax payment systems have a peak of activity every month/quarter. Aurora is a managed database with storage that can automatically grow to 64 TB per instance.</p> 
<p>One challenge with microservices is the Database per Service design pattern. This pattern creates a need for data synchronization within the constraints of the CAP theorem because data is distributed. While specific patterns exist to handle the trade-off between eventual consistency, rollback mechanism, and transactional delay, they were all designed for online transactions. Each of these suffer, however, from network and transactional delay which do not fit with the mainframe Batch latency requirements. This includes a commit time within one milliseconds, whereas patterns such as Saga or API Composition introduce up to 100 milliseconds delay.</p> 
<p>Aurora brings a simple yet effective capability for data synchronization with native Lambda integration. Whenever a record is modified, then a Lambda is triggered. The Lambda is used to stream into Kinesis which delivers to API Gateway. Kinesis allows having multiple subscribers to propagate the data change to their local data store, while API Gateway allows doing API management for each domain. Then, all domains are synchronized simultaneously while each implements its private synchronization APIs based on its private choice of languages and databases</p> 
<p>Aurora Serverless opens new strategies to achieve high performance&nbsp;and behaves like the regular Aurora service but automatically scales up or down based on your application’s needs while preserving ACID transactions. Because of the rapid scaling, Aurora Serverless is a cost-effective solution for Batch, burst, bulk data transfers, data consolidation, reducing elapse time for long processes such as payroll Batches.</p> 
<b>Data Storage Microservice</b> 
<p>In the mainframe system, long-term data storage was handled at the application level, with several Batch jobs being responsible for archiving, back up, and pruning. Furthermore, the mainframe&nbsp;archival is costly and complex because it relies on generational GDG files on mainframe itself, and on tapes shipped to off-site storage.</p> 
<p>With AWS, the long-term data storage microservice is built with a single Lambda function leveraging lower cost storage like <a href="http://aws.amazon.com/s3">Amazon Simple Storage Service</a> (Amazon S3) and <a href="http://aws.amazon.com/glacier">Amazon Glacier</a>.</p> 
<img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/07/Long-Term-Data-Storage-Microservice-1024x373.jpg" /> 
<p class="wp-caption-text"><em>Figure 4 – Long-term data storage microservice.</em></p> 
<p>Preserving the overall defined architecture, Kinesis and API Gateway remain the central data hub. <a href="http://aws.amazon.com/batch">AWS Batch</a> is used to schedule data storage actions through a Lambda function. The Lambda function copies Aurora data into Amazon S3 with a command similar to the following:</p> 
<blockquote> 
<p>SELECT INTO OUTFILE S3 <strong>&lt;sql statement&gt;</strong>, where <strong>sql statement</strong> selects data to be stored externally to the application database.</p> 
</blockquote> 
<p>Amazon S3 functionalities replace z/OS GDG features, local copies of data, audit trails, medium term archiving and pruning of data, and extra backups. For long-term data archival and to satisfy regulatory requirements, the data is later moved from Amazon S3 into Amazon Glacier based on a Lifecycle Rule.</p> 
<h3>Customer Benefits</h3> 
<p>Blu Age Velocity is a ready-to-use solution that accelerates the migration of mainframe Batch to AWS microservices. Because it is a packaged solution, it minimizes project risk and costs. There are savings coming from transitioning from a mainframe MIPS cost structure to pay-as-you-go AWS Managed Services. Such savings typically finance the modernization project in a short time period and allow for a quicker return on investment.</p> 
<p>The target architecture uses AWS Managed Services and serverless technology. As such, each microservice is elastic and minimizes system administrator tasks. It adapts to the client demand, automatically ensuring availability and performance of services while only paying for what you use.</p> 
<p>From a design perspective, mainframe Batch applications are migrated to real-time, which improves customer experience and satisfaction. Batch applications are also transformed into microservices&nbsp;that benefit from more flexibility, increased agility, independent business domains, deployment automation, and safe deployment strategy. In short: better, faster, safer capability to deliver and implement new features.</p> 
<b>Learn More About Blu Age Velocity</b> 
<p>Blu Age Velocity can be used by any customer in any industry, for any mainframe executing languages such as COBOL (including most of its various flavors), JCL, and subsystems such as CICS, IMS, and VSAM. Blu Age Velocity accelerates both the code automated modernization&nbsp;and the target architecture definition.</p> 
<p>Blu Age also facilitates the necessary activities from legacy code base inventory and analysis to control of like-for-like business logic testing and compliance with the latest development standards. Blu Age recommends performing a Proof of Concept with the most complex Batch jobs. This proves the technology robustness and minimizes risk for the other jobs or programs.</p> 
<p><strong><a href="https://aws.amazon.com/marketplace/pp/B078Z1R93R">Visit&nbsp;our Blu Genius listing on AWS Marketplace to access your free sandbox&nbsp;&gt;&gt;</a></strong></p> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-6474');
});
</script> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<meta property="image" content="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/01/Video.jpg" /> 
<b class="lb-b blog-post-title" property="name headline">Using the New Amazon EC2 G3 Instances to Playout an IP-Based Ultra High Definition Channel on AWS</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Mark Stephens</span></span> | on 
<time property="datePublished" datetime="2018-03-06T09:51:52+00:00">06 MAR 2018</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/apn/category/compute/amazon-ec2/" title="View all posts in Amazon EC2*"><span property="articleSection">Amazon EC2*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/storage/amazon-elastic-block-storage-ebs/" title="View all posts in Amazon Elastic Block Storage (EBS)*"><span property="articleSection">Amazon Elastic Block Storage (EBS)*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/analytics/amazon-elasticsearch-service/" title="View all posts in Amazon Elasticsearch Service*"><span property="articleSection">Amazon Elasticsearch Service*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/software/aws-marketplace/" title="View all posts in AWS Marketplace*"><span property="articleSection">AWS Marketplace*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/aws-partner-network/" title="View all posts in AWS Partner Network*"><span property="articleSection">AWS Partner Network*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/apn/using-the-new-amazon-ec2-g3-instances-to-playout-an-ip-based-ultra-high-definition-channel-on-aws/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-6389" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-apn-blog&amp;disqus_identifier=6389&amp;disqus_title=Using+the+New+Amazon+EC2+G3+Instances+to+Playout+an+IP-Based+Ultra+High+Definition+Channel+on+AWS&amp;disqus_url=https://aws.amazon.com/blogs/apn/using-the-new-amazon-ec2-g3-instances-to-playout-an-ip-based-ultra-high-definition-channel-on-aws/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-6389');
});
</script> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><em>By Michael Jacobs, Software as a Service Manager at Cinegy</em></p> 
<p><a href="https://aws.amazon.com/marketplace/pp/B0754S2MNK?qid=1513079044259&amp;sr=0-1&amp;ref_=srh_res_product_title"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/01/Video-300x150.jpg" /></a>Whether you are a content creator, delivery platform provider, or somewhere in between, playout from the cloud is likely a subject of discussion in your organization. More and more companies are looking to the cloud for expansion and the offering of new services, but cloud playout brings its own set of challenges such as&nbsp;knowing which compute resource you will need to run your channels.</p> 
<p><a href="https://aws.amazon.com/partners/find/partnerdetails/?n=Cinegy&amp;id=001E000001FgUVtIAN">Cinegy</a>, an Amazon Web Services (AWS) Standard Technology Partner, has long been an advocate of IP-based video workflows. We understand that maintaining visual quality whilst reducing bandwidth consumption is an ongoing challenge with the increasing data requirements of formats such as Ultra High Definition (UHD). We address this by leveraging the power of NVIDIA’s hardware-based h.264 and h.265 (HEVC) encoding engines instead of using CPU.</p> 
<p>In this post, I will demonstrate how to deploy a fully-functional playout engine using <a href="https://aws.amazon.com/ec2/">Amazon Elastic Compute Cloud</a>&nbsp;(Amazon EC2)&nbsp;resources and the Cinegy Amazon Machine Image (AMI) to deliver a UHD TV channel with graphics.</p> 
<b>Channel in the Cloud</b> 
<p>Some time ago, Cinegy saw the power of CPUs was not increasing at the pace it previously had. We noted, however, that GPUs were still doubling their power every year&nbsp;and decided to invest in leveraging the increasing processing power. We implemented support for NVIDIA encoding and decoding into our products, and this allows video to be offloaded to an available and supported NVIDIA card while keeping the load on the CPU to a minimum.</p> 
<p>Our <strong>Channel in the Cloud bundle</strong>&nbsp;has been&nbsp;<a href="https://aws.amazon.com/marketplace/pp/B0754S2MNK?qid=1519760199294&amp;sr=0-1&amp;ref_=srh_res_product_title">available on AWS Marketplace</a>&nbsp;for some time and has historically deployed on the Amazon EC2 G2 instance family. With the introduction of the G3 instance family, we created a new bundle with better graphic and video format capabilities, such as UHD and multi HD channel support. The new NVIDIA-backed G3 range of instances gives us access to a modern NVIDIA Tesla-based GPU&nbsp;and features such as Enhanced Networking and <a href="https://aws.amazon.com/ebs/">Amazon Elastic Block Service</a>&nbsp;(Amazon EBS)&nbsp;volumes.</p> 
<p>Due to the encoding of the video being carried out by the powerful NVIDIA GPU in the new G3 instance types, it is now possible to playout a UHD-quality video channel, add graphics branding, and monitor the output as well. The latest&nbsp;Channel in the Cloud bundle runs on any of the G3 instance sizes&nbsp;and contains our playout and control software (Cinegy Air PRO) as well as our monitoring software (Cinegy Multiviewer).</p> 
<b>Deploying the Cinegy Software</b> 
<p>The first step is to launch the Cinegy AMI from AWS Marketplace, which has the playout engine configured with channels that are also set to be monitored with the Cinegy Multiviewer application. If you require more in-depth instructions on how to use our software, visit our <a href="https://open.cinegy.com/products/air/11/">Cinegy Air 11</a>&nbsp;and <a href="https://open.cinegy.com/products/multiviewer/12/">Cinegy Multiviewer</a>&nbsp;sections of our document website.</p> 
<p>Making use of the available NVIDIA graphics card with the Cinegy Playout Engine software is relatively straightforward. Let’s go through setting up a single UHD TV channel for RTP output and then look at the load placed upon the instance.</p> 
<p>In addition to the deployed instance, you will need access to the video assets you wish to playout. The media needs to be available on either a locally-attached volume or via UNC path. Alternatively, the video could be an incoming IP stream to the Amazon EC2 instance. Delivery of your generated IP stream will be via your chosen platform, such as over the Internet or satellite uplink location.</p> 
<b>Cinegy Playout Engine – Playback Settings</b> 
<p>To access these settings once you have logged into the instance, right-click the icon in the taskbar to use the configuration utility:</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/02/27/Cinegy-Configuration-Utility.jpg" /></p> 
<p>As you can see in the screenshot below, we have gone into the Playback tab and the channel mode is set to UHD at 25Hz. We will also use the available NVIDIA Tesla M60 in the G3 instance for any graphics rendering on the channel. We added an RTP/UDP output device using the ‘Add device’ button and this will be configured next.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/02/27/Cinegy-Add-Device.jpg" /></p> 
<b>Cinegy Playout Engine – RTP/UDP Settings</b> 
<p>The following screenshot shows the IP output from the engine is set to be encoded using H.264 on the NVIDIA GPU at a bit rate of 100Mbps. We will also be using a constant bit rate and a mostly I-frame mode.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/02/27/Cinegy-IP-Output.jpg" /></p> 
<b>Cinegy Playout Engine – Audio Settings</b> 
<p>After hitting the ‘Next’ button, we can set the audio stream format we wish to use. This has been set to AAC-LC running at 192 kbit/s.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/02/27/Cinegy-Audio-Settings.jpg" /></p> 
<p>Using the above settings on the smallest of the GPU instances, a g3.4xlarge, 1-playout channel configured to output UHD at 25 fps (offloaded to the NVIDIA GPU for H.264 encoding) via RTP at 100Mbps with AAC-LC audio included uses less than 30 percent of the available CPU and less than 10 percent of available RAM.</p> 
<p><span style="color: #ff0000"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/01/Cinegy-Task-Manager-1.jpg" /></span></p> 
<p>If we add some graphics branding to the output, this increases the load on the CPU to about 65 percent when the engine first engages, but then the CPU returns to a slightly increased level, until the graphics sequence is finished.</p> 
<p>If you&nbsp;want to add graphics to your TV channel’s output using Cinegy software, please refer to the <a href="https://open.cinegy.com/products/air/11/titler/">Cinegy Titler manual</a>&nbsp;along with the Handling Items-Secondary Events section of the <a href="https://open.cinegy.com/products/air/11/air/user-manual/handling-items/secondary-events/">Cinegy Air 11 user manual</a>. You can also check out&nbsp;the <a href="https://open.cinegy.com/products/air/11/playout/user-manual/configuration/cg/">Cinegy Playout Engine manual</a>&nbsp;to learn more.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/01/Cinegy-Task-Manager-2.jpg" /></p> 
<p>GPU loading is still very light even when running the additional graphics, with a maximum load of 19 percent being recorded using the <strong>nvidia-smi</strong> command line tool.</p> 
<p>The Cinegy Playout Engine application also includes CPU and memory utilisation graphs for ease of reference.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/02/27/Cinegy-Playout-Dashboard.jpg" /></p> 
<b>Monitoring of Output</b> 
<p>We include our Multiviewer application with the AWS Marketplace offering to give customers the ability to monitor standard broadcast parameters of the output from the Playout Engine, such as Audio Clipping and Video Black. These alerts can be notified to the operators via various mechanisms such as file, SNMP traps, and email, if a problem is detected.</p> 
<p>In addition, Multiviewer alert notifications can be sent as telemetry data to either Cinegy’s or your own <a href="https://aws.amazon.com/elasticsearch-service/">Amazon Elasticsearch Service</a> cluster for visualisation and trend analysis.</p> 
<b>Storage Volumes</b> 
<p>UHD video assets are generally four times larger than the HD equivalent using the same encapsulation and, therefore, also requires four times the bandwidth. By attaching Amazon EBS volumes to the instance, a highly-performant and resilient storage device can be added and used to store media assets. This ensures the critical files required for playback will persist if the instance stops running and has increased availability against single component hardware failure.</p> 
<p>Amazon EBS volumes also provide the flexibility to increase their size and IOPS capacity dynamically on a live system to ensure continued operation.</p> 
<p>The g3.4xlarge instance is an Amazon EBS-optimized instance type. This&nbsp;means it has dedicated bandwidth to communicate with the Amazon EBS service and is separated from any network traffic. The instance size has the capability of having up to 3,500 Mbps of bandwidth available to Amazon EBS, if required.</p> 
<p>As an example, a 1TB-sized general performance SSD (gp2) volume provisioned as a second volume on this instance type would provide 3,000 IOPS of performance and peak throughput of 160 MiB/s.</p> 
<b>Conclusion</b> 
<p>As you can see, the GPU and CPU power available with the Amazon EC2 G3 instances allows you to playout UHD content with graphics branding and be confident you still have some headroom available.</p> 
<p>Combining our Cinegy Air PRO bundle with a G3 instance gives you the capability to achieve UHD playout from the cloud with ease, and provides all the benefits of Amazon EC2, including scalability, monitoring, and dynamic resource allocation. So whether you need to run a single channel for a few hours on a weekend or multiple 24&times;7 channels with redundancy, we encourage you to dive into our solution.</p> 
<p>To take Cinegy for a test run, visit AWS Marketplace and&nbsp;<strong><a href="https://aws.amazon.com/marketplace/pp/B0754S2MNK?qid=1513079044259&amp;sr=0-1&amp;ref_=srh_res_product_title">start enjoying the benefits of UHD cloud playout &gt;&gt;</a></strong></p> 
<hr /> 
<h6><em>The content and opinions in this blog are those of the third party author and AWS is not responsible for the content or accuracy of this post.</em></h6> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-6389');
});
</script> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<meta property="image" content="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/11/17/Build_border.png" /> 
<b class="lb-b blog-post-title" property="name headline">Testing AWS GameDay with the AWS Well-Architected Framework – Continued Remediation</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Ian Scofield</span></span> | on 
<time property="datePublished" datetime="2018-03-01T15:55:26+00:00">01 MAR 2018</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/apn/category/database/amazon-dynamodb/" title="View all posts in Amazon DynamoDB*"><span property="articleSection">Amazon DynamoDB*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/compute/amazon-ec2-container-service/" title="View all posts in Amazon EC2 Container Service*"><span property="articleSection">Amazon EC2 Container Service*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/messaging/amazon-simple-notification-service-sns/" title="View all posts in Amazon Simple Notification Service (SNS)*"><span property="articleSection">Amazon Simple Notification Service (SNS)*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/compute/auto-scaling/" title="View all posts in Auto Scaling*"><span property="articleSection">Auto Scaling*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/management-tools/aws-cloudformation/" title="View all posts in AWS CloudFormation*"><span property="articleSection">AWS CloudFormation*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/compute/aws-lambda/" title="View all posts in AWS Lambda*"><span property="articleSection">AWS Lambda*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/aws-partner-network/" title="View all posts in AWS Partner Network*"><span property="articleSection">AWS Partner Network*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/apn/testing-aws-gameday-with-the-aws-well-architected-framework-continued-remediation/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-6362" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-apn-blog&amp;disqus_identifier=6362&amp;disqus_title=Testing+AWS+GameDay+with+the+AWS+Well-Architected+Framework+%E2%80%93+Continued+Remediation&amp;disqus_url=https://aws.amazon.com/blogs/apn/testing-aws-gameday-with-the-aws-well-architected-framework-continued-remediation/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-6362');
});
</script> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><span style="color: #ff0000">Editor’s note: This is the third in a three-part series about testing AWS GameDay.</span>&nbsp;&nbsp;<span style="color: #993300"><a style="color: #993300" href="https://aws.amazon.com/blogs/apn/testing-aws-gameday-with-the-aws-well-architected-framework/">Read Part 1 &gt;&gt;</a>&nbsp; &nbsp;<a style="color: #993300" href="https://aws.amazon.com/blogs/apn/testing-aws-gameday-with-the-aws-well-architected-framework-remediation/">Read Part 2&gt;&gt;</a></span></p> 
<p><em>By Ian Scofield, Juan Villa, and Mike Ruiz, Partner Solutions Architects at AWS</em></p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/11/17/Build_border.png">Part 1 of the series</a> for an overview of the process, a description of the initial review, and a list of the critical findings identified by the review team.</p> 
<p>In <a href="https://aws.amazon.com/blogs/apn/testing-aws-gameday-with-the-aws-well-architected-framework-remediation/">Part 2 of the series</a>, we remediated the critical findings found in our initial review. We still have other recommendations that we identified to address in our roadmap, and it’s been six months since we remediated our findings. A lot has happened since then, with all the new services and features that were announced at <a href="https://reinvent.awsevents.com/">AWS re:Invent 2017</a>.</p> 
<p>In this post, we’ll cover how we plan on remediating the deficiencies found in our Disaster Recovery plan, as well as other optimizations we’ve made due to recent announcements. We will also discuss how to address another crucial component in our application development—testing.</p> 
<b>Disaster Recovery Deficiencies</b> 
<p>In part 2, you’ll recall we ran a “war game” for our Disaster Recovery plan which focused on the scenario of losing control of a production account. In these tests, we discovered that our move to <a href="https://aws.amazon.com/cloudformation/">AWS CloudFormation</a> to deploy resources gave us the ability to quickly provision identical infrastructure in other accounts and regions. However, we still had work to do to refine our playbooks and Standard Operating Procedures (SOPs) on the exact steps. The most important piece that required attention was our strategy for data stored in <a href="https://aws.amazon.com/dynamodb/">Amazon DynamoDB</a>. We didn’t have automatic backups, and the few manual backups we did have&nbsp;weren’t actively copying to other AWS accounts due to the complexity involved.</p> 
<p>Our initial plan to backup DynamoDB was to leverage <a href="https://aws.amazon.com/datapipeline/?nc2=h_m1">AWS Data Pipeline</a>, which has a built-in template which takes snapshots of your database and stores it in <a href="https://aws.amazon.com/s3/?nc2=h_m1">Amazon Simple Storage Service</a> (Amazon S3). This allows us to back up our tables, but it had some downsides, too. Behind the scenes, Data Pipeline is running an <a href="http://aws.amazon.com/emr">Amazon EMR</a> cluster that retrieves all the items from our table and writes them to Amazon S3. For this reason, it isn’t as quick as we’d like, and due to the abstraction layer it’s hard to debug if anything were to go wrong.</p> 
<p>Additionally, this has a performance impact on our tables since it’s doing a scan operation and is taxing on read capacity. Also, since this is for our Disaster Recovery scenario, our desired end state is for our backups to end up in a different account—the one we will be failing over to in the event of a disaster. This task can be done with Data Pipeline but requires a lot of additional configuration and adds more complexity.</p> 
<p>We then considered using DynamoDB streams to write to a DynamoDB table in our other account, but this doesn’t protect us from propagating errors, and it doesn’t provide us with point-in-time recovery. We had been brainstorming a solution to this problem for some time, when, at AWS re:Invent 2017, we announced the ability to <a href="https://aws.amazon.com/dynamodb/backup-restore/">take backups of DynamoDB tables</a> via the click of a button or simple API call. This feature allows us to take encrypted backups of DynamoDB tables without a performance impact, and it doesn’t require us to provision any additional infrastructure. However, as of this post, the missing piece is that these backups are only available within the same AWS account and region, and they cannot be copied to another account or region.</p> 
<p>The DynamoDB team also came out with the concept of <a href="https://aws.amazon.com/dynamodb/global-tables/">Global Tables</a>, a multi-master DynamoDB table that spans AWS regions. This currently doesn’t support replication across accounts; only across regions within the same account. Now this by itself wouldn’t meet our Disaster Recovery requirements, as replication is not a substitute for backup (e.g. data corruption would be replicated). But if we combined this approach with the previous Backup/Restore feature, this solves our Disaster Recovery strategy. Due to AWS continuing to release new features and enhancements, we communicated the need for these enhancements to our account team and will continue to check to see if they are implemented.</p> 
<p>In the meantime, we needed to come up with a viable solution. We stumbled upon a <a href="https://github.com/awslabs/dynamodb-continuous-backup">continuous DynamoDB backup solution</a> that’s published on the <a href="https://github.com/awslabs">AWS Labs GitHub repo</a>. This solution restores individual items and&nbsp;offers point-in-time recovery. We are in the process of evaluating this solution, which provides us with better granularity of our backups, but it still requires some modification to fulfill our cross-account requirement.</p> 
<p>Based on the lessons learned from our “war game” and continued refinement of our SOPs and playbooks, we have implemented quarterly testing to ensure we are prepared and have the necessary tooling in place.</p> 
<b>Amazon EC2 – M5 Instances</b> 
<p>When we moved to an <a href="http://aws.amazon.com/ecs">Amazon Elastic Container Service</a> (Amazon ECS) cluster, we selected the M4 <a href="https://aws.amazon.com/ec2/">Amazon Elastic Compute Cloud</a> (Amazon EC2) instance family for our nodes. We chose this family after careful consideration, benchmarking, and cost comparison to other EC2 instance types. In particular, this instance family was a good fit because the Docker containers running on the clusters were neither CPU-bound, IO-bound, nor Memory-bound, but rather a balance of all.</p> 
<p>After AWS re:Invent 2017, we were excited to hear about the introduction of M5, the next-generation <a href="https://aws.amazon.com/blogs/aws/m5-the-next-generation-of-general-purpose-ec2-instances/">general purpose instance family</a>. In Jeff Barr’s blog post, he announced the M5 could achieve a better price-performance ratio than the M4 family, by as much as 14 percent. Needless to say, we quickly dove into the console and began testing the M5 instance family in our development environment. We determined M5 provided approximately a 10 percent performance improvement over our current configuration while keeping costs the same.</p> 
<p>At the end of the day, migrating from the M4 to M5 instance family meant we could run less EC2 instances in our Amazon ECS cluster to achieve equivalent performance, and therefore lower operating costs. Keep in mind there was no guarantee the M5 family would enable us to run our workload more cost effectively, as every workload is different. Benchmarking and extensive testing allowed us to safely and methodically calculate the benefits and make the final decision to migrate.</p> 
<b>AWS Fargate</b> 
<p>Another exciting announcement from AWS re:Invent 2017 was the launch of <a href="https://aws.amazon.com/fargate/">AWS Fargate</a>, a managed and easy-to-use service for deploying and managing containers. <a href="https://aws.amazon.com/about-aws/whats-new/2017/11/introducing-aws-fargate-a-technology-to-run-containers-without-managing-infrastructure/">This announcement</a> was particularly exciting because we were in charge of deploying and managing our own Amazon ECS cluster to run and scale our GameDay workload.</p> 
<p>The deployment of the GameDay workload Amazon ECS cluster is currently automated using CloudFormation and Amazon EC2 Scaling Groups. While this approach drastically reduced our day-to-day burden of operating the cluster, we still saw an opportunity for further improvement, simplification, and cost savings by considering AWS Fargate. Naturally, we investigated and dug in further.</p> 
<p>The first thing we considered is how AWS Fargate could eliminate the burden of operating an Amazon ECS cluster. As a managed service, we don’t have to create the cluster, but we instruct AWS Fargate how to deploy our container and how many we need. This means less opportunity for operator error on our end, and easier management of our infrastructure during production events. This also translates to cost savings since it means we need less high-skilled engineers at the helm when running GameDay events.</p> 
<p>In addition to operational simplicity, there is an opportunity for additional cost savings as AWS Fargate’s billing model means we pay only for the running containers. This means that for smaller events we pay only for the containers that are running rather than paying for a full-sized Amazon ECS cluster that costs the same whether we are running a small game or a large game. It’s also worth noting that AWS Fargate allows for seamless scaling, meaning we can scale for larger events very easily without have to scale our Amazon ECS clusters manually, which can be error prone.</p> 
<p>As of this post, we are planning our strategy for testing and ultimately migrating toward AWS Fargate rather than deploying and managing our current Amazon ECS cluster.</p> 
<b>Testing</b> 
<p>Based on the changes we have implemented thus far, there have been some significant architectural modifications. Our team had an event coming up and we knew it would be wise to run several tests to ensure—from an infrastructure and application perspective—everything was working and that we hadn’t introduced any new issues. We found minor items in our testing that we were able to remediate, and we felt confident everything would perform as expected. When it came time to run the actual event, we encountered errors that we previously hadn’t found in our testing.</p> 
<p>When we did our testing, we ran them in large numbers to stress the application and discover as many edge cases as possible. But we didn’t reach the same level of scale we would in our actual event. We were experiencing a hot key issue with DynamoDB, which isn’t something that can be easily remedied during the event since it involves changing our schema. We have since remedied this, and our next iteration of testing will mirror not only our estimated numbers but additional load to ensure we have room for unexpected growth.</p> 
<b>It Was Worth It</b> 
<p>Our team was initially apprehensive about performing a Well-Architected review, as we knew areas of our application weren’t pretty and we didn’t want to draw attention to them. We knew these areas needed work, but we were struggling to prioritize fixing them. We focused on new features as opposed to fixing our existing technical debt. However, looking back on it, we now have a much stronger architecture and can honestly say we feel more prepared for various scenarios in the future. We will continue to work with our account team to ensure we are continuing to follow best practices. We will also keep an eye towards new features and enhancements that can solve some of our existing challenges.</p> 
<b>What’s Next</b> 
<p>GameDay as a training and enablement tool has taken off internally due to the feedback we have received from customers. While&nbsp;our team was continuing to iterate on the version of GameDay outlined in this post, we have been working on building a multi-tenant SaaS platform to enable other teams within AWS to run GameDay and make it more self-service. This new platform powered GameDay at AWS re:Invent 2017 and will power new versions of GameDay moving forward.</p> 
<p>We hope to see you at the next event!</p> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-6362');
});
</script> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<meta property="image" content="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/12/13/Blockchain-Partners.jpg" /> 
<b class="lb-b blog-post-title" property="name headline">Building, Managing, and Deploying Blockchain Applications with BlockApps</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Lana Kalashnyk</span></span> | on 
<time property="datePublished" datetime="2018-03-01T11:01:36+00:00">01 MAR 2018</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/apn/category/aws-partner-network/" title="View all posts in AWS Partner Network*"><span property="articleSection">AWS Partner Network*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/awsquest/" title="View all posts in AWS Quest*"><span property="articleSection">AWS Quest*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/apn/building-managing-and-deploying-blockchain-applications-with-blockapps/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-6371" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-apn-blog&amp;disqus_identifier=6371&amp;disqus_title=Building%2C+Managing%2C+and+Deploying+Blockchain+Applications+with+BlockApps&amp;disqus_url=https://aws.amazon.com/blogs/apn/building-managing-and-deploying-blockchain-applications-with-blockapps/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-6371');
});
</script> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><em>By Lana Kalashnyk, Global Partner Technology Lead for Blockchain at AWS</em></p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/03/BlockApps_AWS-Solutions-300x150.jpg" />Blockchain is a foundational technology that is as promising as it is exciting to explore. What is blockchain? It’s the application of a technology in which a list of records, or blocks, are cryptographically linked to one another via timestamps and other attributes. Blockchains are resistant to data modification since the alteration of one block requires consensus across the recorded chain or ledger.</p> 
<p>With blockchain, it truly becomes a journey of identifying new business models, or optimizing existing ones, to drive the right technology selection for the underlying protocol. As with many journeys, you will need a solid plan, the right tools, and a trusted advisor.</p> 
<p>As you evaluate blockchain protocols, it’s important to understand the underlying pillars of these architectures. Concepts like immutability, distributed ledgers, smart contracts, and the shared perception of truth or consensus are virtually universal. This makes Ethereum a popular starting point for anyone looking to build decentralized applications, or DApps. But setting up an Ethereum network (IDEs, compilers, wallets, APIs, etc.) can be time consuming and,&nbsp;ultimately, may not validate your use case in a timely manner.</p> 
<p>So, what if you want to write your first DApp in a matter of minutes?</p> 
<p><a href="https://blockapps.net/">BlockApps</a> is a leading provider of Ethereum blockchain development solutions. Their private implementation, written in Haskell, provides a highly scalable Ethereum-compliant blockchain with an industry standard RESTful API and an easy-to-use web-based management dashboard.</p> 
<p>These features and quick deployments through <a href="https://aws.amazon.com/marketplace/pp/B071NV8MXT?qid=1519850702868&amp;sr=0-1&amp;ref_=srh_res_product_title">AWS Marketplace</a> enable developers to build, test, and deploy smart contracts faster than ever.</p> 
<b>Key Components of the BlockApps Platform:</b> 
<li><strong>STRATO Management Dashboard (SMD):</strong> Web-based UI for your Private Ethereum Blockchain Network. SMD allows you to interact with user accounts, manage smart contracts in a single dashboard, and explore blocks and transactions. CMD leverages Bloc and STRATO APIs for user and contracts management while offering a SQL-like query interface for smart-contracts leveraging Cirrus.</li> 
<li><strong>Bloc API:</strong> A comprehensive API allowing for user, account management, and smart-contracts management.</li> 
<li><strong>STRATO API:</strong> Blockchain API for exploring and managing blocks and transactions.</li> 
<li><strong>Cirrus:</strong> SQL-like query API for looking up smart-contracts and state changes. Cirrus allows you to index and search smart-contracts by leveraging familiar techniques.</li> 
<p>If you would like to try this solution out,&nbsp;check out&nbsp;BlockApps’&nbsp;<a href="https://aws.amazon.com/marketplace/pp/B071NV8MXT">STRATO Ethereum Blockchain Platform – Developer Edition</a>&nbsp;on AWS Marketplace.</p> 
<img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/02/26/BlockApps-dashboard-1.jpg" /> 
<p class="wp-caption-text"><em>Figure 1 – STRATO Management Dashboard (SMD) shows the current state of the network. Users can inspect blocks and view accounts, launched contracts, and transaction processing metrics.</em></p> 
<b>Building Your First Decentralized Application Stack</b> 
<p>Now that we have a base STRATO stack set up, let’s focus on what it means to derive value from a blockchain application. This is where BlockApps’ core tenants driving the direction of STRATO’s platform vision help us out. BlockApps STRATO is a blockchain platform aimed at practical business and consumer usage. They achieve this by focusing on acceleration, ease of use, and performance scale and security.</p> 
<p>In practice, this means&nbsp;you can use existing technologies where applicable instead of re-inventing the wheel. You will notice that even though BlockApps leverages the Ethereum protocol and reuses the Solidity compiler (Ethereum Virtual Machine, or EVM) without change. They integrate industry-standard relational databases for search and reporting workloads adjacent to the blockchain and utilize RESTful APIs for integration with client applications.</p> 
<p>This can be demonstrated through a <a href="https://github.com/blockapps/blockapps-ba">Supply Chain Demo App</a> built on top of STRATO platform, along with user and development guides.&nbsp;These resources enable you&nbsp;to examine a sample DApp architecture that combines best practices of control plane separation found in traditional Software Development Methodologies, underpinned by Ethereum and smart contracts.</p> 
<p>The diagram in <em>Figure 2</em> shows a typical decentralized application stack built on top of BlockApps. This is a good visualization of how blockchain-specific components, such as the protocol (i.e. Enterprise Ethereum) and business logic (i.e. smart contracts) can be used to build a full application stack completed by the API layers, application middleware, and user interface.</p> 
<img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/02/26/BlockApps-application-stack-1.jpg" /> 
<p class="wp-caption-text"><em>Figure 2 – A decentralized application stack built on top of BlockApps shows how blockchain-specific components can be used to build a full application stack completed by the API layers, application middleware, and user interface.</em></p> 
<b>Next Steps</b> 
<p>Blockchain-based applications introduce new possibilities for both peer-to-peer and enterprise optimization solutions.&nbsp;Amazon Web Services (AWS) is <a href="https://aws.amazon.com/partners/blockchain/">investing in blockchain through our partner community</a>. We provide the broadest and deepest capabilities and the largest global infrastructure for building end-to-end blockchain platforms, cost efficiently and at scale. AWS Partners like BlockApps offer a rapidly growing selection of blockchain and distributed ledger solutions with support for multiple protocols.</p> 
<p><a href="https://aws.amazon.com/marketplace/pp/B071NV8MXT?qid=1519850702868&amp;sr=0-1&amp;ref_=srh_res_product_title"><strong>Check out BlockApps on AWS Marketplace to learn more &gt;&gt;</strong></a></p> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-6371');
});
</script> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<meta property="image" content="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/02/26/IoT-2.jpg" /> 
<b class="lb-b blog-post-title" property="name headline">Connecting IoT Devices and Designing Embedded Applications with Zerynth</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Juan Villa</span></span> | on 
<time property="datePublished" datetime="2018-02-26T09:16:58+00:00">26 FEB 2018</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/apn/category/aws-partner-network/" title="View all posts in AWS Partner Network*"><span property="articleSection">AWS Partner Network*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/awsquest/" title="View all posts in AWS Quest*"><span property="articleSection">AWS Quest*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/internet-of-things/" title="View all posts in Internet of Things*"><span property="articleSection">Internet of Things*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/apn/designing-embedded-applications-and-connecting-iot-devices-with-zerynth/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-6342" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-apn-blog&amp;disqus_identifier=6342&amp;disqus_title=Connecting+IoT+Devices+and+Designing+Embedded+Applications+with+Zerynth&amp;disqus_url=https://aws.amazon.com/blogs/apn/designing-embedded-applications-and-connecting-iot-devices-with-zerynth/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-6342');
});
</script> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><em>By Juan Villa, Partner Solutions Architect at AWS</em></p> 
<p><a href="https://aws.amazon.com/partners/find/partnerdetails/?n=Zerynth&amp;id=0010L00001pAGonQAG"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/05/Zerynth_AWS-Solutions-300x150.jpg" /></a>A challenge many industrial and manufacturing corporations face when adopting&nbsp;an Internet of Things (IoT) strategy is the complexity of designing and developing for embedded devices. This is even more pronounced for corporations that have little knowledge of firmware development for embedded devices, as is the case when established corporations adopt IoT for new product releases.</p> 
<p>Traditionally, when working with embedded devices, a developer needs a complex set of tools on their machine, ranging from embedded toolchains (open source are hard to configure, and commercial are very expensive) to Integrated Development Environments (IDEs) and specialty tools to interface with the target embedded hardware device. This has been a long-standing issue with embedded development.</p> 
<p><a href="https://aws.amazon.com/partners/find/partnerdetails/?n=Zerynth&amp;id=0010L00001pAGonQAG">Zerynth</a>, an AWS Standard Technology Partner, provides a software development suite that enables Python programming on 32-bit microcontrollers and allows easy connectivity to&nbsp;<a href="https://aws.amazon.com/iot/">AWS IoT</a> services. As of this post, Zerynth supports more than 30 different hardware boards, making it a complete ecosystem for IoT development.</p> 
<p>By providing a completely integrated development environment with support for Python, Zerynth removes most the complexities of embedded development, thus making it easier and quicker to launch an IoT product to the market.</p> 
<p><em>Figure 1</em> shows&nbsp;a high-level overview of an IoT solution built on the Zerynth Stack.</p> 
<img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/02/19/Zerynth-Stack_website-1024x512.png" /> 
<p class="wp-caption-text"><em>Figure 1 – The Zerynth Stack includes Zerynth Studio, a powerful IDE and toolchain for developing embedded software in Python, and&nbsp;Zerynth Virtual Machine, a multi-threaded real-time OS for embedded devices.</em></p> 
<h3>The Main Elements of the Zerynth Stack Are:</h3> 
<li><a href="https://www.zerynth.com/zerynth-studio/">Zerynth Studio</a> – Powerful IDE and toolchain for developing embedded software in Python. It even supports hybrid C/Python development, and is both free and cross-platform.</li> 
<li><a href="https://www.zerynth.com/zerynth-virtual-machine/">Zerynth Virtual Machine</a> – Multi-threaded real-time OS for embedded devices that provides true hardware independence and code reuse on a wide range of 32-bit microcontrollers and boards. The VM supports most high-level Python features like modules, classes, multi-threading, callbacks, timers, and exceptions, with a footprint of just 60-80kb of Flash and 3-5kb of RAM.</li> 
<p>Many microcontroller and board manufacturers have already chosen Zerynth as a third-party development tool, including <a href="https://www.espressif.com/en/media_overview/news/zerynth-introduces-python-esp32">Espressif</a>, <a href="https://www.zerynth.com/blog/zerynth-is-an-official-microchip-third-party-development-tool/">Microchip Technologies</a>, <a href="https://www.mikroe.com/blog/flip-click-to-be-officially-supported-by-zerynth-bringing-python-compatibility">Flip &amp; click</a> by Mikroelektronika, <a href="http://www.hexiwear.com/programming-hexiwear-in-python/">Hexiwear</a>&nbsp;by NXP and Mikroelktronika, and <a href="https://www.kickstarter.com/projects/redbearinc/bluetooth-5-ready-ble-module-nano-2-and-blend-2/posts/1812287">RedBear BLE Nano2 and Blend2</a>.</p> 
<p>Before starting your next IoT project, check out&nbsp;how the Zerynth Stack can make your team more productive. I also encourage you to <a href="https://www.youtube.com/watch?v=IZzZF3DGWkY">watch this video tutorial</a>&nbsp;showing how to connect an ESP32 DevKitC to AWS IoT using the Zerynth Stack.</p> 
<p>Zerynth has many other tutorials and announcements on their blog, including this&nbsp;<a href="https://www.zerynth.com/blog/firmware-over-the-air-updates-via-aws-powered-by-zerynth/">tutorial showing a safe and easy mechanism</a> to perform Firmware Over-the-Air (FOTA) updates of Zerynth-powered devices connected to AWS IoT endpoints.</p> 
<p><strong><a href="https://www.zerynth.com/">Visit the Zerynth website to learn more &gt;&gt;</a></strong></p> 
<hr /> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/14/aws_partner_network_blog_02-1024x21.png" /></p> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-6342');
});
</script> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<meta property="image" content="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/02/21/Amazon-Athena.jpg" /> 
<b class="lb-b blog-post-title" property="name headline">Now You Can Query and Visualize Amazon Athena Data Directly in Chartio</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Paul Sears</span></span> | on 
<time property="datePublished" datetime="2018-02-22T08:18:09+00:00">22 FEB 2018</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/apn/category/analytics/amazon-athena/" title="View all posts in Amazon Athena*"><span property="articleSection">Amazon Athena*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/analytics/" title="View all posts in Analytics*"><span property="articleSection">Analytics*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/aws-partner-network/" title="View all posts in AWS Partner Network*"><span property="articleSection">AWS Partner Network*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/awsquest/" title="View all posts in AWS Quest*"><span property="articleSection">AWS Quest*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/apn/now-you-can-query-and-visualize-amazon-athena-data-directly-in-chartio/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-6325" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-apn-blog&amp;disqus_identifier=6325&amp;disqus_title=Now+You+Can+Query+and+Visualize+Amazon+Athena+Data+Directly+in+Chartio&amp;disqus_url=https://aws.amazon.com/blogs/apn/now-you-can-query-and-visualize-amazon-athena-data-directly-in-chartio/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-6325');
});
</script> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><em>By Paul Sears, Partner Solutions Architect at AWS</em></p> 
<p><a href="https://aws.amazon.com/partners/find/partnerdetails/?n=Chartio&amp;id=001E000000Rp5PlIAJ"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/05/Chartio_AWS-Solutions-300x150.jpg">Amazon Simple Storage Service</a> (Amazon S3), consolidating all of their unstructured and structured data into one central, infinitely scalable location. This allows for easy access to that data by users and applications within their organization as part of the data value chain.</p> 
<p>But to make the unstructured and structured data useful or consumable, you previously had to transform the data into a format or schema that your databases and analytics applications could use. Maybe you processed it with <a href="http://aws.amazon.com/emr">Amazon EMR</a> or another Hadoop framework. Or you leveraged <a href="https://aws.amazon.com/glue">AWS Glue</a>, our fully-managed extract, transform, and load (ETL) service. You could also have used one of our many <a href="https://aws.amazon.com/partners/apn-journal/">AWS Partner solutions</a> to transform important data.</p> 
<p>But what if you need to simplify the data value chain or query your data directly in your data lake? This is where <a href="http://aws.amazon.com/athena">Amazon Athena</a> comes in. Athena is a Presto-distributed SQL engine used to query unstructured data using standard SQL, where you pay only for the amount of data you query.</p> 
<p><a href="https://aws.amazon.com/partners/find/partnerdetails/?n=Chartio&amp;id=001E000000Rp5PlIAJ">Chartio</a>, an AWS Advanced Technology Partner with the <a href="https://aws.amazon.com/partners/competencies/big-data/">AWS Big Data Competency</a>, recently announced support for Amazon Athena. Their solution allows you to query and visualize data stored in an Amazon S3 data lake using standard SQL. You can also use their visual drag-and-drop SQL layer, which generates native SQL queries for you.</p> 
<img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/02/19/Chartio-visualization-1024x586.jpg" /> 
<p class="wp-caption-text"><em>Figure 1 – Chartio can generate a visualization using Amazon Athena as a data source.</em></p> 
<p>Chartio is a powerful-yet-intuitive business intelligence and data exploration solution that allows organizations to quickly and easily query and visualize data from any source. With Chartio’s support for Athena, you no longer have to transform and load your data into <a href="https://aws.amazon.com/redshift/">Amazon Redshift</a> or EMR before you create visualizations. Now, you can perform ad hoc queries, join Athena across your disparate cloud apps and databases, and build out customized and interactive dashboards to dig deeper into what’s happening in your business.</p> 
<p>Plus, if there are certain data sets in Athena you know you will query frequently, you can query the data once and utilize <a href="https://support.chartio.com/docs/datastores/">Chartio’s Data Stores</a> to save the results to use without having to send additional queries to Athena. You can then join your Athena data with other sources and apply transformations to the data to get your data exactly how you want it. You can easily control access to Athena but still unleash the data to all of your users with Data Stores, without worrying about extra costs.</p> 
<p><strong><a href="https://blog.chartio.com/building-a-data-stack-amazon-athena-chartio">Learn more about Chartio’s announcement &gt;&gt;</a></strong></p> 
<p><strong><a href="https://chartio.com/signup/">Begin a free trial to start querying your Amazon Athena data with Chartio &gt;&gt;</a></strong></p> 
<hr /> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2018/03/14/aws_partner_network_blog_03-1024x21.png" /></p> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-6325');
});
</script> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<meta property="image" content="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/11/14/AWS-Certification_border-1.png" /> 
<b class="lb-b blog-post-title" property="name headline">Register for the New AWS Certified Developer – Associate Beta Exam</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Cory Calhoun</span></span> | on 
<time property="datePublished" datetime="2018-02-19T11:31:40+00:00">19 FEB 2018</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/apn/category/aws-partner-network/" title="View all posts in AWS Partner Network*"><span property="articleSection">AWS Partner Network*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/apn/register-for-the-new-aws-certified-developer-associate-beta-exam/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-6319" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-apn-blog&amp;disqus_identifier=6319&amp;disqus_title=Register+for+the+New+AWS+Certified+Developer+%26%238211%3B+Associate+Beta+Exam&amp;disqus_url=https://aws.amazon.com/blogs/apn/register-for-the-new-aws-certified-developer-associate-beta-exam/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-6319');
});
</script> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><a href="https://aws.amazon.com/certification/beta-exam/#Developer"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/11/14/AWS-Certification_border-1-300x150.png" /></a>The AWS Training and Certification team is hosting a beta for an updated version of our <strong>AWS Certified Developer – Associate exam</strong>. This beta reflects current Amazon Web Services (AWS) features, services, and best practices.</p> 
<p>You may take the beta exam through March 16. Space is limited and registration will close when capacity is reached.</p> 
<p><strong><a href="https://aws.amazon.com/certification/beta-exam/">Register for the beta exam &gt;&gt;</a></strong></p> 
<p><strong>We are offering the beta exam for $75 USD—a 50% discount off the cost of the standard Developer exam.</strong></p> 
<p>Beta exam results are typically available 90 days (13 weeks) or less from the close of the beta exam. Individuals who pass the beta exam are eligible to receive a voucher to take the AWS Certified DevOps Engineer – Professional exam at 50% off.</p> 
<b>About the Beta Exam</b> 
<p>We recommend candidates have one or more years of hands-on experience designing and maintaining AWS-based applications.</p> 
<p>The beta exam validates an examinee’s ability to:</p> 
<li>Demonstrate an understanding of core AWS services, uses, and basic AWS architecture best practices.</li> 
<li>Demonstrate proficiency in developing, deploying, and debugging cloud-based applications using AWS.</li> 
<p>Recommended AWS knowledge:</p> 
<li>In-depth knowledge of at least one high-level programming language</li> 
<li>Ability to use the AWS service APIs, AWS Command Line Interface (CLI), and software developer kits (SDKs) to write applications</li> 
<li>Ability to identify key features of AWS services</li> 
<li>Understanding of the AWS shared responsibility model</li> 
<li>Understanding of application lifecycle management</li> 
<p><a href="https://aws.amazon.com/certification/beta-exam/">See our beta exam website for more details &gt;&gt;</a></p> 
<b>Beta Exam Preparation</b> 
<p>These training courses and materials may be helpful for examination preparation:</p> 
<h3>AWS Training</h3> 
<li><a href="https://aws.amazon.com/training/course-descriptions/developing/">Developing on AWS</a>&nbsp;– classroom training</li> 
<h3>AWS Whitepapers</h3> 
<li><a href="https://d0.awsstatic.com/whitepapers/Security/AWS_Security_Best_Practices.pdf?refid=em_">AWS Security Best Practices</a>&nbsp;– August 2016</li> 
<li><a href="https://d0.awsstatic.com/whitepapers/architecture/AWS_Well-Architected_Framework.pdf">AWS Well-Architected Framework</a>&nbsp;– November 2017</li> 
<li><a href="https://d0.awsstatic.com/whitepapers/AWS_Cloud_Best_Practices.pdf">Architecting for the Cloud: AWS Best Practices</a> – February 2016</li> 
<li><a href="https://d1.awsstatic.com/whitepapers/DevOps/practicing-continuous-integration-continuous-delivery-on-AWS.pdf">Accelerating Software Delivery with DevOps</a>&nbsp;– June 2017</li> 
<li><a href="https://d1.awsstatic.com/whitepapers/microservices-on-aws.pdf">Microservices on AWS</a>&nbsp;– September 2017</li> 
<li><a href="https://d1.awsstatic.com/whitepapers/AWS_Blue_Green_Deployments.pdf">Blue/Green Deployments on AWS</a>&nbsp;– August 2016</li> 
<p>If you are interested in helping test out the new version of the exam, potentially getting certified, and saving some money, <a href="https://aws.amazon.com/certification/beta-exam/">learn more about the beta exam and register</a>.</p> 
<p>Please&nbsp;<a href="http://proctor2.psionline.com/aws.asp">contact us</a>&nbsp;if you have questions the beta exam.</p> 
<p>Good luck!</p> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-6319');
});
</script> 
</article> 
<p>
© 2018 Amazon Web Services, Inc. or its affiliates. All rights reserved.
</p>

    </div>
  </div>
</div>


    <div id="footer" class="navigation hidden-print">
      <div class="container">
        <div class="row">
          <div class="col-xs-12">
            <ul class="footer-links nav navbar-nav">
              <li><a href="../aws.html">AWS</a></li>
              <li><a href="../linux.html">Linux</a></li>
              <li><a href="../docker.html">Docker</a></li>
              <li><a href="../ibmpower.html">IBM Power</a></li>
              <li><a href="blogsataws1.html">Blogs@AWS (Kindle Friendly)</a></li>
            </ul>
            <ul class="footer-links nav navbar-nav navbar-right">
              <li><a href="../comments.html">Comments?</a></li>
            </ul>
          </div>
        </div>
      </div>
    </div>
  </body>
</html>
