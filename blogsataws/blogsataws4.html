<!DOCTYPE html>
<html lang="en">
  <head>
<!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-593498H');</script>
<!-- End Google Tag Manager -->

    <meta charset="utf-8">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">

    <meta name="msapplication-config" content="/microsoft-tile.xml" />
    <meta name="theme-color" content="#ffffff">

    <meta property="og:url" content="https://bejoycalias.github.io/blogsataws/blogsataws1.html" />
    <meta property="og:site_name" content="Bejoy's TechNotes"/>
    <meta property="og:title" content="Bejoy's TechNotes - Kindle Friendly AWS News Blogs" />
    <meta property="og:image" content="https://bejoycalias.github.io/assets/images/og-image.png"/>
    <meta property="og:image:width" content="1200"/>
    <meta property="og:image:height" content="1200"/>
    <meta property="og:description" content="" />

    <title>Bejoy's TechNotes - Kindle Friendly AWS News Blogs</title>
    <link href="../assets/stylesheets/application-832aa42c.css" rel="stylesheet" />

    <!--[if lt IE 9]>
      <script src="../assets/javascripts/ie-compat-c141a02d.js"></script>
    <![endif]-->
    <script src="../assets/javascripts/application-ff53d307.js"></script>

    <!-- Typekit script to import Klavika font -->
    <script src="https://use.typekit.net/wxf7mfi.js"></script>
    <script>try{Typekit.load({ async: true });}catch(e){}</script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-100043608-1', 'auto');
  ga('send', 'pageview');

</script>

    
  </head>

  <body id="uh-oh-" class="layout-inner page-uh-oh-">
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-593498H"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->


    <div id="header" class="navigation navbar-static-top hidden-print">
      <div class="container">
        <div class="row">
          <div class="col-xs-12">
            <div class="navbar-header">
              <div class="navbar-brand">
                <a href="/">
                  <svg version="1.0" xmlns="http://www.w3.org/2000/svg" width="135.000000pt" height="50" viewbox="0 0 135.000000 45.000000" preserveaspectratio="xMidYMid meet" class="logo">

<g transform="translate(0.000000,45.000000) scale(0.100000,-0.100000)" fill="#000000" stroke="none">
<path class="text" fill="#000000" d="M527 384 c-4 -4 -7 -18 -7 -31 0 -21 4 -24 28 -21 21 2 27 8 27 28 0
18 -6 26 -20 28 -12 2 -24 0 -28 -4z"></path>
<path class="text" fill="#000000" d="M1080 335 c0 -48 2 -55 20 -55 18 0 20 7 20 55 0 48 -2 55 -20 55
-18 0 -20 -7 -20 -55z"></path>
<path class="text" fill="#000000" d="M54 357 c-2 -7 -3 -69 -2 -138 l3 -124 65 -3 c90 -3 130 20 130 77 0
29 -6 44 -20 54 -20 14 -20 15 -3 45 14 25 15 34 5 56 -6 15 -23 31 -38 36
-38 15 -134 13 -140 -3z m110 -33 c19 -7 21 -45 4 -62 -7 -7 -22 -12 -35 -12
-20 0 -23 5 -23 40 0 41 13 50 54 34z m20 -130 c19 -18 19 -20 6 -45 -8 -13
-21 -19 -45 -19 -34 0 -35 1 -35 40 0 38 2 40 29 40 16 0 37 -7 45 -16z"></path>
<path class="text" fill="#000000" d="M319 271 c-23 -24 -29 -38 -29 -74 0 -25 3 -53 6 -62 20 -50 164 -64
164 -15 0 15 -7 17 -45 12 -46 -5 -75 8 -75 34 0 11 16 14 65 14 l65 0 0 35
c0 80 -92 114 -151 56z m99 -33 c3 -15 -4 -18 -37 -18 -43 0 -50 7 -29 28 18
18 62 11 66 -10z"></path>
<path class="text" fill="#000000" d="M520 184 c0 -107 -1 -116 -20 -121 -11 -3 -20 -12 -20 -19 0 -21 76
-19 84 2 3 9 6 69 6 135 l0 119 -25 0 -25 0 0 -116z"></path>
<path class="text" fill="#000000" d="M649 271 c-24 -25 -29 -37 -29 -78 1 -70 34 -103 105 -103 55 0 95
44 95 103 0 60 -7 75 -41 92 -47 25 -96 19 -130 -14z m111 -30 c25 -48 2 -111
-40 -111 -45 0 -69 80 -34 114 21 22 61 20 74 -3z"></path>
<path class="text" fill="#000000" d="M850 287 c0 -8 16 -57 36 -110 28 -76 33 -100 25 -116 -16 -28 -14
-31 18 -31 27 0 29 4 70 123 23 67 41 128 41 135 0 6 -11 12 -24 12 -21 0 -26
-8 -41 -65 -10 -36 -21 -68 -25 -70 -3 -2 -16 27 -29 66 -19 60 -25 69 -47 69
-13 0 -24 -6 -24 -13z"></path>
<path class="text" fill="#000000" d="M1192 284 c-17 -12 -22 -24 -20 -47 2 -26 10 -36 45 -52 49 -23 59
-55 17 -55 -14 0 -34 5 -45 10 -16 9 -19 7 -19 -13 0 -17 7 -27 23 -31 69 -18
117 6 117 60 0 32 -4 37 -45 55 -60 26 -62 54 -4 46 37 -5 40 -3 37 16 -2 18
-11 23 -43 25 -25 2 -49 -3 -63 -14z"></path>
</g>
</svg>

                </a>
              </div>
              <button class="navbar-toggle" type="button">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
              </button>
            </div>
            <div class="buttons hidden-xs">
              <nav class="navigation-links" role="navigation">
                <ul class="main-links nav navbar-nav navbar-right">
                  <li><a href="../aws.html">AWS</a></li>
                  <li><a href="../linux.html">Linux</a></li>
                  <li><a href="../docker.html">Docker</a></li>
                  <li><a href="../ibmpower.html">IBM Power</a></li>
                  <li class="active"><a href="blogsataws1.html">Blogs@AWS (Kindle Friendly)</a></li>
                </ul>
              </nav>
            </div>
          </div>
        </div>
      </div>
    </div>

    <div class="sidebar-overlay"></div>

<aside class="sidebar" role="navigation">
  <div class="sidebar-header">
    <svg version="1.0" xmlns="http://www.w3.org/2000/svg" width="135.000000pt" height="42" viewbox="0 0 135.000000 45.000000" preserveaspectratio="xMidYMid meet">

<g transform="translate(0.000000,45.000000) scale(0.100000,-0.100000)" fill="#000000" stroke="none">
<path class="text" fill="#000000" d="M527 384 c-4 -4 -7 -18 -7 -31 0 -21 4 -24 28 -21 21 2 27 8 27 28 0
18 -6 26 -20 28 -12 2 -24 0 -28 -4z"></path>
<path class="text" fill="#000000" d="M1080 335 c0 -48 2 -55 20 -55 18 0 20 7 20 55 0 48 -2 55 -20 55
-18 0 -20 -7 -20 -55z"></path>
<path class="text" fill="#000000" d="M54 357 c-2 -7 -3 -69 -2 -138 l3 -124 65 -3 c90 -3 130 20 130 77 0
29 -6 44 -20 54 -20 14 -20 15 -3 45 14 25 15 34 5 56 -6 15 -23 31 -38 36
-38 15 -134 13 -140 -3z m110 -33 c19 -7 21 -45 4 -62 -7 -7 -22 -12 -35 -12
-20 0 -23 5 -23 40 0 41 13 50 54 34z m20 -130 c19 -18 19 -20 6 -45 -8 -13
-21 -19 -45 -19 -34 0 -35 1 -35 40 0 38 2 40 29 40 16 0 37 -7 45 -16z"></path>
<path class="text" fill="#000000" d="M319 271 c-23 -24 -29 -38 -29 -74 0 -25 3 -53 6 -62 20 -50 164 -64
164 -15 0 15 -7 17 -45 12 -46 -5 -75 8 -75 34 0 11 16 14 65 14 l65 0 0 35
c0 80 -92 114 -151 56z m99 -33 c3 -15 -4 -18 -37 -18 -43 0 -50 7 -29 28 18
18 62 11 66 -10z"></path>
<path class="text" fill="#000000" d="M520 184 c0 -107 -1 -116 -20 -121 -11 -3 -20 -12 -20 -19 0 -21 76
-19 84 2 3 9 6 69 6 135 l0 119 -25 0 -25 0 0 -116z"></path>
<path class="text" fill="#000000" d="M649 271 c-24 -25 -29 -37 -29 -78 1 -70 34 -103 105 -103 55 0 95
44 95 103 0 60 -7 75 -41 92 -47 25 -96 19 -130 -14z m111 -30 c25 -48 2 -111
-40 -111 -45 0 -69 80 -34 114 21 22 61 20 74 -3z"></path>
<path class="text" fill="#000000" d="M850 287 c0 -8 16 -57 36 -110 28 -76 33 -100 25 -116 -16 -28 -14
-31 18 -31 27 0 29 4 70 123 23 67 41 128 41 135 0 6 -11 12 -24 12 -21 0 -26
-8 -41 -65 -10 -36 -21 -68 -25 -70 -3 -2 -16 27 -29 66 -19 60 -25 69 -47 69
-13 0 -24 -6 -24 -13z"></path>
<path class="text" fill="#000000" d="M1192 284 c-17 -12 -22 -24 -20 -47 2 -26 10 -36 45 -52 49 -23 59
-55 17 -55 -14 0 -34 5 -45 10 -16 9 -19 7 -19 -13 0 -17 7 -27 23 -31 69 -18
117 6 117 60 0 32 -4 37 -45 55 -60 26 -62 54 -4 46 37 -5 40 -3 37 16 -2 18
-11 23 -43 25 -25 2 -49 -3 -63 -14z"></path>
</g>
</svg>

  </div>

  <ul class="nav sidebar-nav">
    <li><a href="../aws.html">AWS</a></li>
    <li><a href="../linux.html">Linux</a></li>
    <li><a href="../docker.html">Docker</a></li>
    <li><a href="../ibmpower.html">IBM Power</a></li>
    <li class="active"><a href="blogsataws1.html">Blogs@AWS (Kindle Friendly)</a></li>
  </ul>
</aside>


    <div class="container">
  <div class="row">
    <div id="docs-sidebar" class="col-sm-3 col-md-3 col-xs-12 hidden-print" role="complementary">
      <ul class="nav docs-sidenav">
      <li class="active"><a href="blogsataws1.html">Blogs @ AWS</a></li>
      <li><a href="whatsnew1.html">What's New @ AWS</a></li>
      <li><a href="mgmtblogs1.html">Management Tools Blogs @ AWS</a></li>
      <li><a href="computeblogs1.html">Compute Blogs @ AWS</a></li>
      <li><a href="devopsblogs1.html">DevOps Blogs @ AWS</a></li>
      <li><a href="secblogs1.html">Security Blogs @ AWS</a></li>
      <li><a href="apnblogs1.html">APN Blogs @ AWS</a></li>

    </ul>
    </div>

    <div id="inner" class="col-sm-9 col-md-9 col-xs-12" role="main">
<p></p>
<p><i>Contents of this page is copied directly from AWS blog sites to make it Kindle friendly. Some styles & sections from these pages are removed to render this properly in 'Article Mode' of Kindle e-Reader browser. All the contents of this page is property of AWS.</i></p>
<p><a href="blogsataws1.html">Page 1</a>|<a href="blogsataws2.html">Page 2</a>|<a href="blogsataws3.html">Page 3</a>|<a href="blogsataws4.html">Page 4</a></p>
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<meta property="image" content="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2017/11/29/AmazonFreeRTOS-02-NewSoftwareConfig1-724x630.png" /> 
<b class="lb-b blog-post-title" property="name headline">Announcing Amazon FreeRTOS – Enabling Billions of Devices to Securely Benefit from the Cloud</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<a href="https://aws.amazon.com/blogs/aws/author/tarawalk/" title="Posts by Tara Walker">Tara Walker</a> | on 
<time property="datePublished" datetime="2017-11-29T10:39:14+00:00">29 NOV 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/aws/category/internet-of-things/amazon-freertos/" title="View all posts in Amazon FreeRTOS"><span property="articleSection">Amazon FreeRTOS</span></a>, <a href="https://aws.amazon.com/blogs/aws/category/events/reinvent/" title="View all posts in AWS re:Invent*"><span property="articleSection">AWS re:Invent*</span></a>, <a href="https://aws.amazon.com/blogs/aws/category/news/launch/" title="View all posts in Launch*"><span property="articleSection">Launch*</span></a>, <a href="https://aws.amazon.com/blogs/aws/category/news/" title="View all posts in News*"><span property="articleSection">News*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/aws/announcing-amazon-freertos/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-22506" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-official-blog&amp;disqus_identifier=22506&amp;disqus_title=Announcing+Amazon+FreeRTOS+%26%238211%3B+Enabling+Billions+of+Devices+to+Securely+Benefit+from+the+Cloud&amp;disqus_url=https://aws.amazon.com/blogs/aws/announcing-amazon-freertos/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-22506');
});
</script> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p>I was recently reading an article on ReadWrite.com titled “<a href="https://readwrite.com/2016/12/21/iot-devices-increase-200-worldwide-five-years-dl4/">IoT devices go forth and multiply, to increase 200% by 2021</a>“, and while the article noted the benefit for consumers and the industry of this growth, two things in the article stuck with me. The first was the specific statement that read “researchers warned that the proliferation of IoT technology will create a new bevvy of challenges. Particularly troublesome will be IoT deployments at scale for both end-users and providers.” Not only was that sentence a mouthful, but it really addressed some of the challenges that can come building solutions and deployment of this exciting new technology area. The second sentiment in the article that stayed with me was that Security issues could grow.</p> 
<p>So the article got me thinking, how can we create these cool IoT solutions using low-cost efficient microcontrollers with a secure operating system that can easily connect to the cloud. Luckily the answer came to me by way of an exciting new open-source based offering coming from AWS that I am happy to announce to you all today. Let’s all welcome, Amazon&nbsp;FreeRTOS to the technology stage.</p> 
<p><a href="https://aws.amazon.com/freertos/"><strong>Amazon FreeRTOS</strong></a> is an IoT microcontroller operating system that&nbsp;simplifies development, security, deployment, and maintenance of microcontroller-based edge devices. Amazon FreeRTOS extends the FreeRTOS kernel, a popular real-time operating system, with libraries that enable local and cloud connectivity, security, and (coming soon) over-the-air updates.</p> 
<p>So what are some of the great benefits of this new exciting offering, you ask. They are as follows:</p> 
<li><strong>Easily to create solutions for Low Power Connected Devices</strong>: provides a common operating system (OS) and libraries that make the development of common IoT capabilities easy for devices. For example; over-the-air (OTA) updates&nbsp;<em>(coming soon)</em> and&nbsp;device configuration.</li> 
<li><strong>Secure Data and Device Connections:&nbsp;</strong>devices only run trusted software using the Code Signing service, Amazon FreeRTOS provides a secure connection to the AWS using TLS, as well as, the ability to securely store keys and sensitive data on the device.</li> 
<li><strong>Extensive Ecosystem:&nbsp;</strong>contains an&nbsp;extensive hardware and technology ecosystem that allows you to choose a variety of qualified chipsets, including Texas Instruments, Microchip, NXP Semiconductors, and STMicroelectronics.</li> 
<li><strong>Cloud or Local Connections:</strong>&nbsp;&nbsp;Devices can connect directly to the AWS Cloud or via <strong>AWS Greengrass</strong>.</li> 
<p>&nbsp;</p> 
<p><span style="color: #3366ff"><strong>What’s cool is that it is easy to get started.</strong>&nbsp;</span></p> 
<p>The <strong>Amazon FreeRTOS</strong> console allows you to select and download the software that you need for your solution.</p> 
<p>There is a Qualification Program that helps to assure you that the microcontroller you choose will run consistently across several hardware options.</p> 
<p>Finally, <strong>Amazon FreeRTOS</strong> kernel is an open-source FreeRTOS operating system that is freely available on GitHub for download.</p> 
<p>But I couldn’t leave you without at least showing you a few snapshots of the <strong>Amazon FreeRTOS</strong> Console.</p> 
<p>Within the <strong>Amazon FreeRTOS</strong> Console, I can select a predefined software configuration that I would like to use.</p> 
<p><img width="100%" src="https://media.amazonwebservices.com/blog/2017/AmazonFreeRTOS-02-NewSoftwareConfig1.png" /></p> 
<p>If I want to have a more customized software configuration, <strong>Amazon FreeRTOS</strong> allows you to customize a solution that is targeted for your use by adding or removing libraries.</p> 
<p><img width="100%" src="https://media.amazonwebservices.com/blog/2017/AmazonFreeRTOS-01-NewSoftwareConfig.png" /></p> 
<p><strong><u>Summary</u></strong></p> 
<p>Thanks for checking out the new <strong>Amazon FreeRTOS&nbsp;</strong>offering. To learn more go to the&nbsp;<strong>Amazon FreeRTOS</strong> <a href="https://aws.amazon.com/freertos/">product page</a> or review the information provided about this exciting IoT device targeted operating system in the <a href="https://aws.amazon.com/documentation/freertos/">AWS documentation</a>.</p> 
<p>Can’t wait to see what great new IoT systems are&nbsp;will be enabled and created with it! Happy Coding.</p> 
<p>– <a href="http://twitter.com/taraw">Tara </a></p> 
<p>&nbsp;</p> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-22506');
});
</script> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<meta property="image" content="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2017/11/29/IoT-Analytics-10-Activities.png" /> 
<b class="lb-b blog-post-title" property="name headline">Presenting AWS IoT Analytics: Delivering IoT Analytics at Scale and Faster than Ever Before</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<a href="https://aws.amazon.com/blogs/aws/author/tarawalk/" title="Posts by Tara Walker">Tara Walker</a> | on 
<time property="datePublished" datetime="2017-11-29T10:35:09+00:00">29 NOV 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/aws/category/internet-of-things/aws-iot-analytics/" title="View all posts in AWS IoT Analytics"><span property="articleSection">AWS IoT Analytics</span></a>, <a href="https://aws.amazon.com/blogs/aws/category/events/reinvent/" title="View all posts in AWS re:Invent*"><span property="articleSection">AWS re:Invent*</span></a>, <a href="https://aws.amazon.com/blogs/aws/category/internet-of-things/" title="View all posts in Internet of Things*"><span property="articleSection">Internet of Things*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/aws/launch-presenting-aws-iot-analytics/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-22134" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-official-blog&amp;disqus_identifier=22134&amp;disqus_title=Presenting+AWS+IoT+Analytics%3A+Delivering+IoT+Analytics+at+Scale+and+Faster+than+Ever+Before&amp;disqus_url=https://aws.amazon.com/blogs/aws/launch-presenting-aws-iot-analytics/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-22134');
});
</script> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p>One of the technology areas I thoroughly enjoy is the Internet of Things (IoT). Even as a child I used to infuriate my parents by taking apart the toys they would purchase for me to see how they worked and if I could somehow put them back together. It seems somehow I was destined to end up the tough and ever-changing world of technology. Therefore, it’s no wonder that I am really enjoying learning and tinkering with IoT devices and technologies. It combines my love of development and software engineering with my curiosity around circuits, controllers, and other facets of the electrical engineering discipline; even though an electrical engineer I can not claim to be.</p> 
<p>Despite all of the information that is collected by the deployment of IoT devices and solutions, I honestly never really thought about the need to analyze, search, and process this data <strong>until</strong> I came up against a scenario where it became of the utmost importance to be able to search and query through loads of sensory data for an anomaly occurrence. Of course, I understood the importance of analytics for businesses to make accurate decisions and predictions to drive the organization’s direction. But it didn’t occur to me initially, how important it was to make analytics an integral part of my IoT solutions. Well, I learned my lesson just in time because this re:Invent a service is launching to make it easier for anyone to process and analyze IoT messages and device data.</p> 
<p>&nbsp;</p> 
<p>Hello, <a href="https://aws.amazon.com/iot-analytics/"><strong>AWS IoT Analytics</strong></a>! &nbsp;<strong>AWS IoT Analytics</strong> is a fully managed service of <strong>AWS IoT</strong> that provides advanced data analysis of data collected from your IoT devices.&nbsp; With the <strong>AWS IoT Analytics</strong> service, you can process messages, gather and store large amounts of device data, as well as, query your data. Also, the new <strong>AWS IoT</strong> <strong>Analytics</strong> service feature integrates with <strong>Amazon Quicksight</strong> for visualization of your data and brings the power of machine learning through integration with <strong>Jupyter Notebooks</strong>.</p> 
<p><strong>Benefits of AWS IoT Analytics</strong></p> 
<li>Helps with predictive analysis of data by providing access to pre-built analytical functions</li> 
<li>Provides ability to visualize analytical output from service</li> 
<li>Provides tools to clean up data</li> 
<li>Can help identify patterns in the gathered data</li> 
<p><strong>Be In the Know: IoT Analytics Concepts </strong></p> 
<li><strong>Channel</strong>: archives the raw, unprocessed messages and collects data from MQTT topics.</li> 
<li><strong>Pipeline</strong>: consumes messages from channels and allows message processing. 
<li><em><strong>Activities</strong></em>: perform transformations on your messages including filtering attributes and invoking lambda functions advanced processing.</li> 
</ul> </li> 
<li><strong>Data Store</strong>: Used as a queryable repository for processed messages. Provide ability to have multiple datastores for messages coming from different devices or locations or filtered by message attributes.</li> 
<li><strong>Data Set</strong>: Data retrieval view from a data store, can be generated by a recurring schedule.<strong>&nbsp;</strong></li> 
<p><strong>Getting Started with AWS IoT Analytics</strong></p> 
<p>First, I’ll create a channel to receive incoming messages.&nbsp; This channel can be used to ingest data sent to the channel via MQTT or messages directed from the Rules Engine. To create a channel, I’ll select the <strong>Channels</strong> menu option and then click the <strong>Create a channel</strong> button.</p> 
<p><img width="100%" src="https://media.amazonwebservices.com/blog/2017/IoT Analytics-01-CreateChannel.png" /></p> 
<p>I’ll name my channel, <strong>TaraIoTAnalyticsID</strong> and give the <strong>Channel</strong> a <strong>MQTT topic filter</strong> of <strong>Temperature</strong>. To complete the creation of my channel, I will click the <strong>Create Channel</strong> button.<img width="100%" src="https://media.amazonwebservices.com/blog/2017/IoT Analytics-02-ChannelID.png" /></p> 
<p><img width="100%" src="https://media.amazonwebservices.com/blog/2017/IoT Analytics-03-ChannelCreated.png" /></p> 
<p>Now that I have my <strong>Channel</strong> created, I need to create a <strong>Data Store</strong> to receive and store the messages received on the <strong>Channel</strong> from my IoT device. Remember you can set up multiple Data Stores for more complex solution needs, but I’ll just create one <strong>Data Store</strong> for my example. I’ll select <strong>Data Stores</strong> from menu panel and click <strong>Create a data store</strong>.</p> 
<p><img width="100%" src="https://media.amazonwebservices.com/blog/2017/IoT Analytics-04-CreateDatasource.png" /></p> 
<p>&nbsp;</p> 
<p>I’ll name my <strong>Data Store</strong>, <strong>TaraDataStoreID</strong>, and once I click the <strong>Create the data store</strong> button and I would have successfully set up a <strong>Data Store</strong> to house messages coming from my <strong>Channel</strong>.</p> 
<p><img width="100%" src="https://media.amazonwebservices.com/blog/2017/IoT Analytics-06-DatasourceCreated.png" /></p> 
<p>Now that I have my <strong>Channel</strong> and my <strong>Data Store</strong>, I will need to connect the two using a <strong>Pipeline</strong>. I’ll create a simple pipeline that just connects my Channel and Data Store, but you can create a more robust pipeline to process and filter messages by adding Pipeline activities like a <strong>Lambda activity</strong>.</p> 
<p>To create a pipeline, I’ll select the <strong>Pipelines</strong> menu option and then click the <strong>Create a pipeline</strong> button.</p> 
<p><img width="100%" src="https://media.amazonwebservices.com/blog/2017/IoT Analytics-07-CreatePipeline.png" /></p> 
<p><img width="100%" src="https://media.amazonwebservices.com/blog/2017/IoT Analytics-08-PipelineID.png" /></p> 
<p>I will not add an <strong>Attribute</strong> for this pipeline. So I will click <strong>Next&nbsp;</strong>button.</p> 
<p><img width="100%" src="https://media.amazonwebservices.com/blog/2017/IoT Analytics-09-Attributes.png" /></p> 
<p>As we discussed there are additional pipeline activities that I can add to my pipeline for the processing and transformation of messages but I will keep my first pipeline simple and hit the <strong>Next</strong> button.</p> 
<p><img width="100%" src="https://media.amazonwebservices.com/blog/2017/IoT Analytics-10-Activities.png" /></p> 
<p>The final step in creating my pipeline is for me to select my previously created <strong>Data Store</strong> and click <strong>Create Pipeline</strong>.</p> 
<p><img width="100%" src="https://media.amazonwebservices.com/blog/2017/IoT Analytics-11-PipelineCreateLastStep.png" /></p> 
<p><img width="100%" src="https://media.amazonwebservices.com/blog/2017/IoT Analytics-12-PipelineCreated.png" /></p> 
<p>All that is left for me to take advantage of the <strong>AWS IoT Analytics</strong> service is to create an IoT rule that sends data to an AWS IoT Analytics channel.&nbsp; Wow, that was a super easy process to set up analytics for IoT devices.</p> 
<p>If I wanted to create a <strong>Data Set</strong> as a result of queries run against my data for visualization with <strong>Amazon Quicksight</strong> or integrate with <strong>Jupyter Notebooks </strong>to&nbsp;perform more advanced analytical functions, I can choose the <strong>Analyze</strong> menu option to bring up the screens to create data sets and access the <strong>Juypter Notebook</strong> instances.</p> 
<p><img width="100%" src="https://media.amazonwebservices.com/blog/2017/IoT Analytics-13-DataSet.png" /></p> 
<p><img width="100%" src="https://media.amazonwebservices.com/blog/2017/IoT Analytics-14-Notebooks.png" /></p> 
<p><strong><u>Summary</u></strong></p> 
<p>As you can see, it was a very simple process to set up the advanced data analysis for AWS IoT. With AWS IoT Analytics, you have the ability to collect, visualize, process, query and store large amounts of data generated from your AWS IoT connected device. Additionally, you can access the AWS IoT Analytics service in a myriad of different ways; the AWS Command Line Interface (AWS CLI), the AWS IoT API, language-specific AWS SDKs, and AWS IoT Device SDKs.</p> 
<p>AWS IoT Analytics is available today for you to dig into the analysis of your IoT data. To learn more about AWS IoT and AWS IoT Analytics go to the <a href="https://aws.amazon.com/iot-analytics/">AWS IoT Analytics product page</a> and/or the <a href="https://aws.amazon.com/documentation/iot/">AWS IoT documentation</a>.</p> 
<p>– <a href="http://twitter.com/taraw">Tara </a></p> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-22134');
});
</script> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">In the Works – AWS IoT Device Defender – Secure Your IoT Fleet</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<a href="https://aws.amazon.com/blogs/aws/author/jbarr/" title="Posts by Jeff Barr">Jeff Barr</a> | on 
<time property="datePublished" datetime="2017-11-29T10:32:36+00:00">29 NOV 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/aws/category/internet-of-things/aws-iot-device-defender/" title="View all posts in AWS IoT Device Defender"><span property="articleSection">AWS IoT Device Defender</span></a>, <a href="https://aws.amazon.com/blogs/aws/category/internet-of-things/aws-iot-platform/" title="View all posts in AWS IoT Platform*"><span property="articleSection">AWS IoT Platform*</span></a>, <a href="https://aws.amazon.com/blogs/aws/category/re-invent/" title="View all posts in AWS re:Invent"><span property="articleSection">AWS re:Invent</span></a>, <a href="https://aws.amazon.com/blogs/aws/category/events/reinvent/" title="View all posts in AWS re:Invent*"><span property="articleSection">AWS re:Invent*</span></a>, <a href="https://aws.amazon.com/blogs/aws/category/internet-of-things/" title="View all posts in Internet of Things*"><span property="articleSection">Internet of Things*</span></a>, <a href="https://aws.amazon.com/blogs/aws/category/news/" title="View all posts in News*"><span property="articleSection">News*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/aws/in-the-works-aws-sepio-secure-your-iot-fleet/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p>Scale takes on a whole new meaning when it comes to IoT. Last year I was lucky enough to tour a gigantic factory that had, on average, one environment sensor per square meter. The sensors measured temperature, humidity, and air purity several times per second, and served as an early warning system for contaminants. I’ve heard customers express interest in deploying IoT-enabled consumer devices in the millions or tens of millions.</p> 
<p>With powerful, long-lived devices deployed in a geographically distributed fashion, managing security challenges is crucial. However, the limited amount of local compute power and memory can sometimes limit the ability to use encryption and other forms of data protection.</p> 
<p>To address these challenges and to allow our customers to confidently deploy IoT devices at scale, we are working on <span title="">IoT Device Defender</span>. While the details might change before release, <span title="">AWS IoT Device Defender</span> is designed to offer these benefits:</p> 
<p><strong>Continuous Auditing</strong> – <span title="">AWS IoT Device Defender</span> monitors the policies related to your devices to ensure that the desired security settings are in place. It looks for drifts away from best practices and supports custom audit rules so that you can check for conditions that are specific to your deployment. For example, you could check to see if a compromised device has subscribed to sensor data from another device. You can run audits on a schedule or on an as-needed basis.</p> 
<p><strong>Real-Time Detection and Alerting</strong> – <span title="">AWS IoT Device Defender</span> looks for and quickly alerts you to unusual behavior that could be coming from a compromised device. It does this by monitoring the behavior of similar devices over time, looking for unauthorized access attempts, changes in connection patterns, and changes in traffic patterns (either inbound or outbound).</p> 
<p><strong>Fast Investigation and Mitigation</strong> – In the event that you get an alert that something unusual is happening, <span title="">AWS IoT Device Defender</span> gives you the tools, including contextual information, to help you to investigate and mitigate the problem. Device information, device statistics, diagnostic logs, and previous alerts are all at your fingertips. You have the option to reboot the device, revoke its permissions, reset it to factory defaults, or push a security fix.</p> 
<p><span style="text-decoration: underline"><strong>Stay Tuned</strong></span><br /> I’ll have more info (and a hands-on post) as soon as possible, so stay tuned!</p> 
<p>— <a href="https://twitter.com/jeffbarr">Jeff</a>;</p> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<meta property="image" content="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2017/11/25/iotdm_tour_1.jpg" /> 
<b class="lb-b blog-post-title" property="name headline">New- AWS IoT Device Management</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<a href="https://aws.amazon.com/blogs/aws/author/jbarr/" title="Posts by Jeff Barr">Jeff Barr</a> | on 
<time property="datePublished" datetime="2017-11-29T10:30:36+00:00">29 NOV 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/aws/category/internet-of-things/aws-iot-device-management/" title="View all posts in AWS IoT Device Management"><span property="articleSection">AWS IoT Device Management</span></a>, <a href="https://aws.amazon.com/blogs/aws/category/events/reinvent/" title="View all posts in AWS re:Invent*"><span property="articleSection">AWS re:Invent*</span></a>, <a href="https://aws.amazon.com/blogs/aws/category/internet-of-things/" title="View all posts in Internet of Things*"><span property="articleSection">Internet of Things*</span></a>, <a href="https://aws.amazon.com/blogs/aws/category/news/launch/" title="View all posts in Launch*"><span property="articleSection">Launch*</span></a>, <a href="https://aws.amazon.com/blogs/aws/category/news/" title="View all posts in News*"><span property="articleSection">News*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/aws/aws-iot-device-management/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-22223" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-official-blog&amp;disqus_identifier=22223&amp;disqus_title=New-+AWS+IoT+Device+Management&amp;disqus_url=https://aws.amazon.com/blogs/aws/aws-iot-device-management/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-22223');
});
</script> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><a href="https://aws.amazon.com/iot" title="">AWS IoT</a> and <a href="https://aws.amazon.com/greengrass" title="">AWS Greengrass</a> give you a solid foundation and programming environment for your IoT devices and applications.</p> 
<p>The nature of IoT means that an at-scale device deployment often encompasses millions or even tens of millions of devices deployed at hundreds or thousands of locations. At that scale, treating each device individually is impossible. You need to be able to set up, monitor, update, and eventually retire devices in bulk, collective fashion while also retaining the flexibility to accommodate varying deployment configurations, device models, and so forth.</p> 
<p><span style="text-decoration: underline"><strong>New AWS IoT Device Management</strong></span><br /> Today we are launching <a href="https://aws.amazon.com/iot-device-management/"><span title="">AWS IoT Device Management</span></a> to help address this challenge. It will help you through each phase of the device lifecycle, from manufacturing to retirement. Here’s what you get:</p> 
<p><strong>Onboarding</strong> – Starting with devices in their as-manufactured state, you can control the provisioning workflow. You can use IoT Device Management templates to quickly onboard entire fleets of devices with a few clicks. The templates can include information about device certificates and access policies.</p> 
<p><strong>Organization</strong> – In order to deal with massive numbers of devices, <span title="">AWS IoT Device Management</span> extends the existing IoT Device Registry and allows you to create a hierarchical model of your fleet and to set policies on a hierarchical basis. You can drill-down through the hierarchy in order to locate individual devices. You can also query your fleet on attributes such as device type or firmware version.</p> 
<p><strong>Monitoring</strong> – Telemetry from the devices is used to gather real-time connection, authentication, and status metrics, which are published to <a href="https://aws.amazon.com/cloudwatch/" title="">Amazon CloudWatch</a>. You can examine the metrics and locate outliers for further investigation. IoT Device Management lets you configure the log level for each device group, and you can also publish change events for the Registry and Jobs for monitoring purposes.</p> 
<p><strong>Remote Management</strong> – <span title="">AWS IoT Device Management</span> lets you remotely manage your devices. You can push new software and firmware to them, reset to factory defaults, reboot, and set up bulk updates at the desired velocity.</p> 
<p><span style="text-decoration: underline"><strong>Exploring AWS IoT Device Management</strong></span><br /> The <span title="">AWS IoT Device Management</span> Console took me on a tour and pointed out how to access each of the features of the service:</p> 
<p><img width="100%" src="https://media.amazonwebservices.com/blog/2017/iotdm_tour_1.jpg" /></p> 
<p>I already have a large set of devices (pressure gauges):</p> 
<p><img width="100%" src="https://media.amazonwebservices.com/blog/2017/dm_gauges_1.jpg" /></p> 
<p>These gauges were created using the new template-driven bulk registration feature. Here’s how I create a template:</p> 
<p><img width="100%" src="https://media.amazonwebservices.com/blog/2017/dm_create_template_1.jpg" /></p> 
<p>The gauges are organized into groups (by US state in this case):</p> 
<p><img width="100%" src="https://media.amazonwebservices.com/blog/2017/dm_thing_groups_1.jpg" /></p> 
<p>Here are the gauges in Colorado:</p> 
<p><img width="100%" src="https://media.amazonwebservices.com/blog/2017/dm_things_in_co_1.png" /></p> 
<p>AWS IoT group policies allow you to control access to specific IoT resources and actions for all members of a group. The policies are structured very much like IAM policies, and can be created in the console:</p> 
<p><img width="100%" src="https://media.amazonwebservices.com/blog/2017/dm_make_policy_1.png" /></p> 
<p>Jobs are used to selectively update devices. Here’s how I create one:</p> 
<p><img width="100%" src="https://media.amazonwebservices.com/blog/2017/dm_jobs_1.png" /></p> 
<p>As indicated by the <strong>Job type</strong> above, jobs can run either once or continuously. Here’s how I choose the devices to be updated:</p> 
<p><img width="100%" src="https://media.amazonwebservices.com/blog/2017/dm_pick_your_ear_1.png" /></p> 
<p>I can create custom authorizers that make use of a Lambda function:</p> 
<p><img width="100%" src="https://media.amazonwebservices.com/blog/2017/dm_custom_auth_1.png" /></p> 
<p>I’ve shown you a medium-sized subset of <span title="">AWS IoT Device Management</span> in this post. <a href="https://aws.amazon.com/iot-device-management/">Check it out</a> for yourself to learn more!</p> 
<p>— <a href="https://twitter.com/jeffbarr">Jeff</a>;</p> 
<p>&nbsp;</p> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-22223');
});
</script> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<meta property="image" content="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2017/11/29/di_con_main_2-1.png" /> 
<b class="lb-b blog-post-title" property="name headline">Amazon Comprehend – Continuously Trained Natural Language Processing</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<a href="https://aws.amazon.com/blogs/aws/author/jbarr/" title="Posts by Jeff Barr">Jeff Barr</a> | on 
<time property="datePublished" datetime="2017-11-29T10:06:19+00:00">29 NOV 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/aws/category/artificial-intelligence/amazon-comprehend/" title="View all posts in Amazon Comprehend"><span property="articleSection">Amazon Comprehend</span></a>, <a href="https://aws.amazon.com/blogs/aws/category/ar-vr/" title="View all posts in AR &amp; VR"><span property="articleSection">AR &amp; VR</span></a>, <a href="https://aws.amazon.com/blogs/aws/category/artificial-intelligence/" title="View all posts in Artificial Intelligence*"><span property="articleSection">Artificial Intelligence*</span></a>, <a href="https://aws.amazon.com/blogs/aws/category/events/reinvent/" title="View all posts in AWS re:Invent*"><span property="articleSection">AWS re:Invent*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/aws/amazon-comprehend-continuously-trained-natural-language-processing/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-22556" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-official-blog&amp;disqus_identifier=22556&amp;disqus_title=Amazon+Comprehend+%26%238211%3B+Continuously+Trained+Natural+Language+Processing&amp;disqus_url=https://aws.amazon.com/blogs/aws/amazon-comprehend-continuously-trained-natural-language-processing/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-22556');
});
</script> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p>Many years ago I was wandering through the <a href="https://www.lib.umd.edu/epsl">University of Maryland CS Library</a> and found a dusty old book titled <a href="https://archive.org/stream/whatcomputerscan017504mbp/whatcomputerscan017504mbp_djvu.txt">What Computers Can’t Do</a>, adjacent to its successor, <a href="https://www.amazon.com/What-Computers-Still-Cant-Artificial/dp/0262540673">What Computers Still Can’t Do</a>. The second book was thicker, which made me realize that Computer Science was a worthwhile field to study. While preparing to write this post I found an archive copy of the first book and found an interesting observation:</p> 
<p style="padding-left: 30px">Since a human being using and understanding a sentence in a natural language requires an implicit knowledge of the sentence’s context-dependent use, the only way to make a computer that could understand and translate a natural language may well be, as Turing suspected, to program it to learn about the world.</p> 
<p>This was a very prescient observation and I’d like to tell you about <span title="">Amazon Comprehend</span>, a new service that actually knows (and is very happy to share) quite a bit about the world!</p> 
<p><span style="text-decoration: underline"><strong>Introducing Amazon Comprehend</strong></span><br /> <img width="100%" src="https://media.amazonwebservices.com/blog/2017/comp_logo_2.png">Comprehend</span>‘s topic modeling service extracts topics from large sets of documents for analysis or topic-based grouping.</p> 
<p>The first four functions (language detection, entity categorization, sentiment analysis, and key phrase extraction) are designed for interactive use, with responses available in hundreds of milliseconds. Topic extraction works on a job-based model, with responses proportional to the size of the collection.</p> 
<p><span title="">Comprehend</span> is a continuously-trained trained Natural Language Processing (NLP) service. Our team of engineers and data scientists continue to extend and refine the training data, with the goal of making the service increasingly accurate and more broadly applicable over time.</p> 
<p><span style="text-decoration: underline"><strong>Exploring Amazon Comprehend</strong></span><br /> You can explore <span title="">Amazon Comprehend</span> using the Console and then build applications that make use of the <span title="">Comprehend</span> APIs. I’ll use the opening paragraph from my <a href="https://aws.amazon.com/blogs/aws/new-aws-direct-connect-gateway-inter-region-vpc-access/">recent post</a> on Direct Connect to exercise the <span title="">Amazon Comprehend</span> API Explorer. I simply paste the text into the box and click on <strong>Analyze</strong>:</p> 
<p><img width="100%" src="https://media.amazonwebservices.com/blog/2017/di_analyze_text_2.png" /></p> 
<p><span title="">Comprehend</span> processes the text at lightning speed, highlights the entities that it identifies (as you can see above), and makes all of the other information available at a click:</p> 
<p><img width="100%" src="https://media.amazonwebservices.com/blog/2017/di_con_main_2.png" /></p> 
<p>Let’s look at each part of the results. <span title="">Comprehend</span> can detect many categories of entities in the text that I supply:</p> 
<p><img width="100%" src="https://media.amazonwebservices.com/blog/2017/di_ent_menu_2.png" /></p> 
<p>Here are all of the entities that were found in my text (they can also be displayed in list or raw JSON form):</p> 
<p><img width="100%" src="https://media.amazonwebservices.com/blog/2017/di_my_entities_vis_2.png" /></p> 
<p>Here are the first key phrases (the rest are available by clicking <strong>Show all</strong>):</p> 
<p><img width="100%" src="https://media.amazonwebservices.com/blog/2017/di_key_phrases_1.png" /></p> 
<p>Language and sentiment are simple and straightforward:</p> 
<p><img width="100%" src="https://media.amazonwebservices.com/blog/2017/di_ls_2.png" /></p> 
<p>Ok, so those are the interactive functions. Let’s take a look at the batch ones! I already have an S3 bucket that contains several thousand of my older blog posts, an empty one for my output, an IAM role that allows <span title="">Comprehend</span> to access both. I enter it and click on <strong>Create job</strong> to get started:</p> 
<p><img width="100%" src="https://media.amazonwebservices.com/blog/2017/di_create_topic_job_8.png" /></p> 
<p>I can see my recent jobs in the Console:</p> 
<p><img width="100%" src="https://media.amazonwebservices.com/blog/2017/di_jobs_4.png" /></p> 
<p>The output appears in my bucket when the job is complete:</p> 
<p><img width="100%" src="https://media.amazonwebservices.com/blog/2017/di_job_s3_output_2.png" /></p> 
<p>For demo purposes I can download the data and take a peek (in most cases I would feed it in to a visualization or analysis tool):</p> 
<code class="lang-bash">$ aws s3 ls s3://comp-out/348414629041-284ed5bdd23471b8539ed5db2e6ae1a7-1511638148578/output/
2017-11-25 19:45:09     105308 output.tar.gz
$ aws s3 cp s3://comp-out/348414629041-284ed5bdd23471b8539ed5db2e6ae1a7-1511638148578/output/output.tar.gz .
download: s3://comp-out/348414629041-284ed5bdd23471b8539ed5db2e6ae1a7-1511638148578/output/output.tar.gz to ./output.tar.gz
$ gzip -d output.tar.gz
$ tar xf output.tar
$ ls -l
total 1020
-rw-r--r-- 1 ec2-user ec2-user 495454 Nov 25 19:45 doc-topics.csv
-rw-rw-r-- 1 ec2-user ec2-user 522240 Nov 25 19:45 output.tar
-rw-r--r-- 1 ec2-user ec2-user  20564 Nov 25 19:45 topic-terms.csv
$
</code> 
<p>The <strong>topic-terms.csv</strong> file clusters related terms within a common topic number (first column). Here are the first 25 lines:</p> 
<code class="lang-bash">topic,term,weight
000,aw,0.0926182
000,week,0.0326755
000,announce,0.0268909
000,blog,0.0206818
000,happen,0.0143501
000,land,0.0140561
000,quick,0.0143148
000,stay,0.014145
000,tune,0.0140727
000,monday,0.0125666
001,cloud,0.0521465
001,quot,0.0292118
001,compute,0.0164334
001,aw,0.0245587
001,service,0.018017
001,web,0.0133253
001,video,0.00990734
001,security,0.00810732
001,enterprise,0.00626157
001,event,0.00566274
002,storage,0.0485621
002,datar,0.0279634
002,gateway,0.015391
002,s3,0.0218211
</code> 
<p>The <strong>doc-topics.csv</strong> file then indicates which files refer to the topics in the first file. Again, the first 25 lines:</p> 
<code class="lang-bash">docname,topic,proportion
calillona_brows.html,015,0.577179
calillona_brows.html,062,0.129035
calillona_brows.html,003,0.128233
calillona_brows.html,071,0.125666
calillona_brows.html,076,0.039886
amazon-rds-now-supports-sql-server-2012.html,003,0.851638
amazon-rds-now-supports-sql-server-2012.html,059,0.061293
amazon-rds-now-supports-sql-server-2012.html,032,0.050921
amazon-rds-now-supports-sql-server-2012.html,063,0.036147
amazon-rds-support-for-ssl-connections.html,048,0.373476
amazon-rds-support-for-ssl-connections.html,005,0.197734
amazon-rds-support-for-ssl-connections.html,003,0.148681
amazon-rds-support-for-ssl-connections.html,032,0.113638
amazon-rds-support-for-ssl-connections.html,041,0.100379
amazon-rds-support-for-ssl-connections.html,004,0.066092
zipkeys_simplif.html,037,1.0
cover_art_appli.html,093,1.0
reverse-dns-for-ec2s-elastic-ip-addresses.html,040,0.359862
reverse-dns-for-ec2s-elastic-ip-addresses.html,048,0.254676
reverse-dns-for-ec2s-elastic-ip-addresses.html,042,0.237326
reverse-dns-for-ec2s-elastic-ip-addresses.html,056,0.085849
reverse-dns-for-ec2s-elastic-ip-addresses.html,020,0.062287
coming-soon-oracle-database-11g-on-amazon-rds-1.html,063,0.368438
coming-soon-oracle-database-11g-on-amazon-rds-1.html,041,0.193081
</code> 
<p><span style="text-decoration: underline"><strong>Building Applications with Amazon Comprehend</strong></span><br /> In most cases you will be using the <span title="">Amazon Comprehend</span> API to add natural language processing to your own applications. Here are the principal interactive functions:</p> 
<p><code>DetectDominantLanguage</code> – Detect the dominant language of the text. Some of the other functions require you to provide this information, so call this function first.</p> 
<p><code>DetectEntities</code> – Detect entities in the text and return them in JSON form.</p> 
<p><code>DetectKeyPhrases</code> – Detect key phrases in the text and return them in JSON form.</p> 
<p><code>DetectSentiment</code> – Detect the sentiment in the text and return POSITIVE, NEGATIVE, NEUTRAL, or MIXED.</p> 
<p>There are also four variants of these functions (each prefixed with <code>Batch</code>) that can process up to 25 documents in parallel. You can use them to build high-throughput data processing pipelines.</p> 
<p>Here are the functions that you can use to create and manage topic detection jobs:</p> 
<p><code>StartTopicsDetectionJob</code> – Create a job and start it running.</p> 
<p><code>ListTopicsDetectionJobs</code> – Get the list of current and recent jobs.</p> 
<p><code>DescribeTopicsDetectionJob</code> – Get detailed information about a single job.</p> 
<p><span style="text-decoration: underline"><strong>Now Available</strong></span><br /> <a href="https://aws.amazon.com/comprehend/"><span title="">Amazon Comprehend</span></a> is available now and you can start building applications with it today!</p> 
<p>— <a href="https://twitter.com/jeffbarr">Jeff</a>;</p> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-22556');
});
</script> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<meta property="image" content="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2017/11/28/Amazon-Translate-01-Console-1260x362.png" /> 
<b class="lb-b blog-post-title" property="name headline">Introducing Amazon Translate – Real-time Language Translation</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<a href="https://aws.amazon.com/blogs/aws/author/tarawalk/" title="Posts by Tara Walker">Tara Walker</a> | on 
<time property="datePublished" datetime="2017-11-29T10:04:34+00:00">29 NOV 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/aws/category/events/reinvent/" title="View all posts in AWS re:Invent*"><span property="articleSection">AWS re:Invent*</span></a>, <a href="https://aws.amazon.com/blogs/aws/category/news/launch/" title="View all posts in Launch*"><span property="articleSection">Launch*</span></a>, <a href="https://aws.amazon.com/blogs/aws/category/news/" title="View all posts in News*"><span property="articleSection">News*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/aws/introducing-amazon-translate-real-time-text-language-translation/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-21810" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-official-blog&amp;disqus_identifier=21810&amp;disqus_title=Introducing+Amazon+Translate+%E2%80%93+Real-time+Language+Translation&amp;disqus_url=https://aws.amazon.com/blogs/aws/introducing-amazon-translate-real-time-text-language-translation/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-21810');
});
</script> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p>With the advent of the internet, the world has become a much smaller place. Loads of information can be stored and transmitted between cultures and countries within a blink of an eye, giving us all the ability to learn and grow from each other. In order for us to take advantage of all of these powerful vehicles of knowledge and data transfer, we must first break through some of the language barriers that may prevent information sharing and communication.</p> 
<p>Outside of being multilingual, one of the ways we can break through these barriers is by leveraging machine translation and related technologies to translate between the languages. Machine translation technologies stem from the computational linguistics field of study that focuses on using software to translate text or speech from one language to another. The concept of machine translation dates back to 1949 when Warren Weaver, an American scientist and mathematician, created the Memorandum on Translation at the request of colleagues from the Division of Natural Sciences at the Rockefeller Foundation to share his language translation ideas. Since then, we have come a long way in the field of machine language translation by using neural networks to enhance the efficiency and quality of translation methods. It should, therefore, be no surprise that the field’s technical progression has led us to the exciting new service I want to introduce to you today.</p> 
<p><strong><u>Let’s Welcome: Amazon Translate</u></strong></p> 
<p>Join me in welcoming the <a href="https://aws.amazon.com/translate/"><strong>Amazon Translate</strong></a> service to the Amazon Web Service family. <strong>Amazon Translate</strong> is a high-quality neural machine translation service that uses advanced machine learning technologies to provide fast language translation of text-based content and enable the development of applications that provide multilingual user experiences. The service is currently in preview and can be used to translate text to and from English and the supported languages.</p> 
<p>With the&nbsp;<strong>Translate</strong> service, organizations and business now have the ability to expand products and services in other regions more easily by allowing consumers to access websites, information, and resources in their preferred language using automated language translations. In addition, customers can engage in multiplayer chats, gather information from consumer forums, dive into educational documents, and even obtain reviews about hotels even if those resources are provided in a language they can’t readily understand.</p> 
<p>If you are like me, you may be curious about how <strong>Amazon Translate</strong> works to provide quality machine language translation. Based on deep learning technologies, Translate uses neural networks to represent models trained to translate between language pairs. The model consists of an encoder component which reads sentences from the source language and creates a representation that captures the meaning of the text provided. The model also has a decoder component that formulates a semantic representation used to generate a translation of the text from the source language to the target language. In addition, attention mechanisms are used by the service to build context from each word of the source text provided in order to decide which words are appropriate for generating the next target word. The concept of attention mechanisms in deep learning means that the neural network focuses on the relevant context of source inputs by taking into account the entire context of the source sentence, as well as everything it has generated previously. This process helps to create more accurate and fluent translations.</p> 
<p><strong>Amazon Translate</strong> can be used with other AWS services to build a robust multilingual experience or enable language-independent processing. For example, the Translate service can be used with some of the following services:</p> 
<li><strong>Amazon Polly:</strong> take translated text and provide lifelike speech and allow creation of applications that speak</li> 
<li><strong>Amazon S3: </strong>provides the<strong>&nbsp;</strong>ability to create translated document repositories</li> 
<li><strong>AWS Elasticsearch:</strong> create multi-language search using the managed Elasticsearch engine</li> 
<li><strong>Amazon Lex:</strong>&nbsp;build a translation chatbot using text and voice</li> 
<li><strong>AWS Lambda:</strong> enable localization of dynamic website content</li> 
<p>These are just a few examples, but there are many possible solutions that can be enabled by pairing <strong>Translate</strong> with other AWS Services. Let’s take a quick look at the console and try out the service preview.</p> 
<p>When I log into the console, I am presented with lots of great information. I can review&nbsp;information detailing how the&nbsp;<strong>Amazon</strong>&nbsp;<strong>Translate</strong> service works including examples, guidelines, and resources around the service and its API.</p> 
<p><img class="aligncenter size-full" src="https://media.amazonwebservices.com/blog/2017/Amazon Translate-01-Console-1.png" /></p> 
<p>Since I am very excited to try out this new service, there is no time like the present. I’ll click <strong>Try Translate</strong> button and go into the API Explorer section of the service.</p> 
<p><img width="100%" src="https://media.amazonwebservices.com/blog/2017/AmazonTranslate-02-APIExplorer-small.png" /></p> 
<p>Since I believe I’m already pretty fluent in English, I’ll switch the language pair to have the <strong>Source Language</strong> as French (fr) and the <strong>Target Language</strong> as English (en). I’ll take some verbiage from the French-based hotel’s website I stayed in while in Belgium working a couple of weeks ago.</p> 
<p>After pasting the French text from the website into the <strong>Translate</strong> service to translate it to English, I was pleasantly surprised to find that the translation was not only quick but accurate.</p> 
<p><img class="aligncenter size-full" src="https://media.amazonwebservices.com/blog/2017/AmazonTranslate-03-FRtoEN-translation-1.png" /></p> 
<p><strong><u>Summary</u></strong></p> 
<p>I am excited to have had the opportunity to provide to you all with an introduction of the new neural-machine translation service, <b>Amazon Translate</b>. With the service, you can translate text to and from English across the breadth of supported languages in real-time. The service is slated to be used directly via the AWS API, CLI, and/or supported SDKs.</p> 
<p>Sign up for the <strong>Amazon Translate</strong> <a href="https://pages.awscloud.com/amazon-translate-preview.html">preview</a> today and try the translation service. Learn more about the service by checking out the preview product page or reviewing the technical guides provided in the AWS documentation.</p> 
<p>– <a href="http://twitter.com/taraw">Tara&nbsp;</a></p> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-21810');
});
</script> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<meta property="image" content="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2017/11/24/transcribe_console_1.png" /> 
<b class="lb-b blog-post-title" property="name headline">Amazon Transcribe – Accurate Speech To Text At Scale</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by Randall Hunt | on 
<time property="datePublished" datetime="2017-11-29T10:02:22+00:00">29 NOV 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/aws/category/artificial-intelligence/amazon-transcribe/" title="View all posts in Amazon Transcribe"><span property="articleSection">Amazon Transcribe</span></a>, <a href="https://aws.amazon.com/blogs/aws/category/artificial-intelligence/" title="View all posts in Artificial Intelligence*"><span property="articleSection">Artificial Intelligence*</span></a>, <a href="https://aws.amazon.com/blogs/aws/category/events/reinvent/" title="View all posts in AWS re:Invent*"><span property="articleSection">AWS re:Invent*</span></a>, <a href="https://aws.amazon.com/blogs/aws/category/news/launch/" title="View all posts in Launch*"><span property="articleSection">Launch*</span></a>, <a href="https://aws.amazon.com/blogs/aws/category/news/" title="View all posts in News*"><span property="articleSection">News*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/aws/amazon-transcribe-scalable-and-accurate-automatic-speech-recognition/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p>Today we’re launching a private <a href="https://pages.awscloud.com/amazon-transcribe-preview.html">preview</a> of <a href="https://aws.amazon.com/transcribe/">Amazon Transcribe</a>, an&nbsp;automatic speech recognition (ASR) service that makes it easy for developers to add speech to text capabilities to their applications. As bandwidth and connectivity improve, more and more of the world’s data is stored in video and audio formats. People are creating and consuming all of this data faster than ever before. It’s important for businesses to have some means of deriving value from all of that rich multimedia content. With Amazon Transcribe you can save on the costly process of manual transcription with an efficient and scalable API.</p> 
<p>You can analyze audio files stored on <a href="https://aws.amazon.com/s3/" title="">Amazon Simple Storage Service (S3)</a> in many common formats (WAV, MP3, Flac, etc.) by starting a job with the API. You’ll receive detailed and accurate transcriptions with timestamps for each word, as well as inferred punctuation. During the preview you can use the asynchronous transcription API to transcribe speech in English or Spanish.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2017/11/24/transcribe_console_1.png" /></p> 
<p>Companies are looking to derive value from both their existing catalogs and their incoming data. By transcribing these stored media, companies can:</p> 
<li>Analyze customer call data</li> 
<li>Automate subtitle creation</li> 
<li>Target advertising based on content</li> 
<li>Enable rich search capabilities on archives of audio and video content</li> 
<p>You can start a transcription job easily with the <a href="https://aws.amazon.com/cli/" title="">AWS Command Line Interface (CLI)</a>, <a href="https://aws.amazon.com/tools/" title="">AWS SDKs</a>, or the Amazon Transcribe console.<br /> <img width="100%" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2017/11/24/transcribe_console_2_border.png" /></p> 
<p>Amazon Transcribe currently has 3, mostly self-explanatory, API Actions:</p> 
<li>StartTranscriptionJob</li> 
<li>GetTranscriptionJob</li> 
<li>ListTranscriptionJobs</li> 
<p>Here’s a quick python script that starts a job and polls until the job is finished:</p> 
<code class="lang-python">from __future__ import print_function
import time
import boto3
transcribe = boto3.client('transcribe')
job_name = &quot;RandallTest1&quot;
job_uri = &quot;https://s3-us-west-2.amazonaws.com/randhunt-transcribe-demos/test.flac&quot;
transcribe.start_transcription_job(
TranscriptionJobName=job_name,
Media={'MediaFileUri': job_uri},
MediaFormat='flac',
LanguageCode='en-US',
MediaSampleRateHertz=44100
)
while True:
status = transcribe.get_transcription_job(TranscriptionJobName=job_name)
if status['TranscriptionJob']['TranscriptionJobStatus'] in ['COMPLETED', 'FAILED']:
break
print(&quot;Not ready yet...&quot;)
time.sleep(5)
print(status)
</code> 
<p>The result of a completed job links to an <a href="https://aws.amazon.com/s3/" title="">Amazon Simple Storage Service (S3)</a> presigned-url that contains our transcription in JSON format:</p> 
<code class="lang-json">{
&quot;jobName&quot;: &quot;RandallTest1&quot;,
&quot;results&quot;: {
&quot;transcripts&quot;: [{&quot;transcript&quot;: &quot;Hello World&quot;, &quot;confidence&quot;: 1}],
&quot;items&quot;: [
{
&quot;start_time&quot;: &quot;0.880&quot;, &quot;end_time&quot;: &quot;1.300&quot;,
&quot;alternatives&quot;: [{&quot;confidence&quot;: 0.91, &quot;word&quot;: &quot;Hello&quot;}]
},
{
&quot;start_time&quot;: &quot;1.400&quot;, &quot;end_time&quot;: &quot;1.620&quot;,
&quot;alternatives&quot;: [{&quot;confidence&quot;: 0.84, &quot;word&quot;: &quot;World&quot;}]
}
]
},
&quot;status&quot;: &quot;COMPLETED&quot;
}
</code> 
<p>As you can see you get timestamps and confidence scores for each word.</p> 
<p>Whether alone or combined with other Amazon AI services this is a powerful service and I can’t wait to see what our customers build with it! Sign up for the <a href="https://pages.awscloud.com/amazon-transcribe-preview.html">preview</a> today.</p> 
<p>– <a href="https://twitter.com/jrhunt/">Randall</a></p> 
<p>P.S.<br /> You might have noticed this lends itself well to <a href="https://aws.amazon.com/step-functions" title="">AWS Step Functions</a> and I thought the same. Here’s a workflow I might use:<br /> <img width="100%" src="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2017/11/24/TranscriptionStepFunction.png" /></p> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<meta property="image" content="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2017/11/29/kvs_splash_1.png" /> 
<b class="lb-b blog-post-title" property="name headline">Amazon Kinesis Video Streams – Serverless Video Ingestion and Storage for Vision-Enabled Apps</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<a href="https://aws.amazon.com/blogs/aws/author/jbarr/" title="Posts by Jeff Barr">Jeff Barr</a> | on 
<time property="datePublished" datetime="2017-11-29T10:00:13+00:00">29 NOV 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/aws/category/analytics/amazon-kinesis-video-streams/" title="View all posts in Amazon Kinesis Video Streams"><span property="articleSection">Amazon Kinesis Video Streams</span></a>, <a href="https://aws.amazon.com/blogs/aws/category/analytics/amazon-kinesis/" title="View all posts in Amazon Kinesis*"><span property="articleSection">Amazon Kinesis*</span></a>, <a href="https://aws.amazon.com/blogs/aws/category/events/reinvent/" title="View all posts in AWS re:Invent*"><span property="articleSection">AWS re:Invent*</span></a>, <a href="https://aws.amazon.com/blogs/aws/category/news/launch/" title="View all posts in Launch*"><span property="articleSection">Launch*</span></a>, <a href="https://aws.amazon.com/blogs/aws/category/news/" title="View all posts in News*"><span property="articleSection">News*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/aws/amazon-kinesis-video-streams-serverless-video-ingestion-and-storage-for-vision-enabled-apps/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p>Cell phones, security cameras, baby monitors, drones, webcams, dashboard cameras, and even satellites can all generate high-intensity, high-quality video streams. Homes, offices, factories, cities, streets, and highways are now host to massive numbers of cameras. They survey properties after floods and other natural disasters, increase public safety, let you know that your child is safe and sound, capture one-off moments for endless “fail” videos (a personal favorite), collect data that helps to identify and solve traffic problems, and more.</p> 
<p>Dealing with this flood of video data can be challenging, to say the least. Incoming streams arrive unannounced, individually or by the millions. The stream contains valuable, real-time data that cannot be deferred, paused, or set aside to be dealt with at a more opportune time. Once you have the raw data, other challenges emerge. Storing, encrypting, and indexing the video data all come to mind. Extracting value—diving deep in to the content, understanding what’s there, and driving action—is the next big step.</p> 
<p><span style="text-decoration: underline"><strong>New Amazon Kinesis Video Streams</strong></span><br /> Today I would like to introduce you to <a href="https://aws.amazon.com/kinesis/video-streams/"><span title="">Amazon Kinesis Video Streams</span></a>, the newest member of the <a href="https://aws.amazon.com/kinesis/">Amazon Kinesis</a> family of real-time streaming services. You now have the power to ingest streaming video (or other time-encoded data) from millions of camera devices without having to set up or run your own infrastructure. <span title="">Kinesis Video Streams</span> accepts your incoming streams, stores them durably and in encrypted form, creates time-based indexes, and enables the creation of vision-enabled applications. You can process the incoming streams using Amazon Rekognition Video, <a href="https://aws.amazon.com/mxnet/" title="">MXNet</a>, <a href="https://www.tensorflow.org/" title="">TensorFlow</a> OpenCV, or your own custom code, all in support of the the cool new robotics, analytics, and consumer apps that I know you will dream up.</p> 
<p>We manage all of the infrastructure for you. First, you use our Producer SDK (device-side) to create an app and then send us video from the device of your choice. The incoming video arrives over a secure TLS connection and is stored in time-indexed form, after being encrypted with a <a href="https://aws.amazon.com/kms/" title="">AWS Key Management Service (KMS)</a> key. Next, you use the Video Streams Parser Library (cloud-side) to consume the video stream and to extract value from it.</p> 
<p>Regardless of how much you send – low resolution or high, from one device or from millions – <span title="">Kinesis Video Streams</span>, will scale to meet your needs. You can, as I never get tired of saying, focus on your application and on your business. <span title="">Amazon Kinesis Video Streams</span> builds on parts of AWS that you already know. It stores video in S3 for cost-effective durability, uses <a href="https://aws.amazon.com/iam/" title="">AWS Identity and Access Management (IAM)</a> for access control, and is accessible from the <a href="https://console.aws.amazon.com" title="">AWS Management Console</a>, <a href="https://aws.amazon.com/cli/" title="">AWS Command Line Interface (CLI)</a>, and through a set of APIs.</p> 
<p><span style="text-decoration: underline"><strong>Amazon Kinesis Video Streams Concepts</strong></span><br /> Let’s run through a couple of concepts and then set up a stream.</p> 
<p><strong>Producer</strong> – A producer is a data source that puts data into a stream. It could be a baby monitor, a video camera on a drone, or something more exotic: perhaps a temperature sensor or a satellite! The Amazon Kinesis Video Producer SDK provides a set of functions that make it easy to establish a connection and to stream video.</p> 
<p><strong>Stream</strong> – A stream allows you to transport live video data, optionally store it, and make it available for real-time or batch consumption. Streams can also carry other types of time-encoded data including audio, radar, <a href="https://en.wikipedia.org/wiki/Lidar">lidar</a>, and sensor readings. In most cases, there’s a 1-to-1 mapping between producers and streams. Multiple independent applications can consume and process data from a single stream.</p> 
<p><strong>Fragment &amp; Frames</strong> – A fragment is a time-bound set of individual frames from a stream.</p> 
<p><strong>Consumer</strong> – A consumer gets data (fragments or frames) from a stream and processes, analyzes, or displays it. Consumers can run in real-time or after the fact, and are built atop the Video Streams Parser Library.</p> 
<p><span style="text-decoration: underline"><strong>Using Amazon Kinesis Video Streams</strong></span><br /> As I noted earlier, there’s a 1-to-1 mapping between producers and streams. In most cases, each instance of a producer will create a unique stream using the Kinesis Video Streams API. However, you can create streams manually for test or demo purposes, or if you need a small, fixed number of them.</p> 
<p>To create a stream manually, I open up the Kinesis Video Streams Console and click on <strong>Create Kinesis video stream</strong>:</p> 
<p><img width="100%" src="https://media.amazonwebservices.com/blog/2017/kvs_splash_1.png" /></p> 
<p>I simply enter the name of my stream and click on <strong>Create stream</strong>:</p> 
<p><img width="100%" src="https://media.amazonwebservices.com/blog/2017/kvs_create_easy_2.png" /></p> 
<p>I can uncheck <strong>Use default settings </strong>if I want to customize my stream (most of the settings can be changed later):</p> 
<p><img width="100%" src="https://media.amazonwebservices.com/blog/2017/kvs_create_non_default_1.png" /></p> 
<p>My stream is ready for use immediately. The console will display video as soon as I start to stream it:</p> 
<p><img width="100%" src="https://media.amazonwebservices.com/blog/2017/kvs_my_cheetah_stream_2.png" /></p> 
<p>The Kinesis team shared this screen with me; I did not have time to take a field trip. Does that make me a <a href="https://en.wikipedia.org/wiki/Cheetah">Cheetah</a>?</p> 
<p><span style="text-decoration: underline"><strong>Developing for Amazon Kinesis Video Streams</strong></span><br /> The next step is to use the Producer SDK to build the producer app. The app runs on the device or out in the field, and is responsible for creating a stream and then posting a stream of fragments (each typically represent 2 to 10 seconds of video) to the stream by making calls to the <code>PutMedia</code> function.</p> 
<p>The consumer side calls the <code>GetMedia</code> and <code>GetMediaFromFragmentList</code> functions to access content from the stream in <a href="https://en.wikipedia.org/wiki/Matroska">Matroska</a> (MKV) container format, and uses the included Video Streams Parser Library to extract the desired content. <code>GetMedia</code> is intended to be used continuous streaming with very low latency; <code>GetMediaFromFragment</code> list is batch-oriented and allows selective processing.</p> 
<p><span style="text-decoration: underline"><strong>Now Available</strong></span><br /> <a href="https://aws.amazon.com/kinesis/video-streams/"><span title="">Amazon Kinesis Video Streams</span></a> is available in the <span title="">US East (Northern Virginia)</span>, <span title="">US West (Oregon)</span>, <span title="">EU (Ireland)</span>, <span title="">EU (Frankfurt)</span>, and <span title="">Asia Pacific (Tokyo)</span> Regions and you can start building your vision-enabled apps with it today.</p> 
<p>Pricing is based on three factors: amount of video produced, amount of video consumed, and amount of video stored.</p> 
<p>— <a href="https://twitter.com/jeffbarr">Jeff</a>;</p> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<meta property="image" content="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2017/11/29/RekognitionVideo-01-VideoConsole-2.png" /> 
<b class="lb-b blog-post-title" property="name headline">Welcoming Amazon Rekognition Video: Deep-Learning Based Video Recognition</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<a href="https://aws.amazon.com/blogs/aws/author/tarawalk/" title="Posts by Tara Walker">Tara Walker</a> | on 
<time property="datePublished" datetime="2017-11-29T09:56:11+00:00">29 NOV 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/aws/category/artificial-intelligence/amazon-rekognition-video/" title="View all posts in Amazon Rekognition Video"><span property="articleSection">Amazon Rekognition Video</span></a>, <a href="https://aws.amazon.com/blogs/aws/category/artificial-intelligence/amazon-rekognition/" title="View all posts in Amazon Rekognition*"><span property="articleSection">Amazon Rekognition*</span></a>, <a href="https://aws.amazon.com/blogs/aws/category/artificial-intelligence/" title="View all posts in Artificial Intelligence*"><span property="articleSection">Artificial Intelligence*</span></a>, <a href="https://aws.amazon.com/blogs/aws/category/events/reinvent/" title="View all posts in AWS re:Invent*"><span property="articleSection">AWS re:Invent*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/aws/launch-welcoming-amazon-rekognition-video-service/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-21933" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-official-blog&amp;disqus_identifier=21933&amp;disqus_title=Welcoming+Amazon+Rekognition+Video%3A+Deep-Learning+Based+Video+Recognition&amp;disqus_url=https://aws.amazon.com/blogs/aws/launch-welcoming-amazon-rekognition-video-service/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-21933');
});
</script> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p>It was this time last year during re:Invent 2016 that <a href="https://aws.amazon.com/blogs/aws/amazon-rekognition-image-detection-and-recognition-powered-by-deep-learning/">Jeff announced the Amazon Rekognition service launch.&nbsp;</a> I was so excited about getting my hands dirty and start coding against the service to build image recognition solutions. As you may know by now, <strong><a href="https://aws.amazon.com/rekognition/image-features/">Amazon Rekognition Image</a>&nbsp;</strong>is a cloud service that uses deep learning to provide scalable image recognition and analysis.&nbsp;<strong>Amazon&nbsp;Rekognition&nbsp;Image</strong> enables you to build and integrate object and scene detection, real-time facial recognition, celebrity recognition, image moderation, as well as, text recognition into your applications and systems.</p> 
<p>The <strong>Amazon Rekognition Image</strong> service was created by using deep learning neural network models and was based on the same technology that enables Prime Photos to analyze billions of images each day. At the time of Rekognition’s release, its primary focus was providing scalable, automated analysis, search, and classification of images.&nbsp; Well that all changes today as I am excited to tell you about some additional features the service now has to offer.</p> 
<p><img width="100%" src="https://media.amazonwebservices.com/blog/2017/RekognitionVideo-00-Header.png" /></p> 
<h3></h3> 
<h3><strong><u>Hello, Amazon Rekognition Video</u></strong></h3> 
<p>Say hello to my new friend, <a href="https://aws.amazon.com/rekognition/video-features/"><strong>Amazon</strong> <strong>Rekognition Video</strong></a>. Yes, of course, I started to use the Scarface movie reference and write “Say hello to my little friend”.&nbsp; But since I didn’t say it, you must give me a little credit for not going completely corny. Now that that’s cleared up, let’s get back to discussing this exciting new AI service feature; <strong>Amazon</strong> <strong>Rekognition Video</strong>.</p> 
<p>&nbsp;</p> 
<p><strong>Amazon Rekognition Video</strong> is a new video analysis service feature that brings scalable computer vision analysis to your S3 stored video, as well as, live video streams. With Rekognition video, you can accurately detect, track, recognize, extract, and moderate thousands of objects, faces, and content from a video.&nbsp; What I believe is even cooler about the new feature is that it not only provides accurate information about the objects within a video but it the first video analysis service of its kind that uses the complete context of visual, temporal, and motion of the video to perform activity detection and person tracking. Thereby using its deep-learning-based capabilities to derive more complete insights about what activities are being performed in the video. For example, this service feature can identify that there is a man, a car, and a tree in the video, as well as, deduce that the man in the video was running to the car. Pretty cool, right! Just imagine all of the possible scenarios that this functionality can provide to customers.</p> 
<p style="text-align: left"><img width="100%" src="https://media.amazonwebservices.com/blog/2017/RekognitionVideo-01-VideoConsole-2.png" /></p> 
<p style="text-align: left">The process of conducting video analysis using the asynchronous <strong>Amazon</strong> <strong>Rekognition Video</strong> API is as follows:</p> 
<ol> 
<li>A <strong>Rekognition Video</strong>&nbsp;<strong>Start</strong> operation API is called on .mp4 or .mov video. Please note videos must be encoded with a H.264 codec. The <strong>Start</strong> operation APIs are as follows: 
<li>StartPersonTracking</li> 
<li>StartFaceDetection</li> 
<li>StartLabelDetection</li> 
<li>StartCelebrityRecognition</li> 
<li>StartContentModeration</li> 
</ul> </li> 
<li><strong>Amazon Rekognition</strong>&nbsp;<strong>Video</strong> processes video and publishes the completion status of the start operation API request to an <a href="https://aws.amazon.com/blogs/aws/aws_shortcode/sns/">Amazon SNS </a>topic.</li> 
<li>You retrieve the notification of the API completion result by subscribing an <a href="https://aws.amazon.com/blogs/aws/aws_shortcode/sqs/">Amazon SQS </a>queue or <a href="https://aws.amazon.com/blogs/aws/aws_shortcode/lambda/">AWS Lambda </a>function to the SNS topic that you specify.</li> 
<li>Call the <strong>Get</strong> operation API associated with the start operation API that processed the video using the JobID provided in the SNS notification. The JobID is also provided to you as a part of the Start API response as well.The <strong>Get</strong> operation APIs are: 
<li>GetPersonTracking</li> 
<li>GetFaceDetection</li> 
<li>GetLabelDetection</li> 
<li>GetCelebrityRecognition</li> 
<li>GetContentModeration</li> 
</ul> </li> 
<li>Retrieve the results of the video analysis via JSON returned from the <strong>Get</strong> operation API and a pagination token to the next set of results if applicable.</li> 
</ol> 
<p>You can leverage the video analysis capabilities of <strong>Amazon</strong> <strong>Rekognition Video</strong> by using the AWS CLI, AWS SDKs, and/or REST APIs. I believe that there is no better way to learn about a new service than diving in and experiencing for yourself.&nbsp; So let’s try it out!</p> 
<p>I’ll start by uploading two music videos in .mp4 file format to my S3 bucket of songs in rotation on my playlist; Run by Foo Fighters and Wild Thoughts by DJ Khaled. Hey, what can I say, my musical tastes are broad and diverse.</p> 
<p><img width="100%" src="https://media.amazonwebservices.com/blog/2017/RekognitionVideo-S3Upload-small.png" /></p> 
<p>I’ll create a SNS topic for notifications from Rekognition Video and a SQS queue to receive notifications from the SNS Topic.</p> 
<p><img width="100%" src="https://media.amazonwebservices.com/blog/2017/RekognitionVideo-CreateSNSTopic-small.png" /></p> 
<p><img width="100%" src="https://media.amazonwebservices.com/blog/2017/RekognitionVideo-CreateSQSQueue-small.png" /><br /> Now I can subscribe my SQS Queue, <strong>RekognitionVideoQueue</strong>, to my SNS Topic, <strong>SNS-RekogntionVideo-Topic</strong>.</p> 
<p><img width="100%" src="https://media.amazonwebservices.com/blog/2017/RekognitionVideo-SQSSubscribeToSNS-small1.png" /><br /> Now, I’ll use the AWS CLI to call the <strong>start-face-detection</strong> API operation on my video,&nbsp;DJ_Khaled-Wild_Thoughts.mp4, and obtain my <strong>JobId</strong> from the API response.</p> 
<p><img width="100%" src="https://media.amazonwebservices.com/blog/2017/RekognitionVideo-05-StartFaceAPI-2.png" /></p> 
<p>Once I have been notified that a message was received from the SNS Topic to my <strong>RekognitionVideoQueue</strong> SQS queue, and <strong>Status</strong> in that message is <strong>SUCCEEDED</strong>, I can call the <strong>get-face-detection</strong> API operation to get the results of the video analysis with the <strong>JobId</strong>.</p> 
<p><img width="100%" src="https://media.amazonwebservices.com/blog/2017/RekognitionVideo-06-GetFaceAPI-2.png" /><br /> I can, also, conduct video analysis on my other video, Foo_Fighters-Run.mp4, to obtain information about the object detected in the frames of the video by calling the <strong>start-label-detection</strong> and <strong>get-label-detection</strong> API operations.</p> 
<p><img width="100%" src="https://media.amazonwebservices.com/blog/2017/RekognitionVideo-07-StartLabelAPI1.png" /></p> 
<p>&nbsp;</p> 
<p><img width="100%" src="https://media.amazonwebservices.com/blog/2017/RekognitionVideo-08-GetLabelAPI.png" /></p> 
<p>&nbsp;</p> 
<p><strong><u>Summary</u></strong></p> 
<p>Now with <strong>Rekognition Video</strong>, video captured with cell phones, cameras, IoT video sensors, and real-time live stream video processing can be used to create scalable, high accuracy video analytics solutions. This new deep-learning video feature will automate all the tasks necessary for detection of objects, faces, and activities in a video, and with the integration of other AWS Services, you can build robust media applications for varying workloads.</p> 
<p>Learn more about <strong>Amazon Rekognition</strong> and the new <strong>Rekognition Video</strong> capability by checking out our&nbsp;<a href="https://aws.amazon.com/rekognition/getting-started/">Getting Started</a>&nbsp;page or the <a href="http://docs.aws.amazon.com/rekognition/latest/dg/how-it-works.html">Rekognition documentation</a>.</p> 
<p>– <a href="http://twitter.com/taraw">Tara&nbsp;</a></p> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-21933');
});
</script> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<meta property="image" content="https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2017/11/29/dl_arch_1.png" /> 
<b class="lb-b blog-post-title" property="name headline">AWS DeepLens – Get Hands-On Experience with Deep Learning With Our New Video Camera</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<a href="https://aws.amazon.com/blogs/aws/author/jbarr/" title="Posts by Jeff Barr">Jeff Barr</a> | on 
<time property="datePublished" datetime="2017-11-29T09:42:23+00:00">29 NOV 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/aws/category/artificial-intelligence/" title="View all posts in Artificial Intelligence*"><span property="articleSection">Artificial Intelligence*</span></a>, <a href="https://aws.amazon.com/blogs/aws/category/artificial-intelligence/aws-deeplens/" title="View all posts in AWS DeepLens"><span property="articleSection">AWS DeepLens</span></a>, <a href="https://aws.amazon.com/blogs/aws/category/events/reinvent/" title="View all posts in AWS re:Invent*"><span property="articleSection">AWS re:Invent*</span></a>, <a href="https://aws.amazon.com/blogs/aws/category/news/launch/" title="View all posts in Launch*"><span property="articleSection">Launch*</span></a>, <a href="https://aws.amazon.com/blogs/aws/category/news/" title="View all posts in News*"><span property="articleSection">News*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/aws/deeplens/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-22104" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-official-blog&amp;disqus_identifier=22104&amp;disqus_title=AWS+DeepLens+%26%238211%3B+Get+Hands-On+Experience+with+Deep+Learning+With+Our+New+Video+Camera&amp;disqus_url=https://aws.amazon.com/blogs/aws/deeplens/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-22104');
});
</script> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p>As I have mentioned a time or two in the past, I am a strong believer in life-long learning. Technological change is coming along faster than ever and you need to do the same in order to keep your skills current.</p> 
<p>For most of my career, artificial intelligence has been an academic topic, with practical applications and real-world deployment “just around the corner.” I think it is safe to say, with the number of practical applications for machine learning, including <a href="https://aws.amazon.com/rekognition/">computer vision</a> and <a href="https://aws.amazon.com/deep-learning/">deep learning</a>, that we’ve turned the corner and that now is the time to start getting some hands-on experience and polishing your skills! Also, while both are more recent and spent far less time gestating, it is safe to say that <a href="https://aws.amazon.com/iot/">IoT</a> and <a href="https://aws.amazon.com/serverless/">serverless</a> computing are here to stay and should be on your list.</p> 
<p><span style="text-decoration: underline"><strong>New AWS DeepLens</strong></span><br /> <img width="100%" src="https://media.amazonwebservices.com/blog/2017/dl_arch_1.png">AI</a> and infrastructure services in your app.</p> 
<p>Let’s start with the hardware. We have packed a lot of power into this device. There’s a 4 megapixel camera that can capture 1080P video, accompanied by a 2D microphone array. An Intel Atom<sup>&reg;</sup> Processor provides over 100 GFLOPS of compute power, enough to run tens of frames of incoming video through on-board deep learning models every second. <span title="">DeepLens</span> is well-connected, with dual-band Wi-Fi, USB and micro HDMI ports. Wrapping it all up, 8 gigabytes of memory for your pre-trained models and your code, makes this a powerful yet compact device.</p> 
<p>On the software side, the <span title="">AWS DeepLens</span> runs Ubuntu 16.04 and is preloaded with the Greengrass Core (Lambda runtime, message manager, and <a href="http://docs.aws.amazon.com/greengrass/latest/developerguide/what-is-gg.html">more</a>). There’s also a device-optimized version of <a href="https://aws.amazon.com/mxnet/" title="">MXNet</a>, and the flexibility to use other frameworks such as <a href="https://www.tensorflow.org/" title="">TensorFlow</a> and <a href="https://caffe2.ai/" title="">Caffe2</a>. The <a href="https://github.com/intel/clDNN">Intel<sup>&reg;</sup> clDNN</a> library provide a set of set of deep learning primitives for computer vision and other AI workloads, taking advantage of special features of the Intel Atom<sup>&reg;</sup> Processor for accelerated inferencing.</p> 
<p>We also give you data! When you build an app that runs on your <span title="">AWS DeepLens</span>, you can take advantage of a set of pre-trained models for image detection and recognition. These models will help you detect cats and dogs, faces, a wide array of household and everyday objects, motions and actions, and even hot dogs. We will continue to train these models, making them better and better over time. Here’s the initial set of models:</p> 
<p><img width="100%" src="https://media.amazonwebservices.com/blog/2017/dl_models_1.png" /></p> 
<p>All of this hardware, software, and data come together to make the <span title="">AWS DeepLens</span> a prime example of an edge device. With eyes, ears, and a fairly powerful brain that are all located out in the field and close to the action, it can run incoming video and audio through on-board deep learning models quickly and with low latency, making use of the cloud for more compute-intensive higher-level processing. For example, you can do face detection on the <span title="">DeepLens</span> and then let <a href="https://aws.amazon.com/rekognition/" title="">Amazon Rekognition</a> take care of the face recognition.</p> 
<p>This is an epic learning opportunity in a box! We’ve also included tons of sample code (Lambda functions) that you can use as-is, pick apart and study, and use as the basis for your own functions. Once you have built something cool and useful, you can deploy it in production form. We’ve made sure that <span title="">AWS DeepLens</span> is robust and secure, with unique certificates for each device and fine-grained, IAM-powered control over access to AWS services and resources.</p> 
<p><span style="text-decoration: underline"><strong>Registering a Device</strong></span><br /> Let’s walk through the process of registering a device and getting it ready for use, starting from the DeepLens Console. I open it up and click on <strong>Register device</strong>:</p> 
<p><img width="100%" src="https://media.amazonwebservices.com/blog/2017/dl_console_splash_2.png" /></p> 
<p>Then I give my camera a name and click on <strong>Next</strong>:</p> 
<p><img width="100%" src="https://media.amazonwebservices.com/blog/2017/dl_reg_cam_1.png" /></p> 
<p>Then I click on <strong>Download certificate</strong> and save it away in a safe place:</p> 
<p><img width="100%" src="https://media.amazonwebservices.com/blog/2017/dl_download_cert_1.png" /></p> 
<p>Next, I create the necessary IAM roles (the console makes it easy) and select each one in the appropriate menu:</p> 
<p><img width="100%" src="https://media.amazonwebservices.com/blog/2017/dl_set_permissions_3.png" /></p> 
<p>Now I am ready to go hands-on with my DeepLens! I power up, connect my laptop to the device’s network, and access the built-in portal to complete the process. The console outlines the steps:</p> 
<p><img width="100%" src="https://media.amazonwebservices.com/blog/2017/dl_setup_guide_1.png" /></p> 
<p>At this point my DeepLens is a fully-functional edge device. The certificate on the device allows it to make secure, signed calls to AWS. The Greengrass Core is running, ready to accept and run a Lambda function.</p> 
<p><span style="text-decoration: underline"><strong>Creating a DeepLens Project</strong></span><br /> With everything connected and set up, I can create my first project. I navigate to the <strong>Projects</strong> and click on <strong>Create new project</strong>:</p> 
<p><img width="100%" src="https://media.amazonwebservices.com/blog/2017/dl_projects_none_1.png" /></p> 
<p>Then I choose a project template or start with a blank project. I’ll go for <strong>cat and dog recognition</strong>, selecting it and clicking on <strong>Next</strong>:</p> 
<p><img width="100%" src="https://media.amazonwebservices.com/blog/2017/dl_choose_project_1.png" /></p> 
<p>The console give me the opportunity to name and customize the project. As you can see, the project refers to a Lambda function and one of the pre-trained models that I listed above. The defaults are all good, so I simply click on <strong>Create</strong>:</p> 
<p><img width="100%" src="https://media.amazonwebservices.com/blog/2017/dl_raining_cats_and_dogs_1.png" /></p> 
<p>Now I simply deploy the project to my camera:</p> 
<p><img width="100%" src="https://media.amazonwebservices.com/blog/2017/dl_deploy_prep_1.png" /></p> 
<p><span style="text-decoration: underline"><strong>Training Cats and Dogs</strong></span><br /> The functions run on the camera and publish their output to an MQTT topic. Here’s an excerpt from the inner loop of the cat and dog recognition function (I removed some error handing):</p> 
<code class="lang-python">while doInfer:
# Get a frame from the video stream
ret, frame = awscam.getLastFrame()
numFrames += 1
# Resize frame to fit model input requirement
frameResize = cv2.resize(frame, (224, 224))
# Run model inference on the resized frame
inferOutput = model.doInference(frameResize)
# Publish a message to the cloud for every 100 frames
if numFrames &gt;= 10:
msg = &quot;Infinite inference is running. Sample result of the last frame is\n&quot;
# Output inference result of the last frame to cloud
# The awsca module can parse the output from some known models
outputProcessed = model.parseResult(modelType, inferOutput)
# Get top 5 results with highest probiblities
topFive = outputProcessed[modelType][0:2]
msg += &quot;label    prob&quot;
for obj in topFive:
msg += &quot;\n{}   {}&quot;.format(outMap[obj[&quot;label&quot;]], obj[&quot;prob&quot;])
client.publish(topic=iotTopic, payload=msg)
numFrames = 0;
</code> 
<p>Like I said, you can modify this or you can start from scratch. Either way, as you can see, it is pretty easy to get started.</p> 
<p>I can’t wait to see what you come up with once you get a <span title="">DeepLens</span> in your hands. To learn more and to have the opportunity to take a <span title="">AWS DeepLens</span> home with you, be sure to attend one of the sixteen <a href="https://www.portal.reinvent.awsevents.com/connect/search.ww#loadSearch-searchPhrase=mcl212&amp;searchType=session&amp;tc=0&amp;sortBy=abbreviationSort&amp;sessionTypeID=1000&amp;p=">DeepLens Workshops</a> at <a href="https://reinvent.awsevents.com/" title="">AWS re:Invent</a>.</p> 
<p><span style="text-decoration: underline"><strong>Pre-Order One Today</strong></span><br /> We’ll start shipping the <span title="">AWS DeepLens</span> in 2018, initially in the US. To learn more about pricing and availability, or to <a href="https://www.amazon.com/dp/B075Y3CK37">pre-order</a> one of your own, visit the <a href="https://aws.amazon.com/deeplens">DeepLens page</a>.</p> 
<p>— <a href="https://twitter.com/jeffbarr">Jeff</a>;</p> 
<p>&nbsp;</p> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-22104');
});
</script> 
</article> 
<p>
© 2018 Amazon Web Services, Inc. or its affiliates. All rights reserved.
</p>

    </div>
  </div>
</div>


    <div id="footer" class="navigation hidden-print">
      <div class="container">
        <div class="row">
          <div class="col-xs-12">
            <ul class="footer-links nav navbar-nav">
              <li><a href="../aws.html">AWS</a></li>
              <li><a href="../linux.html">Linux</a></li>
              <li><a href="../docker.html">Docker</a></li>
              <li><a href="../ibmpower.html">IBM Power</a></li>
              <li class="active"><a href="blogsataws1.html">Blogs@AWS (Kindle Friendly)</a></li>
            </ul>
            <ul class="footer-links nav navbar-nav navbar-right">
              <li><a href="../comments.html">Comments?</a></li>
            </ul>
          </div>
        </div>
      </div>
    </div>
  </body>
</html>
