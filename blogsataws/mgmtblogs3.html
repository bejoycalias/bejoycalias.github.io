<!DOCTYPE html>
<html lang="en">
  <head>
<!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-593498H');</script>
<!-- End Google Tag Manager -->

    <meta charset="utf-8">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">

    <meta name="msapplication-config" content="/microsoft-tile.xml" />
    <meta name="theme-color" content="#ffffff">

    <meta property="og:url" content="https://bejoycalias.github.io/blogsataws/mgmtblogs1.html" />
    <meta property="og:site_name" content="Bejoy's TechNotes"/>
    <meta property="og:title" content="Bejoy's TechNotes - Kindle Friendly AWS Management Tools Blogs" />
    <meta property="og:image" content="https://bejoycalias.github.io/assets/images/og-image.png"/>
    <meta property="og:image:width" content="1200"/>
    <meta property="og:image:height" content="1200"/>
    <meta property="og:description" content="" />

    <title>Bejoy's TechNotes - Kindle Friendly AWS Management Tools Blogs</title>
    <link href="../assets/stylesheets/application-832aa42c.css" rel="stylesheet" />

    <!--[if lt IE 9]>
      <script src="../assets/javascripts/ie-compat-c141a02d.js"></script>
    <![endif]-->
    <script src="../assets/javascripts/application-ff53d307.js"></script>

    <!-- Typekit script to import Klavika font -->
    <script src="https://use.typekit.net/wxf7mfi.js"></script>
    <script>try{Typekit.load({ async: true });}catch(e){}</script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-100043608-1', 'auto');
  ga('send', 'pageview');

</script>

    
  </head>

  <body id="uh-oh-" class="layout-inner page-uh-oh-">
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-593498H"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->


    <div id="header" class="navigation navbar-static-top hidden-print">
      <div class="container">
        <div class="row">
          <div class="col-xs-12">
            <div class="navbar-header">
              <div class="navbar-brand">
                <a href="/">
                  <svg version="1.0" xmlns="http://www.w3.org/2000/svg" width="135.000000pt" height="50" viewbox="0 0 135.000000 45.000000" preserveaspectratio="xMidYMid meet" class="logo">

<g transform="translate(0.000000,45.000000) scale(0.100000,-0.100000)" fill="#000000" stroke="none">
<path class="text" fill="#000000" d="M527 384 c-4 -4 -7 -18 -7 -31 0 -21 4 -24 28 -21 21 2 27 8 27 28 0
18 -6 26 -20 28 -12 2 -24 0 -28 -4z"></path>
<path class="text" fill="#000000" d="M1080 335 c0 -48 2 -55 20 -55 18 0 20 7 20 55 0 48 -2 55 -20 55
-18 0 -20 -7 -20 -55z"></path>
<path class="text" fill="#000000" d="M54 357 c-2 -7 -3 -69 -2 -138 l3 -124 65 -3 c90 -3 130 20 130 77 0
29 -6 44 -20 54 -20 14 -20 15 -3 45 14 25 15 34 5 56 -6 15 -23 31 -38 36
-38 15 -134 13 -140 -3z m110 -33 c19 -7 21 -45 4 -62 -7 -7 -22 -12 -35 -12
-20 0 -23 5 -23 40 0 41 13 50 54 34z m20 -130 c19 -18 19 -20 6 -45 -8 -13
-21 -19 -45 -19 -34 0 -35 1 -35 40 0 38 2 40 29 40 16 0 37 -7 45 -16z"></path>
<path class="text" fill="#000000" d="M319 271 c-23 -24 -29 -38 -29 -74 0 -25 3 -53 6 -62 20 -50 164 -64
164 -15 0 15 -7 17 -45 12 -46 -5 -75 8 -75 34 0 11 16 14 65 14 l65 0 0 35
c0 80 -92 114 -151 56z m99 -33 c3 -15 -4 -18 -37 -18 -43 0 -50 7 -29 28 18
18 62 11 66 -10z"></path>
<path class="text" fill="#000000" d="M520 184 c0 -107 -1 -116 -20 -121 -11 -3 -20 -12 -20 -19 0 -21 76
-19 84 2 3 9 6 69 6 135 l0 119 -25 0 -25 0 0 -116z"></path>
<path class="text" fill="#000000" d="M649 271 c-24 -25 -29 -37 -29 -78 1 -70 34 -103 105 -103 55 0 95
44 95 103 0 60 -7 75 -41 92 -47 25 -96 19 -130 -14z m111 -30 c25 -48 2 -111
-40 -111 -45 0 -69 80 -34 114 21 22 61 20 74 -3z"></path>
<path class="text" fill="#000000" d="M850 287 c0 -8 16 -57 36 -110 28 -76 33 -100 25 -116 -16 -28 -14
-31 18 -31 27 0 29 4 70 123 23 67 41 128 41 135 0 6 -11 12 -24 12 -21 0 -26
-8 -41 -65 -10 -36 -21 -68 -25 -70 -3 -2 -16 27 -29 66 -19 60 -25 69 -47 69
-13 0 -24 -6 -24 -13z"></path>
<path class="text" fill="#000000" d="M1192 284 c-17 -12 -22 -24 -20 -47 2 -26 10 -36 45 -52 49 -23 59
-55 17 -55 -14 0 -34 5 -45 10 -16 9 -19 7 -19 -13 0 -17 7 -27 23 -31 69 -18
117 6 117 60 0 32 -4 37 -45 55 -60 26 -62 54 -4 46 37 -5 40 -3 37 16 -2 18
-11 23 -43 25 -25 2 -49 -3 -63 -14z"></path>
</g>
</svg>

                </a>
              </div>
              <button class="navbar-toggle" type="button">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
              </button>
            </div>
            <div class="buttons hidden-xs">
              <nav class="navigation-links" role="navigation">
                <ul class="main-links nav navbar-nav navbar-right">
                  <li><a href="../aws.html">AWS</a></li>
                  <li><a href="../linux.html">Linux</a></li>
                  <li><a href="../docker.html">Docker</a></li>
                  <li><a href="../ibmpower.html">IBM Power</a></li>
                  <li><a href="blogsataws1.html">Blogs@AWS (Kindle Friendly)</a></li>
                </ul>
              </nav>
            </div>
          </div>
        </div>
      </div>
    </div>

    <div class="sidebar-overlay"></div>

<aside class="sidebar" role="navigation">
  <div class="sidebar-header">
    <svg version="1.0" xmlns="http://www.w3.org/2000/svg" width="135.000000pt" height="42" viewbox="0 0 135.000000 45.000000" preserveaspectratio="xMidYMid meet">

<g transform="translate(0.000000,45.000000) scale(0.100000,-0.100000)" fill="#000000" stroke="none">
<path class="text" fill="#000000" d="M527 384 c-4 -4 -7 -18 -7 -31 0 -21 4 -24 28 -21 21 2 27 8 27 28 0
18 -6 26 -20 28 -12 2 -24 0 -28 -4z"></path>
<path class="text" fill="#000000" d="M1080 335 c0 -48 2 -55 20 -55 18 0 20 7 20 55 0 48 -2 55 -20 55
-18 0 -20 -7 -20 -55z"></path>
<path class="text" fill="#000000" d="M54 357 c-2 -7 -3 -69 -2 -138 l3 -124 65 -3 c90 -3 130 20 130 77 0
29 -6 44 -20 54 -20 14 -20 15 -3 45 14 25 15 34 5 56 -6 15 -23 31 -38 36
-38 15 -134 13 -140 -3z m110 -33 c19 -7 21 -45 4 -62 -7 -7 -22 -12 -35 -12
-20 0 -23 5 -23 40 0 41 13 50 54 34z m20 -130 c19 -18 19 -20 6 -45 -8 -13
-21 -19 -45 -19 -34 0 -35 1 -35 40 0 38 2 40 29 40 16 0 37 -7 45 -16z"></path>
<path class="text" fill="#000000" d="M319 271 c-23 -24 -29 -38 -29 -74 0 -25 3 -53 6 -62 20 -50 164 -64
164 -15 0 15 -7 17 -45 12 -46 -5 -75 8 -75 34 0 11 16 14 65 14 l65 0 0 35
c0 80 -92 114 -151 56z m99 -33 c3 -15 -4 -18 -37 -18 -43 0 -50 7 -29 28 18
18 62 11 66 -10z"></path>
<path class="text" fill="#000000" d="M520 184 c0 -107 -1 -116 -20 -121 -11 -3 -20 -12 -20 -19 0 -21 76
-19 84 2 3 9 6 69 6 135 l0 119 -25 0 -25 0 0 -116z"></path>
<path class="text" fill="#000000" d="M649 271 c-24 -25 -29 -37 -29 -78 1 -70 34 -103 105 -103 55 0 95
44 95 103 0 60 -7 75 -41 92 -47 25 -96 19 -130 -14z m111 -30 c25 -48 2 -111
-40 -111 -45 0 -69 80 -34 114 21 22 61 20 74 -3z"></path>
<path class="text" fill="#000000" d="M850 287 c0 -8 16 -57 36 -110 28 -76 33 -100 25 -116 -16 -28 -14
-31 18 -31 27 0 29 4 70 123 23 67 41 128 41 135 0 6 -11 12 -24 12 -21 0 -26
-8 -41 -65 -10 -36 -21 -68 -25 -70 -3 -2 -16 27 -29 66 -19 60 -25 69 -47 69
-13 0 -24 -6 -24 -13z"></path>
<path class="text" fill="#000000" d="M1192 284 c-17 -12 -22 -24 -20 -47 2 -26 10 -36 45 -52 49 -23 59
-55 17 -55 -14 0 -34 5 -45 10 -16 9 -19 7 -19 -13 0 -17 7 -27 23 -31 69 -18
117 6 117 60 0 32 -4 37 -45 55 -60 26 -62 54 -4 46 37 -5 40 -3 37 16 -2 18
-11 23 -43 25 -25 2 -49 -3 -63 -14z"></path>
</g>
</svg>

  </div>

  <ul class="nav sidebar-nav">
    <li><a href="../aws.html">AWS</a></li>
    <li><a href="../linux.html">Linux</a></li>
    <li><a href="../docker.html">Docker</a></li>
    <li><a href="../ibmpower.html">IBM Power</a></li>
    <li><a href="blogsataws1.html">Blogs@AWS (Kindle Friendly)</a></li>
  </ul>
</aside>


    <div class="container">
  <div class="row">
    <div id="docs-sidebar" class="col-sm-3 col-md-3 col-xs-12 hidden-print" role="complementary">
      <ul class="nav docs-sidenav">
      <li><a href="blogsataws1.html">Blogs @ AWS</a></li>
      <li><a href="whatsnew1.html">What's New @ AWS</a></li>
      <li><a href="secblogs1.html">Security Blogs @ AWS</a></li>
      <li><a href="computeblogs1.html">Compute Blogs @ AWS</a></li>
      <li><a href="apnblogs1.html">APN Blogs @ AWS</a></li>
      <li><a href="devopsblogs1.html">DevOps Blogs @ AWS</a></li>
      <li class="active"><a href="mgmtblogs1.html">Management Tools Blogs @ AWS</a></li>

    </ul>
    </div>

    <div id="inner" class="col-sm-9 col-md-9 col-xs-12" role="main">
<p></p>
<p><i>Contents of this page is copied directly from AWS blog sites to make it Kindle friendly. Some styles & sections from these pages are removed to render this properly in 'Article Mode' of Kindle e-Reader browser. All the contents of this page is property of AWS.</i></p>
<p><a href="mgmtblogs1.html">Page 1</a>|<a href="mgmtblogs2.html">Page 2</a>|<a href="mgmtblogs3.html">Page 3</a>|<a href="mgmtblogs4.html">Page 4</a</p>
<br>
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">Amazon EC2 Systems Manager as a General-Purpose DevOps Tool</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Ananth Vaidyanathan</span></span> | on 
<time property="datePublished" datetime="2017-09-28T12:31:50+00:00">28 SEP 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/amazon-ec2-systems-manager/" title="View all posts in Amazon EC2 Systems Manager*"><span property="articleSection">Amazon EC2 Systems Manager*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools*"><span property="articleSection">Management Tools*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/amazon-ec2-systems-manager-as-a-general-purpose-devops-tool/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><em>This guest post was written by Andrew Rout, Engineer at Riverbed SteelCentral Office of the CTO</em></p> 
<p>A long time ago, a manufacturer in Cincinnati invented Play-Doh to be used as a wallpaper cleaner. Twenty years later, an even better purpose was found for it, and kids everywhere rejoiced.</p> 
<p>History repeats itself with Amazon EC2 Systems Manager as we discover new ways to use this service from AWS. The following walk through shows you how Run Command can be used as a DevOps tool for orchestration and for systems introspection.</p> 
<h3>The need to communicate with EC2 instances</h3> 
<p>To manage the EC2 instances that power Riverbed Technology’s <a href="https://www.riverbed.com/products/steelcentral/use-as-a-service.html">SteelCentral SaaS</a> offering, Riverbed’s DevOps team built an internal tool that allows them to perform tasks on the EC2 instances and gives them insight into the state of the environment. A UI sits on top of a backend that communicates with the EC2 instances and various other AWS services.</p> 
<p>This internal DevOps tool allows our operations team to do the following:</p> 
<li>See dashboards describing the overall health of all infrastructure components and software components of SteelCentral SaaS</li> 
<li>Provision new resources as necessary</li> 
<li>Troubleshoot services running on EC2 instances</li> 
<li>Manage users and licensing<span id="more-1345"></span></li> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/25/steelcentral_saas.png" /></p> 
<p>In addition to a DevOps tool, Riverbed’s SaaS environment includes an event-driven service that also needs to communicate with EC2 instances. The event-driven system is used to provision additional resources on an EC2 instance as the system scales.</p> 
<p>Each of the tasks executed by the DevOps tool and the event-driven service requires one or more remote shell commands to be executed on an EC2 instance to either fetch information from an application or make a change to it.</p> 
<p>The Riverbed DevOps tool initially issued these commands via SSH, but the need to maintain an SSH key in multiple places was a headache from a logistics and security point-of-view. We preferred not to manage the key bits or the access control for SSH keys on our own, nor did we not want to develop and run a web service on all EC2 instances to handle our specific use cases.</p> 
<p><strong>EC2 Systems Manager makes software inventory management easier</strong></p> 
<p>Enter EC2 Systems Manager…</p> 
<p>EC2 Systems Manager was initially designed to be a tool for managing the software packages installed on EC2 instances, but it can be used for much more than just that.</p> 
<p>The original thinking was that if you needed to install or upgrade software on multiple EC2 instances, you could execute the yum, apt-get, Windows PowerShell, or other package manager command via EC2 Systems Manager, and it would do it for you without the user needing to SSH into each EC2 instance individually.</p> 
<p><strong>No, EC2 Systems Manager makes issuing remote commands easier</strong></p> 
<p>Really what <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/execute-remote-commands.html">Run Command</a> did was provide a way to execute ANY command on a remote EC2 instance. Anywhere an SSH command is needed, a Run Command call can take its place.</p> 
<p>The benefits of using Run Command instead of SSH have been stated in other <a href="https://aws.amazon.com/blogs/aws/manage-instances-at-scale-without-ssh-access-using-ec2-run-command/">blog posts</a>, so I’ll briefly list them here.</p> 
<li>No need to store SSH keys anywhere</li> 
<li>Ability to execute remote shell commands is controlled by IAM policies</li> 
<li>Commands issued via Run Command are auditable</li> 
<li>Command output can be stored in Amazon S3 for historical reference</li> 
<p>Essentially, EC2 Systems Manager is used as a communication service between a client and your EC2 instances.&nbsp; In Riverbed’s case, the DevOps tool is the client that wants to communicate with our EC2 instances.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/29/riverbed_arch-diagram.png" /></p> 
<p>Riverbed’s SteelCentral SaaS uses EC2 Systems Manager to issue commands to stop, start, and modify services running on EC2 instances. For example, when a new user signs up, an event is triggered and Run Command sends commands to ensure additional services are provisioned and configured as the system scales.</p> 
<p>In the Riverbed internal DevOps tool, a human operator can visit a page that displays the overall health of all of the services running on the EC2 instance serving the new user. To get that information, a Run Command is sent to the EC2 instance to query process status, and the output is populated into the DevOps tool’s UI.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/25/riverbed_devops.png" /></p> 
<p>Using Run Command in place of SSH has allowed Riverbed Technology to save tens of hours of engineering time each year due to no longer needing to manage and maintain SSH keys or troubleshoot SSH keys that aren’t working.</p> 
<p>More importantly, EC2 Systems Manager makes our security policies simpler to enforce because access controls are moved out of the code and into Amazon IAM. This saves time during compliance reviews and makes it easier for management to get a picture of what access paths are defined.</p> 
<p><strong>Setting up your AWS account to use the SSM Agent</strong></p> 
<p>Before you can execute commands on your EC2 instances using the SSM Agent, you need to do the following:</p> 
<ol> 
<li><a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/ssm-agent.html">Install the SSM Agent on your EC2 instances</a>.</li> 
<li>Update your EC2 instance’s IAM role to include the AWS managed policy named “AmazonEC2RoleforSSM”. Or, you can <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/systems-manager-access.html">create a custom policy</a> for SSM as an alternative to using a managed policy.</li> 
<li>Grant permission to your user’s IAM role to allow it to execute SSM commands. This simple policy grants access to all of SSM:<code class="lang-json"></code></li> 
</ol> 
<pre><code class="lang-json">{
&quot;Effect&quot;: &quot;Allow&quot;,
&quot;Action&quot;: [
&quot;ssm:*”
],
&quot;Resource&quot;: &quot;*&quot;
}
</code></pre> 
<p><strong>Here’s an example of how to execute a command using Run Command<br /> </strong></p> 
<p>As a simple test, let’s execute “whoami” on an EC2 instance via SSM.</p> 
<p>Note: This example is written in Python using the <a href="https://aws.amazon.com/sdk-for-python/">AWS SDK for Python (boto3)</a> to communicate with AWS services, but you can use any SDK of your choice, including the AWS CLI.</p> 
<p>First, send your command to SSM, and note the returned CommandId:</p> 
<pre><code class="lang-python">import boto3
import time
instance_id = 'i-abcdef123456'
cmd = 'whoami'
ssm = boto3.client('ssm', region_name='us-east-1')
response = ssm.send_command(
InstanceIds=[instance_id],
DocumentName='AWS-RunShellScript',
Parameters={&quot;commands&quot;:[cmd]}
)
command_id = response.get('Command', {}).get(&quot;CommandId&quot;, None)</code></pre> 
<p>Second, wait for the command to finish (use the CommandId from the previous step):</p> 
<pre><code class="lang-python">while True:
response = ssm.list_command_invocations(CommandId=command_id, Details=True)
# If the command hasn't started to run yet, keep waiting
#
if len(response['CommandInvocations']) == 0:
time.sleep(1)
continue
# There could be &gt;1 CommandInvocation if the command was sent to multiple
# EC2 instances, but in this example, we just sent the command to one.
#
invocation = response['CommandInvocations'][0]
# Once we detect the command is done, exit the while loop
if invocation['Status'] not in ('Pending', 'InProgress', 'Cancelling'):
break
time.sleep(1)</code></pre> 
<p>Last, grab the command output:</p> 
<pre><code class="lang-python">command_plugin = invocation['CommandPlugins'][-1]
output = command_plugin['Output']
status = command_plugin['ResponseCode']
print &quot;Output =&quot;, output
print &quot;Status =&quot;, status</code></pre> 
<p>If the SSM command succeeded, you should see output that looks like the following:</p> 
<p>Output = root</p> 
<p>Status = 0</p> 
<p>It’s important to note that the command output returned in the SSM response is truncated at 2,500 characters. If you expect your command output to be more than 2,500 characters, you can store the full command output in Amazon S3 and fetch it from there.</p> 
<p>To store the command output in Amazon S3, add the parameter “OutputS3BucketName” when running “send_command”:</p> 
<pre><code class="lang-python">response = ssm.send_command(
InstanceIds=[instance_id],
DocumentName='AWS-RunShellScript',
Parameters={&quot;commands&quot;:[cmd]},
OutputS3BucketName='&lt;bucket-name&gt;'
)</code></pre> 
<h3><strong>Summary</strong></h3> 
<p>Run Command is an ideal service to use inside an application that needs to communicate with EC2 instances. It provides a way to execute any remote command on any of your EC2 instances. With a little bit of IAM configuration, you can throw away your SSH keys forever and let Run Command handle executing your remote shell commands.</p> 
<p>The use cases for using Run Command are as expansive as the use cases for using SSH. Whether it be controlling the applications running on your EC2 instances or fetching system and application level information, AWS has given users a reliable and easy way to manage EC2 instances and the software running on them.</p> 
<h3>About Riverbed Technology</h3> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/29/riverbed-logo.png">SteelCentral SaaS</a> provides full-Stack Application Performance Monitoring with real-time visibility into the end-user experience, network, infrastructure and applications for applications hosted on or off the cloud. Users can diagnose application performance problems down to the offending code, SQL, web service, network, or system resource.</p> 
<h3>About the Author</h3> 
<p><a href="http://www.linkedin.com/in/andrew-r-a425162">Andrew Rout</a> joined Riverbed Technology in 2013. As an engineer in Riverbed’s SteelCentral Office of the CTO, he evaluates new technologies for product integration and has recently spent time leveraging AWS and Docker. He currently builds and manages the tools and AWS infrastructure that power <a href="https://www.riverbed.com/products/steelcentral/use-as-a-service.html">SteelCentral SaaS</a>. He has a strong interest in using Python to drive DevOps activities.</p> 
<p><code class="lang-json"></code><br /> <code class="lang-json"></code></p> 
<p><code class="lang-json"><br /> </code></p> 
<p>&nbsp;</p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/mt/tag/ec2-systems-manager/" rel="tag">EC2 Systems Manager</a>, <a href="https://aws.amazon.com/blogs/mt/tag/run-command/" rel="tag">Run Command</a>, <a href="https://aws.amazon.com/blogs/mt/tag/ssm/" rel="tag">SSM</a></span> 
</footer> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">Automate remediation actions for Amazon EC2 notifications and beyond using EC2 Systems Manager Automation and AWS Health</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Venkat Krish</span></span> | on 
<time property="datePublished" datetime="2017-09-27T13:40:09+00:00">27 SEP 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/amazon-cloudwatch/" title="View all posts in Amazon CloudWatch*"><span property="articleSection">Amazon CloudWatch*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/amazon-ec2-systems-manager/" title="View all posts in Amazon EC2 Systems Manager*"><span property="articleSection">Amazon EC2 Systems Manager*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools*"><span property="articleSection">Management Tools*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/automate-remediation-actions-for-amazon-ec2-notifications-and-beyond-using-ec2-systems-manager-automation-and-aws-health/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p>You can use EC2 <a href="https://aws.amazon.com/ec2/systems-manager/">Systems Manager Automation</a> to take remediation actions in response to events that may impact your AWS resources. To illustrate this concept, this post guides you through setting up automated remediation actions when an <a href="https://aws.amazon.com/ebs/">Amazon EBS</a> backed <a href="https://aws.amazon.com/ec2/systems-manager/">Amazon EC2</a> instance is scheduled for retirement.</p> 
<p>An instance is scheduled to be retired when AWS detects irreparable failure of the underlying hardware hosting the instance. If your instance root device is an Amazon EBS volume you can stop and start the instance at any time of your convenience before the retirement.</p> 
<p>Amazon EC2 Systems Manager (SSM) Automation is an AWS-hosted service that simplifies common instance and system maintenance and deployment tasks at no additional cost.</p> 
<p><span id="more-1352"></span></p> 
<p><a href="http://docs.aws.amazon.com/health/latest/ug/what-is-aws-health.html">AWS Health</a> provides ongoing visibility into the state of your AWS resources, services, and accounts. The service gives you awareness and remediation guidance for resource performance or availability issues that may affect your applications that run on AWS.</p> 
<p>Both services are integrated with <a href="http://docs.aws.amazon.com/AmazonCloudWatch/latest/events/WhatIsCloudWatchEvents.html">Amazon CloudWatch Events</a>, allowing AWS Health events to trigger SSM Automation documents.</p> 
<p>SSM Automation also offers an Approval action which temporarily pauses an Automation execution until your designated principals (e.g. IAM user) either approve or reject the action. More information about SSM automated actions is available <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/automation-actions.html">Systems Manager Automation Actions</a>.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/26/Ec2InstanceRetirement1-1024x441.png" /></p> 
<p>&nbsp;</p> 
<h6>Figure 1: AWS Services feed events into AWS Health which triggers EC2 Systems Manager</h6> 
<p>&nbsp;</p> 
<p>This post will walk through the four steps to setup Stop and Start of EC2 instances using SSM Automation in response to EC2 retirement events from AWS Health. To launch the solution in the us-east-1 region using AWS CloudFormation please click <a href="https://console.aws.amazon.com/cloudformation/home?region=us-east-1#/stacks/new?stackName=StopStartEC2InstancewithApproval&amp;templateURL=https://s3.amazonaws.com/aws-health-tools-assets/cloudformation-templates/AWS-StopStartEC2InstancewithApproval.template">here</a>. Please change the region as required. We recommend reviewing the manual steps below before deploying the CloudFormation stack to have an understanding of the solution.</p> 
<p><strong>Step 1:</strong> Set up required <a href="https://aws.amazon.com/iam/">AWS IAM</a> role<br /> <strong>Step 2:</strong> Set up the <a href="https://aws.amazon.com/sns/">Amazon SNS</a> Topic if you don’t have one already<br /> <strong>Step 3:</strong> Set up the <a href="http://docs.aws.amazon.com/AmazonCloudWatch/latest/events/WhatIsCloudWatchEvents.html">Amazon CloudWatch Events</a> rule with the Automation document<br /> <strong>Step 4:</strong> Test it out and approve the Automation</p> 
<h3></h3> 
<h3>Setup Instructions</h3> 
<p><strong>Step 1: Set up required IAM role</strong></p> 
<p>First setup the required IAM permissions for CloudWatch Events to use by creating an IAM policy and associating with an IAM role for CloudWatch. For the purpose of this example we will call the IAM role the AutomationCWRole. Here is an example of an IAM policy that could be used for this purpose:</p> 
<pre><code class="lang-json">{
&quot;Version&quot;: &quot;2012-10-17&quot;,
&quot;Statement&quot;: [
{
&quot;Effect&quot;: &quot;Allow&quot;,
&quot;Action&quot;: [
&quot;ec2:StartInstances&quot;,
&quot;ec2:StopInstances&quot;,
&quot;ec2:DescribeInstanceStatus&quot;
],
&quot;Resource&quot;: [
&quot;*&quot;
]
},
{
&quot;Effect&quot;: &quot;Allow&quot;,
&quot;Action&quot;: [
&quot;ssm:*&quot;
],
&quot;Resource&quot;: [
&quot;*&quot;
]
},
{
&quot;Effect&quot;: &quot;Allow&quot;,
&quot;Action&quot;: [
&quot;sns:Publish&quot;
],
&quot;Resource&quot;: [
&quot;arn:aws:sns:*:*:Automation*&quot;
]
},
{
&quot;Effect&quot;: &quot;Allow&quot;,
&quot;Action&quot;: [
&quot;iam:PassRole&quot;
],
&quot;Resource&quot;: &quot;arn:aws:iam::&lt;AccountId&gt;:role/AutomationCWRole&quot;
}
]
}</code></pre> 
<p>Please make sure to update the role ARN which account Id and role name. You need to ensure that the role has events.amazonaws.com and ssm.amazonaws.com configured as a trusted entity for the IAM role as shown here:</p> 
<pre><code class="lang-json">{
&quot;Version&quot;: &quot;2012-10-17&quot;,
&quot;Statement&quot;: [
{
&quot;Effect&quot;: &quot;Allow&quot;,
&quot;Principal&quot;: {
&quot;Service&quot;: [
&quot;ssm.amazonaws.com&quot;,
&quot;events.amazonaws.com&quot;
]
},
&quot;Action&quot;: &quot;sts:AssumeRole&quot;
}
]
}
</code></pre> 
<p>More information about CloudWatch and IAM see <a href="http://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/auth-and-access-control-cw.html">Authentication and Access Control for Amazon CloudWatch</a>. For more information about Systems Manager and IAM, see <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/sysman-configuring-access-policies.html">Configuring Access Using Systems Manager Managed Policies</a>.</p> 
<p><strong>Step 2: Set up the Amazon SNS Topic if you don’t have one already</strong></p> 
<p>If you choose to use Automation Approval actions, then you will also need to create an SNS topic that the approval notification will be published to or use an existing one. You will also need to subscribe the approvers to that SNS topic. More information on how to set this up is available <a href="http://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/US_SetupSNS.html">here</a>.</p> 
<p>We will use the SNS topic name AutomationStopStart for this example. Please note that the SNS Topic name must start with the Prefix: Automation.</p> 
<p><strong>Step 3: Set up the Amazon CloudWatch Events rule with the Automation document</strong></p> 
<p>First create a SSM Automation document named StopStartEC2InstancewithApproval by creating a json file using your preferred editor named “StopStartEC2InstancewithApproval.json”:</p> 
<pre><code class="lang-json">{
&quot;description&quot;:&quot;Stop and Start EC2 instances(s) with Approval&quot;,
&quot;schemaVersion&quot;:&quot;0.3&quot;,
&quot;assumeRole&quot;:&quot;{{ AutomationAssumeRole }}&quot;,
&quot;parameters&quot;:{
&quot;AutomationAssumeRole&quot;:{
&quot;type&quot;:&quot;String&quot;,
&quot;description&quot;:&quot;The ARN of the role that allows Automation to perform the actions on your behalf.&quot;,
&quot;default&quot;:&quot;arn:aws:iam::{{global:ACCOUNT_ID}}:role/AutomationServiceRole&quot;
},
&quot;InstanceIds&quot;:{
&quot;type&quot;:&quot;String&quot;,
&quot;description&quot;:&quot;EC2 Instance(s) to Stop and Start&quot;
},
&quot;Approvers&quot;:{
&quot;type&quot;:&quot;StringList&quot;,
&quot;description&quot;:&quot;IAM user or user arn of approvers for the automation action&quot;
},
&quot;SNSTopicArn&quot;:{
&quot;type&quot;:&quot;String&quot;,
&quot;description&quot;:&quot;The SNS topic ARN that you are using to get notifications on about EC2 retirement notifications. The SNS topic name must start with Automation.&quot;
}
},
&quot;mainSteps&quot;:[
{
&quot;name&quot;:&quot;approve&quot;,
&quot;action&quot;:&quot;aws:approve&quot;,
&quot;timeoutSeconds&quot;:999999,
&quot;onFailure&quot;:&quot;Abort&quot;,
&quot;inputs&quot;:{
&quot;NotificationArn&quot;:&quot;{{ SNSTopicArn }}&quot;, 
&quot;Message&quot;: &quot;Your approval is required to proceed with the stop and start of an EC2 instance using the EC2 systems manager automation document that is scheduled for retirement.&quot;,
&quot;MinRequiredApprovals&quot;:1,
&quot;Approvers&quot;:[
&quot;{{Approvers}}&quot;
]
}
},
{
&quot;name&quot;:&quot;stopInstance&quot;,
&quot;action&quot;:&quot;aws:changeInstanceState&quot;,
&quot;maxAttempts&quot;:2,
&quot;timeoutSeconds&quot;:120,
&quot;onFailure&quot;:&quot;Continue&quot;,
&quot;inputs&quot;:{
&quot;InstanceIds&quot;:[
&quot;{{ InstanceIds }}&quot;
],
&quot;DesiredState&quot;:&quot;stopped&quot;
}
},
{
&quot;name&quot;:&quot;forceStopInstance&quot;,
&quot;action&quot;:&quot;aws:changeInstanceState&quot;,
&quot;maxAttempts&quot;:1,
&quot;timeoutSeconds&quot;:60,
&quot;onFailure&quot;:&quot;Continue&quot;,
&quot;inputs&quot;:{
&quot;InstanceIds&quot;:[
&quot;{{ InstanceIds }}&quot;
],
&quot;Force&quot;:true,
&quot;DesiredState&quot;:&quot;stopped&quot;
}
},
{
&quot;name&quot;:&quot;startInstance&quot;,
&quot;action&quot;:&quot;aws:changeInstanceState&quot;,
&quot;maxAttempts&quot;:3,
&quot;timeoutSeconds&quot;:120,
&quot;onFailure&quot;:&quot;Continue&quot;,
&quot;inputs&quot;:{
&quot;InstanceIds&quot;:[
&quot;{{ InstanceIds }}&quot;
],
&quot;DesiredState&quot;:&quot;running&quot;
}
}
]
}
</code></pre> 
<p>Then use the AWS CLI to create the SSM Automation document using the JSON file above:</p> 
<pre><code class="lang-json">[
<em>aws ssm create-document --content file://StopStartEC2InstancewithApproval.json --name &quot; StopStartEC2InstancewithApproval&quot; --document-type &quot;Automation&quot;</em>
]</code></pre> 
<p>More information about creating creating SSM documents can be found at <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/create-ssm-doc.html">Creating Systems Manager Documents</a>.</p> 
<p>You can then create the CloudWatch Events rule that will trigger the Automation document each time an EC2 retirement notification occurs. As an example you can use the following command using the AWS CLI:</p> 
<pre><code class="lang-json">aws events put-rule --name &quot;EC2RetirementNotification&quot; --event-pattern &quot;{\&quot;source\&quot;:[\&quot;aws.health\&quot;],\&quot;detail-type\&quot;:[\&quot;AWS Health Event\&quot;],\&quot;detail\&quot;:{\&quot;service&quot;\&quot;:[\&quot;EC2\&quot;],\&quot;eventTypeCategory&quot;\&quot;:[\&quot;scheduledChange\&quot;],\&quot;eventTypeCode&quot;\&quot;:[\&quot;AWS_EC2_INSTANCE_RETIREMENT_SCHEDULED\&quot;]}&quot;}&quot;</code></pre> 
<p>To set this up you can create a JSON file named <em>targets.json</em> using your preferred editor and then use that to create the CloudWatch Events target:</p> 
<pre><code class="lang-json">[
{
&quot;Id&quot;:&quot;1&quot;,
&quot;Arn&quot;:&quot;arn:aws:ssm:&lt;region&gt;:&lt;accountId&gt;:automation-definition/AWS-StopStartEC2InstancewithApproval&quot;,
&quot;RoleArn&quot;:&quot;arn:aws:iam::&lt;accountId&gt;:role/AutomationCWRole&quot;,
&quot;InputTransformer&quot;:{
&quot;InputPathsMap&quot;:{
&quot;Instances&quot;: &quot;$.resources&quot;
},
&quot;InputTemplate&quot;: &quot;{ \&quot;AutomationAssumeRole\&quot;:[\&quot;aws:iam::&lt;accountId&gt;:role/AutomationCWRole\&quot;],\&quot;Approvers\&quot;:[\&quot;&lt;IAMusername&gt;\&quot;],\&quot;SNSTopicArn\&quot;:[\&quot;arn:aws:sns:&lt;region&gt;:&lt;accountId&gt;:AutomationStopStart\&quot;],\&quot;InstanceIds\&quot;: &lt;Instances&gt; }&quot;
}
}
]</code></pre> 
<p>Please update the region, accountId, SNS topic ARN, IAM role ARN and IAM username in the json file above per your requirements. The target in this case is the Automation document StopStartEC2InstancewithApproval which Stops and Starts the instance(s) provided.</p> 
<p>Then use the AWS CLI to create the target specifying the json file you created:</p> 
<p><em> aws events put-targets –rule EC2RetirementNotification –targets file://targets.json</em></p> 
<p><strong>Step 4: Test it out and approve the Automation</strong></p> 
<p>You can test against the document using direct inputs as well:</p> 
<p><em> aws ssm start-automation-execution –document-name AmazonEC2InstanceStopStartwithApproval –parameters AutomationAssumeRole=”aws:iam::&lt;AccountId&gt;:role/AutomationCWRole”,Approvers=&lt;IAMusername&gt;,SNSTopicArn=”arn:aws:sns:us-east-1:&lt;AccountId&gt;:AutomationStopStart”,InstanceIds=&lt;InstanceId&gt;</em></p> 
<p>You can get the execution status using the AutomationExecutionId returned from the command above: aws ssm&nbsp; get-automation-execution –automation-execution-id &lt;value&gt;</p> 
<p>Once you get the approval message published to your SNS topic’s subscribers, you can choose to approve or reject the action:</p> 
<p><em> aws ssm send-automation-signal –automation-execution-id &lt;automation-execution-id&gt; –signal-type Approve –payload Comment=Replace_This_With_Approve_Comment</em></p> 
<p>The automation can also be approved from the EC2 console in the Automation section:</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/26/Ec2InstanceRetirement2.png" /></p> 
<p>Please note that the approval will trigger the stop and start of the EC2 Instance, regardless of the comments provided.</p> 
<p>You can also skip the approval step and instead use the AmazonEC2InstanceStopStart SSM Automation document. Please note that in very rare situations EC2 instances might not stop even after a force stop; you should contact AWS support if that happens.</p> 
<h3>Conclusion</h3> 
<p>You can use EC2 Systems Manager Automation to take remediation actions on your AWS resources in response to events that may impact. You can take this example and apply it to other EC2 scheduled changes (e.g. system reboot maintenance) or any event with any AWS resource that may suit your needs. You can also use the document provided to Stop and Start EC2 instances in an automated way. We recommend tailoring it and testing for your use-case before deploying in a production environment.</p> 
<h3>About the Author</h3> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/26/Tipu_Quershi.jpg" /></p> 
<p>Tipu Qureshi is a principal engineer in the AWS support organization. He works with customers to implement automation, solve problems and setup new workloads on the AWS platform. He has created various architectures and certifications for cost-optimization and agility through DevOps.</p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/mt/tag/amazon-cloudwatch-events/" rel="tag">Amazon Cloudwatch Events</a>, <a href="https://aws.amazon.com/blogs/mt/tag/automation/" rel="tag">Automation</a>, <a href="https://aws.amazon.com/blogs/mt/tag/aws-iam/" rel="tag">AWS IAM</a>, <a href="https://aws.amazon.com/blogs/mt/tag/aws-sns/" rel="tag">AWS SNS</a>, <a href="https://aws.amazon.com/blogs/mt/tag/ec2-systems-manager/" rel="tag">EC2 Systems Manager</a>, <a href="https://aws.amazon.com/blogs/mt/tag/ec2-windows/" rel="tag">EC2 Windows</a>, <a href="https://aws.amazon.com/blogs/mt/tag/ssm/" rel="tag">SSM</a></span> 
</footer> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">Get Disk Utilization of Your Fleet Using EC2 Systems Manager Custom Inventory Types</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Tanu Mutreja</span></span> | on 
<time property="datePublished" datetime="2017-09-20T14:23:32+00:00">20 SEP 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/amazon-ec2-systems-manager/" title="View all posts in Amazon EC2 Systems Manager*"><span property="articleSection">Amazon EC2 Systems Manager*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools*"><span property="articleSection">Management Tools*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/get-disk-utilization-of-your-fleet-using-ec2-systems-manager-custom-inventory-types/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><a href="https://aws.amazon.com/ec2/systems-manager/inventory/">Amazon EC2 Systems Manager Inventory</a> provides a centralized way to collect and query system, application, and instance metadata. Using the resource data sync feature, you can sync this metadata to Amazon S3. In Amazon S3 you can aggregate the metadata for different AWS Regions and accounts. After you sync this inventory data to Amazon S3, you can create various visuals of the data using Amazon Athena and Amazon QuickSight.</p> 
<p>The inventory data collection policy is configured using <a href="https://aws.amazon.com/ec2/systems-manager/state-manager/">State Manager</a> , which in turn gets executed by <a href="https://github.com/aws/amazon-ssm-agent/tree/master/agent/plugins/inventory">aws:softwareInventory plugin</a> in <a href="https://github.com/aws/amazon-ssm-agent">amazon-ssm-agent</a>.</p> 
<p>Amazon EC2 Systems Manager Inventory provides two ways to define the types of data that it collects: predefined and custom.</p> 
<p>&middot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <strong>Predefined data types (with prefix AWS)</strong> are natively supported by the inventory plugin via multiple <a href="https://github.com/aws/amazon-ssm-agent/tree/master/agent/plugins/inventory/gatherers">gatherers</a>. Some examples of predefined inventory types are AWS:Application and AWS:WindowsUpdate.</p> 
<p>&middot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <strong>Custom data type (with prefix Custom)</strong> is a special inventory data type that can be defined by end users. This data type provides the flexibility of collecting additional inventory data, such as server rack location of a managed instance.</p> 
<p>In this blog, I’ll walk you through an example that shows how to use the custom inventory data type to collect disk utilization for Windows instances. We’ll use PowerShell scripts to collect disk utilization data in the Inventory. After the data is collected, we’ll use this data to get fleet-level aggregation of disk usage.</p> 
<p><span id="more-1234"></span></p> 
<h3>Step1: Create Inventory Policy Document with aws:runPowerShellScript plugin</h3> 
<p>By default, you can use AWS-GatherSoftwareInventory document to collect Inventory data. However, for this example we’ll create a document with <strong>aws:runPowerShellScript &amp; aws:softwareInventory</strong> plugins to ensure that a PowerShell script is invoked before Inventory collection begins. Since amazon-ssm-agent preserves the order of the plugin’s executions, it ensures that the latest Disk Utilization data is captured before Inventory data is collected.</p> 
<h4>Option 1: Create Document using the AWS Management Console</h4> 
<p>You can create the document in the AWS console by going to EC2 -&gt; Systems Manager Shared Resources -&gt; Documents. Here is the document content.</p> 
<pre><code class="lang-json">{
&quot;schemaVersion&quot;: &quot;2.2&quot;,
&quot;description&quot;: &quot;Run first a shell script &amp; then inventory plugin.&quot;,
&quot;mainSteps&quot;: [
{
&quot;action&quot;: &quot;aws:runPowerShellScript&quot;,
&quot;name&quot;: &quot;runPowerShellScript&quot;,
&quot;inputs&quot;: {
&quot;runCommand&quot;: &quot;{{ commands }}&quot;
}
},
{
&quot;action&quot;: &quot;aws:softwareInventory&quot;,
&quot;name&quot;: &quot;collectSoftwareInventoryItems&quot;,
&quot;inputs&quot;: {
&quot;applications&quot;: &quot;{{ applications }}&quot;,
&quot;awsComponents&quot;: &quot;{{ awsComponents }}&quot;,
&quot;networkConfig&quot;: &quot;{{ networkConfig }}&quot;,
&quot;windowsUpdates&quot;: &quot;{{ windowsUpdates }}&quot;,
&quot;customInventory&quot;: &quot;{{ customInventory }}&quot;
}
}
],
&quot;parameters&quot;: {
&quot;commands&quot;: {
&quot;type&quot;: &quot;StringList&quot;,
&quot;description&quot;: &quot;(Required) Specify a shell script or a command to run.&quot;,
&quot;minItems&quot;: 1,
&quot;displayType&quot;: &quot;textarea&quot;
},
&quot;applications&quot;: {
&quot;type&quot;: &quot;String&quot;,
&quot;default&quot;: &quot;Enabled&quot;,
&quot;description&quot;: &quot;(Optional) Collect data for installed applications.&quot;,
&quot;allowedValues&quot;: [
&quot;Enabled&quot;,
&quot;Disabled&quot;
]
},
&quot;awsComponents&quot;: {
&quot;type&quot;: &quot;String&quot;,
&quot;default&quot;: &quot;Enabled&quot;,
&quot;description&quot;: &quot;(Optional) Collect data for AWSComponents like amazon-ssm-agent.&quot;,
&quot;allowedValues&quot;: [
&quot;Enabled&quot;,
&quot;Disabled&quot;
]
},
&quot;networkConfig&quot;: {
&quot;type&quot;: &quot;String&quot;,
&quot;default&quot;: &quot;Enabled&quot;,
&quot;description&quot;: &quot;(Optional) Collect data for Network configurations.&quot;,
&quot;allowedValues&quot;: [
&quot;Enabled&quot;,
&quot;Disabled&quot;
]
},
&quot;windowsUpdates&quot;: {
&quot;type&quot;: &quot;String&quot;,
&quot;default&quot;: &quot;Enabled&quot;,
&quot;description&quot;: &quot;(Optional) Collect data for all WindowsUpdates.&quot;,
&quot;allowedValues&quot;: [
&quot;Enabled&quot;,
&quot;Disabled&quot;
]
},
&quot;customInventory&quot;: {
&quot;type&quot;: &quot;String&quot;,
&quot;default&quot;: &quot;Enabled&quot;,
&quot;description&quot;: &quot;(Optional) Collect data for custom inventory.&quot;,
&quot;allowedValues&quot;: [
&quot;Enabled&quot;,
&quot;Disabled&quot;
]
}
}
}</code></pre> 
<h4>Option 2: Create Document using the AWS command line (aws-cli)</h4> 
<p>a.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Create the document by running the aws-cli command that creates the document:</p> 
<pre><code class="lang-bash">aws ssm create-document --content file://<em>path to your file\FileName</em> --name &quot;CustomInventory-Doc&quot; --document-type Command</code></pre> 
<p>b.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Verify the document’s status by running following command:</p> 
<p><code class="lang-python">aws ssm list-documents --document-filter-list key=Name,value= CustomInventory-Doc<br /> </code></p> 
<p>Here is a sample output that you should see:<br /> <em>{</em><br /> <em>&nbsp;&nbsp;&nbsp; “DocumentIdentifiers”: [</em><br /> <em>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; {</em><br /> <em>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; “Name”: ” CustomInventory-Doc “, </em><br /> <em>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; “PlatformTypes”: [</em><br /> <em>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; “Windows”, </em><br /> <em>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; “Linux”</em><br /> <em>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ], </em><br /> <em>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; “DocumentVersion”: “1”, </em><br /> <em>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; “DocumentType”: “Command”, </em><br /> <em>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; “Owner”: “xxx”, </em><br /> <em>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; “SchemaVersion”: “2.0”</em><br /> <em>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }</em><br /> <em>&nbsp;&nbsp;&nbsp; ]</em><br /> <em>}</em></p> 
<h3>Step2: Create association using CustomInventory-Doc</h3> 
<p>Now that the inventory policy document is created, we will “Create Association,” that is we’ll associate this policy document to the targeted instances. To use the EC2 console to Create Association, go to State Manager under Systems Manager Service.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/18/s1-1.png" /></p> 
<p>Next, you need to pick instances to which you want to attach this Association. In addition, define a schedule for this inventory collection. After you pick the instances and schedule, you can paste following PowerShell script in the Commands parameter (as shown in the screenshot that follows). This script is executed by the <em><strong>aws:runPowerShellScript</strong></em> plugin before the Inventory plugin is invoked.</p> 
<p>Script:</p> 
<pre><code class="lang-powershell">$data = get-wmiobject win32_logicaldisk | Select-Object @{n=&quot;DeviceId&quot;;e={$_.&quot;DeviceID&quot;}}, @{n=&quot;VolumeName&quot;;e={$_.&quot;VolumeName&quot;}}, @{n=&quot;Use%&quot;;e={&quot;{0}&quot; -f [math]::Round(($_.&quot;Size&quot; - $_.&quot;FreeSpace&quot;) * 100 / $_.&quot;Size&quot;,0)}}, @{n=&quot;Size(GB)&quot;;e={&quot;{0}&quot; -f [math]::Round($_.&quot;Size&quot; / 1GB ,0)}} | ConvertTo-Json
$content = &quot;{`&quot;SchemaVersion`&quot; : `&quot;1.0`&quot;, `&quot;TypeName`&quot;: `&quot;Custom:DiskUtilization`&quot;, `&quot;Content`&quot;: $data}&quot;
$instanceId = Invoke-RestMethod -uri http://169.254.169.254/latest/meta-data/instance-id
$filepath = &quot;C:\ProgramData\Amazon\SSM\InstanceData\&quot; + $instanceId + &quot;\inventory\custom\CustomDiskUsage.json&quot;
if (-NOT (Test-Path $filepath)) {
New-Item $filepath -ItemType file
}
Set-Content -Path $filepath -Value $content</code></pre> 
<p>This script gets disk utilization data using win32_logicaldisk. It uses <a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-metadata.html">Instance-Metadata </a>to get InstanceId, which is required in order to save the content in the path: <em>%SystemDrive%\ProgramData\Amazon\SSM\InstanceData\&lt;instance-id&gt;\inventory\custom</em></p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/08/s2.png" /></p> 
<p>Choose Create Association and that’s it. After the policy runs on the targeted instances, disk utilization data will be collected and become ready for consumption.</p> 
<p>Let’s go to Managed Instances and check disk utilization for an instance by choosing the Inventory tab. The following screenshot shows the new Custom data for one of my instances.</p> 
<p>&nbsp;</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/20/ss1-1.png" /></p> 
<p>We can also apply various filters to determine the fleet’s Disk Utilization health.</p> 
<p>Let’s apply a filter to list all instances with disk utilization of more than 50 percent. The following screenshot shows instances matching the filter.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/18/s3-1.png" /></p> 
<h3>Conclusion</h3> 
<p>This blog shows you how to create a custom document with <em><strong>aws:runPowerShellScript</strong></em> &amp; <em><strong>aws:softwareInventory plugin</strong></em>s. This allows you to collect and then send Custom Inventory data from an instance every time the Inventory policy is run. The data can then be queried at both the fleet and instance level.</p> 
<p>In this blog, we used a PowerShell script to get the custom data, however the same document can also be used to trigger any third-party application running in the instance to collect custom data.</p> 
<h4>About the Author</h4> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/13/SaurabhShankar.jpeg" /></p> 
<p>Saurabh Shankar is a Software Development Engineer with the Amazon EC2 Systems Manager team. He has been with Amazon for four years, working on Inventory and other features of Amazon EC2 Systems Manager. Outside work, he enjoys trekking and taking photographs.</p> 
<p>&nbsp;</p> 
<p>&nbsp;</p> 
<p>&nbsp;</p> 
<p>&nbsp;</p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/mt/tag/aws-systems-manager-inventory/" rel="tag">AWS Systems Manager Inventory</a>, <a href="https://aws.amazon.com/blogs/mt/tag/custom-inventory/" rel="tag">Custom Inventory</a>, <a href="https://aws.amazon.com/blogs/mt/tag/custom-inventory-type/" rel="tag">Custom Inventory Type</a>, <a href="https://aws.amazon.com/blogs/mt/tag/ec2-systems-manager-inventory/" rel="tag">EC2 Systems Manager Inventory</a>, <a href="https://aws.amazon.com/blogs/mt/tag/inventory/" rel="tag">Inventory</a>, <a href="https://aws.amazon.com/blogs/mt/tag/ssm/" rel="tag">SSM</a>, <a href="https://aws.amazon.com/blogs/mt/tag/ssm-inventory/" rel="tag">SSM Inventory</a></span> 
</footer> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">Manage your fleet at scale using EC2 Systems Manager</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Venkat Krish</span></span> | on 
<time property="datePublished" datetime="2017-09-19T10:28:04+00:00">19 SEP 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/amazon-ec2-systems-manager/" title="View all posts in Amazon EC2 Systems Manager*"><span property="articleSection">Amazon EC2 Systems Manager*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools*"><span property="articleSection">Management Tools*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/manage-your-fleet-at-scale-using-ec2-systems-manager/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><em>This guest post was written by Michael Baker, who works as a DevOps Engineer for the Infrastructure Engineering team at Bulletproof</em></p> 
<h3>Introduction</h3> 
<p>The Bulletproof Group Limited has spent many years investing in system automation to assist with fleet management at scale. More recently, we have spent a significant amount of time working with <a href="https://aws.amazon.com/ec2/systems-manager/">Amazon EC2 Systems Manager</a>. In this blog post, I describe how we have utilized Amazon EC2 Systems Manager&nbsp;on two recent customer engagements. Much has been written about the rapid change within managed services for the public cloud, but the requirement for patching operating systems is ever present. With an increasing focus on security, patching is arguably higher up our customers’ list of priorities than ever before. Our customers increasingly focus on improving the agility of their businesses. So in addition to understanding the basics, including patching, we are now designing pipelines to be both rugged and as fast as possible.</p> 
<p><span id="more-1287"></span></p> 
<h3>Customer One: Extending Amazon Auto Scaling with automated Amazon Machine Image (AMI) patching and deployment</h3> 
<p>Bulletproof recently has been charged with building a fully automated patching and deployment pipeline as an extension to an existing environment that was built with, among other things,&nbsp;Auto Scaling from AWS. &nbsp;It was important that this pipeline enabled both scheduled and ad hoc operating system and key service patching. &nbsp;During requirements gathering it became clear that owing to governance policy within our customer’s business we were unable to deliver an entirely automated deployment pipeline. A manual approval step was a part of their key requirements.</p> 
<p>After a quick review of tooling in-place within the customer build process, we took a mixture of Bulletproof’s current best practice recommendations and elected to use the following primary toolkit:</p> 
<li><a href="https://aws.amazon.com/ec2/systems-manager/">Amazon EC2 Systems Manager</a></li> 
<li><a href="https://aws.amazon.com/cloudformation/">AWS CloudFormation</a></li> 
<li><a href="https://aws.amazon.com/codedeploy/">AWS CodeDeploy</a></li> 
<li><a href="https://aws.amazon.com/getting-started/projects/setup-jenkins-build-server/">Jenkins (running on Amazon EC2)</a></li> 
<p>Diving in a little more deeply on the Jenkins configuration, the following key steps occur after our customer initiates the deployment job by logging on to their EC2 instances over VPN:</p> 
<li>We clone the customer’s GitHub repository (to pick up the most recent changes).</li> 
<li>Then we execute a Systems Manager Automation to launch an EC2 instance running the up-to-date customer code.</li> 
<li>Next we send and store the SSM command ID within the <a href="https://aws.amazon.com/ec2/systems-manager/parameter-store/">Systems Manager Parameter Store</a>. (We can now use this command ID to view the state of the SSM execution.)</li> 
<li>When the Systems Manager job state reaches complete, we wait 60 seconds and then begin a CodeDeploy run. (The delay is to ensure that the instance is available in time for CodeDeploy.)</li> 
<li>Jenkins queries the parameter store with the command ID of the first job executed and asks Systems Manager for the new AMI ID.</li> 
<li>We then initiate a stack update in the relevant&nbsp;<a href="https://aws.amazon.com/cloudformation/">CloudFormation </a>stack. This updates the <a href="https://aws.amazon.com/autoscaling/">Auto Scaling</a> group configuration with the new AMI. &nbsp;(This happens in such a way as to reduce the chance of service interruption.)</li> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/18/1-1.png" /></p> 
<p>The final key requirement was to enable rapid deployments. Previously even basic change required multiple stakeholders and a brief service outage. &nbsp;Today our customers create change with confidence, knowing that the integration work is&nbsp;successful and it happens without interruption to service. &nbsp;A side effect of rapid deployment is that both Developer and Operations teams are able to collaborate more closely, without one team being slowed down by the other. Continuous improvement or cloud optimization from both teams now happens on a daily basis.</p> 
<h3>Customer Two: Migration of internal services onto Amazon EC2 Container Service (ECS)</h3> 
<p>Bulletproof is currently in the process of migrating a number of internal services from our customer’s environment onto <a href="https://aws.amazon.com/ecs/">Amazon ECS</a>. Because AWS CodeDeploy doesn’t currently support using SSH keys for access to GitHub, we developed a solution to clone data from GitHub into a container. &nbsp;This container contains a deployment for a private GitHub repository.</p> 
<p>First, we use a webhook from GitHub to Amazon API Gateway to initiate a <a href="https://aws.amazon.com/lambda/">Lambda function</a>. That Lambda function then logs the GitHub pull request information into EC2 Systems Manager Parameter Store and calls Systems Manager to perform the artifact build. Next, the repo is cloned into a container. We then have automation systems in place that will create and push a build artifact into an <a href="https://aws.amazon.com/s3/">Amazon S3</a> bucket. Automated testing ensures the validity of the artifact.</p> 
<p>After the artifact is built, it’s copied to Amazon S3, and a Systems Manager Automation document is executed. Next, it calls an Amazon SNS topic, which in turn starts an AWS CodeDeploy task via <a href="https://aws.amazon.com/codepipeline/">AWS CodePipeline</a>. AWS CodeDeploy deploys the build artifact onto the underlying EC2 instance onto shared storage currently provided by Amazon EFS. &nbsp;After a successful deployment, the containers will automatically reload the underlying process based on a file change that happens post-deploy.</p> 
<p>The patching of the underlying EC2 instances is managed with Amazon CloudWatch Events, AWS Lambda, and Systems Manager. &nbsp;On a monthly basis a scheduled CloudWatch Event will trigger an event that calls a Lambda function. This Lambda function then executes a Systems Manager Automation document to to launch an AMI from a pre-baked image&nbsp;because there have been a number of custom changes made to the base AMI. &nbsp;The underlying EC2 instance is then patched with latest updates. After the updates are complete a notification is sent to Bulletproof and the customer via integrations with collaboration software (HipChat/Slack). &nbsp;Lastly, SSM will shut down the server, create the AMI, and update the AWS CloudFormation stack as appropriate.</p> 
<p>With the release of Systems Manager as a target for CloudWatch Events Bulletproof is in the process of migrating the automation across. The workflow for this automation will be a CloudWatch Event schedule that will trigger a <a href="https://aws.amazon.com/ec2/systems-manager/automation/">Systems Manager Automation </a>document with parameters. These parameters are statically set in the event rule. After each AMI baking process is complete the CloudWatch Events parameters are updated with the new base AMI via a Lambda function that is triggered via Amazon SNS after the Systems Manager Automation has been completed.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/18/2-1.png" /></p> 
<h3>Summary</h3> 
<p>The migration to Amazon ECS has provided Bulletproof Support and our customer with the ability to quickly and automatically or manually deploy updates to services. &nbsp;By leveraging AWS Services such as Systems Manager Automation, CodePipeline, and CloudFormation we have managed to achieve an increase of 40% efficiency over our previous static&nbsp;infrastructure. Bulletproof teams can now work from production-like systems on their local machines both online and offline. Since our teams are global this gives them a solution with minimal latency. The teams know that when they commit changes to production the system will behave in a manner that is identical to their local development environments. If an application terminates while it is running we know that Amazon ECS and Elastic Load Balancing health checks will take care of it and bring up a new one. The same applies to the underlying EC2 instances: if they hit capacity a new EC2 instance will be added to the cluster by Auto Scaling. This reduces operational overhead for our support and operations teams.&nbsp;Development teams are now able to run replicas of production systems within the development environment. This minimizes risk and accelerates change.</p> 
<h3>About the Author</h3> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/18/mbaker-150x150.jpg" /></p> 
<p><a href="https://www.linkedin.com/in/lidder/?ppe=1">Michael Baker</a> works as a DevOps Engineer for the Infrastructure Engineering team at <a href="https://www.bulletproof.net.au/">Bulletproof Group Limited</a>. Bulletproof is an AWS Premium Partner headquartered in Sydney, Australia.</p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/mt/tag/amazon-cloudwatch-events/" rel="tag">Amazon Cloudwatch Events</a>, <a href="https://aws.amazon.com/blogs/mt/tag/aws-codedeploy/" rel="tag">AWS CodeDeploy</a>, <a href="https://aws.amazon.com/blogs/mt/tag/aws-opsworks/" rel="tag">AWS OpsWorks</a>, <a href="https://aws.amazon.com/blogs/mt/tag/documents/" rel="tag">Documents</a>, <a href="https://aws.amazon.com/blogs/mt/tag/ec2-systems-manager/" rel="tag">EC2 Systems Manager</a>, <a href="https://aws.amazon.com/blogs/mt/tag/ec2-windows/" rel="tag">EC2 Windows</a>, <a href="https://aws.amazon.com/blogs/mt/tag/maintenance-window/" rel="tag">Maintenance Window</a>, <a href="https://aws.amazon.com/blogs/mt/tag/patch-complaince/" rel="tag">Patch Complaince</a>, <a href="https://aws.amazon.com/blogs/mt/tag/patch-manager/" rel="tag">Patch Manager</a>, <a href="https://aws.amazon.com/blogs/mt/tag/ssm/" rel="tag">SSM</a>, <a href="https://aws.amazon.com/blogs/mt/tag/state-manager/" rel="tag">State Manager</a></span> 
</footer> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">Reducing Configuration Drift with Amazon EC2 Systems Manager State Manager and Amazon CloudWatch Events</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Ananth Vaidyanathan</span></span> | on 
<time property="datePublished" datetime="2017-09-14T12:16:35+00:00">14 SEP 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/amazon-ec2-systems-manager/" title="View all posts in Amazon EC2 Systems Manager*"><span property="articleSection">Amazon EC2 Systems Manager*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools*"><span property="articleSection">Management Tools*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/reducing-configuration-drift-with-amazon-ec2-systems-manager-state-manager-and-amazon-cloudwatch-events/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><em>This post was written by Anupam Shrivastava, Software Development Engineer with Amazon Web Services.</em></p> 
<p>State Manager helps you automate the process of keeping your EC2 instances or virtual machines (VM) in your on-premises data center in a desired state. Some use cases for State Manager include:</p> 
<li>Ensuring that instances are joined to a Windows domain</li> 
<li>Ensuring that instances are patched with specific software throughout their lifecycle. For more information, see <a href="https://aws.amazon.com/blogs/mt/configure-amazon-ec2-instances-in-an-auto-scaling-group-using-state-manager/">Configure Amazon EC2 Instances in an Auto Scaling Group</a>.</li> 
<li>Executing Linux shell scripts or PowerShell scripts at scheduled times during the instances lifecycle. For more information, see <a href="https://aws.amazon.com/blogs/mt/combating-configuration-drift-using-amazon-ec2-systems-manager-and-windows-powershell-dsc/">Combating Configuration Drift Using Amazon EC2 Systems Manager and Windows PowerShell DSC</a>.</li> 
<li>Using other configuration management tools like Ansible. For more information, see <a href="https://aws.amazon.com/blogs/mt/running-ansible-playbooks-using-ec2-systems-manager-run-command-and-state-manager/">Running Ansible Playbooks using EC2 Systems Manager, Run Command and State Manager</a></li> 
<p>In State Manager, an association is a binding between your expressed configuration in a document, and a set of targets, on a specific schedule, to ensure consistent state. As part of the recent launch, we have made it easy for customers to easily remediate their instances when they drift from a desired configuration, provide you more control on when you can reapply configurations, and also make it easy for you to track changes to State Manager associations.</p> 
<p>In this post, I demonstrate some new State Manager features such as association names and versions, rate expressions, and <a href="http://docs.aws.amazon.com/AmazonCloudWatch/latest/events/WhatIsCloudWatchEvents.html">Amazon CloudWatch Events</a> integration. You start by specifying the configuration in a Systems Manager document.</p> 
<p><span id="more-1243"></span></p> 
<h3>Walkthrough</h3> 
<p>Here are the steps that you take to demonstrate these new features of State Manager:</p> 
<ol> 
<li>Create an association to install Windows updates on one of the EC2 instances, using the rate expression of every 1 day. Give the association a name as well.</li> 
<li>Configure CloudWatch Events for this association such that you receive status update notifications on an Amazon SNS topic, which can then be used to send email alerts.</li> 
<li>Update the association’s schedule to execute every 30 minutes, to be more aggressive with checking and installing Windows updates. Use the association name filter to quickly find the right association to update.</li> 
<li>View the different association versions after updating.</li> 
</ol> 
<h4>Step 1: &nbsp;Create an association</h4> 
<p>Open the EC2 console and choose <strong>Systems Manager, State Manager.</strong></p> 
<p>On the State Manager page, create an association with the following settings:</p> 
<li>For <strong>Association Name</strong>, type ‘CriticalWindowsUpdates’.</li> 
<li>For <strong>Select Document</strong>, select the AWS-InstallWindowsUpdates document.</li> 
<li>For <strong>Targets</strong>, select a Windows instance.</li> 
<li>For <strong>Schedule</strong>, choose <strong>Rate schedule builder</strong> and specify a rate expression of every 1 day.</li> 
<li>For <strong>Parameters</strong>, select the following: 
<li>Action: Install</li> 
<li>Allow Reboot: True</li> 
<li>Categories: CriticalUpdates</li> 
</ul> </li> 
<li>Choose <strong>Create Association</strong>.</li> 
<p>You can also perform the same operations with the AWS CLI, using the following command:</p> 
<pre><code class="lang-bash">aws ssm create-association --name AWS-InstallWindowsUpdates --targets &quot;Key=InstanceIds,Values=i-0ca45fddbf4ce950f&quot; --schedule-expression &quot;rate(1 day)&quot; --parameters Action=Install,Categories=CriticalUpdates,AllowReboot=True –-association-name CriticalWindowsUpdates</code></pre> 
<p>If you have not upgraded the SSM agent on your EC2 instance to the latest version, you might get a failed association error of ‘UnsupportedAgent’. In that case, upgrade the SSM agent to the latest version by executing a command using Run Command and the AWS-UpdateSSMAgent document. After you upgrade the agent, the association should start succeeding.</p> 
<h4>Step 2: Configure CloudWatch Events to send notifications for a failed association</h4> 
<p>Because you have created an association to ensure that an instance always has the latest critical Windows updates, you should also configure CloudWatch Events to notify you in case the association failed to check and apply the critical Windows updates.</p> 
<p>Create an Amazon SNS topic that is configured to send you email. In the example below, I have an SNS topic already created with the topic ‘WindowsCriticalUpdates’.</p> 
<p>Open the CloudWatch console and choose <strong>Events, Create rule</strong>. Use the following values:</p> 
<li><strong>Service Name</strong>: EC2 Simple Systems Manager (SSM)</li> 
<li><strong>Event Type</strong>: State Manager</li> 
<li><strong>Specific type</strong>: EC2 State Manager Association State Change</li> 
<li><strong>Specific status</strong>: Failed</li> 
<li><strong>Edit Event Pattern</strong>:&nbsp; Add the Association Name to track the status for a specific Association</li> 
<li>Choose <strong>Configure details</strong>.</li> 
<p>When you’re done, the event pattern should look like the following:</p> 
<pre><code class="lang-json">{
&quot;source&quot;: [&quot;aws.ssm&quot;],
&quot;detail-type&quot;: [&quot;EC2 State Manager Association State Change&quot;],
&quot;detail&quot;: {
&quot;status&quot;: [&quot;Failed&quot;],
&quot;association-name&quot;: [&quot;CriticalWindowsUpdates&quot;]
}
}</code></pre> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/14/cwe.png" /></p> 
<p>Bind the rule to the SNS topic ‘WindowsCriticalUpdates’, which is configured to send you emails for notification purposes.</p> 
<h4>&nbsp;Step 3: Update the association schedule</h4> 
<p>After a few days, you might realize that you want to have a more aggressive schedule of checking every 30 minutes for critical Windows updates. On the State Manager page, filter the associations by the word ‘Critical’. Select ‘CriticalWindowsUpdates’ and edit it.</p> 
<p>On the Edit association page, choose Rate schedule builder and specify a rate expression of every 30 minutes. For Parameters, again select the following:</p> 
<li>Action: Install</li> 
<li>Allow Reboot: True</li> 
<li>Categories: CriticalUpdates</li> 
<p>Choose Edit association. You can also perform the same operations with the AWS CLI, using the following command:</p> 
<pre><code class="lang-bash">aws ssm update-association --association-id 21da58e2-c9e1-4da5-a12a-d7d37eb981a2 --schedule-expression &quot;rate(30 minutes)&quot; --parameters Action=Install,Categories=CriticalUpdates,AllowReboot=True</code></pre> 
<p>After the association is edited, it is immediately scheduled for execution on the target instances.</p> 
<h4>Step 4: Track association changes using versioning</h4> 
<p>The Versions tab provides an audit trail of all the updates that were made to the association. The attributes that can be updated are:</p> 
<li>Association name</li> 
<li>Document name</li> 
<li>Document version</li> 
<li>Parameters</li> 
<li>Targets</li> 
<li>Schedule expression</li> 
<p>When you update any of the fields in an association, State Manager creates a new version. You can see all previous versions, along with the various field values. This enables you to track changes across various versions.</p> 
<p>In the earlier example, you can see two association versions corresponding to the two different rate schedule expressions.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/14/versioning.png" /></p> 
<p>You can also perform the same operations with the AWS CLI, using the following command:</p> 
<pre><code class="lang-bash">aws ssm list-association-versions --association-id 21da58e2-c9e1-4da5-a12a-d7d37eb981a2</code></pre> 
<h3>Conclusion</h3> 
<p>In this post, I showed you how to use several new features in State Manager that will ensure your instances are in a desired state and do not drift:</p> 
<li>Naming associations and filtering by names</li> 
<li>Granular scheduling by rate expressions</li> 
<li>Association status notifications through CloudWatch Events</li> 
<li>Tracking association changes through versions</li> 
<hr /> 
<h3>About the Author</h3> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/14/anupam.jpg">Anupam Shrivastava</a> is a software development engineer on the Amazon EC2 Systems Manager team. He enjoys being part of AWS and building easy-to-use scalable solutions for customers across the globe. Outside of work, he enjoys playing tennis and cricket, swimming, and traveling.</p> 
<p>&nbsp;</p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/mt/tag/aws-systems-manager/" rel="tag">AWS Systems Manager</a>, <a href="https://aws.amazon.com/blogs/mt/tag/configuration-management/" rel="tag">Configuration Management</a>, <a href="https://aws.amazon.com/blogs/mt/tag/ssm/" rel="tag">SSM</a>, <a href="https://aws.amazon.com/blogs/mt/tag/state-manager/" rel="tag">State Manager</a></span> 
</footer> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">Introducing the AWS Config Rule Development Kit (RDK)</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Henry Huang</span></span> | on 
<time property="datePublished" datetime="2017-09-12T13:59:42+00:00">12 SEP 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/aws-config/" title="View all posts in AWS Config*"><span property="articleSection">AWS Config*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools*"><span property="articleSection">Management Tools*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/introducing-the-aws-config-rule-development-kit-rdk/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p>Recently, <a href="https://aws.amazon.com/config">AWS Config</a> released a Rule Development Kit (RDK) that greatly simplifies your custom rule authoring experience. The RDK is an open-source tool that helps you set up AWS Config, author rules, and then test them using a variety of AWS resource types. This allows you to focus on the development of the rule itself. The AWS Config RDK is now available for download from the <a href="https://github.com/awslabs/aws-config-rdk">aws-config-rdk</a> GitHub repo. We follow semantic versioning, and are dedicated to maintaining backwards compatibility for each major version.</p> 
<h3>About AWS Config</h3> 
<p>AWS Config is a service that enables you to assess, audit, and evaluate the configurations of your AWS resources. AWS Config continuously monitors and records your AWS resource configurations and allows you to automate the evaluation of recorded configurations against desired configurations. Rules enable you to automatically check the configuration of AWS resources recorded by AWS Config. There are 37 managed AWS Config rules by default and 34 custom rules maintained by the community in the <a href="https://github.com/awslabs/aws-config-rules">aws-config-rules</a> GitHub repo.</p> 
<p><span id="more-1254"></span></p> 
<b>Getting started</b> 
<p>You can get started with AWS Config RDK and create a rule named “Hello World” in just a few minutes.</p> 
<li>Prerequisites</li> 
<li>Enable AWS Config</li> 
<li>Create your first rule</li> 
<li>Test your rule</li> 
<b>Prerequisites</b> 
<p>The AWS Config RDK requires the latest version of the <a href="https://aws.amazon.com/cli">AWS CLI</a>. You must also log in to an AWS account. Use the following command to install the AWS CLI (<a href="http://docs.aws.amazon.com/cli/latest/userguide/installing.html">requires pip to be installed already</a>):</p> 
<pre><code class="lang-bash">pip install --upgrade --user awscli</code></pre> 
<p>Use the following command to configure the AWS CLI. For more information, see <a style="font-family: Georgia, 'Times New Roman', 'Bitstream Charter', Times, serif" href="http://docs.aws.amazon.com/cli/latest/userguide/cli-chap-getting-started.html">Configuring the AWS CLI</a><span style="font-family: Georgia, 'Times New Roman', 'Bitstream Charter', Times, serif">.</span></p> 
<pre><code class="lang-bash">aws configure --profile myCLIprofile 
AWS Access Key ID [None]: AKIAI44QH8DHBEXAMPLE
AWS Secret Access Key [None]: je7MtGbClwBF/2Zp9Utk/h3yCo8nvbEXAMPLEKEY
Default region name [None]: us-east-1
Default output format [None]: text</code></pre> 
<p>Use the following command to clone the AWS Config RDK on macOS, Linux, or Windows platforms:</p> 
<pre><code class="lang-bash">git clone https://github.com/awslabs/aws-config-rdk.git</code></pre> 
<p>Choose your platform (MacLinux or Windows).<br /> <img src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/12/blog-post-01.png" /></p> 
<b>Enable AWS Config</b> 
<p>To begin, enable AWS Config in your AWS account for the region configured in the AWS CLI. For example, on macOS or Linux, use the following command to configure your profile:</p> 
<pre><code class="lang-bash">cd MacLinux/setup; ./setup myCLIprofile </code></pre> 
<p>You see the following results:<br /> <img src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/12/blog-post-02.png" /><br /> On Windows, use the following command to configure your profile:</p> 
<pre><code class="lang-bash">cd Windows/setup; ./setup.cmd myCLIprofile </code></pre> 
<p>You see the following results:<br /> <img src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/12/blog-post-03.png" /></p> 
<p>In this example, AWS Config in the us-east-1 region has been enabled by RDK setup.<br /> <img src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/12/blog-post-04.png" /></p> 
<b>Create your first rule</b> 
<p>Now you can create your first rule. Use the following command to create the EBS_OPTIMIZED_INSTANCE managed rule, which checks whether Amazon EBS optimization is enabled for your EC2 instances that can be EBS-optimized. Create the rule under the folder /aws-config-rdk/MacLinux/rules on macOS or Linux:</p> 
<pre><code class="lang-bash">cd MacLinux/rules; ./createRule myCLIprofile hello_world AWS::EC2::Instance </code></pre> 
<p>You see the following results:<br /> <img src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/12/blog-post-05.png" /></p> 
<p>On Windows, use the following command:</p> 
<pre><code class="lang-bash">cd Windows/rules; ./createRule.cmd myCLIprofile hello_world AWS::EC2::Instance </code></pre> 
<p>You see the following results:</p> 
<p><img src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/12/blog-post-06.png" /></p> 
<p>The following resources were created:</p> 
<li>The parameter “APPLICABLE_RESOURCE_TYPES” has the same value as “APPLICABLE_RESOURCES” already defined in the rule code</li> 
<li>The AWS Lambda function named “hello_world”</li> 
<li>An AWS Config rule named “hello_world”, which was also associated with the Lambda function</li> 
<p>The rule has started to evaluate EC2 instances for compliance with EBS optimization.<br /> <img src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/12/blog-post-07.png" /><br /> Now you can replace the default values with your own code. Make sure that resource types are consistent between the rule_code.py and createRule.cmd script parameters. Otherwise, your rule returns NOT_APPLICABLE. The rules/ruleCode/rule_util.py script handles the boring parts of a rule, and should not need to be modified.</p> 
<b>Test your rule</b> 
<p>The AWS Config RDK supports testing your rule by invoking the Lambda function with configuration items (used as test cases) from the /rules/testUtil/compliantCIs and /rules/testUtil/noncompliantCIs directories. The RDK checks that the Lambda function returns the corresponding result.</p> 
<p>On macOS or Linux, use the following command:</p> 
<pre><code class="lang-bash">cd MacLinux/rules; ./test myCLIprofile hello_world </code></pre> 
<p>You see the following results:</p> 
<p><img src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/12/blog-post-08.png" /></p> 
<p>On Windows, use the following command:</p> 
<pre><code class="lang-bash">cd Windows/rules; ./test.cmd myCLIprofile hello_world </code></pre> 
<p>You see the following results:</p> 
<p><img src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/12/blog-post-09.png" /></p> 
<p>Besides, we have provided Configuration Item examples in “rules/testUtil/exampleCIs” to help you to write test cases by the modification to make them represent compliant or non-compliant resources.<br /> <img src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/12/blog-post-10.png" /></p> 
<b>Summary</b> 
<p>The AWS Config RDK helps you build rules easily, including the following:</p> 
<li>Preparing the initial rule development environment, by enabling AWS Config with a variety of automatically created AWS resources.</li> 
<li>Creating Lambda functions, rules, and the association between them so that you don’t have to.</li> 
<li>Supporting multiple platforms: &nbsp;macOS, Linux, and Windows.</li> 
<li>Testing rules just by the code, with no more manual setup in complicated test environments.</li> 
<p>We would love to hear your feedback. Feel free to leave comments or suggestions on the&nbsp;<a href="https://github.com/awslabs/aws-config-rdk">aws-config-rdk</a> GitHub page.</p> 
<h3>About the Author</h3> 
<p><img class="alignleft" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/12/blog-post-11.png" /><br /> Henry Huang is a DevOps Consultant for the Professional Services Team&nbsp;at Amazon Web Services in China.</p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/mt/tag/aws-config/" rel="tag">AWS Config</a>, <a href="https://aws.amazon.com/blogs/mt/tag/config-rule/" rel="tag">Config Rule</a>, <a href="https://aws.amazon.com/blogs/mt/tag/rdk/" rel="tag">RDK</a>, <a href="https://aws.amazon.com/blogs/mt/tag/rule-development-kit/" rel="tag">Rule Development Kit</a></span> 
</footer> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<meta property="image" content="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/08/23/prof-473x630.jpg" /> 
<b class="lb-b blog-post-title" property="name headline">Smart Budgeting Using Lambda and Service Catalog</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Tapodipta Ghosh</span></span> | on 
<time property="datePublished" datetime="2017-09-07T11:42:37+00:00">07 SEP 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/mt/category/messaging/amazon-simple-notification-service-sns/" title="View all posts in Amazon Simple Notification Service (SNS)*"><span property="articleSection">Amazon Simple Notification Service (SNS)*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/aws-cost-management/aws-budgets/" title="View all posts in AWS Budgets*"><span property="articleSection">AWS Budgets*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/aws-cost-management/" title="View all posts in AWS Cost Management*"><span property="articleSection">AWS Cost Management*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/compute/aws-lambda/" title="View all posts in AWS Lambda*"><span property="articleSection">AWS Lambda*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/aws-service-catalog/" title="View all posts in AWS Service Catalog*"><span property="articleSection">AWS Service Catalog*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/smart-budgeting-using-lambda-and-service-catalog/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p>If you have a lot of development activity in your organization, it’s important to keep track of your non-production AWS accounts.</p> 
<p>If these accounts aren’t monitored closely, you might easily end up exceeding your budget.</p> 
<p>In this blog post, I demonstrate how you can use the <a href="https://aws.amazon.com/about-aws/whats-new/2015/06/aws-introduces-budgets-a-simple-way-to-manage-your-aws-costs/">AWS Budgets</a> alert in conjunction with<a href="https://aws.amazon.com/lambda/"> AWS Lambda</a> and <a href="https://aws.amazon.com/servicecatalog/">AWS Service Catalog</a> to automate management of your IT budget for non-production environments.<span id="more-1163"></span></p> 
<h3>Workflow</h3> 
<p>For this example, I have created a billing alarm to notify me when the cost for a sandbox account overshoots the forecast by 30 percent. The billing alarm is tied to an Amazon SNS Topic which is subscribed by a Lambda function. This ensures that when the billing alert occurs, the IT administrator gets notified via SNS about the possibility of an overage. At the same time, the Lambda function calls the AWS Service Catalog API to enforce the template constraint to freeze all EC2 instance creation to only the t2.medium type.</p> 
<p>&nbsp;</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/08/23/Screen-Shot-2017-08-07-at-2.00.50-PM-1024x508.png" /></p> 
<h3>Create the SNS topic and subscription</h3> 
<p>In the SNS console, choose&nbsp;Create topic&nbsp;and enter appropriate values for the &nbsp;Topic name&nbsp;(such as BudgetAlert) and&nbsp;Display name&nbsp;(Budget-Alert).</p> 
<p>Choose&nbsp;Create topic. Select the topic and view the details.</p> 
<p>Next, choose&nbsp;Create subscription.</p> 
<p>For&nbsp;Protocol, choose&nbsp;Email. Enter the email address where notifications should be sent and choose&nbsp;Create subscription.</p> 
<p>An email is sent to confirm the SNS topic subscription. In the email, open the&nbsp;SubscribeURL&nbsp;link to complete the subscription. Note the SNS topic Amazon Resource Name (ARN) because it’s used later by the Lambda function.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/07/sns.png" /></p> 
<p>For more information, see&nbsp;<a href="http://docs.aws.amazon.com/sns/latest/dg/CreateTopic.html">Create a Topic</a>&nbsp;in the Amazon SNS Developer Guide.</p> 
<h3>Create the Lambda function</h3> 
<p>In the Lambda console, choose&nbsp;Functions,&nbsp;Create a Lambda function. Choose Blank Function and on the&nbsp;Configure trigger page, choose&nbsp;Next.</p> 
<p>On the next page, enter the following values:</p> 
<p>&middot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Runtime:&nbsp;Python 2.7</p> 
<p>&middot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Code entry type:&nbsp;Inline</p> 
<p>&middot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Role:&nbsp;Create a custom role (takes you to another page). Call the role service-catalog-lambda-&lt;region&gt;-role</p> 
<p>For the policy document, enter the following policy:</p> 
<pre><code class="lang-json">{
&nbsp;&nbsp;&nbsp; &quot;Version&quot;: &quot;2012-10-17&quot;,
&nbsp;&nbsp;&nbsp; &quot;Statement&quot;: [
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; {
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;Action&quot;: [
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;servicecatalog:*&quot;,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;s3:*&quot;,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;cloudformation:ValidateTemplate&quot;,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;iam:GetRole&quot;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ],
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;Resource&quot;: [
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;*&quot;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ],
&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;Effect&quot;: &quot;Allow&quot;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; },
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; {
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;Action&quot;: [
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;logs:CreateLogGroup&quot;,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;logs:CreateLogStream&quot;,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;logs:PutLogEvents&quot;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ],
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;Resource&quot;: &quot;arn:aws:logs:*:*:*&quot;,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&quot;Effect&quot;: &quot;Allow&quot;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }
&nbsp;&nbsp;&nbsp; ]
}</code></pre> 
<p>On the&nbsp;Configure function&nbsp;page, choose&nbsp;Next. Review the configuration settings before choosing&nbsp;Create function.</p> 
<p>You can also follow the instructions here:</p> 
<p><a href="https://github.com/awslabs/aws-service-catalog-enforce-template-constraints/">https://github.com/awslabs/aws-service-catalog-enforce-template-constraints/</a></p> 
<h3>Budget alert</h3> 
<p>Create the AWS Budgets alert and add the IT administrator’s email to notify the administrator when the forecasted budget is greater than the percentage that you choose (in our example, it’s 30 %). Add the SNS Topic ARN and Verify. You should see “Verified” next to the topic ARN.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/08/23/BudgetAlert.png" /></p> 
<p>For more information on how to create AWS budgets, you can refer the AWS Budgets Update blog post.</p> 
<p>After the alert condition is met, the IT administrator will receive an email from AWS Budgets similar to the sample that follows:</p> 
<pre><code class="lang-json">{&nbsp;&quot;Subject&quot; : &quot;Budget&nbsp;Notification: Test is in Alarm State&quot;,
&nbsp; &quot;Message&quot; : &quot;AWS&nbsp;Budget&nbsp;Notification\n\nDear AWS Customer,\n\nYou requested that we notify you when your Actual Cost for your&nbsp;budget&nbsp;\&quot;BudgetAlert\&quot; is greater than $50000. Your Actual Cost for this&nbsp;budget&nbsp;is now $50393. You can find further details below and by accessing your AWS&nbsp;Budgets&nbsp;dashboard.\n\nBudget
}</code></pre> 
<p>The Lambda function also gets triggered. It looks for all portfolios in the Service Catalog, looks for InstanceType template constraints, and it changes the constraint to “t2.medium or small only.” The following example shows how the updated constraint looks after the Lambda function has successfully run.<br /> <img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/08/23/post_lambda_run.png" /></p> 
<h3>Summary</h3> 
<p>In this post, I’ve demonstrated an easy way to keep track of your non-prod accounts budget, while you are also focused on continuous development.</p> 
<hr /> 
<h3>About the Author</h3> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/07/tapo.jpg" /></p> 
<p>Tapodipta Ghosh is a Solutions Architect focusing on AWS Marketplace.&nbsp;&nbsp;Tapo&nbsp;is passionate about cloud computing and loves helping customers on-board their products into AWS Marketplace.</p> 
<p>&nbsp;</p> 
<p>&nbsp;</p> 
<p>&nbsp;</p> 
<p>&nbsp;</p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/mt/tag/aws-budgets/" rel="tag">AWS Budgets</a>, <a href="https://aws.amazon.com/blogs/mt/tag/aws-lambda/" rel="tag">AWS Lambda</a>, <a href="https://aws.amazon.com/blogs/mt/tag/aws-service-catalog/" rel="tag">AWS Service Catalog</a>, <a href="https://aws.amazon.com/blogs/mt/tag/aws-sns/" rel="tag">AWS SNS</a></span> 
</footer> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">The Right Way to Store Secrets using Parameter Store</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Ananth Vaidyanathan</span></span> | on 
<time property="datePublished" datetime="2017-08-27T23:00:38+00:00">27 AUG 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/amazon-ec2-systems-manager/" title="View all posts in Amazon EC2 Systems Manager*"><span property="articleSection">Amazon EC2 Systems Manager*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools*"><span property="articleSection">Management Tools*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/the-right-way-to-store-secrets-using-parameter-store/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><em>This guest post was written by Evan Johnson, who works in the Security team at Segment.</em></p> 
<p>The way companies manage application secrets is critical. Even today, the most high profile security companies can suffer breaches from improper secrets management practices. Having internet facing credentials is like leaving your house key under a doormat that millions of people walk over daily. Even if the secrets are hard to find, it is a game of hide and seek that you eventually lose.</p> 
<p>At <a href="https://segment.com/">Segment</a>, we centrally and securely manage our secrets with <a href="https://aws.amazon.com/ec2/systems-manager/parameter-store/">Amazon EC2 Systems Manager Parameter Store</a>, lots of Terraform code, and <a href="https://github.com/segmentio/chamber">chamber</a>. Parameter store is a great tool for achieving secrets management. If you are running workloads on AWS, then using Parameter Store as a managed secrets store is worth serious consideration. This post has all the information you need to get running with Parameter Store in production.</p> 
<p><span id="more-1184"></span></p> 
<h3>Service Identity</h3> 
<p>At Segment, we run hundreds of services that communicate with one another, AWS APIs, and third-party APIs. The services we run have different needs and should only have access to systems that are strictly necessary. This is called the ‘principle of least privilege’.</p> 
<p>As an example, our main webserver should never have access to security audit logs for our infrastructure. Without giving containers and services an identity, it is not possible to protect and restrict access to secrets with access control policies. Our services identify themselves using IAM roles. From the AWS docs – “<em>An IAM role … is an AWS identity with permission policies that determine what the identity can and cannot do in AWS</em>.”</p> 
<p>For example, our IAM roles for instances have write-only access to an Amazon S3 bucket for appending audit logs, but prevent the deletion and reading of those logs.</p> 
<h4>How do containers get their role securely?</h4> 
<p>A requirement to using <a href="https://aws.amazon.com/ecs/">Amazon ECS</a> is that all containers must run the <a href="https://github.com/aws/amazon-ecs-agent">Amazon ECS container agent</a> (ecs-agent). The agent runs as a container that orchestrates and provides an API with which other containers can communicate. The agent is the central nervous system of how containers fetch IAM role credentials.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/08/25/Diagram1a.png" /></p> 
<p>One important piece to the agent is that it runs an HTTP API that MUST be accessible to the other containers that are running in the cluster. To make this API available, an iptables rule is set on the host instance. This iptables rule forwards traffic destined for a magic IP address to the ecs-agent container.</p> 
<pre><code class="lang-bash">iptables -t nat \
-A OUTPUT \
-d 169.254.170.2 \
-p tcp \
-m tcp \
--dport 80 \
-j REDIRECT \
--to-ports 51679</code></pre> 
<p>Before the agent starts a container, it first fetches credentials for the container’s task role from the AWS credential service. The agent next sets the credentials key ID, a UUID, as the AWS_CONTAINER_CREDENTIALS_RELATIVE_URI environment variable inside the container when it is started.</p> 
<pre><code class="lang-bash">$ env
...
AWS_CONTAINER_CREDENTIALS_RELATIVE_URI=/v2/credentials/53875b56-621a-4b07-8ab6-02ea315b5693
...</code></pre> 
<p>Using this relative URI and UUID, containers fetch AWS credentials from the agent over HTTP. One container cannot access the authentication credentials to impersonate another container because the UUID is sufficiently difficult to guess.</p> 
<pre><code class="lang-bash">$ curl 169.254.170.2$AWS_CONTAINER_CREDENTIALS_RELATIVE_URI | jq .
{
&quot;RoleArn&quot;: &quot;arn:aws:iam::111111111111:role/test-service&quot;,
&quot;AccessKeyId&quot;: &quot;ASIAIYLSOW5USUQCZAAQ&quot;,
&quot;SecretAccessKey&quot;: &quot;REDACTRED&quot;,
&quot;Token&quot;: &quot;REDACTED&quot;,
&quot;Expiration&quot;: &quot;2017-08-10T02:01:43Z&quot;
}</code></pre> 
<h4>Additional security details</h4> 
<p>As heavy Amazon ECS users, we did find security foot-guns associated with ECS task roles. It’s important to realize that any container that can access the Amazon EC2 metadata service on behalf of its host can become any other task role on the system. This could allow containers to circumvent access control policies and gain access to unauthorized systems.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/08/25/Diagram2.png" /></p> 
<p>The two ways a container can access the metadata service is using host networking and over the docker bridge. When a container is run with <span style="text-decoration: underline">–network=’host’</span>, it is always able to connect to the EC2 metadata service using its host’s network. Setting the <span style="text-decoration: underline">ECS_ENABLE_TASK_IAM_ROLE_NETWORK_HOST</span> variable to false in the ecs-agent config file prevents containers from running with this permission.</p> 
<p>Additionally, it’s important to block access to the metadata service IP address over the Docker bridge using iptables. The <a href="http://docs.aws.amazon.com/AmazonECS/latest/developerguide/task-iam-roles.html">IAM task role documentation</a> recommends preventing access to the EC2 metadata service with this specific rule.</p> 
<pre><code class="lang-bash">$ iptables --insert FORWARD 1 --in-interface docker+ --destination 169.254.169.254/32 --jump DROP</code></pre> 
<p>The principle of least privilege is always important to keep in mind when building a security system. Setting <span style="text-decoration: underline">ECS_DISABLE_PRIVILEGED</span> to true in the host’s ecs-agent config file can prevent privileged Docker containers from being run and causing other more nuanced security problems.</p> 
<h3>Parameter Store</h3> 
<p>Parameter Store is an AWS service that stores strings. It can store secret data and non-secret data alike. Secrets stored in Parameter Store are secure strings, encrypted with a customer-specific AWS KMS key.</p> 
<p>Under the hood, a service that requests secure strings from the Parameter Store has a lot of things happening behind the scenes.</p> 
<ol> 
<li>The ECS container agent requests the host instance’s temporary credentials.</li> 
<li>The agent continuously generates temporary credentials for each ECS task role running on ECS, using an undocumented service called ACS.</li> 
<li>When the agent starts each task, it sets a secret UUID in the environment of the container.</li> 
<li>When the task needs its task role credentials, it requests them from the ecs-agent API and authenticates with the secret UUID.</li> 
<li>The ECS task requests its secrets from Parameter Store using the task role credentials.</li> 
<li>Parameter Store transparently decrypts these secure strings before returning them to the ECS task.</li> 
</ol> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/08/25/diagram3-1.png" /></p> 
<p>Using roles with Parameter Store is especially nice because it does not require maintaining additional authentication tokens. This would create additional headache and additional secrets to manage!</p> 
<h4>Parameter Store IAM Policies</h4> 
<p>Each role that accesses the Parameter Store requires the <span style="text-decoration: underline">ssm:GetParameters</span> permission. “SSM” stands for “Simple System Manager”, the previous name for Systems Manager, and is how <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/sysman-paramstore-access.html">AWS denotes Parameter Store operations</a>.</p> 
<p>The ssm:GetParameters permission is the policy used to enforce access control and protect one service’s secrets from another. Segment gives all services an IAM role that grants access to secrets that match the format&nbsp; {{service_name}}/*.&nbsp; Parameter Store <a href="https://aws.amazon.com/blogs/mt/organize-parameters-by-hierarchy-tags-or-amazon-cloudwatch-events-with-amazon-ec2-systems-manager-parameter-store/">supports hierarchies natively</a>, so this permission provides each service with its own directory of secrets.</p> 
<pre><code class="lang-json">{
&quot;Sid&quot;: &quot;&quot;,
&quot;Effect&quot;: &quot;Allow&quot;,
&quot;Action&quot;: &quot;ssm:GetParameters&quot;,
&quot;Resource&quot;: [
&quot;arn:aws:ssm:*:*:parameter/{{service_name}}/*&quot;,
]
},</code></pre> 
<p>In addition to the access control policies, Segment uses a dedicated AWS KMS key to encrypt secure strings within the Parameter Store. Each IAM role is granted a small set of KMS permissions in order to decrypt the secrets they store in Parameter Store.</p> 
<pre><code class="lang-json">{
&quot;Sid&quot;: &quot;&quot;,
&quot;Effect&quot;: &quot;Allow&quot;,
&quot;Action&quot;: [
&quot;kms:ListKeys&quot;,
&quot;kms:ListAliases&quot;,
&quot;kms:Describe*&quot;,
&quot;kms:Decrypt&quot;
],
&quot;Resource&quot;: &quot;parameter_store_key&quot;
}</code></pre> 
<h3>Automating service identity and policies</h3> 
<p class="hide-language">Segment has a small Terraform module that abstracts away the creation of a unique IAM role, load balancers, DNS records, Auto Scaling, and CloudWatch alarms. Below, I show how our nginx load balancer is defined using our service module.</p> 
<pre><code class="lang-yaml">module &quot;nginx&quot; {
source            = &quot;../modules/service&quot;
name              = &quot;nginx&quot;
image             = &quot;segment/nginx&quot;
product_area      = &quot;foudation-security&quot;
health_check_path = &quot;/healthcheck&quot;
environment       = &quot;${var.environment}&quot;
}</code></pre> 
<p>Under the hood, the task role given to each service has all of the IAM policies we previously listed, restricting access to Parameter Store by the value in the name field. No configuration required.</p> 
<p>Additionally, developers have the option to override which secrets their service has access to by providing a “secret label”. This secret label replaces their service name in their IAM policy. If NGINX were to need the same secrets as an HAProxy instance, the two services can share credentials by using the same secret label.</p> 
<pre><code class="lang-yaml"></code><code class="lang-yaml">module &quot;nginx&quot; {
source            = &quot;../modules/service&quot;
name              = &quot;nginx&quot;
image             = &quot;segment/nginx&quot;
product_area      = &quot;foudation-security&quot;
health_check_path = &quot;/healthcheck&quot;
environment       = &quot;${var.environment}&quot;
# Share secrets with loadbalancers
<strong>secret_label = &quot;loadbalancers&quot;</strong>
}</code></pre> 
<h3>Parameter Store in production</h3> 
<p>All Segment employees authenticate with AWS using aws-vault, which can securely store AWS credentials in the macOS keychain or in an encrypted file for Linux users. Segment has several AWS accounts. Engineers can interact with each account using aws-vault, and execute commands locally with their AWS credentials populated in their environment.<code class="lang-json"><br /> </code></p> 
<pre><code class="lang-bash">$ aws-vault exec development -- aws s3 ls s3://segmentio-bucket</code></pre> 
<h4>Using Chamber with Parameter Store</h4> 
<p>Chamber is a CLI tool that Segment built to allow developers and code to communicate with Parameter Store in a consistent manner. By allowing developers to use the same tools that run in production, we decrease the number of differences between code running in development with staging and production.</p> 
<p>Chamber works with aws-vault, and has only a few key subcommands:</p> 
<li>exec—a command after loading secrets in to the environment.</li> 
<li>history—of changes made to a secret in parameter store.</li> 
<li>list—the names of all secrets in a services path.</li> 
<li>write—a secret to the Parameter Store.</li> 
<p>Chamber leverages Parameter Store’s built in search and history mechanisms to implement the list and history subcommands. All strings stored in Parameter Store are automatically versioned. The subcommand used to fetch secrets from the Parameter Store is exec. When developers use the exec subcommand, they use it with aws-vault.</p> 
<p><code class="lang-bash">$ aws-vault exec development -- chamber exec loadbalancers -- nginx</code></p> 
<p>In the preceding command, chamber is executed with the credentials and permissions of the employee in the development account, and it fetches the secrets associated with loadbalancers from Parameter Store. After chamber populates the environment, it runs the NGINX server.</p> 
<h4 class="hide-language">Running chamber in production</h4> 
<p>Chamber is packaged inside our Docker containers as a binary and is the entry point of the container. Chamber passes signals to the program it executes in order to allow the program to gracefully handle them.</p> 
<p>Here’s a diff of what it required to make our main website chamber ready.</p> 
<pre><code class="lang-bash">-ENTRYPOINT [&quot;node&quot;, &quot;server/boot.js&quot;] 
+ENTRYPOINT [&quot;chamber&quot;, &quot;exec&quot;, &quot;app&quot;, &quot;--&quot;, &quot;node&quot;, &quot;server/boot.js&quot;]</code></pre> 
<p>Non-Docker containers can also use chamber to populate the environment before creating configuration files out of templates, run daemons, etc.</p> 
<h3>Auditing</h3> 
<p>All access to Parameter Store is logged with AWS CloudTrail. This makes keeping a full audit trail for all parameters simple and inexpensive. It also makes building custom alerting and audit logging straightforward.</p> 
<pre><code class="lang-json">...
&quot;eventTime&quot;: &quot;2017-08-02T18:54:06Z&quot;,
&quot;eventSource&quot;: &quot;ssm.amazonaws.com&quot;,
&quot;eventName&quot;: &quot;GetParameters&quot;,
&quot;awsRegion&quot;: &quot;us-west-2&quot;,
&quot;sourceIPAddress&quot;: &quot;127.0.0.1&quot;,
&quot;userAgent&quot;: &quot;aws-sdk-go/1.8.1 (go1.8.3; linux; amd64)&quot;,
&quot;requestParameters&quot;: {
&quot;withDecryption&quot;: true,
&quot;names&quot;: [
&quot;test-service.secretname&quot;
]
},
&quot;responseElements&quot;: null,
&quot;requestID&quot;: &quot;88888888-4444-4444-4444-121212121212&quot;,
&quot;eventID&quot;: &quot;88888888-4444-4444-4444-121212121212&quot;,
&quot;readOnly&quot;: true,
...</code></pre> 
<p>CloudTrail makes it possible to determine exactly what secrets are used and can make discovering unused secrets or unauthorized access to secrets possible.</p> 
<p>AWS logs all Parameter Store access for free as a CloudTrail management event. Most security information and events management (SIEM) solutions can be configured to watch, and read data from S3.</p> 
<h3>Summary</h3> 
<p>Using Parameter Store and IAM, Segment was able to build a small tool that provides all of the properties most important in a secrets management system.</p> 
<li>Protect the secrets at rest with strong encryption.</li> 
<li>Enforce strong access control policies.</li> 
<li>Create audit logs of authentication and access history.</li> 
<li>Great developer experience.</li> 
<p>Secrets management is very challenging to get right. Many products have been built to manage secrets, but none fit the use cases needed by Segment better than Parameter Store.</p> 
<h3>About the Author</h3> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/08/25/evan.png">Segment</a>. Segment is the infrastructure for customer data. Businesses use Segment’s API to unlock 200+ tools for every team across their organization. With Segment, developers can stop building tedious and expensive one-off data integrations, turning on their favorite apps right from the Segment dashboard.</p> 
<p><a href="https://segment.com/"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/08/25/segment.png" /></a></p> 
<p>&nbsp;</p> 
<p>&nbsp;</p> 
<hr /> 
<p><em>AWS is not responsible for the content or accuracy of this post. The content and opinions in this blog are solely those of the third party author.</em></p> 
<p><code class="lang-bash"></code><code class="lang-bash"></code></p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/mt/tag/configuration-secrets/" rel="tag">Configuration Secrets</a>, <a href="https://aws.amazon.com/blogs/mt/tag/ec2-systems-manager/" rel="tag">EC2 Systems Manager</a>, <a href="https://aws.amazon.com/blogs/mt/tag/parameter-store/" rel="tag">Parameter Store</a>, <a href="https://aws.amazon.com/blogs/mt/tag/ssm/" rel="tag">SSM</a></span> 
</footer> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">Multi-Account Strategy: Using AWS CloudFormation Custom Resources to Create Amazon Route 53 Resources in Another Account</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Brian Beach</span></span> | on 
<time property="datePublished" datetime="2017-08-24T16:06:05+00:00">24 AUG 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/aws-cloudformation/" title="View all posts in AWS CloudFormation*"><span property="articleSection">AWS CloudFormation*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools*"><span property="articleSection">Management Tools*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/multi-account-strategy-using-aws-cloudformation-custom-resources-to-create-amazon-route-53-resources-in-another-account/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p>Today, most customers have more than one AWS account. While a multi-account strategy brings many benefits―simplified billing, security isolation, decentralized control, etc., it also introduces new challenges. One challenge is that the users in one account occasionally need to create resources in another.</p> 
<p>In this post, I will show you how to use a <a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/template-custom-resources.html">custom resource</a> from <a href="https://aws.amazon.com/cloudformation">AWS CloudFormation</a> to create <a href="https://aws.amazon.com/route53">Amazon Route 53</a> resource records in another account.</p> 
<p><span id="more-976"></span></p> 
<b>Multi-account scenario</b> 
<p>A common driver for adopting a multi-account strategy is to give autonomy and agility to individual business units.</p> 
<p>Imagine that you work for a company that has adopted this strategy. There is a centralized IT team that manages consolidated billing and shared resources such as AWS Direct Connect connections. In addition, they manage the Domain Name System (DNS) for the company. They have chosen to host DNS in Amazon Route 53. Various business units have their own accounts and operate with relatively little oversight.</p> 
<p>The marketing team regularly creates short-lived websites for various marketing campaigns. They use CloudFormation to launch and manage these sites, but CloudFormation cannot create resources in other accounts. Therefore, the marketing team has to submit a request to central IT to update DNS. This often takes hours or even days to complete. They want a simple way to create a CNAME record in the central account from a CloudFormation template in their own account.</p> 
<b>CloudFormation custom resources</b> 
<p>One way to create resources in another account is to use a CloudFormation custom resource, which allows you to execute custom code from a CloudFormation template. CloudFormation supports two types of custom resources:</p> 
<li>The first invokes an <a href="https://aws.amazon.com/lambda">AWS Lambda</a> function, allowing you to execute custom code.</li> 
<li>The second sends a message to an <a href="https://aws.amazon.com/sns">Amazon SNS</a> topic to which you have subscribed.</li> 
<p>Here’s an example. The Figure below outlines a solution to the problem scenario described earlier. Marketing is launching a CloudFormation stack and wants to create a CNAME in Amazon Route 53 hosted in another account.</p> 
<p>The high-level workflow goes like this:</p> 
<ol> 
<li>CloudFormation sends a message to an SNS topic in the central account.</li> 
<li>A Lambda function is invoked in response to the message.</li> 
<li>Lambda creates the Amazon Route 53 CNAME record.</li> 
<li>Lambda calls an Amazon S3 presigned URL, indicating that it completed successfully.</li> 
<li>CloudFormation marks the custom resource complete.</li> 
</ol> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/07/27/cfn-r53-cross-account.png" /><br /> <i>You might be asking yourself why I used SNS when CloudFormation custom resources can invoke Lambda directly. I could have invoked Lambda directly, but SNS simplifies cross account permissions and makes the configuration easier.</i></p> 
<b>Configuring the custom resource</b> 
<p>Begin by configuring the services in the central account. I will assume that Amazon Route 53 is already configured, so you need to configure SNS and Lambda.</p> 
<p>I have included a <a href="https://s3-us-west-2.amazonaws.com/management-tools-blog-cf-template-storage/ConfigCentralAccount.yaml">CloudFormation template to configure these services in the central account</a> for you. The template requires two inputs:</p> 
<li>The ID of the Amazon Route 53 <a href="http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/CreatingHostedZone.html">hosted zone</a> in which to allow the business units to create records.</li> 
<li>A list of the account IDs that are authorized to create resource records in Amazon Route 53.</li> 
<p>This restricts access so that only the accounts that you specify can create resource records in the hosted zone that you specify. Obviously, you don’t want to allow everyone to create―or worse, change―records anywhere in your DNS system.</p> 
<p>After the CloudFormation template completes, it outputs the ARN of the SNS topic used to request new resources. Make note of this, as you use it to configure the custom resource later in this post.</p> 
<p>In the Lambda console, you see a new function called CreateRoute53CNAME. This is the logic for the custom resource. The primary method, lambda_handler, is shown in the code below.</p> 
<p><strong>Example: Lambda function snippet</strong></p> 
<pre><code class="lang-python">def lambda_handler(event, context):
#SNS events contain a wrapper around the Lambda event. Unpack the
#Lambda event from SNS. Not needed if you’re calling Lambda directly.
print(&quot;SNS Event: &quot; + json.dumps(event))
event = json.loads(event['Records'][0]['Sns']['Message'])            
print(&quot;Lambda Event: &quot; + json.dumps(event))
try: 
hostedzone = 'ZXAOMNFL85JIZ'
type = event['RequestType']
source = event['ResourceProperties']['Source']
target = event['ResourceProperties']['Target']
if type == 'Create':
print &quot;Creating CNAME &quot; + source + &quot;-&gt;&quot; + target + &quot; in &quot; + hostedzone
change_resource_record_sets('UPSERT', hostedzone, source, target)
elif type == 'Update':
oldsource = event['OldResourceProperties']['Source']
oldtarget = event['OldResourceProperties']['Target']
print &quot;Deleting old CNAME &quot; + oldsource + &quot;-&gt;&quot; + oldtarget + &quot; in &quot; + hostedzone
change_resource_record_sets('DELETE', hostedzone, oldsource, oldtarget)
print &quot;Creating new CNAME &quot; + source + &quot;-&gt;&quot; + target + &quot; in &quot; + hostedzone
change_resource_record_sets('UPSERT', hostedzone, source, target)
elif type == 'Delete':
print &quot;Deleting CNAME &quot; + source + &quot;-&gt;&quot; + target + &quot; in &quot; + hostedzone
change_resource_record_sets('DELETE', hostedzone, source, target)
else:
print &quot;Unexpected Request Type&quot;
raise Exception(&quot;Unexpected Request Type&quot;)
print &quot;Completed successfully&quot;
responseStatus = 'SUCCESS'
responseData = {}
sendResponse(event, context, responseStatus, responseData)
except: 
print(&quot;Error:&quot;, sys.exc_info()[0])
responseStatus = 'FAILED'
responseData = {}
sendResponse(event, context, responseStatus, responseData)
</code></pre> 
<p>As you can see, the first thing the Lambda function does is unpack the SNS event to get the properties that were passed from CloudFormation. In this example, you pass in a source (for example, www.example.com) and a target (for example, my-loadbalancer-1234567890.us-east-1.elb.amazonaws.com) for a CNAME record.</p> 
<p>In addition, the event always includes a RequestType value of Create, Update, or Delete. The code below is an example of an Update event. In the case of an Update, you get an additional set of OldResourceProperties values that are not included in Create and Delete events.</p> 
<p><strong>Example: Sample update event in SNS</strong></p> 
<pre><code class="lang-json">{ &quot;Records&quot;: [ 
{ &quot;EventVersion&quot;: &quot;1.0&quot;, 
&quot;EventSubscriptionArn&quot;: &quot;arn:aws:sns:us-east-1:…:RequestRoute53CNAME:…&quot;, 
&quot;EventSource&quot;: &quot;aws:sns&quot;, 
&quot;Sns&quot;: { 
&quot;MessageId&quot;: &quot;6ae3f7a1-2772-568c-9175-a603bc40bf03&quot;, 
&quot;Message&quot;: {
&quot;RequestType&quot;:“Update&quot;,
&quot;ResponseURL&quot;:&quot; https://cloudformation-custom-resource-response-useast1...&quot;,
&quot;ResourceType&quot;:&quot;Custom::CNAME&quot;,
&quot;OldResourceProperties&quot;:{
“Target&quot;:&quot;my-first-loadbalancer.us-east-1.elb.amazonaws.com&quot;,
“Source&quot;:&quot;test.example.com“
},
&quot;ResourceProperties&quot;:{
“Target&quot;:&quot;my-second-loadbalancer.us-east-1.elb.amazonaws.com&quot;,
“Source&quot;:&quot;test.example.com“
}
}
} 
} 
} 
]}
</code></pre> 
<p>Depending on the type of event received, call the Amazon Route 53 <a href="http://boto3.readthedocs.io/en/latest/reference/services/route53.html#Route53.Client.change_resource_record_sets">change_resource_record_sets</a> API operation to create or delete the appropriate records. Finally, you must send the result of the operation to CloudFormation so it can mark the resource complete. The code below reports status.</p> 
<p><strong>Example: Reporting results to CloudFormation</strong></p> 
<pre><code class="lang-python">def sendResponse(event, context, responseStatus, responseData):
data = json.dumps({
'Status': responseStatus,
'Reason': 'See the details in CloudWatch Log Stream: ' + context.log_stream_name,
'PhysicalResourceId': context.log_stream_name,
'StackId': event['StackId'],
'RequestId': event['RequestId'],
'LogicalResourceId': event['LogicalResourceId'],
'Data': responseData
})
opener = urllib2.build_opener(urllib2.HTTPHandler)
request = urllib2.Request(url=event['ResponseURL'], data=data)
request.add_header('Content-Type', '')
request.get_method = lambda: 'PUT'
url = opener.open(request)
</code></pre> 
<p>As you can see, CloudFormation expects the Lambda function to provide a JSON document. This document must include a status of either SUCCESS or FAILED. The original request (such as the SNS update event) included a response URL, an <a href="http://docs.aws.amazon.com/AmazonS3/latest/dev/PresignedUrlUploadObject.html">S3 presigned URL</a>. I use the urllib2 module to PUT the JSON document to the presigned URL.</p> 
<b>Using the custom resource</b> 
<p>Now that you have your Lambda function created in the central account, you can invoke it from a custom resource in one of the accounts owned by your authorized business units. The code below shows a simple example stack that uses the custom resource.</p> 
<p>Pass three things to your custom resource. First, pass the ARN of the SNS topic used to initiate the custom resource. The ARN was an output from the template used earlier to create the custom resource in the central account. Second and third, pass the source and target values for the CNAME.</p> 
<p><strong>Example: Using the custom resource</strong></p> 
<pre><code class="lang-yaml">Parameters:
Queue: 
ServiceToken: The ARN of the SNS topic used to request a CNAME record. 
Type: String
Default: arn:aws:sns:us-east-1:999999999999:RequestRoute53CNAME
Source: 
Description: The pretty name for the CNAME record.
Type: String
Default: www.example.com 
Target: 
Description: The target of the CNAME record.
Type: String
Default: my-loadbalancer-1234567890.us-east-1.elb.amazonaws.com
Resources: 
CNAME: 
Type: Custom::CNAME
Properties: 
ServiceToken: !Ref Queue
Source: !Ref Source
Target: !Ref Target
</code></pre> 
<p>As you can see, the custom resource is easy to use but not valuable on its own. Here’s how to incorporate this into a larger solution. In the code below, I create an Elastic Beanstalk stack (using the <a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/quickref-elasticbeanstalk.html">PHP sample application stack</a>) and use the custom resource to create a CNAME record (for example, beanstalk.example.com) and a friendly name for the stack.</p> 
<p><strong>Example: Using the custom resource in a larger solution</strong></p> 
<pre><code class="lang-yaml">Resources: 
sampleApplication:
Type: AWS::ElasticBeanstalk::Application
Properties:
Description: AWS Elastic Beanstalk Sample Application
sampleApplicationVersion:
Type: AWS::ElasticBeanstalk::ApplicationVersion
Properties:
ApplicationName:
Ref: sampleApplication
Description: AWS Elastic Beanstalk Sample Application Version
SourceBundle:
S3Bucket: !Sub &quot;elasticbeanstalk-samples-${AWS::Region}&quot;
S3Key: php-sample.zip
sampleConfigurationTemplate:
Type: AWS::ElasticBeanstalk::ConfigurationTemplate
Properties:
ApplicationName:
Ref: sampleApplication
Description: AWS Elastic Beanstalk Sample Configuration Template
OptionSettings:
- Namespace: aws:autoscaling:asg
OptionName: MinSize
Value: '2'
- Namespace: aws:autoscaling:asg
OptionName: MaxSize
Value: '6'
- Namespace: aws:elasticbeanstalk:environment
OptionName: EnvironmentType
Value: LoadBalanced
SolutionStackName: 64bit Amazon Linux running PHP 5.3
sampleEnvironment:
Type: AWS::ElasticBeanstalk::Environment
Properties:
ApplicationName:
Ref: sampleApplication
Description: AWS Elastic Beanstalk Sample Environment
TemplateName:
Ref: sampleConfigurationTemplate
VersionLabel:
Ref: sampleApplicationVersion
CNAME: 
Type: Custom::CNAME
Properties: 
ServiceToken: arn:aws:sns:us-east-1:999999999999:RequestRoute53CNAME
Source: beanstalk.example.com
Target: !GetAtt sampleEnvironment.EndpointURL
</code></pre> 
<p>This CloudFormation stack waits for the Elastic Beanstalk environment to launch and then creates a CNAME record in the central IT account.</p> 
<b>Conclusion</b> 
<p>In this post, you learned how to create a CloudFormation custom resource, which allows you to execute custom logic in a CloudFormation template. You also learned how to invoke custom code in one AWS account, from a CloudFormation stack in another account.</p> 
<p><strong>About the Author</strong></p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/08/24/beabrian.jpg">Brian Beach</a> is a Solutions Architect on the World Wide Public Sector team&nbsp;where he focuses on higher education. Brian is excited by the growth of cloud computing and enjoys&nbsp;teaching others about technology. He is a frequent author and speaker. In his free time, Brian can be found playing with his three children in Raleigh, NC.</p> 
<footer> 
</footer> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">Amazon EC2 Systems Manager Automation is now a Amazon CloudWatch Events Target</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Venkat Krish</span></span> | on 
<time property="datePublished" datetime="2017-08-21T11:42:35+00:00">21 AUG 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/amazon-ec2-systems-manager/" title="View all posts in Amazon EC2 Systems Manager*"><span property="articleSection">Amazon EC2 Systems Manager*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools*"><span property="articleSection">Management Tools*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/amazon-ec2-systems-manager-automation-is-now-a-amazon-cloudwatch-events-target/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p>Today&nbsp;we are excited to announce a new target for Amazon CloudWatch Events: Amazon EC2 Systems Manager Automation. Through this integration, Automation workflows can be triggered by a schedule, or when specific AWS system events occur.</p> 
<li><a href="https://aws.amazon.com/ec2/systems-manager/automation/">Automation </a>is part of <a href="https://aws.amazon.com/ec2/systems-manager/">Amazon EC2 Systems Manager</a>.&nbsp; Using Automation you can build workflows that are streamlined, repeatable and auditable. For example, you can create workflows to patch, update agents, or bake applications into an Amazon Machine Image (AMI). You can also avoid the time and effort associated with updating your images manually, and instead build AMIs that meet your IT standards and make the approved AMIs available to you teams.</li> 
<li>Amazon&nbsp;<a href="http://docs.aws.amazon.com/AmazonCloudWatch/latest/events/WhatIsCloudWatchEvents.html">CloudWatch Events</a> allows you to create rules that trigger based on AWS events, or on a periodic schedule. &nbsp;CloudWatch Events can be setup to respond to Amazon EC2 Service state changes, Amazon Simple Storage Service (S3) bucket operations, and other events automatically. Supported targets include <a href="https://aws.amazon.com/lambda/">AWS Lambda</a>, Amazon SNS, Amazon EC2 Systems Manager Run Command, and now Amazon EC2 Systems Manager Automation.</li> 
<p>With Automation as a supported CloudWatch Events target, you can take advantage of some interesting use cases. You can perform routine tasks better when you schedule tasks for specific days and times or after specific event patterns. In this blog, we are going to show examples of how you can use CloudWatch Events and Automation to automate repetitive tasks, such as periodically starting and stopping instances.</p> 
<p><span id="more-825"></span></p> 
<h3>Automatically stop and start instances on weekends</h3> 
<p>Identifying and automatically stopping unused non-production instances in your account can save costs and improve efficiency of how you use your resources. Suppose you would like to automatically stop an instance every Friday evening and start it back on Monday morning. You can easily accomplish this using two CloudWatch Events that triggers an Automation Document for stopping and starting instances.</p> 
<h3>Create an Automation Document</h3> 
<p>For this example, follow the steps to <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/automation-createdoc.html">create an Automation Document</a>. The following code can be used to quickly create the Document.</p> 
<pre><code class="lang-json">{
&quot;description&quot;:&quot;Systems Manager Automation Demo - Start Instances via CWE&quot;,
&quot;schemaVersion&quot;:&quot;0.3&quot;,
&quot;parameters&quot;:{
&quot;automationRoleArn&quot;:{
&quot;type&quot;:&quot;String&quot;,
&quot;description&quot;:&quot;(Required) The ARN of the role that allows Automation to perform the actions on your behalf.&quot;
},
&quot;instanceIds&quot;:{
&quot;type&quot;:&quot;StringList&quot;,
&quot;description&quot;:&quot;(Required) The Instance ID(s) to Stop or Start.&quot;
},
&quot;state&quot;:{
&quot;type&quot;:&quot;String&quot;,
&quot;description&quot;:&quot;(Required) The state you would like the Instance(s) placed in. Options are: running | stopped&quot;
}
},
&quot;assumeRole&quot;:&quot;{{automationRoleArn}}&quot;,
&quot;mainSteps&quot;:[
{
&quot;name&quot;:&quot;startStopInstance&quot;,
&quot;action&quot;:&quot;aws:changeInstanceState&quot;,
&quot;maxAttempts&quot;:2,
&quot;timeoutSeconds&quot;:120,
&quot;onFailure&quot;:&quot;Continue&quot;,
&quot;inputs&quot;:{
&quot;InstanceIds&quot;:[&quot;{{instanceIds}}&quot;],
&quot;DesiredState&quot;:&quot;{{state}}&quot;
}
}
]
}</code></pre> 
<h3>Steps to create CloudWatch event rules to trigger Automation</h3> 
<p>After you have created the Document and saved it, you can create two CloudWatch event rules that automatically trigger at specific times.</p> 
<p><strong>Step 1</strong>. In the AWS Management Console, choose CloudWatch, Events, Rules and Create rule.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/07/24/CWERules.png" /></p> 
<p><strong>Step 2:&nbsp;</strong>&nbsp;Under <strong>Event Source</strong>, choose <strong>Schedule</strong>, <strong>Cron expression</strong>. To stop specified instances automatically at 6 PM every Friday, enter the following cron expression to trigger the rule:</p> 
<p><em>0 18 ? * FRI *</em></p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/07/25/CR1-1.png" /></p> 
<p>&nbsp;</p> 
<p><strong>Step 3:</strong> Under Targets, choose <strong>Add target</strong>, <strong>SSM Automation</strong>.</p> 
<p><strong>Step 4:</strong>&nbsp;For Document, select the Automation Document you saved for stopping and starting specified instances.</p> 
<p><strong>Step 5:</strong>&nbsp;For Configure document version, choose Default or a particular version number.</p> 
<p><strong>Step 6:</strong>&nbsp;Choose <strong>‘Constant’</strong> automation &nbsp;and enter the enter instance ID that you would like to be stopped automatically per the rule that you are creating. You can also choose&nbsp;<strong>‘Input Transformer’</strong> to provide custom inputs based on a template.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/07/24/Targets.png" /></p> 
<p><strong>Step 7:</strong>&nbsp;Provide permission for CloudWatch event to call SSM Start Automation Execution. You can either create an existing role that you previously created or create a new role.</p> 
<p><strong>Step 8:</strong>&nbsp;Choose <strong>Configure details</strong>, and enter a name and description for your rule. Ensure that Enabled is selected.</p> 
<p><strong>Step 9:</strong>&nbsp;Choose <strong>Create rule</strong>.</p> 
<p>Your rule is now created and automatically executes every Friday at 6 PM to stop your specified instance. To start the instance back up say on Monday morning, repeat the steps to create another CloudWatch event rule, set your cron expression to Monday AM at your desired time, and target the same Automation Document. Make sure you provide “running” as your desired state.</p> 
<p>With this setup you can now automatically stop and start your instances, thus using your resources optimally.</p> 
<h3>Additional methods to trigger Automation</h3> 
<p>Outside of setting up an Automation workflow to be triggered on a schedule, you can also trigger executions based on event patterns. For example, you can setup a CloudWatch event on a&nbsp;<a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/systems-manager-paramstore.html">Parameter Store</a> value. Based on changes to the value you can trigger an Automation workflow. You can create&nbsp;a Parameter Store key/value to store AMI Ids which you typically use to create golden images for your organization. Every time you change the value of the key to a new AMI ID, you can setup a CloudWatch event rule on that parameter and target Automation. The target can point either to your custom Document or the <em>AWS-UpdateWindowsAMI</em> Document published by AWS. This automatically creates a new image with the latest updates that you can provide as inputs to your CI/CD pipeline or to Auto Scaling groups. For your reference, here is a blog that talks about how you can <a href="https://aws.amazon.com/blogs/mt/windows-ami-patching-and-maintenance-with-amazon-ec2-systems-manager-2/">update and patch your Windows AMIs</a>&nbsp;using Automation.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/07/24/PS.png" /></p> 
<p>&nbsp;</p> 
<h3>Conclusion</h3> 
<p>Automation simplifies common system maintenance and deployment tasks. By using CloudWatch Events, you can orchestrate task execution based on any events relating to AWS services. You can also trigger your predefined workflows on a schedule. Using this integration, you can easily orchestrate management of your resources and expect your workflows to perform tasks at scale automatically.</p> 
<p><strong>About the author</strong></p> 
<p><a href="https://www.linkedin.com/in/venkatkr/"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/07/19/KRVenkt.jpg" /></a></p> 
<p><a href="https://www.linkedin.com/in/venkatkr/">Venkat Krishnamachari</a> is a Product Manager in the Amazon EC2 Systems Manager team. Venkat is excited by the opportunities presented by cloud computing, and loves helping customers benefit from the value of efficient infrastructure and management. In his personal time Venkat volunteers with NGOs and loves producing live theater and music shows.</p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/mt/tag/amazon-cloudwatch-events/" rel="tag">Amazon Cloudwatch Events</a>, <a href="https://aws.amazon.com/blogs/mt/tag/aws-codedeploy/" rel="tag">AWS CodeDeploy</a>, <a href="https://aws.amazon.com/blogs/mt/tag/aws-opsworks/" rel="tag">AWS OpsWorks</a>, <a href="https://aws.amazon.com/blogs/mt/tag/documents/" rel="tag">Documents</a>, <a href="https://aws.amazon.com/blogs/mt/tag/ec2-systems-manager/" rel="tag">EC2 Systems Manager</a>, <a href="https://aws.amazon.com/blogs/mt/tag/ec2-windows/" rel="tag">EC2 Windows</a>, <a href="https://aws.amazon.com/blogs/mt/tag/maintenance-window/" rel="tag">Maintenance Window</a>, <a href="https://aws.amazon.com/blogs/mt/tag/patch-complaince/" rel="tag">Patch Complaince</a>, <a href="https://aws.amazon.com/blogs/mt/tag/patch-manager/" rel="tag">Patch Manager</a>, <a href="https://aws.amazon.com/blogs/mt/tag/ssm/" rel="tag">SSM</a>, <a href="https://aws.amazon.com/blogs/mt/tag/state-manager/" rel="tag">State Manager</a></span> 
</footer> 
</article> 
<p>
© 2017, Amazon Web Services, Inc. or its affiliates. All rights reserved.
</p>

    </div>
  </div>
</div>


    <div id="footer" class="navigation hidden-print">
      <div class="container">
        <div class="row">
          <div class="col-xs-12">
            <ul class="footer-links nav navbar-nav">
              <li><a href="../aws.html">AWS</a></li>
              <li><a href="../linux.html">Linux</a></li>
              <li><a href="../docker.html">Docker</a></li>
              <li><a href="../ibmpower.html">IBM Power</a></li>
              <li><a href="blogsataws1.html">Blogs@AWS (Kindle Friendly)</a></li>
            </ul>
            <ul class="footer-links nav navbar-nav navbar-right">
              <li><a href="../comments.html">Comments?</a></li>
            </ul>
          </div>
        </div>
      </div>
    </div>
  </body>
</html>
