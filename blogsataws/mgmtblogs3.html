<!DOCTYPE html>
<html lang="en">
  <head>
<!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-593498H');</script>
<!-- End Google Tag Manager -->

    <meta charset="utf-8">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">

    <meta name="msapplication-config" content="/microsoft-tile.xml" />
    <meta name="theme-color" content="#ffffff">

    <meta property="og:url" content="https://bejoycalias.github.io/blogsataws/mgmtblogs1.html" />
    <meta property="og:site_name" content="Bejoy's TechNotes"/>
    <meta property="og:title" content="Bejoy's TechNotes - Kindle Friendly AWS Management Tools Blogs" />
    <meta property="og:image" content="https://bejoycalias.github.io/assets/images/og-image.png"/>
    <meta property="og:image:width" content="1200"/>
    <meta property="og:image:height" content="1200"/>
    <meta property="og:description" content="" />

    <title>Bejoy's TechNotes - Kindle Friendly AWS Management Tools Blogs</title>
    <link href="../assets/stylesheets/application-832aa42c.css" rel="stylesheet" />

    <!--[if lt IE 9]>
      <script src="../assets/javascripts/ie-compat-c141a02d.js"></script>
    <![endif]-->
    <script src="../assets/javascripts/application-ff53d307.js"></script>

    <!-- Typekit script to import Klavika font -->
    <script src="https://use.typekit.net/wxf7mfi.js"></script>
    <script>try{Typekit.load({ async: true });}catch(e){}</script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-100043608-1', 'auto');
  ga('send', 'pageview');

</script>

    
  </head>

  <body id="uh-oh-" class="layout-inner page-uh-oh-">
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-593498H"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->


    <div id="header" class="navigation navbar-static-top hidden-print">
      <div class="container">
        <div class="row">
          <div class="col-xs-12">
            <div class="navbar-header">
              <div class="navbar-brand">
                <a href="/">
                  <svg version="1.0" xmlns="http://www.w3.org/2000/svg" width="135.000000pt" height="50" viewbox="0 0 135.000000 45.000000" preserveaspectratio="xMidYMid meet" class="logo">

<g transform="translate(0.000000,45.000000) scale(0.100000,-0.100000)" fill="#000000" stroke="none">
<path class="text" fill="#000000" d="M527 384 c-4 -4 -7 -18 -7 -31 0 -21 4 -24 28 -21 21 2 27 8 27 28 0
18 -6 26 -20 28 -12 2 -24 0 -28 -4z"></path>
<path class="text" fill="#000000" d="M1080 335 c0 -48 2 -55 20 -55 18 0 20 7 20 55 0 48 -2 55 -20 55
-18 0 -20 -7 -20 -55z"></path>
<path class="text" fill="#000000" d="M54 357 c-2 -7 -3 -69 -2 -138 l3 -124 65 -3 c90 -3 130 20 130 77 0
29 -6 44 -20 54 -20 14 -20 15 -3 45 14 25 15 34 5 56 -6 15 -23 31 -38 36
-38 15 -134 13 -140 -3z m110 -33 c19 -7 21 -45 4 -62 -7 -7 -22 -12 -35 -12
-20 0 -23 5 -23 40 0 41 13 50 54 34z m20 -130 c19 -18 19 -20 6 -45 -8 -13
-21 -19 -45 -19 -34 0 -35 1 -35 40 0 38 2 40 29 40 16 0 37 -7 45 -16z"></path>
<path class="text" fill="#000000" d="M319 271 c-23 -24 -29 -38 -29 -74 0 -25 3 -53 6 -62 20 -50 164 -64
164 -15 0 15 -7 17 -45 12 -46 -5 -75 8 -75 34 0 11 16 14 65 14 l65 0 0 35
c0 80 -92 114 -151 56z m99 -33 c3 -15 -4 -18 -37 -18 -43 0 -50 7 -29 28 18
18 62 11 66 -10z"></path>
<path class="text" fill="#000000" d="M520 184 c0 -107 -1 -116 -20 -121 -11 -3 -20 -12 -20 -19 0 -21 76
-19 84 2 3 9 6 69 6 135 l0 119 -25 0 -25 0 0 -116z"></path>
<path class="text" fill="#000000" d="M649 271 c-24 -25 -29 -37 -29 -78 1 -70 34 -103 105 -103 55 0 95
44 95 103 0 60 -7 75 -41 92 -47 25 -96 19 -130 -14z m111 -30 c25 -48 2 -111
-40 -111 -45 0 -69 80 -34 114 21 22 61 20 74 -3z"></path>
<path class="text" fill="#000000" d="M850 287 c0 -8 16 -57 36 -110 28 -76 33 -100 25 -116 -16 -28 -14
-31 18 -31 27 0 29 4 70 123 23 67 41 128 41 135 0 6 -11 12 -24 12 -21 0 -26
-8 -41 -65 -10 -36 -21 -68 -25 -70 -3 -2 -16 27 -29 66 -19 60 -25 69 -47 69
-13 0 -24 -6 -24 -13z"></path>
<path class="text" fill="#000000" d="M1192 284 c-17 -12 -22 -24 -20 -47 2 -26 10 -36 45 -52 49 -23 59
-55 17 -55 -14 0 -34 5 -45 10 -16 9 -19 7 -19 -13 0 -17 7 -27 23 -31 69 -18
117 6 117 60 0 32 -4 37 -45 55 -60 26 -62 54 -4 46 37 -5 40 -3 37 16 -2 18
-11 23 -43 25 -25 2 -49 -3 -63 -14z"></path>
</g>
</svg>

                </a>
              </div>
              <button class="navbar-toggle" type="button">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
              </button>
            </div>
            <div class="buttons hidden-xs">
              <nav class="navigation-links" role="navigation">
                <ul class="main-links nav navbar-nav navbar-right">
                  <li><a href="../aws.html">AWS</a></li>
                  <li><a href="../linux.html">Linux</a></li>
                  <li><a href="../docker.html">Docker</a></li>
                  <li><a href="../ibmpower.html">IBM Power</a></li>
                  <li><a href="blogsataws1.html">Blogs@AWS (Kindle Friendly)</a></li>
                </ul>
              </nav>
            </div>
          </div>
        </div>
      </div>
    </div>

    <div class="sidebar-overlay"></div>

<aside class="sidebar" role="navigation">
  <div class="sidebar-header">
    <svg version="1.0" xmlns="http://www.w3.org/2000/svg" width="135.000000pt" height="42" viewbox="0 0 135.000000 45.000000" preserveaspectratio="xMidYMid meet">

<g transform="translate(0.000000,45.000000) scale(0.100000,-0.100000)" fill="#000000" stroke="none">
<path class="text" fill="#000000" d="M527 384 c-4 -4 -7 -18 -7 -31 0 -21 4 -24 28 -21 21 2 27 8 27 28 0
18 -6 26 -20 28 -12 2 -24 0 -28 -4z"></path>
<path class="text" fill="#000000" d="M1080 335 c0 -48 2 -55 20 -55 18 0 20 7 20 55 0 48 -2 55 -20 55
-18 0 -20 -7 -20 -55z"></path>
<path class="text" fill="#000000" d="M54 357 c-2 -7 -3 -69 -2 -138 l3 -124 65 -3 c90 -3 130 20 130 77 0
29 -6 44 -20 54 -20 14 -20 15 -3 45 14 25 15 34 5 56 -6 15 -23 31 -38 36
-38 15 -134 13 -140 -3z m110 -33 c19 -7 21 -45 4 -62 -7 -7 -22 -12 -35 -12
-20 0 -23 5 -23 40 0 41 13 50 54 34z m20 -130 c19 -18 19 -20 6 -45 -8 -13
-21 -19 -45 -19 -34 0 -35 1 -35 40 0 38 2 40 29 40 16 0 37 -7 45 -16z"></path>
<path class="text" fill="#000000" d="M319 271 c-23 -24 -29 -38 -29 -74 0 -25 3 -53 6 -62 20 -50 164 -64
164 -15 0 15 -7 17 -45 12 -46 -5 -75 8 -75 34 0 11 16 14 65 14 l65 0 0 35
c0 80 -92 114 -151 56z m99 -33 c3 -15 -4 -18 -37 -18 -43 0 -50 7 -29 28 18
18 62 11 66 -10z"></path>
<path class="text" fill="#000000" d="M520 184 c0 -107 -1 -116 -20 -121 -11 -3 -20 -12 -20 -19 0 -21 76
-19 84 2 3 9 6 69 6 135 l0 119 -25 0 -25 0 0 -116z"></path>
<path class="text" fill="#000000" d="M649 271 c-24 -25 -29 -37 -29 -78 1 -70 34 -103 105 -103 55 0 95
44 95 103 0 60 -7 75 -41 92 -47 25 -96 19 -130 -14z m111 -30 c25 -48 2 -111
-40 -111 -45 0 -69 80 -34 114 21 22 61 20 74 -3z"></path>
<path class="text" fill="#000000" d="M850 287 c0 -8 16 -57 36 -110 28 -76 33 -100 25 -116 -16 -28 -14
-31 18 -31 27 0 29 4 70 123 23 67 41 128 41 135 0 6 -11 12 -24 12 -21 0 -26
-8 -41 -65 -10 -36 -21 -68 -25 -70 -3 -2 -16 27 -29 66 -19 60 -25 69 -47 69
-13 0 -24 -6 -24 -13z"></path>
<path class="text" fill="#000000" d="M1192 284 c-17 -12 -22 -24 -20 -47 2 -26 10 -36 45 -52 49 -23 59
-55 17 -55 -14 0 -34 5 -45 10 -16 9 -19 7 -19 -13 0 -17 7 -27 23 -31 69 -18
117 6 117 60 0 32 -4 37 -45 55 -60 26 -62 54 -4 46 37 -5 40 -3 37 16 -2 18
-11 23 -43 25 -25 2 -49 -3 -63 -14z"></path>
</g>
</svg>

  </div>

  <ul class="nav sidebar-nav">
    <li><a href="../aws.html">AWS</a></li>
    <li><a href="../linux.html">Linux</a></li>
    <li><a href="../docker.html">Docker</a></li>
    <li><a href="../ibmpower.html">IBM Power</a></li>
    <li><a href="blogsataws1.html">Blogs@AWS (Kindle Friendly)</a></li>
  </ul>
</aside>


    <div class="container">
  <div class="row">
    <div id="docs-sidebar" class="col-sm-3 col-md-3 col-xs-12 hidden-print" role="complementary">
      <ul class="nav docs-sidenav">
      <li><a href="blogsataws1.html">Blogs @ AWS</a></li>
      <li><a href="whatsnew1.html">What's New @ AWS</a></li>
      <li><a href="secblogs1.html">Security Blogs @ AWS</a></li>
      <li><a href="computeblogs1.html">Compute Blogs @ AWS</a></li>
      <li><a href="apnblogs1.html">APN Blogs @ AWS</a></li>
      <li><a href="devopsblogs1.html">DevOps Blogs @ AWS</a></li>
      <li class="active"><a href="mgmtblogs1.html">Management Tools Blogs @ AWS</a></li>

    </ul>
    </div>

    <div id="inner" class="col-sm-9 col-md-9 col-xs-12" role="main">
<p></p>
<p><i>Contents of this page is copied directly from AWS blog sites to make it Kindle friendly. Some styles & sections from these pages are removed to render this properly in 'Article Mode' of Kindle e-Reader browser. All the contents of this page is property of AWS.</i></p>
<p><a href="mgmtblogs1.html">Page 1</a>|<a href="mgmtblogs2.html">Page 2</a>|<a href="mgmtblogs3.html">Page 3</a>|<a href="mgmtblogs4.html">Page 4</a</p>
<br>
<article class="post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="b post-title" property="name headline">Multi-Account Strategy: Using AWS CloudFormation Custom Resources to Create Amazon Route 53 Resources in Another Account</b> 
<footer class="meta">
by 
<span property="author" typeof="Person"><span property="name">Brian Beach</span></span> | on 
<time property="datePublished" datetime="2017-08-24T16:06:05+00:00">24 AUG 2017</time> | in 
<span class="categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/aws-cloudformation/" title="View all posts in AWS CloudFormation"><span property="articleSection">AWS CloudFormation</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools"><span property="articleSection">Management Tools</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/multi-account-strategy-using-aws-cloudformation-custom-resources-to-create-amazon-route-53-resources-in-another-account/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog=""><span class="span icon-share"></span>&nbsp;Share</a> 
<ul> 
</ul> 
</footer> 
<p>Today, most customers have more than one AWS account. While a multi-account strategy brings many benefits―simplified billing, security isolation, decentralized control, etc., it also introduces new challenges. One challenge is that the users in one account occasionally need to create resources in another.</p> 
<p>In this post, I will show you how to use a <a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/template-custom-resources.html">custom resource</a> from <a href="https://aws.amazon.com/cloudformation">AWS CloudFormation</a> to create <a href="https://aws.amazon.com/route53">Amazon Route 53</a> resource records in another account.</p> 
<p><span id="more-976"></span></p> 
<b>Multi-account scenario</b> 
<p>A common driver for adopting a multi-account strategy is to give autonomy and agility to individual business units.</p> 
<p>Imagine that you work for a company that has adopted this strategy. There is a centralized IT team that manages consolidated billing and shared resources such as AWS Direct Connect connections. In addition, they manage the Domain Name System (DNS) for the company. They have chosen to host DNS in Amazon Route 53. Various business units have their own accounts and operate with relatively little oversight.</p> 
<p>The marketing team regularly creates short-lived websites for various marketing campaigns. They use CloudFormation to launch and manage these sites, but CloudFormation cannot create resources in other accounts. Therefore, the marketing team has to submit a request to central IT to update DNS. This often takes hours or even days to complete. They want a simple way to create a CNAME record in the central account from a CloudFormation template in their own account.</p> 
<b>CloudFormation custom resources</b> 
<p>One way to create resources in another account is to use a CloudFormation custom resource, which allows you to execute custom code from a CloudFormation template. CloudFormation supports two types of custom resources:</p> 
<ul> 
<li>The first invokes an <a href="https://aws.amazon.com/lambda">AWS Lambda</a> function, allowing you to execute custom code.</li> 
<li>The second sends a message to an <a href="https://aws.amazon.com/sns">Amazon SNS</a> topic to which you have subscribed.</li> 
</ul> 
<p>Here’s an example. The Figure below outlines a solution to the problem scenario described earlier. Marketing is launching a CloudFormation stack and wants to create a CNAME in Amazon Route 53 hosted in another account.</p> 
<p>The high-level workflow goes like this:</p> 
<ol> 
<li>CloudFormation sends a message to an SNS topic in the central account.</li> 
<li>A Lambda function is invoked in response to the message.</li> 
<li>Lambda creates the Amazon Route 53 CNAME record.</li> 
<li>Lambda calls an Amazon S3 presigned URL, indicating that it completed successfully.</li> 
<li>CloudFormation marks the custom resource complete.</li> 
</ol> 
<p><img class="alignnone size-full wp-image-982" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/07/27/cfn-r53-cross-account.png" alt="" width="795" height="761" /><br /> <i>You might be asking yourself why I used SNS when CloudFormation custom resources can invoke Lambda directly. I could have invoked Lambda directly, but SNS simplifies cross account permissions and makes the configuration easier.</i></p> 
<b>Configuring the custom resource</b> 
<p>Begin by configuring the services in the central account. I will assume that Amazon Route 53 is already configured, so you need to configure SNS and Lambda.</p> 
<p>I have included a <a href="https://s3-us-west-2.amazonaws.com/management-tools-blog-cf-template-storage/ConfigCentralAccount.yaml">CloudFormation template to configure these services in the central account</a> for you. The template requires two inputs:</p> 
<ul> 
<li>The ID of the Amazon Route 53 <a href="http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/CreatingHostedZone.html">hosted zone</a> in which to allow the business units to create records.</li> 
<li>A list of the account IDs that are authorized to create resource records in Amazon Route 53.</li> 
</ul> 
<p>This restricts access so that only the accounts that you specify can create resource records in the hosted zone that you specify. Obviously, you don’t want to allow everyone to create―or worse, change―records anywhere in your DNS system.</p> 
<p>After the CloudFormation template completes, it outputs the ARN of the SNS topic used to request new resources. Make note of this, as you use it to configure the custom resource later in this post.</p> 
<p>In the Lambda console, you see a new function called CreateRoute53CNAME. This is the logic for the custom resource. The primary method, lambda_handler, is shown in the code below.</p> 
<p><strong>Example: Lambda function snippet</strong></p> 
<pre><code class="lang-python">def lambda_handler(event, context):
#SNS events contain a wrapper around the Lambda event. Unpack the
#Lambda event from SNS. Not needed if you’re calling Lambda directly.
print(&quot;SNS Event: &quot; + json.dumps(event))
event = json.loads(event['Records'][0]['Sns']['Message'])            
print(&quot;Lambda Event: &quot; + json.dumps(event))
try: 
hostedzone = 'ZXAOMNFL85JIZ'
type = event['RequestType']
source = event['ResourceProperties']['Source']
target = event['ResourceProperties']['Target']
if type == 'Create':
print &quot;Creating CNAME &quot; + source + &quot;-&gt;&quot; + target + &quot; in &quot; + hostedzone
change_resource_record_sets('UPSERT', hostedzone, source, target)
elif type == 'Update':
oldsource = event['OldResourceProperties']['Source']
oldtarget = event['OldResourceProperties']['Target']
print &quot;Deleting old CNAME &quot; + oldsource + &quot;-&gt;&quot; + oldtarget + &quot; in &quot; + hostedzone
change_resource_record_sets('DELETE', hostedzone, oldsource, oldtarget)
print &quot;Creating new CNAME &quot; + source + &quot;-&gt;&quot; + target + &quot; in &quot; + hostedzone
change_resource_record_sets('UPSERT', hostedzone, source, target)
elif type == 'Delete':
print &quot;Deleting CNAME &quot; + source + &quot;-&gt;&quot; + target + &quot; in &quot; + hostedzone
change_resource_record_sets('DELETE', hostedzone, source, target)
else:
print &quot;Unexpected Request Type&quot;
raise Exception(&quot;Unexpected Request Type&quot;)
print &quot;Completed successfully&quot;
responseStatus = 'SUCCESS'
responseData = {}
sendResponse(event, context, responseStatus, responseData)
except: 
print(&quot;Error:&quot;, sys.exc_info()[0])
responseStatus = 'FAILED'
responseData = {}
sendResponse(event, context, responseStatus, responseData)
</code></pre> 
<p>As you can see, the first thing the Lambda function does is unpack the SNS event to get the properties that were passed from CloudFormation. In this example, you pass in a source (for example, www.example.com) and a target (for example, my-loadbalancer-1234567890.us-east-1.elb.amazonaws.com) for a CNAME record.</p> 
<p>In addition, the event always includes a RequestType value of Create, Update, or Delete. The code below is an example of an Update event. In the case of an Update, you get an additional set of OldResourceProperties values that are not included in Create and Delete events.</p> 
<p><strong>Example: Sample update event in SNS</strong></p> 
<pre><code class="lang-json">{ &quot;Records&quot;: [ 
{ &quot;EventVersion&quot;: &quot;1.0&quot;, 
&quot;EventSubscriptionArn&quot;: &quot;arn:aws:sns:us-east-1:…:RequestRoute53CNAME:…&quot;, 
&quot;EventSource&quot;: &quot;aws:sns&quot;, 
&quot;Sns&quot;: { 
&quot;MessageId&quot;: &quot;6ae3f7a1-2772-568c-9175-a603bc40bf03&quot;, 
&quot;Message&quot;: {
&quot;RequestType&quot;:“Update&quot;,
&quot;ResponseURL&quot;:&quot; https://cloudformation-custom-resource-response-useast1...&quot;,
&quot;ResourceType&quot;:&quot;Custom::CNAME&quot;,
&quot;OldResourceProperties&quot;:{
“Target&quot;:&quot;my-first-loadbalancer.us-east-1.elb.amazonaws.com&quot;,
“Source&quot;:&quot;test.example.com“
},
&quot;ResourceProperties&quot;:{
“Target&quot;:&quot;my-second-loadbalancer.us-east-1.elb.amazonaws.com&quot;,
“Source&quot;:&quot;test.example.com“
}
}
} 
} 
} 
]}
</code></pre> 
<p>Depending on the type of event received, call the Amazon Route 53 <a href="http://boto3.readthedocs.io/en/latest/reference/services/route53.html#Route53.Client.change_resource_record_sets">change_resource_record_sets</a> API operation to create or delete the appropriate records. Finally, you must send the result of the operation to CloudFormation so it can mark the resource complete. The code below reports status.</p> 
<p><strong>Example: Reporting results to CloudFormation</strong></p> 
<pre><code class="lang-python">def sendResponse(event, context, responseStatus, responseData):
data = json.dumps({
'Status': responseStatus,
'Reason': 'See the details in CloudWatch Log Stream: ' + context.log_stream_name,
'PhysicalResourceId': context.log_stream_name,
'StackId': event['StackId'],
'RequestId': event['RequestId'],
'LogicalResourceId': event['LogicalResourceId'],
'Data': responseData
})
opener = urllib2.build_opener(urllib2.HTTPHandler)
request = urllib2.Request(url=event['ResponseURL'], data=data)
request.add_header('Content-Type', '')
request.get_method = lambda: 'PUT'
url = opener.open(request)
</code></pre> 
<p>As you can see, CloudFormation expects the Lambda function to provide a JSON document. This document must include a status of either SUCCESS or FAILED. The original request (such as the SNS update event) included a response URL, an <a href="http://docs.aws.amazon.com/AmazonS3/latest/dev/PresignedUrlUploadObject.html">S3 presigned URL</a>. I use the urllib2 module to PUT the JSON document to the presigned URL.</p> 
<b>Using the custom resource</b> 
<p>Now that you have your Lambda function created in the central account, you can invoke it from a custom resource in one of the accounts owned by your authorized business units. The code below shows a simple example stack that uses the custom resource.</p> 
<p>Pass three things to your custom resource. First, pass the ARN of the SNS topic used to initiate the custom resource. The ARN was an output from the template used earlier to create the custom resource in the central account. Second and third, pass the source and target values for the CNAME.</p> 
<p><strong>Example: Using the custom resource</strong></p> 
<pre><code class="lang-yaml">Parameters:
Queue: 
ServiceToken: The ARN of the SNS topic used to request a CNAME record. 
Type: String
Default: arn:aws:sns:us-east-1:999999999999:RequestRoute53CNAME
Source: 
Description: The pretty name for the CNAME record.
Type: String
Default: www.example.com 
Target: 
Description: The target of the CNAME record.
Type: String
Default: my-loadbalancer-1234567890.us-east-1.elb.amazonaws.com
Resources: 
CNAME: 
Type: Custom::CNAME
Properties: 
ServiceToken: !Ref Queue
Source: !Ref Source
Target: !Ref Target
</code></pre> 
<p>As you can see, the custom resource is easy to use but not valuable on its own. Here’s how to incorporate this into a larger solution. In the code below, I create an Elastic Beanstalk stack (using the <a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/quickref-elasticbeanstalk.html">PHP sample application stack</a>) and use the custom resource to create a CNAME record (for example, beanstalk.example.com) and a friendly name for the stack.</p> 
<p><strong>Example: Using the custom resource in a larger solution</strong></p> 
<pre><code class="lang-yaml">Resources: 
sampleApplication:
Type: AWS::ElasticBeanstalk::Application
Properties:
Description: AWS Elastic Beanstalk Sample Application
sampleApplicationVersion:
Type: AWS::ElasticBeanstalk::ApplicationVersion
Properties:
ApplicationName:
Ref: sampleApplication
Description: AWS Elastic Beanstalk Sample Application Version
SourceBundle:
S3Bucket: !Sub &quot;elasticbeanstalk-samples-${AWS::Region}&quot;
S3Key: php-sample.zip
sampleConfigurationTemplate:
Type: AWS::ElasticBeanstalk::ConfigurationTemplate
Properties:
ApplicationName:
Ref: sampleApplication
Description: AWS Elastic Beanstalk Sample Configuration Template
OptionSettings:
- Namespace: aws:autoscaling:asg
OptionName: MinSize
Value: '2'
- Namespace: aws:autoscaling:asg
OptionName: MaxSize
Value: '6'
- Namespace: aws:elasticbeanstalk:environment
OptionName: EnvironmentType
Value: LoadBalanced
SolutionStackName: 64bit Amazon Linux running PHP 5.3
sampleEnvironment:
Type: AWS::ElasticBeanstalk::Environment
Properties:
ApplicationName:
Ref: sampleApplication
Description: AWS Elastic Beanstalk Sample Environment
TemplateName:
Ref: sampleConfigurationTemplate
VersionLabel:
Ref: sampleApplicationVersion
CNAME: 
Type: Custom::CNAME
Properties: 
ServiceToken: arn:aws:sns:us-east-1:999999999999:RequestRoute53CNAME
Source: beanstalk.example.com
Target: !GetAtt sampleEnvironment.EndpointURL
</code></pre> 
<p>This CloudFormation stack waits for the Elastic Beanstalk environment to launch and then creates a CNAME record in the central IT account.</p> 
<b>Conclusion</b> 
<p>In this post, you learned how to create a CloudFormation custom resource, which allows you to execute custom logic in a CloudFormation template. You also learned how to invoke custom code in one AWS account, from a CloudFormation stack in another account.</p> 
<p><strong>About the Author</strong></p> 
<p><img class="size-full wp-image-1180 alignleft" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/08/24/beabrian.jpg" alt="" width="119" height="160" /><a href="https://www.linkedin.com/in/brianjbeach/">Brian Beach</a> is a Solutions Architect on the World Wide Public Sector team&nbsp;where he focuses on higher education. Brian is excited by the growth of cloud computing and enjoys&nbsp;teaching others about technology. He is a frequent author and speaker. In his free time, Brian can be found playing with his three children in Raleigh, NC.</p> 
<footer> 
</footer> 
</article> 
<article class="post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="b post-title" property="name headline">Amazon EC2 Systems Manager Automation is now a Amazon CloudWatch Events Target</b> 
<footer class="meta">
by 
<span property="author" typeof="Person"><span property="name">Venkat Krish</span></span> | on 
<time property="datePublished" datetime="2017-08-21T11:42:35+00:00">21 AUG 2017</time> | in 
<span class="categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/amazon-ec2-systems-manager/" title="View all posts in Amazon EC2 Systems Manager"><span property="articleSection">Amazon EC2 Systems Manager</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools"><span property="articleSection">Management Tools</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/amazon-ec2-systems-manager-automation-is-now-a-amazon-cloudwatch-events-target/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog=""><span class="span icon-share"></span>&nbsp;Share</a> 
<ul> 
</ul> 
</footer> 
<p>Today&nbsp;we are excited to announce a new target for Amazon CloudWatch Events: Amazon EC2 Systems Manager Automation. Through this integration, Automation workflows can be triggered by a schedule, or when specific AWS system events occur.</p> 
<ul> 
<li><a href="https://aws.amazon.com/ec2/systems-manager/automation/">Automation </a>is part of <a href="https://aws.amazon.com/ec2/systems-manager/">Amazon EC2 Systems Manager</a>.&nbsp; Using Automation you can build workflows that are streamlined, repeatable and auditable. For example, you can create workflows to patch, update agents, or bake applications into an Amazon Machine Image (AMI). You can also avoid the time and effort associated with updating your images manually, and instead build AMIs that meet your IT standards and make the approved AMIs available to you teams.</li> 
<li>Amazon&nbsp;<a href="http://docs.aws.amazon.com/AmazonCloudWatch/latest/events/WhatIsCloudWatchEvents.html">CloudWatch Events</a> allows you to create rules that trigger based on AWS events, or on a periodic schedule. &nbsp;CloudWatch Events can be setup to respond to Amazon EC2 Service state changes, Amazon Simple Storage Service (S3) bucket operations, and other events automatically. Supported targets include <a href="https://aws.amazon.com/lambda/">AWS Lambda</a>, Amazon SNS, Amazon EC2 Systems Manager Run Command, and now Amazon EC2 Systems Manager Automation.</li> 
</ul> 
<p>With Automation as a supported CloudWatch Events target, you can take advantage of some interesting use cases. You can perform routine tasks better when you schedule tasks for specific days and times or after specific event patterns. In this blog, we are going to show examples of how you can use CloudWatch Events and Automation to automate repetitive tasks, such as periodically starting and stopping instances.</p> 
<p><span id="more-825"></span></p> 
<h3>Automatically stop and start instances on weekends</h3> 
<p>Identifying and automatically stopping unused non-production instances in your account can save costs and improve efficiency of how you use your resources. Suppose you would like to automatically stop an instance every Friday evening and start it back on Monday morning. You can easily accomplish this using two CloudWatch Events that triggers an Automation Document for stopping and starting instances.</p> 
<h3>Create an Automation Document</h3> 
<p>For this example, follow the steps to <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/automation-createdoc.html">create an Automation Document</a>. The following code can be used to quickly create the Document.</p> 
<pre><code class="lang-json">{
&quot;description&quot;:&quot;Systems Manager Automation Demo - Start Instances via CWE&quot;,
&quot;schemaVersion&quot;:&quot;0.3&quot;,
&quot;parameters&quot;:{
&quot;automationRoleArn&quot;:{
&quot;type&quot;:&quot;String&quot;,
&quot;description&quot;:&quot;(Required) The ARN of the role that allows Automation to perform the actions on your behalf.&quot;
},
&quot;instanceIds&quot;:{
&quot;type&quot;:&quot;StringList&quot;,
&quot;description&quot;:&quot;(Required) The Instance ID(s) to Stop or Start.&quot;
},
&quot;state&quot;:{
&quot;type&quot;:&quot;String&quot;,
&quot;description&quot;:&quot;(Required) The state you would like the Instance(s) placed in. Options are: running | stopped&quot;
}
},
&quot;assumeRole&quot;:&quot;{{automationRoleArn}}&quot;,
&quot;mainSteps&quot;:[
{
&quot;name&quot;:&quot;startStopInstance&quot;,
&quot;action&quot;:&quot;aws:changeInstanceState&quot;,
&quot;maxAttempts&quot;:2,
&quot;timeoutSeconds&quot;:120,
&quot;onFailure&quot;:&quot;Continue&quot;,
&quot;inputs&quot;:{
&quot;InstanceIds&quot;:[&quot;{{instanceIds}}&quot;],
&quot;DesiredState&quot;:&quot;{{state}}&quot;
}
}
]
}</code></pre> 
<h3>Steps to create CloudWatch event rules to trigger Automation</h3> 
<p>After you have created the Document and saved it, you can create two CloudWatch event rules that automatically trigger at specific times.</p> 
<p><strong>Step 1</strong>. In the AWS Management Console, choose CloudWatch, Events, Rules and Create rule.</p> 
<p><img class="alignnone size-full wp-image-854" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/07/24/CWERules.png" alt="" width="1152" height="603" /></p> 
<p><strong>Step 2:&nbsp;</strong>&nbsp;Under <strong>Event Source</strong>, choose <strong>Schedule</strong>, <strong>Cron expression</strong>. To stop specified instances automatically at 6 PM every Friday, enter the following cron expression to trigger the rule:</p> 
<p><em>0 18 ? * FRI *</em></p> 
<p><img class="alignnone size-full wp-image-945" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/07/25/CR1-1.png" alt="" width="1021" height="636" /></p> 
<p>&nbsp;</p> 
<p><strong>Step 3:</strong> Under Targets, choose <strong>Add target</strong>, <strong>SSM Automation</strong>.</p> 
<p><strong>Step 4:</strong>&nbsp;For Document, select the Automation Document you saved for stopping and starting specified instances.</p> 
<p><strong>Step 5:</strong>&nbsp;For Configure document version, choose Default or a particular version number.</p> 
<p><strong>Step 6:</strong>&nbsp;Choose <strong>‘Constant’</strong> automation &nbsp;and enter the enter instance ID that you would like to be stopped automatically per the rule that you are creating. You can also choose&nbsp;<strong>‘Input Transformer’</strong> to provide custom inputs based on a template.</p> 
<p><img class="alignnone size-full wp-image-861" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/07/24/Targets.png" alt="" width="785" height="822" /></p> 
<p><strong>Step 7:</strong>&nbsp;Provide permission for CloudWatch event to call SSM Start Automation Execution. You can either create an existing role that you previously created or create a new role.</p> 
<p><strong>Step 8:</strong>&nbsp;Choose <strong>Configure details</strong>, and enter a name and description for your rule. Ensure that Enabled is selected.</p> 
<p><strong>Step 9:</strong>&nbsp;Choose <strong>Create rule</strong>.</p> 
<p>Your rule is now created and automatically executes every Friday at 6 PM to stop your specified instance. To start the instance back up say on Monday morning, repeat the steps to create another CloudWatch event rule, set your cron expression to Monday AM at your desired time, and target the same Automation Document. Make sure you provide “running” as your desired state.</p> 
<p>With this setup you can now automatically stop and start your instances, thus using your resources optimally.</p> 
<h3>Additional methods to trigger Automation</h3> 
<p>Outside of setting up an Automation workflow to be triggered on a schedule, you can also trigger executions based on event patterns. For example, you can setup a CloudWatch event on a&nbsp;<a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/systems-manager-paramstore.html">Parameter Store</a> value. Based on changes to the value you can trigger an Automation workflow. You can create&nbsp;a Parameter Store key/value to store AMI Ids which you typically use to create golden images for your organization. Every time you change the value of the key to a new AMI ID, you can setup a CloudWatch event rule on that parameter and target Automation. The target can point either to your custom Document or the <em>AWS-UpdateWindowsAMI</em> Document published by AWS. This automatically creates a new image with the latest updates that you can provide as inputs to your CI/CD pipeline or to Auto Scaling groups. For your reference, here is a blog that talks about how you can <a href="https://aws.amazon.com/blogs/mt/windows-ami-patching-and-maintenance-with-amazon-ec2-systems-manager-2/">update and patch your Windows AMIs</a>&nbsp;using Automation.</p> 
<p><img class="alignnone size-full wp-image-857" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/07/24/PS.png" alt="" width="1009" height="852" /></p> 
<p>&nbsp;</p> 
<h3>Conclusion</h3> 
<p>Automation simplifies common system maintenance and deployment tasks. By using CloudWatch Events, you can orchestrate task execution based on any events relating to AWS services. You can also trigger your predefined workflows on a schedule. Using this integration, you can easily orchestrate management of your resources and expect your workflows to perform tasks at scale automatically.</p> 
<p><strong>About the author</strong></p> 
<p><a href="https://www.linkedin.com/in/venkatkr/"><img class="size-full wp-image-831 alignleft" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/07/19/KRVenkt.jpg" alt="" width="119" height="160" /></a></p> 
<p><a href="https://www.linkedin.com/in/venkatkr/">Venkat Krishnamachari</a> is a Product Manager in the Amazon EC2 Systems Manager team. Venkat is excited by the opportunities presented by cloud computing, and loves helping customers benefit from the value of efficient infrastructure and management. In his personal time Venkat volunteers with NGOs and loves producing live theater and music shows.</p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/mt/tag/amazon-cloudwatch-events/" rel="tag">Amazon Cloudwatch Events</a>, <a href="https://aws.amazon.com/blogs/mt/tag/aws-codedeploy/" rel="tag">AWS CodeDeploy</a>, <a href="https://aws.amazon.com/blogs/mt/tag/aws-opsworks/" rel="tag">AWS OpsWorks</a>, <a href="https://aws.amazon.com/blogs/mt/tag/documents/" rel="tag">Documents</a>, <a href="https://aws.amazon.com/blogs/mt/tag/ec2-systems-manager/" rel="tag">EC2 Systems Manager</a>, <a href="https://aws.amazon.com/blogs/mt/tag/ec2-windows/" rel="tag">EC2 Windows</a>, <a href="https://aws.amazon.com/blogs/mt/tag/maintenance-window/" rel="tag">Maintenance Window</a>, <a href="https://aws.amazon.com/blogs/mt/tag/patch-complaince/" rel="tag">Patch Complaince</a>, <a href="https://aws.amazon.com/blogs/mt/tag/patch-manager/" rel="tag">Patch Manager</a>, <a href="https://aws.amazon.com/blogs/mt/tag/ssm/" rel="tag">SSM</a>, <a href="https://aws.amazon.com/blogs/mt/tag/state-manager/" rel="tag">State Manager</a></span> 
</footer> 
</article> 
<article class="post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="b post-title" property="name headline">Maintenance Windows: Support for New Task Types Using Amazon EC2 Systems Manager</b> 
<footer class="meta">
by 
<span property="author" typeof="Person"><span property="name">Lavanya Krishnan</span></span> | on 
<time property="datePublished" datetime="2017-08-16T10:50:46+00:00">16 AUG 2017</time> | in 
<span class="categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/amazon-ec2-systems-manager/" title="View all posts in Amazon EC2 Systems Manager"><span property="articleSection">Amazon EC2 Systems Manager</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools"><span property="articleSection">Management Tools</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/maintenance-windows-support-for-new-task-types-using-amazon-ec2-systems-manager/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog=""><span class="span icon-share"></span>&nbsp;Share</a> 
<ul> 
</ul> 
</footer> 
<p>In <a href="https://aws.amazon.com/ec2/systems-manager">Amazon EC2 Systems Manager</a>, the <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/systems-manager-maintenance.html">Maintenance Windows</a> service allows you to define a set of tasks, along with the instances where those tasks should be run and a run schedule. In this post, I talk about a new feature for Maintenance Windows—support for New Task types.</p> 
<p>Maintenance Windows now supports Systems Manager Automation documents, AWS Step Functions tasks, and AWS Lambda functions as tasks, including support for Parameter Store (when using Step Functions and Lambda).&nbsp;This allows you to perform complex workflows on your instances, such as patching a server running SQL Server using an Automation document.</p> 
<p>In this post, I show you the steps for executing this example and walk through the required configuration steps one-by-one.</p> 
<p><span id="more-1127"></span></p> 
<h4>Walkthrough</h4> 
<p>In this walkthrough, you learn how to create a maintenance window with an Automation task type. This task stops an instance, creates snapshots of attached EBS volumes using a Lambda function, restarts the instance, checks for missing Windows updates using another Lambda function, and installs the missing updates. The walkthrough includes the following steps:</p> 
<ul> 
<li>Set up IAM users and roles.</li> 
<li>Create Lambda functions.</li> 
<li>Create an Automation document.</li> 
<li>Create an EC2 instance.</li> 
<li>Create a maintenance window.</li> 
<li>Register an Automation task with the maintenance window.</li> 
</ul> 
<h4>Set up IAM users and roles</h4> 
<p>Because maintenance windows run on a schedule without a user taking specific actions, you need to create a role that grants the maintenance window the appropriate permissions to run the Automation document you’re creating. Similarly, a role needs to be created for the Automation document that grants the permissions to perform the actions in the document. Finally, create a role for the Lambda function so the function can take EBS snapshots.</p> 
<ol> 
<li>Create a user with Systems Manager full access as defined in <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/sysman-configuring-access-policies.html#sysman-access-user">Create a User Account for Systems Manager</a>.</li> 
<li>Create an instance role for Systems Manager as defined in <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/sysman-configuring-access-policies.html#sysman-configuring-access-role">Create a Role for Systems Manager Managed Instances</a>.</li> 
<li>Create a role for Systems Manager Automation to perform actions as defined in <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/automation-permissions.html#automation-role">Create an IAM Role for Automation</a> and <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/automation-permissions.html#automation-trust2">Add a Trust Relationship for Automation</a>.</li> 
<li>Create a role for the Systems Manager to allow Lambda functions to perform actions as defined in <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/automation-simpatch.html#automation-pet2">Create an IAM Role for AWS Lambda</a> 
<ul> 
<li>Attach a policy: <strong>AmazonEC2FullAccess.</strong></li> 
<li>Add a <strong>lambda.amazonaws.com</strong> trust relationship (similar to what was done in <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/automation-permissions.html#automation-trust2">Add a Trust Relationship for Automation</a> but replacing ssm.amazonaws.com with lambda.amazonaws.com).</li> 
</ul> </li> 
<li>Create a role for the Systems Manager maintenance window to perform actions as defined in <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/sysman-maintenance-permissions.html#sysman-maintenance-perm-console">Controlling Access to Maintenance Windows Using the AWS Console</a>. 
<ul> 
<li>Attach the iam:PassRole policy to this role for passing the Automation role created earlier (similar to what was defined for the Automation role in <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/automation-permissions.html#automation-passpolicy">Attach the iam:PassRole Policy</a>).</li> 
</ul> </li> 
</ol> 
<h4>Create Lambda functions</h4> 
<p>Create two Lambda functions:</p> 
<ul> 
<li>One to initiate the creation of an EBS snapshot.</li> 
<li>One to check the status of the snapshot creation so you can wait for the snapshot to be created.</li> 
</ul> 
<p>Here are the steps to create these functions.</p> 
<ol> 
<li>Open the AWS Lambda console at <a href="https://console.aws.amazon.com/lambda/">https://console.aws.amazon.com/lambda/</a>.</li> 
<li>Choose <strong>Create a Lambda function</strong>.</li> 
<li>On the <strong>Select blueprint</strong> page, choose <strong>Author from scratch</strong>.</li> 
<li>On the <strong>Configure triggers</strong> page, choose <strong>Next</strong>.</li> 
<li>On the <strong>Configure function</strong> page, for Name, type SSM-Automation-CreateSnapshots, and type an optional description.</li> 
<li>For <strong>Runtime</strong>, choose <strong>Python 2.7</strong>.</li> 
<li>In the <strong>Lambda function code</strong> section, delete the pre-populated code and paste the code in Table 1.</li> 
<li>In the <strong>Lambda function handler and role</strong> section, for <strong>Role</strong>, choose the service role for Lambda that you created earlier.</li> 
<li>Choose <strong>Next</strong>, <strong>Create function</strong>.</li> 
</ol> 
<p>Table 1.</p> 
<pre><code class="lang-python">from __future__ import print_function
import json
import boto3
print('Loading function')
#Expects instanceIds
def lambda_handler(event, context):
print(&quot;Received event: &quot; + json.dumps(event, indent=2))
# get EC2 client
ec2 = boto3.client('ec2')
# find volumes for given instances
response = ec2.describe_volumes(
Filters=[
{
'Name': 'attachment.instance-id',
'Values': [ event['instanceIds'] ],
},
]
)
# hold list of snapshot ids
snapshotIdList = []
# create snapshot of each volume id
for ids in response['Volumes']:
print('Creating snapshot for volumeId : %s' % ids['VolumeId'])
# create snapshot
response = ec2.create_snapshot(
Description='New snapshot for test',
VolumeId=ids['VolumeId'],
DryRun=False
)
print('Created snapshotId : %s' % response['SnapshotId'])
# add snapshot id to be returned
snapshotIdList.append(response['SnapshotId'])
returnString = &quot;,&quot;.join(str(id) for id in snapshotIdList)
return returnString</code></pre> 
<ol> 
<li>Repeat steps 1–4 from the first Lambda function.</li> 
<li>On the <strong>Configure function</strong> page, for <strong>Name</strong>, type SSM-Automation-CheckSnapshots and type an optional description.</li> 
<li>For <strong>Runtime</strong>, choose <strong>Python 2.7</strong>.</li> 
<li>In the <strong>Lambda function code</strong> section, delete the pre-populated code and paste the code in Table 2.</li> 
<li>In the <strong>Lambda function handler and role</strong> section, for <strong>Role</strong>, choose the service role for Lambda that you created earlier.</li> 
<li>Choose <strong>Next</strong>, <strong>Create function</strong>.</li> 
</ol> 
<p>Table 2.<code class="lang-python"><br /> </code></p> 
<pre><code class="lang-python">from __future__ import print_function
import json
import boto3
print('Loading function')
#Expects snapshotIds
def lambda_handler(event, context):
print(&quot;Received event: &quot; + json.dumps(event, indent=2))
# get EC2 client
ec2 = boto3.client('ec2')
# get the snapshotIds passed
snapshotIds = event['snapshotIds'].split(',')
# check the state of each snapshot
for id in snapshotIds:
response = ec2.describe_snapshots(
SnapshotIds=[
id,
],
DryRun=False
)
# if the state is not completed then it can't continue, so throw an error
for state in response['Snapshots']:
print('SnapshotId ' + id + ' in state : %s' % state['State'])
if state['State'] != 'completed':
errorString = 'Unable to proceed, snapshot in ' + state['State'] + ' state for: ' + id
raise Exception(errorString)
return &quot;Snapshots completed.&quot;</code></pre> 
<h4>Create an Automation document</h4> 
<p>An Automation document allows you to create your own custom workflow using a series of steps. Automation has several predefined actions that when stitched together can create complex and robust workflows.</p> 
<p>In this example, you use a few of these actions to build a custom workflow, such as <strong>aws:changeInstanceState</strong>, <strong>aws:invokeLambdaFunction</strong>, <strong>aws:sleep</strong> and <strong>aws:runCommand</strong>.&nbsp; The steps in this Automation document perform the following actions:</p> 
<ul> 
<li>Stop an EC2 instance</li> 
<li>Initiate the creation of volume snapshots with a Lambda function</li> 
<li>Wait a specified time while the snapshots are created</li> 
<li>Use another Lambda function to check if the snapshots have been successfully created</li> 
<li>Restart the EC2 instance</li> 
<li>Use a Run Command document to install updates on to the EC2 instance.</li> 
</ul> 
<p>Here are the steps to create the document.</p> 
<ol> 
<li>Open the Amazon EC2 console at https://console.aws.amazon.com/ec2/v2/home.</li> 
<li>In the navigation pane, choose <strong>Documents</strong>, <strong>Create Document</strong>.</li> 
<li>For <strong>Name</strong>, type CreateVolumeSnapshots.</li> 
<li>For <strong>Document Type</strong>, choose <strong>Automation</strong>.</li> 
<li>Delete the brackets in the <strong>Content</strong> box, and then paste the following JSON document.</li> 
<li>Choose <strong>Create Document</strong>.</li> 
</ol> 
<pre><code class="lang-json">{
&quot;schemaVersion&quot;:&quot;0.3&quot;,
&quot;description&quot;:&quot;Create EBS snapshots and update a Windows instance.&quot;,
&quot;assumeRole&quot;:&quot;{{AutomationAssumeRole}}&quot;,
&quot;parameters&quot;:{
&quot;instanceId&quot;:{
&quot;type&quot;:&quot;String&quot;,
&quot;description&quot;:&quot;(Required) Id of the instance&quot;
},
&quot;AutomationAssumeRole&quot;:{
&quot;type&quot;:&quot;String&quot;,
&quot;description&quot;:&quot;(Required) Role under which to execute this automation.&quot;
},
&quot;SnapshotTimeout&quot;:{
&quot;type&quot;:&quot;String&quot;,
&quot;description&quot;:&quot;(Required) Timeout for checking for snapshot completion.&quot;,
&quot;default&quot;: &quot;PT20M&quot;
}
},
&quot;mainSteps&quot;:[
{
&quot;name&quot;:&quot;stopInstance&quot;,
&quot;action&quot;:&quot;aws:changeInstanceState&quot;,
&quot;maxAttempts&quot;:1,
&quot;timeoutSeconds&quot;:300,
&quot;onFailure&quot;:&quot;Abort&quot;,
&quot;inputs&quot;:{
&quot;InstanceIds&quot;:[
&quot;{{ instanceId }}&quot;
],
&quot;DesiredState&quot;:&quot;stopped&quot;
}
},
{
&quot;name&quot;:&quot;createVolumeSnapshots&quot;,
&quot;action&quot;:&quot;aws:invokeLambdaFunction&quot;,
&quot;timeoutSeconds&quot;:120,
&quot;maxAttempts&quot;:1,
&quot;onFailure&quot;:&quot;Abort&quot;,
&quot;inputs&quot;:{
&quot;FunctionName&quot;:&quot;Automation-CreateSnapshots&quot;,
&quot;Payload&quot;:&quot;{\&quot;instanceIds\&quot;:\&quot;{{instanceId}}\&quot;}&quot;
}
},
{
&quot;name&quot;:&quot;waitForSnapshotsToCreate&quot;,
&quot;action&quot;:&quot;aws:sleep&quot;,
&quot;inputs&quot;:{
&quot;Duration&quot;:&quot;{{ SnapshotTimeout }}&quot;
}
},
{
&quot;name&quot;:&quot;checkVolumeSnapshots&quot;,
&quot;action&quot;:&quot;aws:invokeLambdaFunction&quot;,
&quot;timeoutSeconds&quot;:120,
&quot;maxAttempts&quot;:1,
&quot;onFailure&quot;:&quot;Abort&quot;,
&quot;inputs&quot;:{
&quot;FunctionName&quot;:&quot;Automation-CheckSnapshots&quot;,
&quot;Payload&quot;:&quot;{\&quot;snapshotIds\&quot;:\&quot;{{createVolumeSnapshots.Payload}}\&quot;}&quot;
}
},
{
&quot;name&quot;:&quot;startInstance&quot;,
&quot;action&quot;:&quot;aws:changeInstanceState&quot;,
&quot;maxAttempts&quot;:1,
&quot;timeoutSeconds&quot;:600,
&quot;onFailure&quot;:&quot;Abort&quot;,
&quot;inputs&quot;:{
&quot;InstanceIds&quot;:[
&quot;{{ instanceId }}&quot;
],
&quot;DesiredState&quot;:&quot;running&quot;
}
},
{
&quot;name&quot;:&quot;installMissingWindowsUpdates&quot;,
&quot;action&quot;:&quot;aws:runCommand&quot;,
&quot;maxAttempts&quot;:1,
&quot;timeoutSeconds&quot;:14400,
&quot;onFailure&quot;:&quot;Continue&quot;,
&quot;inputs&quot;:{
&quot;DocumentName&quot;:&quot;AWS-InstallWindowsUpdates&quot;,
&quot;InstanceIds&quot;:[
&quot;{{ instanceId }}&quot;
],
&quot;Parameters&quot;:{}
}
}
]
}</code></pre> 
<h4>Create an EC2 instance</h4> 
<p>To try out the Automation document, you need to have an instance running and managed by Systems Manager.&nbsp; For this example, use a Windows instance.</p> 
<p>Create an EC2 instance that uses the Systems Manager instance role created earlier. For more information, see <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/sysman-configuring-access-policies.html#sysman-create-instance-with-role">Create an Amazon EC2 Instance that Uses the Systems Manager Role</a>.</p> 
<h4>Create a maintenance window</h4> 
<p>Maintenance Windows let customers set up recurring schedules to perform defined actions on their instances.&nbsp; Each maintenance window has a schedule, duration, set of registered targets, and set of registered tasks to be performed against the targets. In this example, you create a maintenance window so it can be the initiator of the Automation task created earlier.</p> 
<p>Create a maintenance window and assign the new instance as a target. For more information, see <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/sysman-maintenance-console.html">Maintenance Window Console Walkthrough</a>.</p> 
<h4>Register an Automation task with the maintenance window</h4> 
<p>With the maintenance window created, you can now register an Automation task to run the Automation document and pass it the necessary parameters.</p> 
<ol> 
<li>Open the Amazon EC2 console at <a href="https://console.aws.amazon.com/ec2/v2/home">https://console.aws.amazon.com/ec2/v2/home</a>.</li> 
<li>In the navigation pane, choose <strong>Maintenance Windows</strong> and select the new maintenance window. Enter the following values: 
<ul> 
<li>For <strong>Actions</strong>, choose <strong>Register automation task</strong>.</li> 
<li>For <strong>Document</strong>, choose the CreateVolumeSnapshots document.</li> 
<li>For <strong>Task Priority</strong>, specify a priority for this task. 1 is the highest priority. Tasks in a maintenance window are scheduled in priority order with tasks that have the same priority scheduled in parallel.</li> 
<li>In the <strong>Target by</strong> section, choose <strong>Selecting registered target groups</strong> and select the target that you created earlier.</li> 
<li>In the <strong>Parameters</strong> section, for <strong>Execute</strong> <strong>on</strong>, specify 1. For <strong>Stop after</strong>, specify 1.</li> 
<li>For <strong>Role</strong>, specify the maintenance window role ARN created earlier.</li> 
<li>In the <strong>Input Parameters</strong> section, for <strong>AutomationAssumeRole</strong>, specify the Automation role ARN. Enter a timeout for waiting for the snapshots to complete. For InstanceId, type the instance ID of the instance created earlier.</li> 
</ul> </li> 
<li>Choose <strong>Register automation task</strong>.</li> 
</ol> 
<p>Most of the steps for registering a task in the AWS Management Console can be executed using AWS CLI commands instead.&nbsp; Furthermore, these steps could as easily be executed using the AWS SDK with Java, SDK for Python (Boto), or any of the other languages supported. This gives you many options when working with an AWS service. The following code examples use the AWS CLI for creating a maintenance window, registering a target with that maintenance window, and registering an Automation task using the Automation document created earlier.</p> 
<ol> 
<li>If needed, follow the steps to get started on creating a maintenance window with the AWS CLI in <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/sysman-maintenance-cli.html">Maintenance Window CLI Walkthrough</a>.</li> 
<li>Run the following CLI command and find the WindowId value for the maintenance window created earlier.<br /> <strong><em>aws ssm describe-maintenance-windows</em></strong><br /> This command returns the following, noting that the values for WindowId, name, description, and other fields below are fictional examples:<p></p> <pre><code class="lang-json">{
&quot;WindowIdentities&quot;: [
{
&quot;WindowId&quot;: &quot;mw-abc1234e3ddc9e286&quot;,
&quot;Name&quot;: &quot;MW1&quot;,
&quot;Description&quot;: &quot;MW1 description&quot;,
&quot;Enabled&quot;: true,
&quot;Duration&quot;: 2,
&quot;Cutoff&quot;: 1
}
]
}</code></pre> </li> 
<li>Run the following CLI command and find the WindowTargetId value for the instance that was assigned when you created the maintenance window.</li> 
</ol> 
<p><em>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <strong>aws ssm describe-maintenance-window-targets –window-id “mw-abc1234e3ddc9e286”</strong> </em></p> 
<p>This command returns the following:</p> 
<pre><code class="lang-json">{
&quot;Targets&quot;: [
{
&quot;WindowId&quot;: &quot;mw-abc1234e3ddc9e286&quot;,
&quot;WindowTargetId&quot;: &quot;2ecce06f-130c-41a3-870c-d36deff6cbba&quot;,
&quot;ResourceType&quot;: &quot;INSTANCE&quot;,
&quot;Targets&quot;: [
{
&quot;Key&quot;: &quot;InstanceIds&quot;,
&quot;Values&quot;: [
&quot;i-000a0a0ca4caf9861&quot;
]
}
],
&quot;OwnerInformation&quot;: &quot;test&quot;,
&quot;Name&quot;: &quot;test&quot;,
&quot;Description&quot;: &quot;test description&quot;
}
]
}</code></pre> 
<p>4. Run the following CLI command to register the Automation task to the maintenance window.<code class="lang-json"><br /> </code></p> 
<p><strong><em>aws ssm register-task-with-maintenance-window –window-id “mw-abc1234e3ddc9e286” –targets “Key=WindowTargetIds,Values=2ecce06f-130c-41a3-870c-d36deff6cbba” –task-arn “CreateVolumeSnapshots” –service-role-arn “arn:aws:iam::111111111111:role/MaintenanceWindowRole” –task-type “AUTOMATION” –task-invocation-parameters “Automation={Parameters={instanceId=i-000a0a0ca4caf9861,AutomationAssumeRole=arn:aws:iam::111111111111:role/AutomationRole,SnapshotTimeout=PT20M}}” –priority 1 –max-concurrency 1 –max-errors 1 –name “Automation_Task1” –description “Automation_Task1 description”</em></strong></p> 
<p>This command returns the following:</p> 
<pre><code class="lang-json">{
&quot;WindowTaskId&quot;: &quot;563e10e1-7b9c-4285-8c0c-cb94912b2839&quot;
}</code></pre> 
<h4>View the maintenance window execution</h4> 
<p>A maintenance window is executed based on the schedule that was specified.&nbsp; After the maintenance window execution, results can be viewed in the History tab on the selected maintenance window landing page.</p> 
<h4>Conclusion</h4> 
<p>In this post, I showed you how to use the newly launched task types in Maintenance Windows to schedule and automate the execution of many common systems administration tasks. Using the maintenance window, you can now create different types of tasks, run your tasks when needed on specified targets, and get notified about any problems running these tasks. This helps you get the status on scheduled tasks, with details of the errors, enabling you to take appropriate action.</p> 
<hr /> 
<h4>About the Authors</h4> 
<p><img class="size-full wp-image-1146 alignleft" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/08/16/Profile-pic.jpeg" alt="" width="120" height="120" />Lavanya Krishnan is a Technical Product Manager in the EC2 Systems Manager team responsible for Patch Manager and Maintenance Window capabilities. Lavanya is passionate about building Enterprise and Cloud Products and Services. When not working, she loves to spend time with family, travel, read books and play board games.</p> 
<p>&nbsp;</p> 
<p>&nbsp;</p> 
<p><img class="size-full wp-image-1149 alignleft" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/08/16/Tracy.jpeg" alt="" width="119" height="160" />Tracy Williams is a Software Development Manager in the EC2 Systems Manager team and is responsible for Maintenance Window Capabilities. In his free time Tracy enjoys hiking, movies and sports cars.</p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/mt/tag/ec2-systems-manager/" rel="tag">EC2 Systems Manager</a>, <a href="https://aws.amazon.com/blogs/mt/tag/maintenance-window/" rel="tag">Maintenance Window</a></span> 
</footer> 
</article> 
<article class="post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="b post-title" property="name headline">Improving Security through Delegated Administration with Amazon EC2 Systems Manager Automation</b> 
<footer class="meta">
by 
<span property="author" typeof="Person"><span property="name">Venkat Krish</span></span> | on 
<time property="datePublished" datetime="2017-08-15T01:49:20+00:00">15 AUG 2017</time> | in 
<span class="categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/amazon-ec2-systems-manager/" title="View all posts in Amazon EC2 Systems Manager"><span property="articleSection">Amazon EC2 Systems Manager</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools"><span property="articleSection">Management Tools</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/improving-security-through-delegated-administration-with-amazon-ec2-systems-manager-automation/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog=""><span class="span icon-share"></span>&nbsp;Share</a> 
<ul> 
</ul> 
</footer> 
<p><a href="https://aws.amazon.com/ec2/systems-manager/automation/">EC2 Systems Manager Automation</a> simplifies common system maintenance and deployment tasks. You can create workflows to automate repetitive tasks such as systems configuration, deployment and maintenance. Workflows are authored in JSON and saved as <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/automation-createdoc.html">Automation documents</a>.</p> 
<p>Automation service operates in the context of the user that invokes the execution. Automation documents can be authored with an optional service role (also called an assume Role) with an attached managed policy (<a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/automation-permissions.html">AmazonSSMAutomationRole</a>).</p> 
<ul> 
<li><strong>When the service role is specified:</strong> The Automation service executes the document in the context of the role.</li> 
<li><strong>When the service role is not specified:</strong> The Automation service creates a temporary session in the context of the user and then executes the document.</li> 
</ul> 
<p>In this blog, we are going to show the two methods for executing Automation. If you are using Automation for the first time or when you would like to automate and execute simple workflows in the context of your Account, the service role is not required. When you would like to control the context in which Automation workflows are executed, and limit permissions needed by a user that executes workflows you will use the service role.</p> 
<p>Note: For Automation documents that you expect to run longer than 12 hours, you must specify a service role because the temporary session to execute Automation in the user’s context expires 12 hours after starting the execution.</p> 
<p><span id="more-1116"></span></p> 
<p>By including a service role in the Automation document, you can achieve higher security and control. Here’s how delegated administration can be accomplished in the context of personas, where the personas could be different users or the same users within the organization.</p> 
<ul> 
<li><strong>Author</strong> – Creates Automation documents in JSON. For example, a document can take a service role as one parameter, and an AMI ID as another parameter. The document can incorporate <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/automation-actions.html">Automation actions</a> such as aws:runInstances and awscreateTags to launch and tag instances per corporate IT policies. The author <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/ssm-sharing.html">shares the document </a>with other users in the organization. Every time someone executes this document, EC2 instances are crated with the specified tags.</li> 
<li><strong>Administrator</strong> – Manages the infrastructure and ensures that appropriate permissions allow users to perform their IT systems management and configuration tasks. For example, the administrator requires the author to create tags with values that help easily identify the instance, and enforces that a service role is used in the document to perform actions. The administrator determines which users can create and launch EC2 instances, and <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/automation-permissions.html#automation-passrole">configures permissions</a> to select roles and users to execute the Automation document.</li> 
<li><strong>Operator</strong> – Performs IT tasks. In this post, it is a user who needs to launch an EC2 instance. The user does not require permissions to launch EC2 instances as they have permissions to execute the Automation document.</li> 
</ul> 
<p>In this model, administrators can ensure that only users with permissions to execute the document are able to launch EC2 instances. Thus, you can avoid having to grant permissions directly to operators. The administrator can work with the author to also enforce IT policies on an ongoing basis.</p> 
<h3>Walkthrough</h3> 
<p><strong>To view this model in action, follow the steps below:</strong></p> 
<ol> 
<li>Create an IAM user and attach the following policy that explicitly denies the user permissions to launch EC2 instances: <pre><code class="lang-json">{
&quot;Version&quot;: &quot;2012-10-17&quot;,
&quot;Statement&quot;: [{
&quot;Effect&quot;:&quot;Deny&quot;,
&quot;Action&quot;: [&quot;ec2:*&quot;],
&quot;Resource&quot;:&quot;*&quot;
}]
}</code></pre> </li> 
<li>Login as the IAM user and <a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/LaunchingAndUsingInstances.html">launch an EC2 instance </a>via the console or AWS CLI. This step fails.</li> 
<li>Create a service role. Fpr more information see Task4: <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/automation-permissions.html#automation-passpolicy">Attach the iam:PassRole</a> Policy to your Automation Role.</li> 
<li>Create an Automation document and include the service role that you created in step 4. Allow permissions to execute the document for the IAM user that you created in step 1.</li> 
<li>Login as the IAM user and execute the Automation document. This step succeeds and you can successfully launch the EC2 instance.</li> 
</ol> 
<h3>Summary</h3> 
<p>Automation documents can be executed by any IAM user in their own context without requiring an additional service role. However, it is a best practice to create a service role and enforce delegated administration via Automation. This ensures higher security and control for resources, in addition to auditing. When you use the service role you can tightly scope user permissions. As an administrator, you should also use this model to perform your own operations, and improve safety when managing resources at scale.</p> 
<h3>About the author</h3> 
<p><a href="https://www.linkedin.com/in/venkatkr/"><img class="size-full wp-image-831 alignleft" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/07/19/KRVenkt.jpg" alt="" width="119" height="160" />Venkat Krishnamachari</a>&nbsp;is a Product Manager in the Amazon EC2 Systems Manager team. Venkat is excited by the opportunities presented by cloud computing, and loves helping customers benefit from the value of efficient infrastructure and management. In his personal time Venkat volunteers with NGOs and loves producing live theater and music shows.</p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/mt/tag/automation/" rel="tag">Automation</a>, <a href="https://aws.amazon.com/blogs/mt/tag/ec2-systems-manager/" rel="tag">EC2 Systems Manager</a></span> 
</footer> 
</article> 
<article class="post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="b post-title" property="name headline">Example Scenarios for AWS Config Continuous Monitoring of Amazon S3 Bucket Access Controls</b> 
<footer class="meta">
by 
<span property="author" typeof="Person"><span property="name">Catherine Dodge</span></span> | on 
<time property="datePublished" datetime="2017-08-14T10:36:21+00:00">14 AUG 2017</time> | in 
<span class="categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/aws-config/" title="View all posts in AWS Config"><span property="articleSection">AWS Config</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools"><span property="articleSection">Management Tools</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/example-scenarios-for-aws-config-continuous-monitoring-of-amazon-s3-bucket-access-controls/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog=""><span class="span icon-share"></span>&nbsp;Share</a> 
<ul> 
</ul> 
</footer> 
<p><a href="https://aws.amazon.com/about-aws/whats-new/2017/08/aws-config-supports-new-managed-rules-for-securing-amazon-s3-buckets/">Recently</a>, <a href="https://aws.amazon.com/config/">AWS Config</a> announced two new managed rules to detect Amazon S3 buckets that have overly permissive controls. You can now check your S3 buckets continuously for unrestricted public write access or unrestricted public read access. In addition, you can view compliance of all your S3 buckets against these rules, and receive notifications via Amazon SNS when permissions change. You can also view the permissions history in the Config console.</p> 
<p>With these new rules, you can view the historical state of bucket Access Control Lists (ACLs) and bucket policies, and you can identify when changes were made. If someone changes a bucket policy or a bucket ACL, the Config rule automatically re-evaluates the new effective access. The rules evaluate the ACL to determine whether any anonymous user or any AWS user is allowed read or write permissions. The bucket polices are evaluated using a semantic-based automated reasoning engine, which returns a compliance decision.</p> 
<p>“These AWS Config rules are backed by a new formal model of IAM semantics, offering a dramatic improvement over existing tools that rely on simple pattern matching, which often fails to capture the nuances of the IAM policy language,” said Bridgewater Associates engineer Dan Peebles. “For the first time, <span id="more-1092"></span>we can make strong universal statements about our S3 IAM policies and be confident that our assumptions aren’t violated. We’ve been keenly collaborating with AWS on this formal model during its development; it provides the foundation for future tools that will be game changers in our ability to reason about our AWS infrastructure.”</p> 
<p>Tracking configuration changes to S3 bucket ACLs and policies is valuable from a governance perspective. It tells you how and when a bucket permission was modified. You can use this information to troubleshoot operational issues and outages, and maintain audit compliance. In addition, by turning on CloudTrail Data Events for S3 buckets, you can receive full audit logs around who read or wrote objects to that S3 bucket.</p> 
<p>Learn more: <a href="http://docs.aws.amazon.com/awscloudtrail/latest/userguide/logging-management-and-data-events-with-cloudtrail.html#logging-data-events-with-the-cloudtrail-console">Logging Data Events with the CloudTrail Console</a></p> 
<p>In this post, we present an example scenario in detail.</p> 
<p>&nbsp;</p> 
<b>Use case: S3 Public Write Access Rule</b> 
<p>Granting all AWS users access to write to your S3 bucket is almost never an intended configuration. Ensuring that S3 bucket policies don’t provide unrestricted write access is a security best practice within AWS Security. Misconfigurations of the bucket policy that provide unrestricted write access can allow unauthorized users to add malicious content to a bucket and overwrite content.</p> 
<p>One scenario where you should be sure these rules are in place is after the acquisition of a new company. Often a large enterprise centrally manages a number of AWS accounts, ensuring consistent centralized controls are in place. When a new business unit joins the organization, with their own AWS assets, it can be difficult for a security team to quickly assess the security posture of the acquired business.</p> 
<p>As an engineer tasked with assessing the security posture of newly acquired accounts, you can turn on write access detection to quickly see the status across all buckets in a given account. First, log in to the Config console. Choose <strong>Add rule</strong> to see the list of rules. Type ‘write’ in the search bar to see the s3-bucket-public-write-prohibited rule. The following screenshot shows the Add rule page.</p> 
<p>&nbsp;</p> 
<p>&nbsp;</p> 
<p><img class="alignnone size-full wp-image-1093" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/08/07/Blog1.png" alt="" width="975" height="525" /></p> 
<p>&nbsp;</p> 
<p>&nbsp;</p> 
<p>Click the rule description, which opens the rule configuration page. The default values are set to trigger rule evaluation on any change to S3 resources. Click <strong>Save</strong> and the rule will be enabled for your account, with the status shown as Evaluating…</p> 
<p>&nbsp;</p> 
<p><img class="alignnone size-full wp-image-1094" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/08/07/Blog2.png" alt="" width="975" height="450" /></p> 
<p>&nbsp;</p> 
<p>In this scenario, rule evaluation is completed and returns a status of Noncompliant. The evaluation identifies one bucket belonging to the newly acquired business that has a resource policy granting public write access.</p> 
<p>&nbsp;</p> 
<p><img class="alignnone size-full wp-image-1095" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/08/07/Blog3.png" alt="" width="975" height="194" /></p> 
<p>&nbsp;</p> 
<p>The Annotation field provides information about which access control is Noncompliant: the bucket ACL, the bucket policy, or both. In the example that follows, the Annotation field notes that it is the bucket policy that violates the check.</p> 
<p>The Config rule marks the bucket resource as Noncompliant if either the bucket ACL or the bucket resource policy allow unrestricted public write access. If the bucket ACL and bucket policy are configured with different write accesses, this means that the controls are in conflict. Providing users visibility into these conflicts allows them to correct the conflict.</p> 
<p>In our scenario, the startup you have recently acquired attempted to apply a policy to restrict bucket access to their AWS users logged on using multi-factor authentication (MFA). This is the policy that was used:</p> 
<pre><code class="lang-json">{
&quot;Version&quot;: &quot;2012-10-17&quot;,
&quot;Statement&quot;: [
{
&quot;Effect&quot;: &quot;Allow&quot;,
&quot;Principal&quot;: &quot;*&quot;,
&quot;Action&quot;: &quot;s3:PutObject*&quot;,
&quot;Resource&quot;: &quot;arn:aws:s3:::config-write-test/*&quot;,
&quot;Condition&quot;: {
&quot;Bool&quot;: {
&quot;aws:MultiFactorAuthPresent&quot;: &quot;true&quot;
}
}
}
]
}
</code></pre> 
<p>Here the condition key aws:MultiFactorAuthPresent isn’t sufficient to restrict public write access. Since the Principal value is set to “*” the net effect of this policy is to restrict S3 write access to any AWS user in any account who is logged on with multi-factor authentication. Since anyone could create an AWS account, and enable login using MFA, this policy effectively grants public write permissions. There is no clause tying the principal to the account where the bucket is hosted. The ability to reason in this way about this net effect of a policy can be quite difficult to do using simple scripts or using human inspection, but it is now possible using the semantic-based automated reasoning tool for policies developed by AWS.</p> 
<p>An example of an appropriately configured S3 resource policy that only allows access from a given VPC is shown in the following example:</p> 
<pre><code class="lang-json">{
&quot;Version&quot;: &quot;2012-10-17&quot;,
&quot;Statement&quot;: [
{
&quot;Sid&quot;: &quot;Open access to vpc-01234567&quot;,
&quot;Effect&quot;: &quot;Allow&quot;,
&quot;Principal&quot;: &quot;*&quot;,
&quot;Action&quot;: &quot;s3:*&quot;,
&quot;Resource&quot;: [
&quot;arn:aws:s3:::config-write-test/*&quot;
],
&quot;Condition&quot;: {
&quot;StringEquals&quot;: {
&quot;aws:sourceVpc&quot;: &quot;vpc-01234567&quot;
}
}
},
{
&quot;Sid&quot;: &quot;Deny access to non vpc-012345667&quot;,
&quot;Effect&quot;: &quot;Deny&quot;,
&quot;Principal&quot;: &quot;*&quot;,
&quot;Action&quot;: &quot;*&quot;,
&quot;Resource&quot;: [
&quot;arn:aws:s3:::config-write-test/*&quot;
],
&quot;Condition&quot;: {
&quot;StringNotEqualsIfExists&quot;: {
&quot;aws:sourceVpc&quot;: &quot;vpc-01234567&quot;
}
}
}
]
}
</code></pre> 
<p>The semantic-based automated reasoning tool for policies used by the Config rule correctly determines that the policy correctly limits writes to those coming from the selected VPC. By limiting write access to a given VPC, we can now re-evaluate the rule, and we are now Compliant.</p> 
<p><img class="alignnone size-full wp-image-1096" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/08/07/Blog4.png" alt="" width="975" height="194" /></p> 
<p>Enabling these rules in every account owned by a newly acquired company lets the central IT team within an organization quickly identify any misconfigurations that could pose a potential risk to the organization. If there are multiple accounts, the new <a href="https://aws.amazon.com/about-aws/whats-new/2017/07/aws-cloudformation-supports-multiple-account-and-region-provisioning-with-stackset/">StackSet</a> feature can be used to enable the Config rule across multiple accounts. The rule quickly pinpoints the source of the misconfiguration, enabling quick remediation to bring the account in line with best practices.</p> 
<p>&nbsp;</p> 
<b>Checking unrestricted public read access</b> 
<p>&nbsp;</p> 
<p>You can also check for unrestricted public read access, using a similar new rule. For media or website content, granting public access to read your S3 bucket is the desired configuration. However, if that isn’t your use case, unrestricted read access is likely a misconfiguration. Enabling the s3-bucket-public-read-prohibited rule ensures that you are alerted to any misconfigured buckets that allow public read access today. After any misconfigurations are fixed, the Config rule will continuously re-evaluate any changes made in the future to ensure continued compliance.</p> 
<p>To enable the rule, follow the steps outlined earlier for the public write rule, instead using ‘read’ as the rule search term. After rule evaluation is enabled and completed, the console will report a Compliant status if no S3 buckets allow unrestricted public write access. If any buckets do allow unrestricted public read access, the status will be reported as Noncompliant, along with the number of Noncompliant buckets. The annotation provided explains which access control is Noncompliant, either the bucket ACL, the bucket resource policy, or both.</p> 
<p>&nbsp;</p> 
<b>Summary</b> 
<p>By enabling these new rules, you can now easily monitor S3 access controls and ensure that access to your data is configured as you expect. These rules can be accessed using the AWS Management Console, as shown here, or evaluated using the <a href="http://aws.amazon.com/cli">AWS CLI</a> or <a href="http://aws.amazon.com/tools">AWS SDKs</a>.</p> 
<p>&nbsp;</p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/mt/tag/aws-config/" rel="tag">AWS Config</a>, <a href="https://aws.amazon.com/blogs/mt/tag/config-rules/" rel="tag">Config rules</a></span> 
</footer> 
</article> 
<article class="post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="b post-title" property="name headline">Secure, Scalable, and Efficient Instance Management Using Amazon EC2 Run Command</b> 
<footer class="meta">
by 
<span property="author" typeof="Person"><span property="name">Ananth Vaidyanathan</span></span> | on 
<time property="datePublished" datetime="2017-08-08T13:50:03+00:00">08 AUG 2017</time> | in 
<span class="categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/amazon-ec2-systems-manager/" title="View all posts in Amazon EC2 Systems Manager"><span property="articleSection">Amazon EC2 Systems Manager</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools"><span property="articleSection">Management Tools</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/secure-scalable-and-efficient-instance-management-using-amazon-ec2-run-command/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog=""><span class="span icon-share"></span>&nbsp;Share</a> 
<ul> 
</ul> 
</footer> 
<p><em>This post was written by Miguel Jo&atilde;o, Cloud Software Engineer at OutSystems.</em></p> 
<p>The OutSystems low-code development platform allows users to create and deliver high-quality web and mobile apps a lot faster, leveraging all the advantages of visual programming with few of the drawbacks. Of course, providing this high productivity, enterprise-grade <a href="https://en.wikipedia.org/wiki/Platform_as_a_service">Platform-as-a-Service</a> (PaaS) solution can be challenging. For us at OutSystems, those challenges ended up inspiring us to build custom solutions to manage large infrastructures.</p> 
<p>We were working on a custom offer for clients that would enable them to build their tailored apps. That led us to deploy our own orchestration processes.</p> 
<ul> 
<li>Instead of only using the common configuration management tools, we had to deploy a <strong>custom remote command execution environment</strong>. This resulted in a tight control over all the steps in the deployment and configuration of the infrastructure.</li> 
<li>We needed to provide an <strong>enterprise-grade PaaS solution with secure access, data integrity, and high availability</strong>.</li> 
<li>This solution must scale to meet future demand, and for the long run we’re talking about <strong>1M+ instances</strong>.</li> 
<li>We had to <strong>ensure a path for the solution to evolve</strong> without disrupting the customer service.</li> 
</ul> 
<p>Sounds complicated, right? Well, it was, especially when you consider that we had to apply our custom environment to an existing underlying infrastructure while keeping the security, isolation, and evolution requirements.</p> 
<p>The end result was a leaner and more secure solution. <a href="https://aws.amazon.com/ec2/run-command">Amazon EC2 Run Command</a> service improved the stability of our orchestration processes (error ratio reduction of over 80%), and the performance (10–20 times faster).</p> 
<p><span id="more-1024"></span></p> 
<h3>Problem: Difficult to manage instance proliferation</h3> 
<p>We designed with the standardization of the underlying infrastructure that supports our PaaS offer in mind. However, the need to respond to the specific needs of our enterprise customers led to the development of an orchestration process that takes advantage of configuration management tools like Chef for the initial and base configuration. Afterwards, we extended that orchestration to support the customization using on-demand remote command execution.</p> 
<p>The adoption of these orchestration processes in our cloud services has grown, and it now supports all of our paid and free PaaS offers, and some of our R&amp;D internal development quality assurance requirements.</p> 
<p>We currently provision <a href="https://aws.amazon.com/ec2/">EC2</a> instances and <a href="https://aws.amazon.com/rds/">Amazon RDS</a> instances to meet our needs in six different AWS Regions, in an automated fashion, 24/7. Our current infrastructure landscape consists of more than a thousand EC2 instances, and hundreds of RDS instances with many different software versions and software configurations. We have Windows and Linux operating systems, and at least two database flavors: Microsoft SQL Server and Oracle. This graphic shows the management nightmare for which we signed up.</p> 
<p><img class="size-full wp-image-1030 alignnone" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/08/01/infra_growth-1.png" alt="" width="500" height="327" /></p> 
<h3>Temporary solution (not scalable): SSH and ESB</h3> 
<p>Early in the PaaS project, we determined that direct remote commands would control the infrastructure servers, and we designed the orchestration processes to support that.</p> 
<p>The result was a remote command architecture with an <a href="https://en.wikipedia.org/wiki/Enterprise_service_bus">Enterprise Service Bus (ESB)</a> and <a href="https://en.wikipedia.org/wiki/Secure_Shell">secure shell connections (SSH)</a>. The ESB served as a central point of convergence for all remote connections managing the cloud servers, allowing remote commands to be executed through a synchronous SSH. The orchestration processes invoke the remote command execution via the ESB, and expect a callback from the ESB when the command finishes executing.</p> 
<p><img class="size-full wp-image-1034 alignnone" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/08/01/old_arch.png" alt="" width="450" height="303" /></p> 
<p>However, this solution rapidly began to show its limitations:</p> 
<ul> 
<li><strong>Performance overhead</strong> due to connection handshake and authentication</li> 
<li><strong>Increased error rate</strong> due to <strong>instability</strong> in the network and long standing connections</li> 
<li><strong>Limited parallelism</strong> due to concurrent number of remote long standing connections in the ESB (we started to see instability after 40 concurrent remote executions per ESB node)</li> 
<li><strong>Security concerns</strong> about having SSH inbound traffic on the instances for orchestration purposes, and all the hassle of managing the SSH authentication best practices (keys vs. passwords)</li> 
</ul> 
<p>With the growth in demand for our cloud services, we had to consider other options immediately. Before we committed to searching for or developing better alternatives that would scale for 1M+ instances, AWS answered our prayers with the <a href="https://aws.amazon.com/ec2/run-command/">EC2 Run Command</a> feature.</p> 
<h3>Better solution: Scalable, secure remote commands</h3> 
<p>After a short assessment of Run Command, we realized that it would allow us to greatly improve our efforts and our custom orchestration systems, increasing both reliability and performance. We started changing our orchestration to use this new feature, and replaced the remote command execution engine with Run Command.</p> 
<p><img class="size-full wp-image-1035 alignnone" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/08/01/new_arch.png" alt="" width="450" height="304" /></p> 
<p>Sending the remote command through Run Command removed the SSH connectivity requirement, eliminating security concerns. The feature also keeps network instability concerns at bay because keeping long-standing connections during the command execution is no longer necessary. It’s all asynchronous.</p> 
<p>The most significant changes in our orchestration were:</p> 
<ul> 
<li>Roll out (re-create) EC2 instances with <a href="http://docs.aws.amazon.com/IAM/latest/UserGuide/introduction.html">IAM</a> roles</li> 
<li>Deploy updated EC2Config and SSM Agent services on the EC2 instances</li> 
<li>Implement the callback after execution end, based on the S3 output files, using an AWS Lambda function that runs when a new output file is created</li> 
<li>Change our orchestration command execution engine module to invoke Run Command (using SSM API)</li> 
</ul> 
<p>We were able to evaluate, design, develop, test, and deploy the changes to our orchestration processes in approximately two months. This opened the door to a new growth spurt in our cloud services, mainly because the parallelism limitations were gone.</p> 
<h3>Replacing the ESB services: Additional details</h3> 
<p>We had our system architected to be modular, so replacing the ESB services with the Run Command services seemed like it would be straightforward. But as with any new development, we had to deal with some unexpected challenges. No straightforward replacement—after all, where would be the fun in that?</p> 
<ul> 
<li>To use Run Command, each EC2 instance had to have an associated instance role. Unfortunately, at the time, it was not possible to associate an IAM role with a running instance. Instead, we re-created about 80% of our EC2 instances to activate Run Command. Thankfully, <a href="https://aws.amazon.com/about-aws/whats-new/2017/02/new-attach-an-iam-role-to-your-existing-amazon-ec2-instance/">it is now possible</a> to add an instance role to an existing EC2 instance without having to re-create it</li> 
<li>Run Command requires agents installed in the EC2 instances. However, the configuration and execution outputs of these agents differ between Windows and Linux systems. At the time, to use Run Command on Windows, we needed to have the EC2Config service running. For Linux, we needed the SSM Agent service. These two different applications require different configurations, and as such, the output log files prefixes in the S3 output bucket were also different. So, we had to make allowances for these differences as part of the process. Nowadays, the <span style="text-decoration: underline">SSM Agent service is available for both Windows and Linux</span>, which simplifies the configurations and eases the setup between different operating systems</li> 
<li>Managing the S3 bucket access across the few hundred different AWS accounts that require specific permissions is practically impossible. We had to get creative with the S3 bucket management for the Run Command outputs.<br /> Using a single bucket, each output log would be owned by the account hosting the EC2 instance where the log ran. No other user could access it, so we created a secondary S3 bucket and moved the output logs from the original bucket, fixing the object permissions. This way, we could keep the output logs secured in a bucket with restricted accesses, not allowing the instances to access it anymore. In the meantime, <span style="text-decoration: underline">new versions of the SSM Agent support changing the output log ownership in the bucket</span>.</li> 
</ul> 
<p>After it was all up and running, magic started to happen. Before, with the ESB solution, our average error rate was usually up to 5%, and it increased to over 20% during the second half of 2016. This growing error rate was a reflex of the ESB solution not keeping up with the growing demand. When we started using Run Command, the average error ratio dropped to values below 1%, regardless of the growth in demand. It seriously made our lives better, as you can see in the stability comparison:</p> 
<p><img class="size-full wp-image-1053 alignnone" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/08/01/stability-1.png" alt="" width="505" height="330" /></p> 
<p>Additionally, the Run Command solution improved the remote command execution average time by one order of magnitude: from 10 to 20 times faster. The solution allowed us to remove the bottlenecks in the ESB and the SSH connections, as well as improve stability by reducing the error rate. Here’s the performance comparison so you don’t have to take our word for it:</p> 
<p><img class="size-full wp-image-1052 alignnone" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/08/01/performance.png" alt="" width="505" height="330" /></p> 
<p>The new Run Command feature responded as advertised. The end result is a faster, leaner, and more robust remote command execution engine that complies with our on-demand custom configuration orchestration requirements.</p> 
<h3>About the Author</h3> 
<p><a href="https://www.linkedin.com/in/migueljoao/">Miguel Jo&atilde;o</a><img class="alignleft size-full wp-image-1109" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/08/08/miguel.jpg" alt="" width="119" height="130" /> joined OutSystems R&amp;D in 2005, and became a Cloud Software Engineer in 2013. Since then, he’s been working on the Platform-as-a-Service offer of the industry-leading, low-code platform for mobile and web application development. Miguel is a technology enthusiast, and he is passionate about automation.</p> 
<p>&nbsp;</p> 
<p>&nbsp;</p> 
<p>&nbsp;</p> 
<p>&nbsp;</p> 
<hr /> 
<p><img class="alignnone wp-image-1111 size-full" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/08/08/oustsystems-logo-1.png" alt="" width="300" height="64" /></p> 
<hr /> 
<p><em>AWS is not responsible for the content or accuracy of this post. The content and opinions in this blog are solely those of the third party author. </em></p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/mt/tag/ec2-systems-manager/" rel="tag">EC2 Systems Manager</a>, <a href="https://aws.amazon.com/blogs/mt/tag/run-command/" rel="tag">Run Command</a></span> 
</footer> 
</article> 
<article class="post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="b post-title" property="name headline">Supercharge Multi-Account Management with AWS CloudFormation</b> 
<footer class="meta">
by 
<span property="author" typeof="Person"><span property="name">Adam McLean</span></span> | on 
<time property="datePublished" datetime="2017-08-04T10:17:17+00:00">04 AUG 2017</time> | in 
<span class="categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/aws-cloudformation/" title="View all posts in AWS CloudFormation"><span property="articleSection">AWS CloudFormation</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools"><span property="articleSection">Management Tools</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/supercharge-multi-account-management-with-aws-cloudformation/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog=""><span class="span icon-share"></span>&nbsp;Share</a> 
<ul> 
</ul> 
</footer> 
<p>As your use of Amazon Web Services evolves, you will probably outgrow your first account, and need to move into a multi-account model.</p> 
<p>There are plenty of benefits to using more than one AWS account:</p> 
<ul> 
<li><b>An administrative boundary:</b> I can choose how permissive or restrictive my policies are based on the account type. Separating user authority within an account can be complicated and error prone. Using separate accounts is often the answer.</li> 
<li><b>A workload boundary:</b> I can choose to peer (or not to peer) various workloads together within accounts, ensuring that my ‘blast radius’ for a poorly behaved application is minimized.</li> 
<li><b>A billing entity:</b> Detailed bills are generated at an account level. An account has higher ‘resolution’ than is afforded by billing tags, and can be easier to implement.</li> 
</ul> 
<p>However, management complexities increase using multiple accounts. How do you manage the administrative boundaries? Who can log in and how? How do you manage your baseline infrastructure, such as VPCs and CloudTrail? Is it possible to deploy these by hand and not make potentially critical mistakes?</p> 
<p>In this blog post I’ll explore ways to manage deployments in your multi-account AWS environment.</p> 
<p><span id="more-917"></span></p> 
<p>The broad answer to the questions above is to use infrastructure as code, and tools like <a title="AWS CloudFormation" href="https://aws.amazon.com/cloudformation" target="_blank" rel="noopener noreferrer">AWS CloudFormation</a>. CloudFormation gives you a language to describe your desired state, and have it implemented programmatically. For complex multi-account deployments, this can get difficult to manage quickly, especially for complex subjects such as IAM users, groups, polices, and roles.</p> 
<p>The recent release of <a title="AWS Orgnizations" href="https://aws.amazon.com/organizations/" target="_blank" rel="noopener noreferrer">AWS Organizations</a> has certainly helped with this complexity. Using policies, you can broadly permit or deny service use within your AWS account organizational structure. Layering these capabilities with consistently deployed IAM elements gets the most value from a multi-account model.</p> 
<b>A tool to help</b> 
<p>I’d like to introduce a tool I wrote while working with multiple AWS customers as a Professional Services Consultant. This tool allows you to describe complex multi-account IAM elements using simple YAML, and Jinja2 templates. Running a build produces a CloudFormation template per account that can be deployed in your preferred fashion.</p> 
<p>Some customers have even built a pipeline so that when the configuration YAML is changed, a build is run and deployed automatically. They’re managing multiple accounts completely hands-off, from a central source of truth!</p> 
<p>I’ll discuss the tool a bit. First, the tool assumes that you’re using a ‘parent’ account model where everyone logs in, or federates, into a single account. Then, users assume roles in the ‘child’ accounts for which they have permissions. This model was explored in more detail by an AWS customer with hundreds of accounts. For more information, see <a title="SEC315" href="https://youtu.be/CY-xvo8Cc54" target="_blank" rel="noopener noreferrer">(SEC315) AWS Directory Service Deep Dive</a> re:Invent session video.</p> 
<p>I’ve included a simplification of the model for reference. Your child accounts can be one or many.</p> 
<p><img class="alignnone size-medium wp-image-926" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/07/25/Parent-Child-Account-Model.png" alt="" width="708" height="303" /></p> 
<b>Tool walk-through</b> 
<h3>Prerequisites</h3> 
<p>To go through this walkthrough, you need the following:</p> 
<ul> 
<li>A bash environment</li> 
<li>A Python 2.7 interpreter</li> 
<li>At least two AWS accounts that you can experiment with. You can use AWS Organizations to create them programmatically</li> 
<li>The <a title="Tropsophere" href="https://github.com/cloudtools/troposphere" target="_blank" rel="noopener noreferrer">troposphere</a> and the <a title="Tropsophere" href="https://github.com/pallets/jinja" target="_blank" rel="noopener noreferrer">jinja2</a> libraries installed</li> 
</ul> 
<pre><code class="lang-bash">
sudo pip install troposphere
sudo pip install jinja2
</code></pre> 
<h3>Download the code</h3> 
<p>Clone or download the project from /awslabs/ on GitHub:</p> 
<pre><code class="lang-bash">
git clone git@github.com:awslabs/aws-iam-generator.git
</code></pre> 
<h3>Build your configuration file</h3> 
<p>Start with a simple configuration and grow it over time, as you would naturally evolve your AWS environment.</p> 
<p>Create a file called config.yaml in the downloaded projects root directory. Cut and paste the example configuration below into the file. <b>Substitute the account IDs with the account IDs that you’re using for this walkthrough.</b></p> 
<pre><code class="lang-yaml">
---
accounts:
central:
# Change to the ID of your central parent account.
id: 012345678910
parent: true
lab:
# Change to the ID of a child account for specific roles.
id: 109876543210
policies:
AssumeLabPowerUser:
description: Allow assumption of the PowerUser Role in the lab account
assume:
roles:
- PowerUser
accounts:
# Use the name you've given your account in the 'accounts' section.
- lab
in_accounts:
# Use the keyword 'parent' to match the account that has 'parent: true'
- parent
roles:
PowerUser:
trusts:
- parent
managed_policies:
- arn:aws:iam::aws:policy/PowerUserAccess
in_accounts:
# Use the keyword 'children' to match all accounts except the one marked 'parent: true'
- children
groups:
LabUsers:
managed_policies:
- arn:aws:iam::aws:policy/IAMSelfManageServiceSpecificCredentials
- arn:aws:iam::aws:policy/IAMUserChangePassword
- arn:aws:iam::aws:policy/IAMUserSSHKeys
- arn:aws:iam::aws:policy/IAMReadOnlyAccess
- AssumeLabPowerUser
in_accounts:
- parent
users:
TestUser:
groups:
- LabUsers
in_accounts:
- parent
</code></pre> 
<h3>What happens now?</h3> 
<p>Because you have two accounts, expect two CloudFormation templates to be created.</p> 
<p>The CloudFormation template for your <code>central</code> account should contain:</p> 
<ul> 
<li>A managed policy called <code>AssumeLabPowerUser</code>. The policy document permits sts::AssumeRole on your child account.</li> 
<li>A group called <code>LabUsers</code>. This group has built-in AWS policies attached to it to allow self service credential management. It also has the <code>AssumeLabPowerUser</code> policy attached that you created under the <code>policies:</code> section.</li> 
<li>A user called <code>TestUser</code> who is a member of the <code>LabUser</code> group.</li> 
</ul> 
<p>The CloudFormation template for your <code>lab</code> account should contain:</p> 
<ul> 
<li>A role called <code>PowerUser</code>. This role has a trust document that allows it to be assumed from the <code>central</code> account. The roles policy document is modeled from the AWS built-in PowerUserAccess policy document.</li> 
</ul> 
<h3>Run the build</h3> 
<p>Executing the build.py script reads the contents of the config.yaml file and creates CloudFormation templates in your output_templates/ directory. If the build is successful, you won’t see any output. When a build fails, the output should produce an meaningful error to help figure out what’s wrong. Most of the time, the problem is in the yaml formatting (usually, indentation).</p> 
<pre><code class="lang-bash">
python build.py
</code></pre> 
<p>If your build ran, you should see output in the <code>output_templates/</code> directory</p> 
<pre><code class="lang-bash">
ls -l output_templates/
-rw-r--r-- 1 user user Users 3367 Apr 10 10:14 central(012345678910)-IAM.template
-rw-r--r-- 1 user user Users 1680 Apr 10 10:14 lab(109876543210)-IAM.template
</code></pre> 
<p>You can see both of your CloudFormation templates. They are named so that you can easily identify the account in which they should be run. Also notice that your <code>central</code> template is about double the size of the <code>lab</code> template. This is expected as <code>central</code> contains a lot more information.</p> 
<h3>Explore the output</h3> 
<p>View the <code>central</code> template in your favorite viewer.</p> 
<p>Your managed policy is there, with the sts::AssumeRole correctly formed:</p> 
<pre><code class="lang-json">
...
&quot;AssumeLabPowerUser&quot;: {
&quot;Properties&quot;: {
&quot;Description&quot;: &quot;Allow assumption of the PowerUser role in the lab account&quot;,
&quot;Groups&quot;: [],
&quot;PolicyDocument&quot;: {
&quot;Statement&quot;: [
{
&quot;Action&quot;: &quot;sts:AssumeRole&quot;,
&quot;Effect&quot;: &quot;Allow&quot;,
&quot;Resource&quot;: &quot;arn:aws:iam::109876543210:role/PowerUser&quot;
}
],
&quot;Version&quot;: &quot;2012-10-17&quot;
},
&quot;Roles&quot;: [],
&quot;Users&quot;: []
},
&quot;Type&quot;: &quot;AWS::IAM::ManagedPolicy&quot;
},
...
</code></pre> 
<p>You can also see the group that uses this managed policy:</p> 
<pre><code class="lang-json">
....
&quot;LabUsersGroup&quot;: {
&quot;Properties&quot;: {
&quot;GroupName&quot;: &quot;LabUsers&quot;,
&quot;ManagedPolicyArns&quot;: [
&quot;arn:aws:iam::aws:policy/IAMSelfManageServiceSpecificCredentials&quot;,
&quot;arn:aws:iam::aws:policy/IAMUserChangePassword&quot;,
&quot;arn:aws:iam::aws:policy/IAMUserSSHKeys&quot;,
&quot;arn:aws:iam::aws:policy/IAMReadOnlyAccess&quot;,
{
&quot;Ref&quot;: &quot;AssumeLabPowerUser&quot;
}
],
&quot;Path&quot;: &quot;/&quot;,
&quot;Policies&quot;: []
},
&quot;Type&quot;: &quot;AWS::IAM::Group&quot;
}
...
</code></pre> 
<p>Finally, your user is here as a member of the group you’ve created:</p> 
<pre><code class="lang-json">
...
&quot;TestUserUser&quot;: {
&quot;Properties&quot;: {
&quot;Groups&quot;: [
&quot;LabUsers&quot;
],
&quot;ManagedPolicyArns&quot;: [],
&quot;Path&quot;: &quot;/&quot;,
&quot;Policies&quot;: [],
&quot;UserName&quot;: &quot;TestUser&quot;
},
&quot;Type&quot;: &quot;AWS::IAM::User&quot;
}
...
</code></pre> 
<p>When you view the <code>lab</code> template, you can see the PowerUser role that you’re permitted to assume, with the trust set correctly to the parent.</p> 
<pre><code class="lang-json">
...
&quot;PowerUserRole&quot;: {
&quot;Properties&quot;: {
&quot;AssumeRolePolicyDocument&quot;: {
&quot;Statement&quot;: [
{
&quot;Action&quot;: &quot;sts:AssumeRole&quot;,
&quot;Effect&quot;: &quot;Allow&quot;,
&quot;Principal&quot;: {
&quot;AWS&quot;: &quot;arn:aws:iam::012345678910:root&quot;
}
}
],
&quot;Version&quot;: &quot;2012-10-17&quot;
},
&quot;ManagedPolicyArns&quot;: [
&quot;arn:aws:iam::aws:policy/PowerUserAccess&quot;
],
&quot;Path&quot;: &quot;/&quot;,
&quot;Policies&quot;: [],
&quot;RoleName&quot;: &quot;PowerUser&quot;
},
&quot;Type&quot;: &quot;AWS::IAM::Role&quot;
}
...
</code></pre> 
<h3>Deploy in your accounts</h3> 
<p>Deploy the CloudFormation templates in your favorite way, either through the console or the <a title="AWS CLI" href="https://aws.amazon.com/cli" target="_blank" rel="noopener noreferrer">AWS CLI</a>. I’ve included example CLI commands.</p> 
<p>To use multiple accounts from the AWS CLI, configure profiles. For more information about setting up profiles, see <a title="Configuring the AWS CLI" href="http://docs.aws.amazon.com/cli/latest/userguide/cli-chap-getting-started.html#cli-multiple-profiles" target="_blank" rel="noopener noreferrer">AWS CLI</a>.</p> 
<p>Deploy in your <code>central</code> account. <b>Substitute your –template-body –profile and –region accordingly.</b></p> 
<pre><code class="lang-bash">
aws cloudformation create-stack \
--stack-name CentralIAMPolicies \
--template-body 'file://./output_templates/central(012345678910)-IAM.template' \
--capabilities CAPABILITY_NAMED_IAM \
--profile central \
--region us-east-2
</code></pre> 
<p>Deploy in your <code>lab</code> account. <b>Substitute your –template-body –profile and –region accordingly.</b></p> 
<pre><code class="lang-bash">
aws cloudformation create-stack \
--stack-name CentralIAMPolicies \
--template-body 'file://./output_templates/lab(109876543210)-IAM.template' \
--capabilities CAPABILITY_NAMED_IAM \
--profile lab \
--region us-east-2
</code></pre> 
<h3>Explore the results</h3> 
<p>Sign into the <code>central</code> account with an existing role or user and <a title="Set the password" href="http://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_passwords_admin-change-user.html" target="_blank" rel="noopener noreferrer">set the password</a> for the <code>TestUser</code> user. You could have set a password in the CloudFormation template, but then it would be in plaintext!</p> 
<p>Sign into the <code>central</code> account as <code>TestUser</code>. Verify that you have read-only access. You should be able to self-manage your credentials though (set your own password, etc.).</p> 
<p>Now, switch roles to the <code>PowerUser</code> role in the <code>lab</code> account. Switching roles can be done through the console. For more information, see <a title="Switching to a Role" href="http://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-console.html" target="_blank" rel="noopener noreferrer">Switching to a Role</a> (AWS Management Console).</p> 
<p>Confirm that you can now perform expected activities in the <code>lab</code> account. You should be able to create resources, as per the PowerUserAccess reference policy.</p> 
<b>Add a new account</b> 
<p>A new line of business has decided to use AWS and has asked for a new lab environment. You used AWS Organizations to create a new account for them. Now, bring their IAM policies up to the central standard.</p> 
<p>Edit config.yaml and add the new account:</p> 
<pre><code class="lang-yaml">
---
accounts:
central:
# Change to the ID of the central parent account.
id: 012345678910
parent: true
lab:
# Change to the ID of the child account.
id: 109876543210
newlab:
# Change to the ID of the new account created using Organizations.
id: 543210123456
...
</code></pre> 
<p>This automatically creates the <code>PowerUser</code> role definition in the <code>newlab</code> account because you’ve used a keyword of <code>children</code> in the <code>in_accounts</code> section of the <code>PowerUser</code> role definition. This is a great way to assure that roles are kept consistent across all accounts. Only the users who can assume those roles change.</p> 
<p>You also need to create a managed policy, group, and a test user in the <code>central</code> account to make use of the new account.</p> 
<p>For reference your config.yaml should now look like this:</p> 
<pre><code class="lang-yaml">
---
accounts:
central:
# Change to the ID of the central parent account.
id: 012345678910
parent: true
lab:
# Change to the ID of the child account.
id: 109876543210
newlab:
# Change to the ID of the new account created using Organizations.
id: 543210123456
policies:
AssumeLabPowerUser:
description: Allow assumption of the PowerUser role in the lab account
assume:
roles:
- PowerUser
accounts:
- lab
in_accounts:
- parent
# The new managed policy lets users assume PowerUser in the newlab account.
AssumeNewLabPowerUser:
description: Allow assumption of the PowerUser role in the newlab account
assume:
roles:
- PowerUser
accounts:
# Here is the new account added in the accounts section
- newlab
in_accounts:
- parent
roles:
PowerUser:
trusts:
- parent
managed_policies:
- arn:aws:iam::aws:policy/PowerUserAccess
in_accounts:
# Because you use the keyword 'children' here, the newlab account gets this role
- children
groups:
LabUsers:
managed_policies:
- arn:aws:iam::aws:policy/IAMSelfManageServiceSpecificCredentials
- arn:aws:iam::aws:policy/IAMUserChangePassword
- arn:aws:iam::aws:policy/IAMUserSSHKeys
- arn:aws:iam::aws:policy/IAMReadOnlyAccess
- AssumeLabPowerUser
in_accounts:
- parent
# This group services the newlab account users.
NewLabUsers:
managed_policies:
- arn:aws:iam::aws:policy/IAMSelfManageServiceSpecificCredentials
- arn:aws:iam::aws:policy/IAMUserChangePassword
- arn:aws:iam::aws:policy/IAMUserSSHKeys
- arn:aws:iam::aws:policy/IAMReadOnlyAccess
# This matches our new policy above.
- AssumeNewLabPowerUser
in_accounts:
- parent
users:
TestUser:
groups:
- LabUsers
in_accounts:
- parent
NewTestUser:
groups:
- NewLabUsers
in_accounts:
- parent
</code></pre> 
<h3>Build and deploy</h3> 
<p>Run the build:</p> 
<pre><code class="lang-bash">
python build.py
</code></pre> 
<p>Now, you see a new set of CloudFormation templates in output_templates/:</p> 
<pre><code class="lang-bash">
ls -l output_templates/
-rw-r--r-- 1 user user Users 6307 Apr 10 10:59 central(012345678910)-IAM.template
-rw-r--r-- 1 user user Users 1680 Apr 10 10:59 lab(109876543210)-IAM.template
-rw-r--r-- 1 user user Users 1683 Apr 10 10:59 newlab(543210123456)-IAM.template
</code></pre> 
<p>View one of the templates, and notice that the build number has changed:</p> 
<pre><code class="lang-json">
...
&quot;AWSTemplateFormatVersion&quot;: &quot;2010-09-09&quot;,
&quot;Description&quot;: &quot;Build 2017-07-25Z19:35:41 - IAM Users, Groups, Roles, and Policies for account central (012345678910)&quot;,
...
</code></pre> 
<p>The build number is the datestamp when the build was executed. It will be the same across all of the templates generated during that build. Use it to assure the environment remtains consistent. You can audit all of your accounts to assure this number is identical to assure deployment conssitency.</p> 
<p>Again, deploy using your favorite mechanism or use the AWS CLI commands below.</p> 
<p>In <code>central</code> this is an update which creates the new managed policy, group, and user.</p> 
<pre><code class="lang-bash">
aws cloudformation update-stack \
--stack-name CentralIAMPolicies \
--template-body 'file://./output_templates/central(012345678910)-IAM.template' \
--capabilities CAPABILITY_NAMED_IAM \
--profile central \
--region us-east-2
</code></pre> 
<p>In <code>lab</code>, this is a simple version increment. Nothing else changes but keeping the version consistent ensures that your environment is consistently deployed.</p> 
<pre><code class="lang-bash">
aws cloudformation update-stack \
--stack-name CentralIAMPolicies \
--template-body 'file://./output_templates/lab(109876543210)-IAM.template' \
--capabilities CAPABILITY_NAMED_IAM \
--profile lab \
--region us-east-2
</code></pre> 
<p>In <code>newlab</code>, this is the first deployment.</p> 
<pre><code class="lang-bash">
aws cloudformation create-stack \
--stack-name CentralIAMPolicies \
--template-body 'file://./output_templates/newlab(543210123456)-IAM.template' \
--capabilities CAPABILITY_NAMED_IAM \
--profile newlab \
--region us-east-2
</code></pre> 
<h3>Explore the results</h3> 
<p>You’ve enabled a new account and brought it in line with centrally managed IAM policies, with a few changes to a configuration yaml file.</p> 
<p>As before, create a password for <code>NewTestUser</code> and assume the <code>PowerUser</code> Role in the <code>newlab</code> account. As a test step, confirm that you cannot assume the <code>PowerUser</code> role in the <code>lab</code> account from this user because you didn’t permit that in the config.yaml file.</p> 
<b>Corral users into a specific region</b> 
<p>As your use of AWS has grown, you’ve noticed that your users are creating EC2 instances in multiple regions. This is becoming difficult to manage, and you’d like to restrict their region use to us-east-2.</p> 
<p>There is no ‘off the shelf’ managed policy for this, so you need to create one. Going through the <a title="IAM Policy Generator" href="https://awspolicygen.s3.amazonaws.com/policygen.html" target="_blank" rel="noopener noreferrer">IAM Policy Generator</a>, create a policy that looks like the following:</p> 
<pre><code class="lang-json">
{
&quot;Version&quot;: &quot;2012-10-17&quot;,
&quot;Statement&quot;: [
{
&quot;Sid&quot;: &quot;DenyAllButOhio&quot;,
&quot;Action&quot;: &quot;ec2:*&quot;,
&quot;Effect&quot;: &quot;Deny&quot;,
&quot;Resource&quot;: &quot;*&quot;,
&quot;Condition&quot;: {
&quot;StringNotEquals&quot;: {
&quot;ec2:Region&quot;: &quot;us-east-2&quot;
}
}
}
]
}
</code></pre> 
<h3>Update the configuration</h3> 
<p>To support the region restrictions, create a file called <code>policy/restrictEc2Region.j2</code>, and copy the policy json contents above into it.</p> 
<p>Edit the config.yaml file and make some changes.</p> 
<p>Define the new managed policy to restrict regions based on the template in the <code>policy/</code> directory.</p> 
<pre><code class="lang-yaml">
...
policies:
...
restrictEc2Region:
description: Prevent EC2 actions outside of us-east-2
# Get the policy json content from the file in the policy/ directory
policy_file: restrictEc2Region.j2
in_accounts:
- children
...
</code></pre> 
<p>Modify the <code>PowerUser</code> role to include this region restriction policy:</p> 
<pre><code class="lang-yaml">
...
roles:
PowerUser:
trusts:
- parent
managed_policies:
# Add our new managed policy
- restrictEc2Region
- arn:aws:iam::aws:policy/PowerUserAccess
in_accounts:
- children
...
</code></pre> 
<p>For reference your config.yaml should now look like this:</p> 
<pre><code class="lang-yaml">
---
accounts:
central:
# Change to the ID of the central parent account.
id: 012345678910
parent: true
lab:
# Change to the ID of the child account.
id: 109876543210
newlab:
# Change to the ID of the new account created using Organizations.
id: 543210123456
policies:
AssumeLabPowerUser:
description: Allow assumption of the PowerUser role in the lab account
assume:
roles:
- PowerUser
accounts:
- lab
in_accounts:
- parent
# The new managed policy lets users assume PowerUser in the newlab account.
AssumeNewLabPowerUser:
description: Allow assumption of the PowerUser role in the newlab account
assume:
roles:
- PowerUser
accounts:
# Here is the new account added in the accounts section
- newlab
in_accounts:
- parent
# A policy document taken from a jinja template
restrictEc2Region:
description: Prevent EC2 actions outside of us-east-2
# Get the policy json content from the file in the policy/ directory
policy_file: restrictEc2Region.j2
in_accounts:
- children
roles:
PowerUser:
trusts:
- parent
managed_policies:
# Add our new managed policy
- restrictEc2Region
- arn:aws:iam::aws:policy/PowerUserAccess
in_accounts:
# Because you use the keyword 'children' here, the newlab account gets this role
- children
groups:
LabUsers:
managed_policies:
- arn:aws:iam::aws:policy/IAMSelfManageServiceSpecificCredentials
- arn:aws:iam::aws:policy/IAMUserChangePassword
- arn:aws:iam::aws:policy/IAMUserSSHKeys
- arn:aws:iam::aws:policy/IAMReadOnlyAccess
- AssumeLabPowerUser
in_accounts:
- parent
# This group services the newlab account users.
NewLabUsers:
managed_policies:
- arn:aws:iam::aws:policy/IAMSelfManageServiceSpecificCredentials
- arn:aws:iam::aws:policy/IAMUserChangePassword
- arn:aws:iam::aws:policy/IAMUserSSHKeys
- arn:aws:iam::aws:policy/IAMReadOnlyAccess
# This matches our new policy above.
- AssumeNewLabPowerUser
in_accounts:
- parent
users:
TestUser:
groups:
- LabUsers
in_accounts:
- parent
NewTestUser:
groups:
- NewLabUsers
in_accounts:
- parent
</code></pre> 
<h3>Build and deploy</h3> 
<p>Build the CloudFormation templates:</p> 
<pre><code class="lang-bash">
python build.py
</code></pre> 
<p>View the <code>lab</code> CloudFormation template. You can see the new managed policy:</p> 
<pre><code class="lang-json">
...
&quot;restrictEc2Region&quot;: {
&quot;Properties&quot;: {
&quot;Description&quot;: &quot;Prevent EC2 actions outside of us-east-2&quot;,
&quot;Groups&quot;: [],
&quot;PolicyDocument&quot;: {
&quot;Statement&quot;: [
{
&quot;Action&quot;: &quot;ec2:*&quot;,
&quot;Condition&quot;: {
&quot;StringNotEquals&quot;: {
&quot;ec2:Region&quot;: &quot;us-east-2&quot;
}
},
&quot;Effect&quot;: &quot;Deny&quot;,
&quot;Resource&quot;: &quot;*&quot;,
&quot;Sid&quot;: &quot;DenyAllButOhio&quot;
}
],
&quot;Version&quot;: &quot;2012-10-17&quot;
},
&quot;Roles&quot;: [],
&quot;Users&quot;: []
},
&quot;Type&quot;: &quot;AWS::IAM::ManagedPolicy&quot;
}
...
</code></pre> 
<p>You can also see that <code>PowerUser</code> definition now includes the following:</p> 
<pre><code class="lang-json">
...
&quot;ManagedPolicyArns&quot;: [
&quot;arn:aws:iam::aws:policy/PowerUserAccess&quot;,
{
&quot;Ref&quot;: &quot;restrictEc2Region&quot;
}
],
...
</code></pre> 
<p>If you look at <code>newlab</code>, you see the same set of definitions are there too. If you had tens or even hundreds of child accounts, those would all reflect the new policy and updated role definitions as well. This scales very nicely!</p> 
<p>Now, deploy to your three accounts.</p> 
<p>In <code>central</code>, nothing actually changes. It’s just a deployment version update.</p> 
<pre><code class="lang-bash">
aws cloudformation update-stack \
--stack-name CentralIAMPolicies \
--template-body 'file://./output_templates/central(012345678910)-IAM.template' \
--capabilities CAPABILITY_NAMED_IAM \
--profile central \
--region us-east-2
</code></pre> 
<p>In <code>lab</code> and <code>newlab</code>, this deploys the new managed policy, and update the <code>PowerUser</code> role.</p> 
<pre><code class="lang-bash">
aws cloudformation update-stack \
--stack-name CentralIAMPolicies \
--template-body 'file://./output_templates/lab(109876543210)-IAM.template' \
--capabilities CAPABILITY_NAMED_IAM \
--profile lab \
--region us-east-2
</code></pre> 
<pre><code class="lang-bash">
aws cloudformation update-stack \
--stack-name CentralIAMPolicies \
--template-body 'file://./output_templates/newlab(543210123456)-IAM.template' \
--capabilities CAPABILITY_NAMED_IAM \
--profile newlab \
--region us-east-2
</code></pre> 
<b>Conclusion</b> 
<p>I hope you find this tool as useful as I have. The tool is capable of much more complex deployments as well, which leverage the power of Jinja2 templating. Explore the contents of <code>sample_configs/config-complex.yaml</code> and the policy examples in the <code>sample_policy/</code> directory in the project.</p> 
<p>The <a title="README.md" href="https://github.com/awslabs/aws-iam-generator/blob/master/README.md" target="_blank" rel="noopener noreferrer">README.md</a> file has more detailed explanations of functionality and syntax usage.</p> 
<h4>About the Author</h4> 
<p><img class="size-full wp-image-831 alignleft" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/07/25/apmclean.jpeg" alt="" width="119" height="160" /><br /> <a title="LinkedIn Profile" href="https://www.linkedin.com/in/adam-mclean-90bb3020/" target="_blank" rel="noopener noreferrer">Adam McLean</a> is a Cloud Infrastructure Architect with AWS Professional Services. Adam enjoys helping his Canadian enterprise customers achieve success on their cloud journey. In his spare time, Adam enjoys spending time with his family and three small children.</p> 
<p>&nbsp;</p> 
<p>&nbsp;</p> 
<p>&nbsp;</p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/mt/tag/aws-cloudformation/" rel="tag">AWS CloudFormation</a>, <a href="https://aws.amazon.com/blogs/mt/tag/aws-iam/" rel="tag">AWS IAM</a>, <a href="https://aws.amazon.com/blogs/mt/tag/aws-multi-account-management/" rel="tag">AWS Multi-Account Management</a>, <a href="https://aws.amazon.com/blogs/mt/tag/configuration-management/" rel="tag">Configuration Management</a></span> 
</footer> 
</article> 
<article class="post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="b post-title" property="name headline">How Cloudticity Automates Security Patches for Linux and Windows using Amazon EC2 Systems Manager and AWS Step Functions</b> 
<footer class="meta">
by 
<span property="author" typeof="Person"><span property="name">Ananth Vaidyanathan</span></span> | on 
<time property="datePublished" datetime="2017-08-02T19:14:49+00:00">02 AUG 2017</time> | in 
<span class="categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/amazon-ec2-systems-manager/" title="View all posts in Amazon EC2 Systems Manager"><span property="articleSection">Amazon EC2 Systems Manager</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/application-services/aws-step-functions/" title="View all posts in AWS Step Functions"><span property="articleSection">AWS Step Functions</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools"><span property="articleSection">Management Tools</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/how-cloudticity-automates-security-patches-for-linux-and-windows-using-amazon-ec2-systems-manager-and-aws-step-functions/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog=""><span class="span icon-share"></span>&nbsp;Share</a> 
<ul> 
</ul> 
</footer> 
<p><em>This guest post was written by Uri Katsir, AWS Architect at Cloudticity, and Thomas Zinn, Project Manager at Cloudticity.</em></p> 
<p>As a provider of HIPAA-compliant solutions using AWS, Cloudticity always has security as the base of everything we do. HIPAA breaches would be an end-of-life event for most of our customers. Having been born in the cloud with automation in our DNA, Cloudticity embeds automation into all levels of infrastructure management including security, monitoring, and continuous compliance. As mandated by the HIPAA Security Rule (45 CFR <a href="http://www.access.gpo.gov/nara/cfr/waisidx_07/45cfr160_07.html">Part 160</a> and Subparts A and C of <a href="http://www.access.gpo.gov/nara/cfr/waisidx_07/45cfr164_07.html">Part 164</a>), patches at the operating system and application level are required to prevent security vulnerabilities. As a result, patches are a major component of infrastructure management.</p> 
<p><span id="more-988"></span></p> 
<p>Cloudticity strives to provide consistent and reliable services to all of our customers. As such, we needed to create a custom patching solution that supports both Linux and Windows. The minimum requirements for such a solution were to read from a manifest file that contains instance names and a list of knowledge base articles (KBs) or security packages to apply to each instance. Below is a simplified, high-level process overview.</p> 
<p><img class="size-full wp-image-1016 alignnone" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/07/31/flowchart-patching.png" alt="" width="340" height="423" /></p> 
<p>There were a few guidelines to be considered when designing the solution:</p> 
<ol> 
<li>Each customer has a defined maintenance window that patches can be completed within. As such, the solution must be able to perform the updates within the specified maintenance window.</li> 
<li>The solution must be able to provide patches to one or many instances and finish within the maintenance window.</li> 
<li>The solution should use as many AWS services as possible to reduce time-to-market and take advantage of the built-in scaling that many AWS services provide.</li> 
<li>Code reusability is essential.</li> 
</ol> 
<p>In this post, we walk through our solution and discuss how combining <a href="https://aws.amazon.com/ec2/systems-manager/">Amazon EC2 Systems Manager</a> and <a href="https://aws.amazon.com/step-functions/">AWS Step Functions</a> is ideal for this particular use case.</p> 
<h3>Systems Manager for Patch Management</h3> 
<p>We have been using Systems Manager to remotely manage instances from its inception, so it was natural to consider it as part of the solution. We use Systems Manager in many ways:</p> 
<ol> 
<li>Installing New Relic and Trend Micro agents for every new instance that is launched (whether manually or via Auto Scaling).</li> 
<li>Ensuring that EC2Config and the SSM agents are running the latest versions.</li> 
<li>Deploying software updates to multiple remote instances.</li> 
</ol> 
<p>We began with the <a href="https://docs.aws.amazon.com/systems-manager/latest/userguide/sysman-ssm-docs.html">Systems Manager predefined documents</a> “AWS-InstallWindowsUpdates” for Windows and “AWS-RunShellScript” for Linux. To achieve maximum code reusability, we created several AWS Lambda functions to perform individual tasks, such as identifying operating system type (Linux or Windows) or applying patches using the SSM agents. Each process (rectangle) in the flowchart above is implemented using a single Lambda function. The Systems Manager document is smart enough to apply multiple patches provided by a manifest file stored in Amazon S3 and only perform a single reboot, if a reboot is required to complete the patch process. Below is a code snippet from the Lambda function that runs Linux patches:</p> 
<pre><code class="lang-clike">if (IncludedKB === '') {	
// Build the yum command based on the entry in the manifest file
command = 'sudo yum update -y';
} else if (IncludedKB.toUpperCase() == 'SECURITY') {
command = 'yum update --security -y';
} else {
command = 'yum --security update ' + IncludedKB + ' -y';
}
var commands = [];
commands.push(command);
//prepare parameters for the Systems Manager command. Specify the output folder to hold the run //results.
var params = {
DocumentName: 'AWS-RunShellScript',
InstanceIds: [instanceId],
Comment: 'OS Patch command',
OutputS3BucketName: bucket,
OutputS3KeyPrefix: OutputFolder,
Parameters: {
commands: commands
},
TimeoutSeconds: 60
};
console.log('Sending command to InstanceID: ' + instanceId);
console.log('Command is: ' + command);
ssm.sendCommand(params, function(err, data) {
//console.log('err= ' + err);
if (err) {
callback(command + ', Error, ' + err.code);
} else {
console.log(command + ', ' + data.Command.CommandId + ', ' + data.Command.Status);
callback(null);
}
});
</code></pre> 
<h3>Step Functions for workflow orchestration</h3> 
<p>Given the nature of the solution (microservices that perform unique and distinct tasks), we needed a centralized service to manage and drive the process end-to-end, as well as pass parameters between Lambda functions. In other words, a state machine of Lambda functions. At AWS re:Invent 2016, AWS Step Functions was released. It allowed us to spin up multiple concurrent processes for completing the patches (one for each row in the manifest file) without the need to worry about scale, <a href="https://en.wikipedia.org/wiki/Deadlock">deadlocks</a>, timeouts, or <a href="https://en.wikipedia.org/wiki/Race_condition">race conditions</a>. By running concurrent processes, we can complete the patch process in the minimum time required for the patches to be applied without introducing any overhead to the process.</p> 
<p>Step Functions provides some additional benefits including visualization of the overall state machine, passing input/output parameters between Lambda functions, and simplified debugging for each step in the process.</p> 
<p>The image below is a visual preview of the patching process generated by the Step Functions user interface in the AWS Management Console. Notice how the resulting state machine mimics the initial workflow.</p> 
<p><img class="alignleft wp-image-989" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/07/31/Step-functions-diagram.png" alt="" width="521" height="320" /></p> 
<p>&nbsp;</p> 
<p>&nbsp;</p> 
<p>&nbsp;</p> 
<p>&nbsp;</p> 
<p>&nbsp;</p> 
<p>&nbsp;</p> 
<p>&nbsp;</p> 
<p>&nbsp;</p> 
<p>&nbsp;</p> 
<p>&nbsp;</p> 
<p>&nbsp;</p> 
<pre><code class="lang-json">{
&quot;Comment&quot;: &quot;Cloudticity-Oxygen-OS-Patch-SF.&quot;,
&quot;StartAt&quot;: &quot;GetInstancePlatform&quot;,
&quot;States&quot;: {
&quot;GetInstancePlatform&quot;: {
&quot;Type&quot;: &quot;Task&quot;,
&quot;Resource&quot;: &quot;arn:aws:lambda:us-east-1:123456789012:function:Cloudticity-Oxygen-GetInstancePlatform&quot;,
&quot;Next&quot;: &quot;ChoiceState&quot;
},
&quot;ChoiceState&quot;: {
&quot;Type&quot;: &quot;Choice&quot;,
&quot;Choices&quot;: [
{
&quot;Variable&quot;: &quot;$.PlatformType&quot;,
&quot;StringEquals&quot;: &quot;Windows&quot;,
&quot;Next&quot;: &quot;WindowsMatchState&quot;
},
{
&quot;Variable&quot;: &quot;$.PlatformType&quot;,
&quot;StringEquals&quot;: &quot;Linux&quot;,
&quot;Next&quot;: &quot;LinuxMatchState&quot;
}
],
&quot;Default&quot;: &quot;NoMatchFound&quot;
},
&quot;WindowsMatchState&quot;: {
&quot;Type&quot;: &quot;Task&quot;,
&quot;Resource&quot;: &quot;arn:aws:lambda:us-east-1:123456789012:function:Cloudticity-Oxygen-Windows-OS-Patching&quot;,
&quot;Retry&quot;: [
{
&quot;ErrorEquals&quot;: [
&quot;States.ALL&quot;
],
&quot;IntervalSeconds&quot;: 6,
&quot;MaxAttempts&quot;: 2,
&quot;BackoffRate&quot;: 3
}
],
&quot;End&quot;: true
},
&quot;LinuxMatchState&quot;: {
&quot;Type&quot;: &quot;Task&quot;,
&quot;Resource&quot;: &quot;arn:aws:lambda:us-east-1:123456789012:function:Cloudticity-Oxygen-Linux-OS-Patching&quot;,
&quot;End&quot;: true
},
&quot;NoMatchFound&quot;: {
&quot;Type&quot;: &quot;Fail&quot;,
&quot;Cause&quot;: &quot;No Matches!&quot;
}
}
}
</code></pre> 
<p>The first state (GetInstancePlatform) executes the <a href="https://github.com/Cloudticity/o2-instance-patching/blob/master/utility/GetInstancePlatform.js">Cloudticity-Oxygen-GetInstancePlatform</a> Lambda function. As you can see in the code snippet below, the Lambda function then invokes the <a href="https://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/SSM.html#describeInstanceInformation-property">ssm.describeInstanceInformation</a> method to retrieve the platform type of the instance (Linux or Windows).</p> 
<pre><code class="lang-clike">var aws = require('aws-sdk');	
var getInstancePlatform = function(instanceID, event, IncludeKbs, isReboot, bucket, OutputFolder, callback) {
var ssm = new aws.SSM();
//Prepare the parameters for the Systems Manager run. Instance ID is an input parameter in the //manifest file.
var params = {
InstanceInformationFilterList: [{
key: &quot;InstanceIds&quot;,
valueSet: [
instanceID
]
}]
};
ssm.describeInstanceInformation(params, function(err, instanceData) {
if (err) {
callback(err);
} else {
let instanceInformation = instanceData.InstanceInformationList[0];
if (instanceInformation) {
console.log('Running GetInstancePlatform. PlatformType = ' + instanceInformation.PlatformType);
//return instance information to the next step in the Step Function.
callback(null, {
PlatformType: instanceInformation.PlatformType,
kB: IncludeKbs,
instanceID: instanceID,
isReboot: isReboot,
bucket: bucket,
OutputFolder: OutputFolder
}, event);
} else {
callback('Unknown instance platform');
}
}
});
};</code></pre> 
<p>The platform information is passed on to the built-in <a href="https://docs.aws.amazon.com/step-functions/latest/dg/amazon-states-language-choice-state.html">Choice</a> state (InstancePlatform) that adds branching logic to a state machine. The InstancePlatform state uses the platform information to route traffic via one of three options:</p> 
<ul> 
<li>PatchWindows</li> 
<li>PatchLinux</li> 
<li>NoMatchFound.</li> 
</ul> 
<p>When patching Windows instances, the state is transferred to the <a href="https://github.com/Cloudticity/o2-instance-patching/blob/master/lib/Windows_updates-patcher.js">Cloudticity-Oxygen-Windows-OS-Patching</a> Lambda function that invokes the <a href="https://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/SSM.html#sendCommand-property">ssm.sendCommand</a> method with “AWS-InstallWindowsUpdates” as the document name. An input to this document is a <a href="https://github.com/Cloudticity/o2-instance-patching/blob/master/events/ManifestFileSample.csv">manifest file</a>, which contains the Windows Knowledge Base (KBs) numbers to be applied to instances.</p> 
<p>Below is a snippet from the Lambda function that patches Windows instances.</p> 
<pre><code class="lang-clike">//prepare parameters for the ssm command. Instance ID and included KBs are input from the manifest file.
var params = {	
DocumentName: 'AWS-InstallWindowsUpdates',
Comment: 'OS Patch command',
InstanceIds: [instanceId],
OutputS3BucketName: bucket,
OutputS3KeyPrefix: OutputFolder,
Parameters: {
&quot;Action&quot;: [&quot;Install&quot;],
&quot;IncludeKbs&quot;: [IncludeKbs]
},
TimeoutSeconds: 60
};
console.log(&quot;Sending InstallWindowsUpdates ssm command with the following InstanceId: &quot; + instanceId + &quot;\n&quot;);
//Send the ssm command.
ssm.sendCommand(params, function(err, data) {
if (err) callback(command + ', Error, ' + err.code + &quot;\n&quot;);
else {
callback(null);
console.log(&quot;Sending InstallWindowsUpdates &quot; + command + ', ' + data.Command.CommandId + ', ' + data.Command.Status + &quot;\n&quot;);
}
});</code></pre> 
<p>When patching a Linux instance, the state is transferred to the <a href="https://github.com/Cloudticity/o2-instance-patching/blob/master/lib/linux_updates-patcher.js">Cloudticity-Oxygen-Linux-OS-Patching</a> Lambda function that invokes the <a href="https://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/SSM.html#sendCommand-property">ssm.sendCommand</a> method with “AWS-RunShellScript” as the document name. Our Linux patching implementation provides two options:</p> 
<ol> 
<li>Security packages that need to be applied are entered into a <a href="https://github.com/Cloudticity/o2-instance-patching/blob/master/events/ManifestFileSample.csv">manifest file</a>. This file is referenced as an input parameter to the “AWS-RunShellScript” document.</li> 
<li>In the <a href="https://github.com/Cloudticity/o2-instance-patching/blob/master/events/ManifestFileSample.csv">manifest file</a>, instead of listing packages, “security” is specified in the packages place.</li> 
</ol> 
<p>In the latter case, all security-related packages are applied to the specified instance according to the manifest file.</p> 
<h3>Looking Ahead</h3> 
<p>Based on our customer feedback and internal reviews, we are planning to add the following features to the above implementation:</p> 
<ul> 
<li>Add AMI patching as part of the overall process: Replace an AMI in an Auto Scaling Launch Configuration with the patched AMI.</li> 
<li>Add additional exception handling for process failures and the patching product: If an SSM command successfully sent, but the patch process fails on the instance. A notification or support ticket is created. In some cases, a single patch process can take longer than five minutes to run. Since five minutes is the maximum runtime for Lambda functions, we introduce a polling mechanism to query the patch progress following the guidelines outlined in this <a href="https://aws.amazon.com/blogs/compute/building-high-throughput-genomics-batch-workflows-on-aws-workflow-layer-part-4-of-4/">post</a>.</li> 
</ul> 
<h3>Summary</h3> 
<p>Using <a href="https://docs.aws.amazon.com/systems-manager/latest/userguide/sysman-ssm-docs.html">Systems Manager predefined documents</a> and <a href="https://aws.amazon.com/step-functions/">AWS Step Functions</a> together allowed this <a href="https://github.com/Cloudticity/o2-instance-patching">solution</a> to be implemented within a short time frame. It also enabled the release of a scalable patching service to multiple customers. Beyond the automation and scalability, our customers see additional benefits like the ability to decrease the length of maintenance windows.</p> 
<h3>About the Authors</h3> 
<p><img class="size-full wp-image-1004 alignnone" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/07/31/uri-2.jpg" alt="" width="150" height="114" />Uri Katsir is an AWS Architect at Cloudticity, where he spends his days building really cool HIPAA-compliant services for the healthcare industry.</p> 
<p>&nbsp;</p> 
<p><img class="size-full wp-image-1003 alignnone" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/07/31/thomas.png" alt="" width="151" height="151" />Thomas Zinn is a Project Manager at Cloudticity, where he provides HIPAA-compliant infrastructure solutions using AWS.</p> 
<h3>About Cloudticity</h3> 
<p><a href="http://cloudticity.com/">Cloudticity</a> helps healthcare organizations design, build, migrate, and manage HIPAA-compliant systems using AWS. We are an <a href="https://aws.amazon.com/partners/managed-service/">audited AWS Managed Service Provider (MSP)</a>, <a href="https://aws.amazon.com/health/healthcare-partners/">AWS Healthcare Competency Partner</a> and <a href="https://aws.amazon.com/devops/partner-solutions/">AWS DevOps Competency Partner</a>. In addition, as an AWS Service Catalog Partner and Public Sector Partner, Cloudticity is well positioned to help providers, payers, and healthcare services organizations use AWS securely and effectively. For further reading, check out <a href="https://aws.amazon.com/blogs/apn/how-cloudticity-uses-automation-to-scale-healthcare-solutions/">How Cloudticity Uses Automation to Scale Healthcare Solutions</a> and <a href="https://aws.amazon.com/partners/success/cloudticity/">AWS Partner Story: Cloudticity</a>.</p> 
<hr /> 
<p><em>AWS is not responsible for the content or accuracy of this post. The content and opinions in this blog are solely those of the third party author. It is each customer’s responsibility to determine whether they are subject to HIPAA, and if so, how best to comply with HIPAA and its implementing regulations. Before using AWS in connection with protected health information, customers must enter an AWS Business Associate Addendum (BAA) and follow its configuration requirements.</em></p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/mt/tag/ec2-systems-manager/" rel="tag">EC2 Systems Manager</a>, <a href="https://aws.amazon.com/blogs/mt/tag/run-command/" rel="tag">Run Command</a></span> 
</footer> 
</article> 
<article class="post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<meta property="image" content="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/07/25/DSC2_statemanager-888x630.png" /> 
<b class="b post-title" property="name headline">Combating Configuration Drift Using Amazon EC2 Systems Manager and Windows PowerShell DSC</b> 
<footer class="meta">
by 
<span property="author" typeof="Person"><span property="name">Shaun Breen</span></span> | on 
<time property="datePublished" datetime="2017-07-26T10:12:43+00:00">26 JUL 2017</time> | in 
<span class="categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/amazon-ec2-systems-manager/" title="View all posts in Amazon EC2 Systems Manager"><span property="articleSection">Amazon EC2 Systems Manager</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools"><span property="articleSection">Management Tools</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/combating-configuration-drift-using-amazon-ec2-systems-manager-and-windows-powershell-dsc/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog=""><span class="span icon-share"></span>&nbsp;Share</a> 
<ul> 
</ul> 
</footer> 
<p>Configuration drift occurs when a system “drifts” or changes from its intended configuration. It is caused by having inconsistent configuration items (CIs) across environments.</p> 
<p><a href="https://aws.amazon.com/ec2/systems-manager">Amazon EC2 Systems Manager</a> is a management service that helps you automatically collect a software inventory, apply OS patches, create system images, and configure Windows and Linux operating systems. These capabilities help you define and track system configurations, prevent drift, and maintain software compliance of your EC2 and on-premises configurations.</p> 
<p>Systems Manager provides a management approach that is designed for the scale and agility of the cloud but extends into your on-premises data center. Systems Manager makes it easier for you to seamlessly bridge your existing infrastructure with AWS.</p> 
<p>In my last <a href="https://aws.amazon.com/blogs/mt/using-microsoft-powershell-dsc-with-amazon-ec2-systems-manager/">post</a>, I introduced the concept of using Systems Manager <a href="https://aws.amazon.com/ec2/systems-manager/run-command/">Run Command</a> to apply a declarative based model for EC2 instance configuration (configuration as code) via Windows PowerShell Desired State Configuration (DSC). In this post, I show how you can combat configuration drift at scale using PowerShell DSC and a management tool from Systems Manager called <a href="https://aws.amazon.com/ec2/systems-manager/state-manager/">State Manager</a>.</p> 
<p><span id="more-886"></span></p> 
<b>Configuration drift</b> 
<p>Configuration drift can happen for a multitude of reasons and can occur in many types of environments such as database systems, network configurations, directory services, web servers, and custom APIs. Some possible reasons that drift can occur include system updates, code pushes, hardware upgrades, or software updates that get applied to some, but not all of your intended systems. I am sure that you have seen this firsthand. &nbsp;We have all heard “but it worked in my dev environment.”</p> 
<p>Configuration drift can cause problems that can result in unintended system behaviors, system failures, disaster recovery issues, and many other potential problems. Fortunately, there are tools and technologies that help mitigate drift.</p> 
<ul> 
<li><strong>Configuration as code</strong></li> 
</ul> 
<p style="padding-left: 30px">Declaratively define a desired state within a configuration file that can be applied to a system to interpret and apply.</p> 
<ul> 
<li><strong>State Manager</strong></li> 
</ul> 
<p style="padding-left: 30px">An EC2 tool that helps you apply a configuration to a set of on-premises servers and EC2 instances on a scheduled basis.</p> 
<ul> 
<li><strong>Configuration management databases (CMDB)</strong></li> 
</ul> 
<p style="padding-left: 30px">CMDBs help track the state of IT assets (also known as configuration items), allowing IT administrators the ability to check on the current state of CIs at any time. A common issue with CMDBs is stale data, meaning that the current state is not always up-to-date. The inability to reliably detect drift is problematic as mitigation is not performed. While CMDBs are popular, I do not use them as a solution in this post.</p> 
<b>Configuration as code via PowerShell DSC</b> 
<p>Before I dive into a solution to help with the ongoing struggles of configuration drift, here are the benefits of using configuration as code via PowerShell DSC:</p> 
<ul> 
<li><strong>Definition files.</strong></li> 
</ul> 
<p style="padding-left: 30px">A system “desired state” is defined in declaratively based configuration files. You no longer need to develop custom code and scripts to handle the configuration state that you want for your servers.</p> 
<ul> 
<li><strong>Idempotency.</strong></li> 
</ul> 
<p style="padding-left: 30px">You can apply the configuration file repeatedly without adverse side effects.</p> 
<ul> 
<li><strong>Self-documentation.</strong></li> 
</ul> 
<p style="padding-left: 30px">The configuration files are human-readable and easily understood.</p> 
<b>State Manager</b> 
<p>State Manager allows you to schedule a script to be run against your on-premises servers and EC2 instances on a scheduled basis. If the scripts are idempotent, you can apply them repeatedly. This gives way to a simple and scalable pattern that helps mitigate configuration drift.</p> 
<ol> 
<li>Define your set of servers.</li> 
<li>Create idempotent scripts or use PowerShell DSC to define your desired state configuration.</li> 
<li>Apply the script on a scheduled basis to mitigate any drift that may have occurred since the last time you ran the script.</li> 
</ol> 
<b>State Manager and PowerShell DSC</b> 
<p>This is a powerful combination! State Manager and PowerShell DSC allow you to define configuration policies that can be applied to your EC2 instances at scale. It ensures that your instances remain in that state by reapplying the policy on a defined schedule. While this does not prevent drift from occurring, it helps you mitigate any drift that may have occurred. Thus, this is an excellent pattern to ensure that both your on-premises servers and EC2 instances stay in your desired state.</p> 
<p><img class="alignnone size-full wp-image-902" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/07/25/DSC2_statemanager.png" alt="" width="1431" height="1015" /></p> 
<p>In this section, I show you how to use State Manager from the AWS Management Console. You learn to use both State Manager and PowerShell DSC to combat configuration drift.</p> 
<p>At a high level, this is the walk-through process:</p> 
<ol> 
<li>Create EC2 Windows instances.</li> 
<li>Tag those instances such that they are considered a set of instances that share a common purpose.</li> 
<li>Create a State Manager association. This association executes a PowerShell DSC script against the tagged instances on a specified schedule. 
<ul> 
<li>The PowerShell DSC script is contained in a PowerShell module downloaded from a S3 endpoint. It is authored by AWS and its intent is to install IIS on the instance and enable ASP and Tracing features. The module is publicly available and can be <a href="https://s3.amazonaws.com/aws-windows-samples-us-east-1/PSModules/SSMDevOps.zip">downloaded</a>.</li> 
</ul> </li> 
</ol> 
<b>Walk-through</b> 
<ol> 
<li>In the EC2 console, <a href="http://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/EC2_GetStarted.html#ec2-launch-instance_linux">create two or more new Windows Server instances</a>.</li> 
<li>Choose <strong>Instances</strong>, select the instances that you just created, and choose <strong>Tags</strong>.</li> 
<li>Choose <strong>Add/Edit Tags</strong> and set the following values: 
<ul> 
<li><strong>Set Key</strong> = Metadata</li> 
<li><strong>Set Value</strong> = {“Environment”: “Production”, “Type”: “IIS Web Server”}</li> 
</ul> </li> 
<li>In the EC2 console, choose <strong>State Manager</strong>, <strong>Create Association</strong>, and select the document <strong>AWS-InstallPowerShellModule</strong>. Set the following values: 
<ul> 
<li>Keep the document version as $DEFAULT.</li> 
<li>For <strong>Specifying a Tag</strong>, select: 
<ul> 
<li><strong>Tag Name</strong> = Metadata</li> 
<li><strong>Tag Value</strong> = {“Environment”: “Production”, “Type”: “IIS Web Server”}</li> 
</ul> </li> 
<li>For <strong>Schedule</strong>, choose Every <strong>30</strong> Minutes.</li> 
<li>For the <strong>Source</strong>, enter the following URL: <a href="https://s3.amazonaws.com/aws-windows-samples-us-east-1/PSModules/SSMDevOps.zip">https://s3.amazonaws.com/aws-windows-samples-us-east-1/PSModules/SSMDevOps.zip</a></li> 
<li>For <strong>Commands</strong>, copy and paste the following:</li> 
<li> <pre><code class="lang-powershell">Set-ExecutionPolicy -ExecutionPolicy Unrestricted -Force
Import-Module SSMDevOps
Install-SsmDoIIS
Start-DscConfiguration -Path Install-SsmDoIIS -Wait</code></pre> </li> 
</ul> </li> 
<li>Choose <strong>Create Association</strong>.</li> 
</ol> 
<b>Conclusion</b> 
<p>Systems Manager offers a suite of tools to help you manage both your EC2 and on-premises instances. In this post, I discussed some common approaches to mitigate configuration drift at scale. Finally, I provided an example walk-through to try mitigating configuration drift using Systems Manager and PowerShell DSC.</p> 
<b>About the Author</b> 
<p><strong><a href="https://www.linkedin.com/in/shaunbreen/"><img class="alignleft wp-image-618" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/06/02/shaunbreen.png" alt="" width="130" height="174" /></a>Shaun Breen is a Systems Development Engineer on the Amazon EC2 Windows team</strong>.&nbsp;The EC2 Windows team is responsible for producing Windows Server AMIs and Systems Manager documents. Shaun enjoys developing solutions that make EC2 the best place to run Microsoft Windows Server in the cloud. When not working on EC2 Windows solutions, he enjoys attending sporting events, coaching ice hockey, and spending time with his wife and three children.</p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/mt/tag/ec2-systems-manager/" rel="tag">EC2 Systems Manager</a>, <a href="https://aws.amazon.com/blogs/mt/tag/powershell-dsc/" rel="tag">PowerShell DSC</a>, <a href="https://aws.amazon.com/blogs/mt/tag/state-manager/" rel="tag">State Manager</a></span> 
</footer> 
</article> 
<article class="post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="b post-title" property="name headline">Organize Parameters by Hierarchy, Tags, or Amazon CloudWatch Events with Amazon EC2 Systems Manager Parameter Store</b> 
<footer class="meta">
by 
<span property="author" typeof="Person"><span property="name">Ananth Vaidyanathan</span></span> | on 
<time property="datePublished" datetime="2017-07-25T17:30:01+00:00">25 JUL 2017</time> | in 
<span class="categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/amazon-ec2-systems-manager/" title="View all posts in Amazon EC2 Systems Manager"><span property="articleSection">Amazon EC2 Systems Manager</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools"><span property="articleSection">Management Tools</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/organize-parameters-by-hierarchy-tags-or-amazon-cloudwatch-events-with-amazon-ec2-systems-manager-parameter-store/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog=""><span class="span icon-share"></span>&nbsp;Share</a> 
<ul> 
</ul> 
</footer> 
<p><em>This post was written by Lusha Zhang, Software Development Engineer with Amazon Web Services.</em></p> 
<p><a href="https://aws.amazon.com/ec2/systems-manager/parameter-store/">Parameter Store</a>, part of <a href="https://aws.amazon.com/ec2/systems-manager/">Amazon EC2 Systems Manager</a>, provides a centralized, encrypted store to manage your configuration data, whether plaintext data (database strings) or secrets (passwords, API keys for example). Because Parameter Store is available through the AWS CLI, APIs, and SDKs, you can easily reference parameters across AWS services such as AWS Lambda and Amazon ECS.</p> 
<p>For additional posts on Parameter Store, please see:</p> 
<ul> 
<li><a href="https://aws.amazon.com/blogs/compute/managing-secrets-for-amazon-ecs-applications-using-parameter-store-and-iam-roles-for-tasks/">Managing Secrets for Amazon ECS Applications Using Parameter Store and IAM Roles for Tasks</a></li> 
<li><a href="https://aws.amazon.com/blogs/mt/use-parameter-store-to-securely-access-secrets-and-config-data-in-aws-codedeploy/">Use Parameter Store to Securely Access Secrets and Config Data in AWS CodeDeploy</a></li> 
</ul> 
<p>Parameter Store recently <a href="https://aws.amazon.com/about-aws/whats-new/2017/06/amazon-ec2-systems-manager-adds-hierarchy-tagging-and-notification-support-for-parameter-store/">launched</a> hierarchy support, parameter tagging, and CloudWatch Events support, which makes it easy to organize and manage parameters at scale. In this post, I demonstrate how you can use these new features to scale and improve your security posture.</p> 
<p><span id="more-864"></span></p> 
<h3>Hierarchical parameters</h3> 
<p>Parameter Store support for hierarchies lets you organize parameters based on your deployment. It provides powerful tools for parameter organization, querying, and permission control.</p> 
<p>A common DevOps scenario is to automate software deployment across different environments such as Dev, Beta, and Prod. For example, when you create a deployment configuration, you can use Parameter Store to save your settings. Maybe you have to set the minimum healthy host number or percentage for each deployment environment, and want to store it in Parameter Store, with different values for each environment.</p> 
<h4>Step 1. Create the path for deployment configuration</h4> 
<p>Use the following commands to create the path and parameters to store:</p> 
<pre><code class="lang-bash">aws ssm put-parameter --name /DeploymentConfig/Prod/FleetHealth --value 75 --type String
aws ssm put-parameter --name /DeploymentConfig/Beta/FleetHealth --value 20 --type String
</code></pre> 
<p>You can also organize your secrets under a dedicated path. For example,</p> 
<pre><code class="lang-bash">aws ssm put-parameter –-name /DeploymentConfig/Prod/Password/SQLPassword –-value <span style="color: #ff0000">&lt;password&gt;</span> --type SecureString</code></pre> 
<p>For more information about how to use the SecureString type parameter, see <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/sysman-paramstore-about.html">About Systems Manager Parameters</a>.</p> 
<p>Your parameter hierarchy now looks like the following:</p> 
<p>&nbsp;</p> 
<p>Step 2. Use parameters to manage your deployment configuration<br /> When you create a deployment configuration using an AWS CloudFormation template, you can set the FleetHealth for a Prod stage as in the following example.</p> 
<p><img class="alignnone size-full wp-image-870" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/07/25/hierarchy.png" alt="" width="681" height="349" /></p> 
<h4>Step 2. Use parameters to manage your deployment configuration</h4> 
<p>When you create a deployment configuration using an AWS CloudFormation template, you can set the FleetHealth for a Prod stage as in the following example.</p> 
<pre><code class="lang-bash">#!/bin/bash
fleetHealth=$(aws ssm get-parameter --name /DeploymentConfig/Prod/FleetHealth --query Parameter.Value)
aws cloudformation create-stack --stack-name <span style="color: #ff0000">&lt;stack_name&gt;</span> --template-url <span style="color: #ff0000">&lt;templateurl&gt;</span> --parameters ParameterKey=FleetHealth,ParameterValue=$fleetHealth
</code></pre> 
<p>You can retrieve all the configuration parameters of your Prod or Beta environments using the recursive flag and parse the configuration hierarchy returned to get the parameter of your choice.</p> 
<pre><code class="lang-bash">aws ssm get-parameters-by-path --path /DeploymentConfig/Prod –-recursive</code></pre> 
<p>You can also filter parameters by path from the AWS Management Console or AWS CLI.</p> 
<pre><code class="lang-bash">aws ssm describe-parameters --parameter-filters Key=Path,Option=Recursive,Values=/DeploymentConfig/Prod</code></pre> 
<p><img class="alignnone wp-image-876" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/07/25/getParamsbypath.png" alt="" width="941" height="320" /></p> 
<h4>Control access to hierarchies</h4> 
<p>Now that you have created a parameter hierarchy for your deployment configuration in the Prod and Beta environments, you may want to restrict access to parameters. Maybe the Dev team should have access only to the Beta environment parameters, and not to the Prod environment parameters.</p> 
<p>Use IAM to control access to the Beta parameter hierarchy. For example, the following IAM policy restricts user access to Prod parameters.</p> 
<pre><code class="lang-json">{
&quot;Effect&quot;: &quot;Deny&quot;,
&quot;Action&quot;: [
&quot;ssm:GetParametersByPath&quot;
],
&quot;Condition&quot;: {
&quot;StringEquals&quot;: {
&quot;ssm:Recursive&quot;: [
&quot;true&quot;
]
}
},
&quot;Resource&quot;:“arn:aws:ssm:&lt;region&gt;:&lt;account_id&gt;:parameter/DeploymentConfig/Prod*&quot;
}
</code></pre> 
<p>Now when a user runs the following command, they get AccessDeniedException.</p> 
<pre><code class="lang-bash">aws ssm get-parameters-by-path --path /DeploymentConfig/Prod —-recursive</code></pre> 
<h3>Tagging parameters</h3> 
<p>Tags let you manage your AWS resources easily. You can now also tag parameters, allowing you to group and query them. Using the same deployment configuration example, you can add a tag with a <span style="text-decoration: underline">Tag Key</span> value of “Password”, and <span style="text-decoration: underline">Tag Value</span> equal to “Beta” or “Prod”.</p> 
<pre><code class="lang-bash">aws ssm add-tags-to-resource --resource-type Parameter --resource-id  /DeploymentConfig/Beta/FleetHealth --tags Key=Password,Value=Beta</code></pre> 
<p>You can also apply multiple filters to get a combined filter result. For example, if you apply Tag Key Password and a path /DeploymentConfig/Beta with the recursive flag, you get those parameters in your Beta environment that are password-related.</p> 
<pre><code class="lang-bash">aws ssm describe-parameters --parameter-filters Key=tag:Password Key=Path,Option=Recursive,Values=/DeploymentConfig/Beta</code></pre> 
<p><img class="alignnone wp-image-878" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/07/25/multiple-tag-filters.png" alt="" width="1012" height="261" /><br /> You can manage the security access with IAM policies. For more information, see <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/sysman-paramstore-access.html">Controlling Access to Systems Manager Parameters</a>.</p> 
<h3>Get change notifications with CloudWatch Events rules</h3> 
<p>Parameter Store is now a <a href="http://docs.aws.amazon.com/AmazonCloudWatch/latest/events/WhatIsCloudWatchEvents.html">CloudWatch Events</a> source. You can set up CloudWatch rules to trigger a CloudWatch Event target such as a Lambda function or SNS topic whenever a parameter gets created, updated, or deleted.</p> 
<p>The following example shows you how to set up a CloudWatch rule to trigger an SNS topic for your parameter update. For more information, see <a href="http://docs.aws.amazon.com/gettingstarted/latest/deploy/creating-an-sns-topic.html">Step 2: Create an SNS Topic</a>. After you set up your SNS topic to trigger an email notification about your parameter update, create a CloudWatch rule to associate with the SNS topic as a target. You can edit the Event Pattern value to specify the parameters for which to get notified:</p> 
<pre><code class="lang-json">{
&quot;source&quot;: [
&quot;aws.ssm&quot;
],
&quot;detail-type&quot;: [
&quot;Parameter Store Change&quot;
],
&quot;detail&quot;: {
&quot;name&quot;: [
&quot;/DeploymentConfig/Prod/FleetHealth&quot;,
&quot;/DeploymentConfig/Beta/FleetHealth&quot;
],
&quot;operation&quot;: [
&quot;Update&quot;,
&quot;Delete&quot;
]
}
}
</code></pre> 
<p><img class="alignnone wp-image-873" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/07/25/CWE-filled.png" alt="" width="886" height="572" /></p> 
<p>When you change the value of the /DeploymentConfig/Beta/FleetHealth parameter, the CloudWatch event should show up in the metrics.</p> 
<p><img class="alignnone wp-image-875" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/07/25/CWE-metrics.png" alt="" width="593" height="349" /></p> 
<p>In the meantime, the SNS topic that you created is triggered and you should receive an email as well.</p> 
<h3>Conclusion</h3> 
<p>This post demonstrated several new Parameter Store features to manage parameters: &nbsp;hierarchy, tagging, and CloudWatch notifications. Hierarchical parameters make it easier to organize and control access to configuration data, whether plaintext or secrets. Tagging support provides you with another way to group and query parameters easily. With CloudWatch Events, you can get timely notifications about parameter updates.</p> 
<hr /> 
<h3>About the Author</h3> 
<p><img class="size-full wp-image-877 alignleft" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/07/25/lusha-zhang.jpg" alt="" width="119" height="160" />Lusha Zhang is a Software Development Engineer in the Amazon EC2 System Manager Team. She has worked on various products at Amazon from Amazon Textbook Rentals to AWS Parameter Store. Outside work, she enjoys playing the violin and the piano as well as surfing in the Pacific Northwest.</p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/mt/tag/amazon-cloudwatch-events/" rel="tag">Amazon Cloudwatch Events</a>, <a href="https://aws.amazon.com/blogs/mt/tag/ec2-systems-manager/" rel="tag">EC2 Systems Manager</a></span> 
</footer> 
</article> 
<p>
© 2017, Amazon Web Services, Inc. or its affiliates. All rights reserved.
</p>

    </div>
  </div>
</div>


    <div id="footer" class="navigation hidden-print">
      <div class="container">
        <div class="row">
          <div class="col-xs-12">
            <ul class="footer-links nav navbar-nav">
              <li><a href="../aws.html">AWS</a></li>
              <li><a href="../linux.html">Linux</a></li>
              <li><a href="../docker.html">Docker</a></li>
              <li><a href="../ibmpower.html">IBM Power</a></li>
              <li><a href="blogsataws1.html">Blogs@AWS (Kindle Friendly)</a></li>
            </ul>
            <ul class="footer-links nav navbar-nav navbar-right">
              <li><a href="../comments.html">Comments?</a></li>
            </ul>
          </div>
        </div>
      </div>
    </div>
  </body>
</html>
