<!DOCTYPE html>
<html lang="en">
  <head>
<!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-593498H');</script>
<!-- End Google Tag Manager -->

    <meta charset="utf-8">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">

    <meta name="msapplication-config" content="/microsoft-tile.xml" />
    <meta name="theme-color" content="#ffffff">

    <meta property="og:url" content="https://bejoycalias.github.io/blogsataws/mgmtblogs1.html" />
    <meta property="og:site_name" content="Bejoy's TechNotes"/>
    <meta property="og:title" content="Bejoy's TechNotes - Kindle Friendly AWS Management Tools Blogs" />
    <meta property="og:image" content="https://bejoycalias.github.io/assets/images/og-image.png"/>
    <meta property="og:image:width" content="1200"/>
    <meta property="og:image:height" content="1200"/>
    <meta property="og:description" content="" />

    <title>Bejoy's TechNotes - Kindle Friendly AWS Management Tools Blogs</title>
    <link href="../assets/stylesheets/application-832aa42c.css" rel="stylesheet" />

    <!--[if lt IE 9]>
      <script src="../assets/javascripts/ie-compat-c141a02d.js"></script>
    <![endif]-->
    <script src="../assets/javascripts/application-ff53d307.js"></script>

    <!-- Typekit script to import Klavika font -->
    <script src="https://use.typekit.net/wxf7mfi.js"></script>
    <script>try{Typekit.load({ async: true });}catch(e){}</script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-100043608-1', 'auto');
  ga('send', 'pageview');

</script>

    
  </head>

  <body id="uh-oh-" class="layout-inner page-uh-oh-">
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-593498H"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->


    <div id="header" class="navigation navbar-static-top hidden-print">
      <div class="container">
        <div class="row">
          <div class="col-xs-12">
            <div class="navbar-header">
              <div class="navbar-brand">
                <a href="/">
                  <svg version="1.0" xmlns="http://www.w3.org/2000/svg" width="135.000000pt" height="50" viewbox="0 0 135.000000 45.000000" preserveaspectratio="xMidYMid meet" class="logo">

<g transform="translate(0.000000,45.000000) scale(0.100000,-0.100000)" fill="#000000" stroke="none">
<path class="text" fill="#000000" d="M527 384 c-4 -4 -7 -18 -7 -31 0 -21 4 -24 28 -21 21 2 27 8 27 28 0
18 -6 26 -20 28 -12 2 -24 0 -28 -4z"></path>
<path class="text" fill="#000000" d="M1080 335 c0 -48 2 -55 20 -55 18 0 20 7 20 55 0 48 -2 55 -20 55
-18 0 -20 -7 -20 -55z"></path>
<path class="text" fill="#000000" d="M54 357 c-2 -7 -3 -69 -2 -138 l3 -124 65 -3 c90 -3 130 20 130 77 0
29 -6 44 -20 54 -20 14 -20 15 -3 45 14 25 15 34 5 56 -6 15 -23 31 -38 36
-38 15 -134 13 -140 -3z m110 -33 c19 -7 21 -45 4 -62 -7 -7 -22 -12 -35 -12
-20 0 -23 5 -23 40 0 41 13 50 54 34z m20 -130 c19 -18 19 -20 6 -45 -8 -13
-21 -19 -45 -19 -34 0 -35 1 -35 40 0 38 2 40 29 40 16 0 37 -7 45 -16z"></path>
<path class="text" fill="#000000" d="M319 271 c-23 -24 -29 -38 -29 -74 0 -25 3 -53 6 -62 20 -50 164 -64
164 -15 0 15 -7 17 -45 12 -46 -5 -75 8 -75 34 0 11 16 14 65 14 l65 0 0 35
c0 80 -92 114 -151 56z m99 -33 c3 -15 -4 -18 -37 -18 -43 0 -50 7 -29 28 18
18 62 11 66 -10z"></path>
<path class="text" fill="#000000" d="M520 184 c0 -107 -1 -116 -20 -121 -11 -3 -20 -12 -20 -19 0 -21 76
-19 84 2 3 9 6 69 6 135 l0 119 -25 0 -25 0 0 -116z"></path>
<path class="text" fill="#000000" d="M649 271 c-24 -25 -29 -37 -29 -78 1 -70 34 -103 105 -103 55 0 95
44 95 103 0 60 -7 75 -41 92 -47 25 -96 19 -130 -14z m111 -30 c25 -48 2 -111
-40 -111 -45 0 -69 80 -34 114 21 22 61 20 74 -3z"></path>
<path class="text" fill="#000000" d="M850 287 c0 -8 16 -57 36 -110 28 -76 33 -100 25 -116 -16 -28 -14
-31 18 -31 27 0 29 4 70 123 23 67 41 128 41 135 0 6 -11 12 -24 12 -21 0 -26
-8 -41 -65 -10 -36 -21 -68 -25 -70 -3 -2 -16 27 -29 66 -19 60 -25 69 -47 69
-13 0 -24 -6 -24 -13z"></path>
<path class="text" fill="#000000" d="M1192 284 c-17 -12 -22 -24 -20 -47 2 -26 10 -36 45 -52 49 -23 59
-55 17 -55 -14 0 -34 5 -45 10 -16 9 -19 7 -19 -13 0 -17 7 -27 23 -31 69 -18
117 6 117 60 0 32 -4 37 -45 55 -60 26 -62 54 -4 46 37 -5 40 -3 37 16 -2 18
-11 23 -43 25 -25 2 -49 -3 -63 -14z"></path>
</g>
</svg>

                </a>
              </div>
              <button class="navbar-toggle" type="button">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
              </button>
            </div>
            <div class="buttons hidden-xs">
              <nav class="navigation-links" role="navigation">
                <ul class="main-links nav navbar-nav navbar-right">
                  <li><a href="../aws.html">AWS</a></li>
                  <li><a href="../linux.html">Linux</a></li>
                  <li><a href="../docker.html">Docker</a></li>
                  <li><a href="../ibmpower.html">IBM Power</a></li>
                  <li><a href="blogsataws1.html">Blogs@AWS (Kindle Friendly)</a></li>
                </ul>
              </nav>
            </div>
          </div>
        </div>
      </div>
    </div>

    <div class="sidebar-overlay"></div>

<aside class="sidebar" role="navigation">
  <div class="sidebar-header">
    <svg version="1.0" xmlns="http://www.w3.org/2000/svg" width="135.000000pt" height="42" viewbox="0 0 135.000000 45.000000" preserveaspectratio="xMidYMid meet">

<g transform="translate(0.000000,45.000000) scale(0.100000,-0.100000)" fill="#000000" stroke="none">
<path class="text" fill="#000000" d="M527 384 c-4 -4 -7 -18 -7 -31 0 -21 4 -24 28 -21 21 2 27 8 27 28 0
18 -6 26 -20 28 -12 2 -24 0 -28 -4z"></path>
<path class="text" fill="#000000" d="M1080 335 c0 -48 2 -55 20 -55 18 0 20 7 20 55 0 48 -2 55 -20 55
-18 0 -20 -7 -20 -55z"></path>
<path class="text" fill="#000000" d="M54 357 c-2 -7 -3 -69 -2 -138 l3 -124 65 -3 c90 -3 130 20 130 77 0
29 -6 44 -20 54 -20 14 -20 15 -3 45 14 25 15 34 5 56 -6 15 -23 31 -38 36
-38 15 -134 13 -140 -3z m110 -33 c19 -7 21 -45 4 -62 -7 -7 -22 -12 -35 -12
-20 0 -23 5 -23 40 0 41 13 50 54 34z m20 -130 c19 -18 19 -20 6 -45 -8 -13
-21 -19 -45 -19 -34 0 -35 1 -35 40 0 38 2 40 29 40 16 0 37 -7 45 -16z"></path>
<path class="text" fill="#000000" d="M319 271 c-23 -24 -29 -38 -29 -74 0 -25 3 -53 6 -62 20 -50 164 -64
164 -15 0 15 -7 17 -45 12 -46 -5 -75 8 -75 34 0 11 16 14 65 14 l65 0 0 35
c0 80 -92 114 -151 56z m99 -33 c3 -15 -4 -18 -37 -18 -43 0 -50 7 -29 28 18
18 62 11 66 -10z"></path>
<path class="text" fill="#000000" d="M520 184 c0 -107 -1 -116 -20 -121 -11 -3 -20 -12 -20 -19 0 -21 76
-19 84 2 3 9 6 69 6 135 l0 119 -25 0 -25 0 0 -116z"></path>
<path class="text" fill="#000000" d="M649 271 c-24 -25 -29 -37 -29 -78 1 -70 34 -103 105 -103 55 0 95
44 95 103 0 60 -7 75 -41 92 -47 25 -96 19 -130 -14z m111 -30 c25 -48 2 -111
-40 -111 -45 0 -69 80 -34 114 21 22 61 20 74 -3z"></path>
<path class="text" fill="#000000" d="M850 287 c0 -8 16 -57 36 -110 28 -76 33 -100 25 -116 -16 -28 -14
-31 18 -31 27 0 29 4 70 123 23 67 41 128 41 135 0 6 -11 12 -24 12 -21 0 -26
-8 -41 -65 -10 -36 -21 -68 -25 -70 -3 -2 -16 27 -29 66 -19 60 -25 69 -47 69
-13 0 -24 -6 -24 -13z"></path>
<path class="text" fill="#000000" d="M1192 284 c-17 -12 -22 -24 -20 -47 2 -26 10 -36 45 -52 49 -23 59
-55 17 -55 -14 0 -34 5 -45 10 -16 9 -19 7 -19 -13 0 -17 7 -27 23 -31 69 -18
117 6 117 60 0 32 -4 37 -45 55 -60 26 -62 54 -4 46 37 -5 40 -3 37 16 -2 18
-11 23 -43 25 -25 2 -49 -3 -63 -14z"></path>
</g>
</svg>

  </div>

  <ul class="nav sidebar-nav">
    <li><a href="../aws.html">AWS</a></li>
    <li><a href="../linux.html">Linux</a></li>
    <li><a href="../docker.html">Docker</a></li>
    <li><a href="../ibmpower.html">IBM Power</a></li>
    <li><a href="blogsataws1.html">Blogs@AWS (Kindle Friendly)</a></li>
  </ul>
</aside>


    <div class="container">
  <div class="row">
    <div id="docs-sidebar" class="col-sm-3 col-md-3 col-xs-12 hidden-print" role="complementary">
      <ul class="nav docs-sidenav">
      <li><a href="blogsataws1.html">Blogs @ AWS</a></li>
      <li><a href="whatsnew1.html">What's New @ AWS</a></li>
      <li class="active"><a href="mgmtblogs1.html">Management Tools Blogs @ AWS</a></li>
      <li><a href="computeblogs1.html">Compute Blogs @ AWS</a></li>
      <li><a href="devopsblogs1.html">DevOps Blogs @ AWS</a></li>
      <li><a href="secblogs1.html">Security Blogs @ AWS</a></li>
      <li><a href="apnblogs1.html">APN Blogs @ AWS</a></li>

    </ul>
    </div>

    <div id="inner" class="col-sm-9 col-md-9 col-xs-12" role="main">
<p></p>
<p><i>Contents of this page is copied directly from AWS blog sites to make it Kindle friendly. Some styles & sections from these pages are removed to render this properly in 'Article Mode' of Kindle e-Reader browser. All the contents of this page is property of AWS.</i></p>
<p><a href="mgmtblogs1.html">Page 1</a>|<a href="mgmtblogs2.html">Page 2</a>|<a href="mgmtblogs3.html">Page 3</a>|<a href="mgmtblogs4.html">Page 4</a></p>
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">Automate IIS and HttpErr Logs to Amazon CloudWatch Using EC2 Systems Manager</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Pawan Puthran</span></span> | on 
<time property="datePublished" datetime="2017-11-22T09:56:52+00:00">22 NOV 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/amazon-ec2-systems-manager/" title="View all posts in Amazon EC2 Systems Manager*"><span property="articleSection">Amazon EC2 Systems Manager*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools*"><span property="articleSection">Management Tools*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/automate-iis-and-httperr-logs-to-amazon-cloudwatch-using-ec2-systems-manager/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p>When you have workloads or applications hosted on IIS Web Server, it’s important to monitor and analyze both <a href="https://www.iis.net/configreference/system.applicationhost/sites/sitedefaults/logfile#003">IIS</a> and <a href="https://support.microsoft.com/en-us/help/820729/error-logging-in-http-apis#Kinds%20of%20errors%20that%20the%20HTTP%20API%20logs">HttpErr</a> logs for abnormalities. IIS logs contain an entry for every request to the site. However, at times, you might not find the requests in IIS logs, even though IIS logging is enabled. There is a good chance that the request was rejected by HTTP.sys (Kernel mode driver for HTTP) before it was handed to the IIS worker process. Some of the common reasons for rejecting a request include the following:</p> 
<li>The service is unavailable because the application pool is offline. (Http 503: Service Unavailable)</li> 
<li>Parse error – Bad request. (Http 400)</li> 
<p>In this blog post, we show you how to configure Windows EC2 instances to send HttpErr and IIS logs to <a href="https://aws.amazon.com/cloudwatch/">Amazon CloudWatch</a> using <a href="https://aws.amazon.com/ec2/systems-manager">Amazon EC2 Systems Manager (SSM)</a>. Then we show you how to set up a CloudWatch alarm to notify you when the IIS application pool stops using <a href="https://aws.amazon.com/sns/" target="_blank" rel="noopener noreferrer">Amazon Simple Notification Service</a> (SNS).</p> 
<p><span id="more-1788"></span></p> 
<p><a href="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/flowdiag.png"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/flowdiag-1024x293.png" /></a></p> 
<p>Amazon EC2 Systems Manager is a management service that helps you automate management tasks such as collecting system inventory, applying operating system (OS) patches, automating the creation of Amazon Machine Images (AMIs), and configuring operating systems and applications at scale. Systems Manager lets you remotely and securely manage the configuration of your managed instances.</p> 
<b>Configuring Windows EC2 for CloudWatch using EC2 Systems Manager</b> 
<p>There are <a href="http://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/send_logs_to_cwl.html">many ways to send instance metrics</a> to CloudWatch. Let’s look at the steps you need to follow to integrate <a href="https://aws.amazon.com/ec2/systems-manager/state-manager/">System Manager State Manager</a> with CloudWatch.</p> 
<ol> 
<li>Set up the configuration file for CloudWatch</li> 
<li>Configure integration with CloudWatch</li> 
<li>Create a CloudWatch metric filter and configure an alarm</li> 
</ol> 
<b>Step 1: Set up the configuration file for CloudWatch</b> 
<ol> 
<li>Download the sample <a href="https://s3.amazonaws.com/ec2-downloads-windows/CloudWatchConfig/AWS.EC2.Windows.CloudWatch.json">JSON file for CloudWatch</a></li> 
<li>Ensure that “isEnabled” is set to true <code class="lang-json">{
&quot;IsEnabled&quot;: true,
&quot;EngineConfiguration&quot;: {
...
}
}</code> </li> 
<li>In the JSON file, add the following configuration information after the IISLogs section. <code class="lang-json">{
&quot;Id&quot;: &quot;HttpErrLogs&quot;,
&quot;FullName&quot;: &quot;AWS.EC2.Windows.CloudWatch.CustomLog.CustomLogInputComponent,AWS.EC2.Windows.CloudWatch&quot;,
&quot;Parameters&quot;: {
&quot;LogDirectoryPath&quot;: &quot;C:\\Windows\\System32\\LogFiles\\HTTPERR&quot;,
&quot;TimestampFormat&quot;: &quot;yyyy-MM-dd HH:mm:ss&quot;,
&quot;Encoding&quot;: &quot;UTF-8&quot;,
&quot;Filter&quot;: &quot;&quot;,
&quot;CultureName&quot;: &quot;en-US&quot;,
&quot;TimeZoneKind&quot;: &quot;UTC&quot;,
&quot;LineCount&quot;: &quot;3&quot;
}
}</code> </li> 
<li>Add the following configuration to ensure that the log data is sent to CloudWatch. Modify or update the Region, LogGroup, and Logstream name. <code class="lang-json">{
&quot;Id&quot;: &quot;HttpErrCloudWatchLogs&quot;,
&quot;FullName&quot;: &quot;AWS.EC2.Windows.CloudWatch.CloudWatchLogsOutput,AWS.EC2.Windows.CloudWatch&quot;,
&quot;Parameters&quot;: {
&quot;AccessKey&quot;: &quot;&quot;,
&quot;SecretKey&quot;: &quot;&quot;,
&quot;Region&quot;: &quot;us-east-2&quot;,
&quot;LogGroup&quot;: &quot;WebServer&quot;,
&quot;LogStream&quot;: &quot;{instance_id}-httpErr&quot;
}
}</code> <p><strong>Region</strong>: The Region where you want to send log data.<br /> <strong>LogGroup</strong>: Name for your log group. This will appear on the Log Groups screen on the CloudWatch console.<br /> <strong>LogStream</strong>: Destination log stream. This will appear on the Log Groups &gt; Streams screen on the CloudWatch console.</p> <p>Note: If you use Systems Manager State Manager, you don’t have to provide credentials in the configuration file.</p></li> 
<li>Flow Control – Each data type must have a corresponding destination in the Flows section. For example, to send log details defined in the HttpErrLogs section to the destination defined in the HttpCloudWatchLog section, add “HttpErrLogs,HttpCloudWatchLog” to the Flows section <code class="lang-json">&quot;Flows&quot;: {
&quot;Flows&quot;: [
&quot;HttpErrLogs,HttpErrCloudWatchLogs&quot;
]
}
</code> <p>Similarly, add the following to configure the IIS logs (for LogDirectoryPath, check the IIS logs directory and SiteID)</p> <code class="lang-json">{
&quot;Id&quot;: &quot;IISLogs&quot;,
&quot;FullName&quot;: &quot;AWS.EC2.Windows.CloudWatch.CustomLog.CustomLogInputComponent,AWS.EC2.Windows.CloudWatch&quot;,
&quot;Parameters&quot;: {
&quot;LogDirectoryPath&quot;: &quot;C:\\inetpub\\logs\\LogFiles\\W3SVC1&quot;,
&quot;TimestampFormat&quot;: &quot;yyyy-MM-dd HH:mm:ss&quot;,
&quot;Encoding&quot;: &quot;UTF-8&quot;,
&quot;Filter&quot;: &quot;&quot;,
&quot;CultureName&quot;: &quot;en-US&quot;,
&quot;TimeZoneKind&quot;: &quot;UTC&quot;,
&quot;LineCount&quot;: &quot;3&quot;
}
},
{
&quot;Id&quot;: &quot;IISCloudWatchLogs&quot;,
&quot;FullName&quot;: &quot;AWS.EC2.Windows.CloudWatch.CloudWatchLogsOutput,AWS.EC2.Windows.CloudWatch&quot;,
&quot;Parameters&quot;: {
&quot;AccessKey&quot;: &quot;&quot;,
&quot;SecretKey&quot;: &quot;&quot;,
&quot;Region&quot;: &quot;us-east-2&quot;,
&quot;LogGroup&quot;: &quot;WebServer&quot;,
&quot;LogStream&quot;: &quot;{instance_id}-iis&quot;
}
}
...
&quot;Flows&quot;: {
&quot;Flows&quot;: [
&quot;IISLogs,IISCloudWatchLogs&quot;,
&quot;HttpErrLogs,HttpCloudWatchLogs&quot;
]
}
}</code> <p>Complete the configuration using this <a href="https://s3-us-west-2.amazonaws.com/management-tools-blog-cf-template-storage/SSM_HttpErr_Cloudwatch.json">SSM_HttpErr_Cloudwatch</a> example file</p></li> 
</ol> 
<b>Step 2: Configure integration with CloudWatch</b> 
<p>You can either choose Run Command or State Manager features of Systems Manager to integrate with CloudWatch. In this blog, we will show you how to use State Manager to integrate with CloudWatch.</p> 
<p>State Manager automates the process of keeping your managed instances in a defined state. You can use State Manager to ensure that your instances are bootstrapped with specific software at start up, joined to a Windows domain (Windows instances only), or patched with specific software updates.</p> 
<p>Note: Amazon EC2 Systems Manager requires an IAM role for EC2 instances that will process commands. Please ensure you have the correct <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/sysman-configuring-access-policies.html">policy</a> attached to the instance.</p> 
<li>Open the AWS Management Console, and go to the EC2 console. In the EC2 console navigation pane, choose <strong>State Manager</strong> in the <strong>Systems Manager Services</strong> section and select <strong>Create an association</strong>.</li> 
<p><a href="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/association.png"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/association-1024x426.png" /></a></p> 
<li>Provide an associate name and select AWS-ConfigureCloudWatch as the <strong>Document</strong>.</li> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/selectdocument-1024x622.png" /></p> 
<li>For <strong>Targets</strong>, choose the instances to integrate with CloudWatch either by tag or manually. We recommend choosing the target by tag. In case you don’t see any instances here, please check the IAM role policy.</li> 
<li>For <strong>Schedule</strong>, choose 30 minutes as the time interval for how often you want Systems Manager to apply this policy. This doesn’t affect the frequency when the SSM Agent sends data to CloudWatch.</li> 
<li>For <strong>Parameters</strong>, ensure <strong>Status</strong> is <strong>Enabled</strong> and copy and paste your <a href="https://s3-us-west-2.amazonaws.com/management-tools-blog-cf-template-storage/SSM_HttpErr_Cloudwatch.json">JSON contents</a> into the properties.</li> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/targets-1024x854.png" /></p> 
<li>(Optional) Select <strong>Advanced, Write to S3</strong> to send command output to an Amazon S3 bucket.</li> 
<li>Choose <strong>Create Association</strong>.</li> 
<li><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/successassociation-1024x367.png" />On the State Manager, select the association that you just created and then choose <strong>Apply Association Now</strong>.</li> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/apply-1024x179.png" /></p> 
<p>For more information, see <a href="http://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/send_logs_to_cwl_instances.html#ec2-configuration-cwl">http://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/send_logs_to_cwl_instances.html#ec2-configuration-cwl</a></p> 
<p>After you configure integration, the SSM Agent sends all the logs you configured in your JSON file to CloudWatch. SSM creates a log file that can be found at: C:/ProgramData/Amazon/SSM/Logs. It contains the following entries if LogGroup and LogStream are created successfully. If you don’t see these entries, check the error log, which can be found in the same path.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/SSM_Logs-1024x112.png" /></p> 
<p>In the CloudWatch Logs console, in the <strong>Log Groups</strong> list, you should see WebServer, and in the <strong>LogStream</strong> list you should see {instance_id}-httpErr.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/cw-1024x359.png" /></p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/logstream-1024x173.png" /></p> 
<b>Step 3: Create a CloudWatch metric filter and configure an alarm</b> 
<p>Next, we create a metric filter and configure an alarm that is triggered when an IIS application pool stops. If an IIS application stops or goes offline, the following entries are logged in HttpErr logs with s-status as 503 and s-reason as AppOffline.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/HTTPErrlogs-1024x152.png" /></p> 
<p>These logs are located at C:/Windows/System32/LogFiles/HTTPERR</p> 
<li>In the CloudWatch console choose <strong>Logs</strong> in the navigation pane.</li> 
<li>Select the <strong>WebServer</strong> log group and then choose the <strong>Create Metric Filter</strong> button.</li> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/createmetric-1-1024x499.png" /></p> 
<li>Type “AppOffline” for the <strong>Filter pattern</strong>.</li> 
<li>You can test your filter pattern by selecting <strong>Log Data to Test</strong>.</li> 
<li>Choose <strong>Assign Metric</strong> and type “IIS AppPool” for the <strong>Filter Name</strong>.</li> 
<li>For <strong>Metric Details</strong>, type “IIS” for <strong>Metrics Namespace</strong> and “AppPoolOffline” for the <strong>Metric Name</strong>. Choose Create Filter.</li> 
<li>Next, let’s create an alarm.</li> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/createalarm.png" /></p> 
<li>Provide the Alarm name and a brief description. In the <strong>Whenever</strong> section, specify a threshold (AppPoolOffline &gt; 0) for 2 consecutive periods (period of 1 minute). For <strong>Statistic</strong>, choose <strong>Standard</strong>. Be sure that <strong>Sample Count</strong> is chosen in the drop-down box. You could choose a higher resolution based on your requirements, but remember that there are cost implications.</li> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/alarmthreshold-1024x535.png" /></p> 
<li>For <strong>Actions</strong>, for <strong>Whenever this alarm</strong> select <strong>State is Alarm</strong>. For <strong>Send notification to</strong> create a New list to send notification to. Make sure to confirm the subscription.</li> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/alarm-1.png" /></p> 
<li>Whenever an alarm threshold is breached (that is, when the App Pool stops), you will receive an email notification.</li> 
<b><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/email_alert-1024x441.png" /></b> 
<b>Conclusion</b> 
<p>Businesses are moving toward automated IT. It’s common for applications to span across environments and locations. They can be in the &nbsp;AWS Cloud and in on-premises data centers. It’s a challenge to ensure that the infrastructure powering your applications is consistent.. To help ensure a consistent approach, you can use State Manager to create policies, reapply these policies to prevent configuration drift, and monitor the status of your intended state.</p> 
<p>In this blog post, you have learned how to configure a Windows EC2 instance to send HttpErr and IIS logs to CloudWatch using Amazon EC2 Systems Manager. These steps can be applied to a fleet of Windows Instances running IIS to consolidate logs from all the instances centrally.</p> 
<p>To learn more about Amazon EC2 Systems Manager and EC2 Systems Manager State Manager, go to – <a href="https://aws.amazon.com/ec2/systems-manager/">https://aws.amazon.com/ec2/systems-manager/</a></p> 
<h3></h3> 
<hr /> 
<h3>About the Author</h3> 
<p>&nbsp;</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/PawanPuthran_AWS_TAM-150x150.jpg" />Pawan Puthran is a Senior Technical Account Manager at Amazon Web Services. He works with Enterprise Support customers, and he provides technical guidance and assistance to help them make the best use of AWS services. He loves to write blogs outlining his solutions on multiple AWS products.</p> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">Take Microsoft VSS-Enabled Snapshots Using Amazon EC2 Systems Manager</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Purvi Goyal</span></span> | on 
<time property="datePublished" datetime="2017-11-20T13:54:47+00:00">20 NOV 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/amazon-ec2-systems-manager/" title="View all posts in Amazon EC2 Systems Manager*"><span property="articleSection">Amazon EC2 Systems Manager*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/compute/amazon-ec2/" title="View all posts in Amazon EC2*"><span property="articleSection">Amazon EC2*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/storage/amazon-elastic-block-storage-ebs/" title="View all posts in Amazon Elastic Block Storage (EBS)*"><span property="articleSection">Amazon Elastic Block Storage (EBS)*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools*"><span property="articleSection">Management Tools*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/take-microsoft-vss-enabled-snapshots-using-amazon-ec2-systems-manager/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p>We are happy to announce the support for Microsoft Volume Shadow Copy Service (VSS) on Amazon EC2 instances running Windows AMIs. VSS is a popular volume backup technology in the Microsoft Windows ecosystem (compatible with most Microsoft applications, including SQL Server and Exchange Server). VSS manages disk operations, such as file writes, when a backup is in progress so that the resulting backups are application-consistent.&nbsp;<em>Application-consistent</em> backups are the backups of volumes attached to a machine or an instance, taken at the same time, along with capturing all data in memory and all transactions in progress.</p> 
<p>VSS-enabled snapshots of Amazon EBS volumes are available through Amazon EC2 Systems Manager Run Command. The command <em>AWSEC2-CreateVssSnapshot</em> allows you to take application-consistent snapshots of all EBS volumes attached to your running EC2 Windows instances, without losing transactional data consistency between your EC2 instances and attached EBS volumes during the backup process.&nbsp;With this capability, you don’t need to use application-specific backup solutions, such as native SQL Backup, or develop and maintain custom scripts. In addition, you don’t need to run third-party tools for taking image-level backups that are application-consistent.</p> 
<p><span id="more-2030"></span></p> 
<h3>How to use&nbsp;AWSEC2-CreateVssSnapshot</h3> 
<p>You can take VSS-enabled EBS snapshots on EC2 instances running Windows by calling the command <em>AWSEC2-CreateVssSnapshot</em> through EC2 Systems Manager Run Command. You can use the AWS Management Console, the AWS CLI, or you can call it through a custom PowerShell script or a Lambda function. In this blog post, we’ll call the command using the EC2 console.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/15/1.png" /></p> 
<p>In the EC2 console, first select the Run command document <em>AWSEC2-CreateVssSnapshot</em> to take a VSS-enabled snapshot of your EBS volumes attached to an instance. Then select the instance, and specify the description and tags that you want to add to your resulting snapshots. You can also choose to exclude the boot volume from the snapshot process.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/22/7.png" /></p> 
<p>When initiated, the Run Command call makes the VSS components (More details to follow) on your instances coordinate all ongoing I/O operations on VSS-aware applications running on the EC2 Windows instances. This way the I/O buffers are flushed to the EBS volumes, and all I/O operations are frozen while snapshots are taken. This results in application consistency. After the snapshot is initiated, the freeze on I/O is lifted and normal operations are resumed.</p> 
<p>The list of snapshots created through the Run Command or the script can be found under EBS snapshots in the left navigation pane in the EC2 console. All VSS-enabled EBS snapshots that are successfully created from this process are tagged as “AppConsistent:True”. To learn more about this capability, go to the <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/integration-vss.html">documentation for&nbsp;<em>AWSEC2-CreateVssSnapshot</em></a>.</p> 
<h3>Setting up your EC2 instances to take VSS-enabled snapshots</h3> 
<li><strong>Snapshot permissions to instances</strong>: You need to open the IAM console, and use Policy generator to create new Policy for AWS service “Amazon EC2” and attach the following actions to this policy. 
<ol> 
<li>DescribeInstances</li> 
<li>CreateTags</li> 
<li>CreateSnapshot</li> 
</ol> </li> 
<p>Now create an Amazon EC2 role in the IAM console and attach the actions we previously listed and <em>AmazonEC2RoleForSSM</em> policies to it. Attach this role directly to your EC2 Windows instances.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/22/8.png" /></p> 
<li><strong>Installing VSS components</strong>: All instances created using Microsoft Windows Server AMIs dated 2017.11.18 or later have the VSS components pre-installed. If your Windows instances are not updated with the latest packages, you need to perform additional steps to take VSS-enabled EBS snapshots. 
<li><strong>Update SSM agent</strong>: If your instances don’t have SSM agent 2.2.58.0 or later, you need to call the <em>AWS-UpdateSSMAgent</em> Run Command to update latest SSM agent. You can use Managed Instances under the Shared Systems Manager Resources in the left navigation pane to see the SSM agent version installed on your instances. <img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/22/managed.png" /></li> 
<li><strong>Configure AWS package</strong>: You need to install the VSS components (<em>AwsVssComponents</em>) on them by calling the <em>AWS-ConfigureAWSPackage</em> command using Systems Manager Run Command.</li> 
</ul> </li> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/15/4.png" /></p> 
<p>For more information on how you can set up your EC2 instances to take VSS-enabled EBS snapshots, go to the <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/integration-vss.html#integration-vss-prereqs">Amazon EC2 documentation</a>.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/15/5.png" /></p> 
<p>Using the command AWSEC2-CreateVssSnapshot requires you to provide IAM permissions to create and tag EBS snapshots to your EC2 instances.&nbsp;Alternatively, if you don’t want to provide additional IAM permissions to your instances for policy or compliance reasons, then you can use a customizable sample script. To read more about this script, refer to the <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/integration-vss.html#integration-vss-AWSEC2-ManageVssIO">documentation for <em>AWSEC2-ManageVssIO</em></a>.</p> 
<p>The process for restoring the VSS-based EBS snapshots is the same process that you use to restore EBS snapshots. In addition, you can use <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/integration-vss.html#integration-vss-restore">a sample restore script</a> that we provide. This restore script allows you to restore from specified EBS Snapshots to a given Windows instance on Amazon EC2.</p> 
<hr /> 
<h4>About the Author</h4> 
<p style="text-align: left"><img width="100%" src="https://internal-cdn.amazon.com/badgephotos.amazon.com/?uid=goyapurv" />Purvi Goyal is a Senior Product Manager with the Amazon EC2 team, where she strives to enhance the cloud experience of AWS Enterprise customers. Outside of work, she enjoys outdoor activities like hiking and kayaking.</p> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">Query for the Latest Windows AMI Using Systems Manager Parameter Store</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Venkat Krish</span></span> | on 
<time property="datePublished" datetime="2017-11-17T13:03:38+00:00">17 NOV 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/amazon-ec2-systems-manager/" title="View all posts in Amazon EC2 Systems Manager*"><span property="articleSection">Amazon EC2 Systems Manager*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools*"><span property="articleSection">Management Tools*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/query-for-the-latest-windows-ami-using-systems-manager-parameter-store/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p>AWS has introduced a simpler way for you to query for the latest Windows Amazon Machine Image (AMI). You can now use Amazon EC2 Systems Manager Parameter Store. Prior to this release, finding the latest regional ImageID for an Amazon-provided AMI involved a three-step process. First, use an API call to search the list of available public AMIs. Second, filter the results by a given partial string name. Third, sort the matches by CreationDate property and select the newest ImageID.</p> 
<p>Now, the latest version of a Windows regional ImageID can be returned from a simple Parameter Store query. Each Windows AMI now has its own Parameter Store namespace that is public and describable. Upon querying, an AMI namespace returns only its regional ImageID value.</p> 
<p><strong>The&nbsp;namespace is made up of two parts:</strong></p> 
<ol> 
<li>Parameter Store Prefix (tree): /aws/service/ami-windows-latest/</li> 
<li>AMI name alias: Windows_Server-2016-English-Full-Base</li> 
</ol> 
<p>You can determine a Windows AMI alias by taking the full AMI name property of a Windows public AMI and removing the date-based version identifier at the end.&nbsp; A list of these AMI name properties can be seen by running one for the following EC2 queries.</p> 
<p><span id="more-1946"></span></p> 
<p>Using PowerShell</p> 
<code class="lang-powershell">- Get-EC2ImageByName -Name Windows_Server* | Sort-Object CreationDate | Select-Object Name
</code> 
<p>Using AWS CLI</p> 
<code class="lang-bash">- aws ec2 describe-images --owners amazon --filters &quot;Name=name,Values=Windows_Server*&quot; --query 'sort_by(Images, &amp;CreationDate)[].Name'</code> 
<p>For example, Windows_Server-2016-English-Full-Base-2017.10.13 without the date-based version becomes Windows_Server-2016-English-Full-Base. When you add the public Parameter Store prefix namespace to the AMI alias you have the Parameter Store name of “/aws/service/ami-windows-latest/Windows_Server-2016-English-Full-Base”</p> 
<p>Each unique AMI namespace always remains the same. You no longer need to pattern match on name filters, and you no longer need to sort through CreationDate AMI properties. As Windows AMIs are patched and new versions are released to the public, AWS will update the Parameter Store value with the latest ImageID for each AMI namespace in all supported Regions.</p> 
<b><strong>Querying for the latest AMI using public Parameters</strong></b> 
<p>Once you have your target namespace, your query can be created to retrieve the latest AWS Windows ImageID. Each region has an exact replica namespace containing its region specific ImageID value.</p> 
<p>Using PowerShell</p> 
<code class="lang-powershell">Get-SSMParameter -Name /aws/service/ami-windows-latest/Windows_Server-2016-English-Full-Base -region us-east-1</code> 
<p>Using AWS CLI</p> 
<code class="lang-bash">aws ssm get-parameters --names /aws/service/ami-windows-latest/Windows_Server-2016-English-Full-Base --region us-east-1</code> 
<b><strong>Always launch new instances with the latest ImageID</strong></b> 
<p>After you have created the query, you can embed the command as a command substitution into your new instance launches.</p> 
<p>Using PowerShell</p> 
<code class="lang-powershell">New-EC2Instance -ImageId ((Get-SSMParameterValue -Name /aws/service/ami-windows-latest/Windows_Server-2016-English-Full-Base).Parameters[0].Value) -InstanceType m4.large -AssociatePublicIp $true -SubnetId subnet-abcd1234</code> 
<p>Using AWS CLI</p> 
<code class="lang-bash">aws ec2 run-instances --image-id $(aws ssm get-parameters --names /aws/service/ami-windows-latest/Windows_Server-2016-English-Full-Base&nbsp; --query 'Parameters[0].[Value]' --output text) --count 1 --instance-type m4.large --subnet-id subnet-abcd1234</code> 
<p>This new instance launch always results in the latest publicly available Windows AMI for Windows_Server-2016-English-Full-Base. Similar embedding can be used in a number of automation process, docs, and coding languages.</p> 
<b>Display a complete list of all available public Parameter Windows AMIs</b> 
<p>You can also query for the complete list of AWS Windows Parameter Store namespaces available.</p> 
<p>Using PowerShell</p> 
<code class="lang-powershell">Get-SSMParametersByPath -Path &quot;/aws/service/ami-windows-latest&quot; –region us-east-1</code> 
<p>Using AWS CLI</p> 
<code class="lang-bash">aws ssm get-parameters-by-path –-path &quot;/aws/service/ami-windows-latest&quot; –-region us-east-1</code> 
<b>Partial list of public Parameter AWS Windows AMIs</b> 
<code class="lang-bash">/aws/service/ami-windows-latest/Windows_Server-2016-Turkish-Full-Base
/aws/service/ami-windows-latest/Windows_Server-2016-Swedish-Full-Base
/aws/service/ami-windows-latest/Windows_Server-2016-Spanish-Full-Base
/aws/service/ami-windows-latest/Windows_Server-2016-Russian-Full-Base
/aws/service/ami-windows-latest/Windows_Server-2016-Portuguese_Portugal-Full-Base
/aws/service/ami-windows-latest/Windows_Server-2016-Portuguese_Brazil-Full-Base
/aws/service/ami-windows-latest/Windows_Server-2016-Polish-Full-Base
/aws/service/ami-windows-latest/Windows_Server-2016-Korean-Full-SQL_2016_SP1_Standard
/aws/service/ami-windows-latest/Windows_Server-2016-Korean-Full-Base
/aws/service/ami-windows-latest/Windows_Server-2016-Japanese-Full-SQL_2016_SP1_Web
/aws/service/ami-windows-latest/Windows_Server-2016-Japanese-Full-SQL_2016_SP1_Standard
/aws/service/ami-windows-latest/Windows_Server-2016-Japanese-Full-SQL_2016_SP1_Express
/aws/service/ami-windows-latest/Windows_Server-2016-Japanese-Full-SQL_2016_SP1_Enterprise
/aws/service/ami-windows-latest/Windows_Server-2016-Japanese-Full-Base
/aws/service/ami-windows-latest/Windows_Server-2016-Italian-Full-Base
/aws/service/ami-windows-latest/Windows_Server-2016-Hungarian-Full-Base
/aws/service/ami-windows-latest/Windows_Server-2016-German-Full-Base
/aws/service/ami-windows-latest/Windows_Server-2016-French-Full-Base
/aws/service/ami-windows-latest/Windows_Server-2016-English-Nano-Base
/aws/service/ami-windows-latest/Windows_Server-2016-English-Full-SQL_2017_Web
/aws/service/ami-windows-latest/Windows_Server-2016-English-Full-SQL_2017_Standard
/aws/service/ami-windows-latest/Windows_Server-2016-English-Full-SQL_2017_Express
/aws/service/ami-windows-latest/Windows_Server-2016-English-Full-SQL_2017_Enterprise 
</code>… 
<b>About the Author</b> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/16/download.jpg" /></p> 
<p>Steven Armentrout is a Systems Engineer on the Amazon EC2 Windows team and has over a decade of enterprise experience in the public and private sectors as System Administrator, Systems Engineer and Network Engineer.&nbsp;The resident expert on Windows Amazon Machine Images.&nbsp;The seeker of simplicity and ease of use.&nbsp;Living the dream and making a mark on the future of the cloud.</p> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">FINRA Gatekeeper: Amazon EC2 Access Management System Using Amazon EC2 Systems Manager</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Ananth Vaidyanathan</span></span> | on 
<time property="datePublished" datetime="2017-11-14T18:14:22+00:00">14 NOV 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/amazon-ec2-systems-manager/" title="View all posts in Amazon EC2 Systems Manager*"><span property="articleSection">Amazon EC2 Systems Manager*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools*"><span property="articleSection">Management Tools*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/finra-gatekeeper-amazon-ec2-access-management-system-using-amazon-ec2-systems-manager/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><em><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/13/finra-logo.png" />By Daniel Koo, Senior Director at FINRA, and Stephen Mele, Software Developer at FINRA</em></p> 
<h3>Introduction</h3> 
<p>Moving from a traditional data center to the cloud can impose many questions around compliance and security. FINRA took these concerns very seriously with our cloud migration journey to AWS. As a regulatory organization, overseeing up to 75 billion market transactions every day, it is critical for us to establish proper governance to ensure that compliance is met and that the right level of security is in place. In order for us to achieve this, we looked at building solutions on top of existing AWS services for managing human access. We wanted to make sure we properly control who has access to which resources, allow transparency to look at who is trying to access what resources, and add the necessary approval process when access is requested. The goal was to develop a solution which follows a self-service model, making it very easy for the development and ops community to adopt. The <a href="https://aws.amazon.com/ec2/systems-manager/">Amazon EC2 Systems Manager</a> (SSM) and <a href="https://console.aws.amazon.com/ssm/run-command">Run Command</a> service provided us exactly what we needed to build the right solution.</p> 
<p><span id="more-2011"></span></p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/13/problem.png" /></p> 
<h3>Solution Approach</h3> 
<p>Our solution was to provide temporary access to people using their existing credentials and permissions already being leveraged. We also wanted to make sure that we give the temporary access in a timely and responsive manner. In a traditional data center, it takes a significant amount of time to request access to a particular server and finally be granted the access. This is typically done through a paper process. Given that the majority of the servers are transient in the cloud, this long process did not work so we needed to automate the process and have a fast turnaround time. Ultimately, we wanted to discourage people from accessing the servers so that we could promote cloud-centric approaches such as re-deployment and self-healing. However this solution was necessary to achieve our desired control when access was absolutely needed. Following this approach, while keeping the compliance and security goals in mind, we developed an application called Gatekeeper which leverages <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/execute-remote-commands.html">Run Command</a> as the main technology.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/13/approach.png" /></p> 
<h3>Gatekeeper Application</h3> 
<p>Gatekeeper is designed as a Web application that is built around a request lifecycle management system, where a user performs a search, selects one or more EC2 resources for a specified environment (such as DEV, QA, Production), and makes a request for temporary access. The users have the ability to specify a set of people desiring the temporary access as well as the number of hours needed. Upon submitting the request, depending on the environment they are requesting for, there are two outcomes:</p> 
<ol> 
<li>The temporary access is immediately granted to the user(s).</li> 
<li>The access request requires a review and approval before being granted the temporary access. Upon approval, access is immediately granted to the user(s), otherwise the access is denied.</li> 
</ol> 
<p>Once the request is live, our lifecycle management system keeps track of the time that has elapsed since a request has been fulfilled. As soon as the time allotted to a specific request expires, the system will automatically revoke the user’s access from the resources specified in their request.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/15/schema_ssm.jpg" /></p> 
<h3>Creating the Users</h3> 
<p>Gatekeeper needs to be able to create an account for each user on all of the instances provided with the Access Request. To achieve this goal, Gatekeeper has documents staged in EC2 Systems Manager that perform the creation of users on running instances. The document itself is a simple shell script which will set up the user for the temporary access. Gatekeeper calls these documents by leveraging EC2 Systems Manager with the AWS SDK for Java. By taking this route, we do not have to worry about directly connecting to each instance and creating the users; we can simply make an AWS API call and let Systems Manager do all of the heavy lifting for us. Upon successful creation, the system will distribute the private keys to each user that is specified in the Access Request. Currently we have create/delete documents for Amazon Linux, Ubuntu, and Windows, but we could easily add more documents to support more operating systems should the need arise.</p> 
<h4>Example Create Document</h4> 
<code class="lang-json">{
&quot;schemaVersion&quot;:&quot;1.2&quot;,
&quot;description&quot;:&quot;Script for GateKeeper to create temp user.&quot;,
&quot;parameters&quot;:{
&quot;userName&quot;:{
&quot;type&quot;:&quot;String&quot;,
&quot;description&quot;:&quot;(Required) The username to create.&quot;,
&quot;allowedPattern&quot;:&quot;gk-.*&quot;,
&quot;maxChars&quot;:64
},
&quot;publicKey&quot;:{
&quot;type&quot;:&quot;String&quot;,
&quot;description&quot;:&quot;(Required) The public key string for the user.&quot;,
&quot;maxChars&quot;:4096
},
&quot;executionTimeout&quot;:{
&quot;type&quot;:&quot;String&quot;,
&quot;default&quot;:&quot;300&quot;,
&quot;description&quot;:&quot;(Optional) The time in seconds for a command to be completed before it is considered to have failed. Default is 3600 (1 hour). Maximum is 28800 (8 hours).&quot;,
&quot;allowedPattern&quot;:&quot;([1-9][0-9]{0,3})|(1[0-9]{1,4})|(2[0-7][0-9]{1,3})|(28[0-7][0-9]{1,2})|(28800)&quot;
}
},
&quot;runtimeConfig&quot;:{
&quot;aws:runShellScript&quot;:{
&quot;properties&quot;:[
{
&quot;id&quot;:&quot;0.aws:runShellScript&quot;,
&quot;runCommand&quot;:[
&quot;useradd -e `date -d '+2 days' '+%Y-%m-%d'` {{ userName }} -m&quot;,
&quot;mkdir /home/{{ userName }}/.ssh&quot;,
&quot;echo '{{ publicKey }}' &gt;&gt; /home/{{ userName }}/.ssh/authorized_keys&quot;,
&quot;chown -R {{ userName }}:{{ userName }} /home/{{ userName }}&quot;,
&quot;chmod -R go-rwx /home/{{ userName }}/.ssh&quot;,
&quot;echo '{{ userName }}  ALL=(ALL) NOPASSWD: ALL' &gt; /etc/sudoers.d/{{ userName }}&quot;,
&quot;usermod -p '*' {{ userName }}&quot;
],
&quot;workingDirectory&quot;:&quot;/root&quot;,
&quot;timeoutSeconds&quot;:&quot;{{ executionTimeout }}&quot;
}
]
}
}
}</code> 
<p>At a high level the script takes in 3 parameters and uses these to execute a shell script. The arguments for this script are:</p> 
<ol> 
<li><strong>userName</strong> – the username that the script will set up</li> 
<li><strong>publicKey</strong> – the public key that will be used for this user</li> 
<li><strong>executionTimeout</strong> – how much time to wait for the script to successfully complete</li> 
</ol> 
<p>The Gatekeeper application is responsible for providing the Systems Manager document with the <strong>userName</strong> and the public SSH key associated with that user. Gatekeeper will generate a new public/private SSH key each time so that no key will be re-used.</p> 
<p>The script itself will create the user via the&nbsp;<strong>useradd</strong> command, which will set up the user to expire after 2 days (if the system is unable to successfully remove the user). The user will be able to log into the instance only via their private key.</p> 
<h3>Revoking the User(s) Access</h3> 
<p>The Gatekeeper application keeps track of each Access Request that is active and determines whether it is time to revoke the user’s access. When the access period for a request expires, the system will invoke a different Systems Manager script that will execute a shell script which removes the user from the instance(s) to which they had requested access.</p> 
<h4>Example Remove Document</h4> 
<code class="lang-json">{
&quot;schemaVersion&quot;:&quot;1.2&quot;,
&quot;description&quot;:&quot;Script for GateKeeper to cleanup expired users.&quot;,
&quot;parameters&quot;:{
&quot;userName&quot;:{
&quot;type&quot;:&quot;String&quot;,
&quot;description&quot;:&quot;(Required) The username to delete.&quot;,
&quot;allowedPattern&quot;:&quot;gk-.*&quot;,
&quot;maxChars&quot;:64
},
&quot;executionTimeout&quot;:{
&quot;type&quot;:&quot;String&quot;,
&quot;default&quot;:&quot;300&quot;,
&quot;description&quot;:&quot;(Optional) The time in seconds for a command to be completed before it is considered to have failed. Default is 3600 (1 hour). Maximum is 28800 (8 hours).&quot;,
&quot;allowedPattern&quot;:&quot;([1-9][0-9]{0,3})|(1[0-9]{1,4})|(2[0-7][0-9]{1,3})|(28[0-7][0-9]{1,2})|(28800)&quot;
}
},
&quot;runtimeConfig&quot;:{
&quot;aws:runShellScript&quot;:{
&quot;properties&quot;:[
{
&quot;id&quot;:&quot;0.aws:runShellScript&quot;,
&quot;runCommand&quot;:[ &quot;cut -f1 -d':' /etc/passwd | grep {{ userName }} &gt; /dev/null &amp;&amp; (userdel -rf {{ userName }} ; echo 'user deleted' ) || echo 'no user to delete'&quot;,
&quot;ls /etc/sudoers.d/ | grep {{ userName }} &gt; /dev/null &amp;&amp; (rm -f /etc/sudoers.d/{{ userName }} ; echo 'sudo file deleted' ) || echo 'no sudo file to delete'&quot;    ],
&quot;workingDirectory&quot;:&quot;/root&quot;,
&quot;timeoutSeconds&quot;:&quot;{{ executionTimeout }}&quot;
}
]
}
}
}</code> 
<p>The arguments for this script are:</p> 
<ol> 
<li><strong>userName</strong>&nbsp;– the username that the script will delete</li> 
<li><strong>executionTimeout</strong>&nbsp;– how much time to wait for the script to successfully complete</li> 
</ol> 
<p>The script itself uses the <strong>userName</strong>&nbsp;parameter to delete the user from the instance(s). Should the script for some reason fail to run, it will re-try a set amount of times, and if there was no successful run, then the system will notify the Ops team to investigate and remove the user.</p> 
<h3>Conclusion</h3> 
<p>By leveraging Amazon EC2 Systems Manager and other services such as Amazon EC2 and AWS Identity and Access Management (IAM), FINRA was able to build a solution to manage temporary access to our resources running in AWS across multiple environments. Systems Manager is very easy to adopt, and it is extremely reliable and fast. It is a great tool for performing ad-hoc execution of scripts on running instances.</p> 
<p><em>The content and opinions in this blog are those of the third-party author and AWS is not responsible for the content or accuracy of this post.</em></p> 
<p>&nbsp;</p> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">How to Export EC2 Instance Execution Logs to an S3 Bucket Using CloudWatch Logs, Lambda, and CloudFormation</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Veronika Megler</span></span> | on 
<time property="datePublished" datetime="2017-11-13T11:12:07+00:00">13 NOV 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/amazon-cloudwatch/" title="View all posts in Amazon CloudWatch*"><span property="articleSection">Amazon CloudWatch*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/aws-cloudformation/" title="View all posts in AWS CloudFormation*"><span property="articleSection">AWS CloudFormation*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools*"><span property="articleSection">Management Tools*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/how-to-export-ec2-instance-execution-logs-to-an-s3-bucket-using-cloudwatch-logs-lambda-and-cloudformation/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p>“We want to get execution logs from our EC2 instances into S3,” my customer said. “Then we can store them and process them later, for optimization, audit, and security review, and so on. We’d like to do it in our CloudFormation stacks, as that’s our execution standard. Can you help us?”</p> 
<p>This blog post shows you how to build a solution for this problem. We’ll build it using Amazon CloudWatch Logs, AWS Lambda, and some useful capabilities in AWS CloudFormation for customizing EC2 instances.</p> 
<p><span id="more-1466"></span></p> 
<b>How it works</b> 
<p>To export the logs, we add some components to the CloudFormation stack that builds the EC2 instance. The following diagram and code samples show how this solution works in a stand-alone fashion. Later, we’ll discuss other ways to integrate these components into your production infrastructure.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/13/cwexport-arch.png" /></p> 
<p>We use a CloudFormation stack (1) to create the components shown. When everything is up and running, we have an EC2 instance running a CloudWatch Logs agent (2). The agent routes the configured logs to a CloudWatch Logs log group (3). A Lambda function (4) that’s subscribed to the log group picks up each log and writes it to an existing Amazon S3 bucket (5). Note that there’s some delay from the time a log message is created on the EC2 instance to the time it appears in the S3 bucket.</p> 
<p>To configure the EC2 instance, we use a neat feature in CloudFormation, the <a title="undefined" href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/cfn-helper-scripts-reference.html" target="_blank" rel="noopener noreferrer">CloudFormation helper functions</a>. These helper functions can be combined to install and update a variety of software packages, configure them, start services, and more. We’ll show you how in this blog.</p> 
<p>If you’d like to skip ahead and see the code in action, go to “Running the Solution.”</p> 
<b>The implementation</b> 
<p>The implementation consists of the following four files, which we’ll discuss later:</p> 
<p>1.&nbsp;<code>Cwexport-master-template.yaml</code>: This template creates a security group and IAM role for our EC2 instance, and calls two embedded CloudFormation templates to do the real work.</p> 
<p>2.&nbsp;<code>Cloudwatchlogsexport.yaml</code>: This template creates the CloudWatch log group the logs will be sent to, and defines the Lambda function that will perform the export from the log group to S3. It then creates a CloudWatch Log subscription to automatically send the CloudWatch log streams to the Lambda function.</p> 
<p>3.&nbsp;<code>Cloudwatch-log-lambda.zip</code>: This zip file contains the code for the Lambda function, packaged along with its prerequisites.</p> 
<p>4.&nbsp;<code>Run-ec2-instance.yaml</code>: This template creates the EC2 instance, installs the <a title="undefined" href="http://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/AgentReference.html" target="_blank" rel="noopener noreferrer">CloudWatch Log Agent</a>, &nbsp;configures it to export the desired logs, and performs a specified task on startup (in this case, calculating digits of Pi).</p> 
<p>In practice we first set up the CloudWatch log group and export to Amazon S3, and then set up and configure the EC2 instance.</p> 
<b>Exporting logs from CloudWatch Logs to S3</b> 
<p>In Cloudwatchlogsexport.yaml, we first set up the CloudWatch Logs log group itself (<a title="undefined" href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-logs-loggroup.html" target="_blank" rel="noopener noreferrer"><code>&quot;AWS::Logs::LogGroup&quot;</code></a>).</p> 
<p>Next, we define the Lambda function that will perform the actual export. We’ve packaged our Python code into a Lambda deployment package for uploading and deployment by CloudFormation. The function (cloudwatch-log-lambda.py) requires two environment variables, s3BucketName and s3KeyPrefix, to tell it where the log files should be exported to. We specify these variables as inputs to the master CloudFormation script, which passes them to the Lambda function at execution time.</p> 
<p>The Lambda function receives logs from CloudWatch. For each invocation it unzips the received log file, converts it from JSON into a dictionary, then writes it out to S3 with our naming convention (&lt;s3KeyPrefix&gt;/&lt;logGroup&gt;/&lt;logStream&gt;/&lt;timestamp&gt;). You can see the source code of the Lambda <a title="Lambda code" href="https://management-tools-blog-cf-template-storage.s3.amazonaws.com/cloudwatchlogsexport2s3/cloudwatch-exportlogs2s3-lambda.py" target="_blank" rel="noopener noreferrer">here</a>.</p> 
<p>Then, we associate the Lambda function and the CloudWatch log group via an <a title="undefined" href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-logs-subscriptionfilter.html" target="_blank" rel="noopener noreferrer"><code>“AWS::Logs::SubscriptionFilter”</code></a> tag, specifying the Lambda function and the log group it’s subscribing to. This subscription will trigger the Lambda function when new logs are written to the CloudWatch log group, and pass the new log to it.</p> 
<b>Customizing your EC2 instance</b> 
<p>The last CloudFormation template, Run-ec2-instance.yaml, starts our EC2 instance. We use CloudFormation tags to customize the properties of the EC2 instance: specifying the EC2 instance type, AMI, the IAM role, VPC, and so on.</p> 
<p>In our case, we also want to automatically install some software packages (notably, the CloudWatch Logs agent); configure some files; and then start some services – all before the actual processing specified in our UserData section is triggered. We can do so by using some capabilities that CloudFormation provides.</p> 
<p>First, we use an <a title="undefined" href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-init.html" target="_blank" rel="noopener noreferrer"><code>AWS::CloudFormation::Init</code></a> tag in the metadata section of our EC2 definition to define customizations. Then we call a <a title="undefined" href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/cfn-helper-scripts-reference.html" target="_blank" rel="noopener noreferrer">set of provided CloudFormation helper scripts</a> from our EC2 instances’s UserData to implement the definitions before we move on to doing the work we’ve set up the EC2 instance to do. We describe the tag and definitions next.</p> 
<b>The AWS::CloudFormation::Init tag</b> 
<p>We use the <code>AWS::CloudFormation::Init</code> type to include metadata for our Amazon EC2 instance. The metadata can later be accessed by the helper scripts. When we execute the helper scripts from our EC2 instance’s UserData, the script looks for resource metadata specified in the AWS::CloudFormation::Init metadata key and uses that information to customize the instance. Here’s the beginning of our definition:</p> 
<code class="lang-yaml">&nbsp; EC2Instance:
&nbsp;&nbsp;&nbsp; Type: 'AWS::EC2::Instance'
&nbsp;&nbsp;&nbsp; Metadata:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 'AWS::CloudFormation::Init':
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; configSets:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; default:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [config]
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; config:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; …</code> 
<p>The CloudFormation Init tag supports a wide variety of capabilities, which we encourage you to explore. For this EC2 instance we’ll use three: packages, files, and services.</p> 
<h4>Using CloudFormation::Init to install software</h4> 
<p>We can use the packages tag to download and install pre-packaged applications and components. For this blog post, we want to install one yum package: awslogs, the AWS CloudWatch Logs agent. Because the software is installed by the <a title="undefined" href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/cfn-init.html" target="_blank" rel="noopener noreferrer">cfn-init</a> helper script, we’re limited to the package formats it supports. Currently, on Linux the package formats are apt, msi, python, rpm, rubygems, and yum. We specify the package manager, then each package’s name, and a list of (possibly empty) versions. Because we aren’t sensitive to the version here, we’ll leave the version tag blank. In this case, cfn-init installs the latest version if the package isn’t already installed, or leaves it at the current version if the package is installed.</p> 
<code class="lang-yaml">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; config:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; packages:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; yum:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; awslogs: []
...</code> 
<h4>Configuring files</h4> 
<p>Next, we want to use CloudFormation to <a title="undefined" href="http://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/EC2NewInstanceCWL.html" target="_blank" rel="noopener noreferrer">create or modify the CloudWatch Log agent configuration files on the EC2 instance</a>. We can do this by using the “files” key of our <code>AWS::CloudFormation::Init</code>. There are several options for creating the files. Here, we include the desired content for the files directly in the CloudFormation template. We create two <a title="undefined" href="http://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/AgentReference.html" target="_blank" rel="noopener noreferrer">CloudWatch agent configuration files</a> and two CloudFormation helper configuration files:</p> 
<p><strong>/etc/awslogs/awscli.conf:</strong> This short example shows how an entire file is specified within this tag. The file will contain the default Region, and a plugin setting:</p> 
<code class="lang-yaml">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; files:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; '/etc/awslogs/awscli.conf':
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; content: !Sub |
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [default]
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; region = ${AWS::Region}
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [plugins]
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; cwlogs = cwlogs
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; mode: '000644'
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; owner: root
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; group: root</code> 
<p><strong>/etc/awslogs/awslogs.conf:</strong> We specify the local files we want to send to CloudWatch Logs, along with the log stream name to send them to, and other characteristics. The list being exported includes the CloudFormation execution logs. We encourage you to extend the list to include logs for your application or other logs of interest.</p> 
<p>We’ve configured each selected EC2 instance local log file to go to a log stream that consists of the stack name, followed by the EC2 instance ID, followed by the name of the file. This way, the files associated with one instance are grouped together and are easily findable in CloudWatch. This naming convention can easily be changed.</p> 
<p>The CloudWatch Logs agent lets us specify the size of the batches, the time stamp formats, the encoding, and more. By default, the logs are sent using enable gzip http content encoding to send compressed payloads to CloudWatch Logs. This decreases CPU usage, lowers Network Out, and decreases put latency. Our Lambda function unzips the files before writing them out.</p> 
<p><strong>/etc/cfn/cfn-hup.conf and /etc/cfn/hooks.d/cfn-auto-reloader.conf:</strong> These two configuration files are used to configure the <a title="undefined" href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/cfn-hup.html" target="_blank" rel="noopener noreferrer">cfn-hup daemon</a>. This daemon detects changes in the EC2 resource metadata and runs user-specified actions when a change is detected. This allows you to make configuration updates on your running Amazon EC2 instances through the UpdateStack API action.</p> 
<h4>Starting and restarting services</h4> 
<p>The third section in the metadata that we specify is the <a title="undefined" href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-init.html#aws-resource-init-services" target="_blank" rel="noopener noreferrer">services</a> key. This key defines which services should be enabled or disabled when the instance is launched. The services key also allows you to specify dependencies on sources, packages and files. If a restart is needed after files have been installed, cfn-init will take care of the service restart. In our example, we use this key to restart two services after we’ve created the config files for awslogs and cfn-hup.</p> 
<code class="lang-yaml">          services:
sysvinit:
awslogs:
enabled: true
ensureRunning: true
packages:
yum:
- awslogs
files:
- '/etc/awslogs/awslogs.conf'
- '/etc/awslogs/awscli.conf'
cfn-hup:
enabled: true
ensureRunning: true
files:
- '/etc/cfn/cfn-hup.conf'
- '/etc/cfn/hooks.d/cfn-auto-reloader.conf'</code> 
<h4>Finally: Executing the definitions</h4> 
<p>Having specified the files to install, config files to set up, and services to be started, we need to ensure that the <a title="undefined" href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/cfn-init.html" target="null">cfn-init</a> helper function is run to implement these specifications. In the EC2 instance’s UserData section, we first update the helper scripts and ensure that other yum packages are up-to-date. Then, we execute cfn-init, telling it which resource and CloudFormation stack to use as parameters.</p> 
<p>Lastly, we call the <a title="undefined" href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/cfn-signal.html" target="null">cfn-signal</a> helper function to let CloudFormation know that our EC2 instance is up and ready. We pass it the name of the stack, the Region, and the resource we’re sending a signal for. This signal causes CloudFormation to switch the EC2 instance to “Complete”.</p> 
<code class="lang-yaml">&nbsp; UserData:
&nbsp;&nbsp;&nbsp; 'Fn::Base64': !Sub |
&nbsp;&nbsp;&nbsp; #!/bin/bash -x
&nbsp;&nbsp;&nbsp; # Use the line below to ensure the CloudFormation helper scripts are updated to the latest version
&nbsp;&nbsp;&nbsp; # Per: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/cfn-helper-scripts-reference.html
&nbsp;&nbsp;&nbsp; yum install -y aws-cfn-bootstrap
&nbsp;&nbsp;&nbsp; yum update -y&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; /opt/aws/bin/cfn-init -v --stack ${AWS::StackName} --resource EC2Instance --configsets default --region ${AWS::Region}
&nbsp;&nbsp;&nbsp; /opt/aws/bin/cfn-signal -e $? --stack ${AWS::StackName} --region ${AWS::Region} --resource=EC2Instance</code> 
<p>Now, we’re ready to actually perform the work of this EC2 instance. In our example, it’s a dummy job that calculates digits of Pi. We’re actually more interested in the log files created.</p> 
<h3>Running the solution</h3> 
<p>To see this solution in operation in us-west-2, choose the “Launch Stack” button&nbsp;below.</p> 
<p>&nbsp;</p> 
<p>Choose “Next”, then update the parameters shown below for your environment: TheLogsBucketName, VPCId, VPC Subnet and s3BucketForResults (leave the Template Locations as is).</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/30/Cloudwatchloggroup-stackparms.png" /></p> 
<p>Click “Next” twice, acknowledge that AWS CloudFormation might create IAM resources with custom names, and click “Create”. Then wait for the CloudFormation master stack and its two nested stacks to reach a status of “CREATE_COMPLETE”.</p> 
<p>After our EC2 instance is up and running, the files we specified in our CloudWatch Logs agent configuration are exported to CloudWatch. Here’s an example of our log group, as seen in the CloudWatch Logs console:</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/06/Cloudwatch-loggroup-capprechng.png" /></p> 
<p>The Lambda function receives each log from CloudWatch and unzips it. It then writes the event file out to Amazon S3, giving it an S3 key that consists of the given S3 key prefix, followed by the log group, the log stream name (i.e., the filename), and a timestamp.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/13/cwexport-s3-output.png" /></p> 
<p>If the logs don’t appear in Amazon S3 as expected, check the Lambda function’s CloudWatch Logs log group for execution errors. The CloudWatch logs for the Lambda function can be found in a log group named: <code>/aws/lambda/&lt;mainstackname&gt;-CWExportStack-CWEc2LogsLambdaFunction-&lt;id&gt;</code>.</p> 
<h4>The power of change sets</h4> 
<p>Earlier, we configured a cfn-hup daemon. The cfn-hup helper is a daemon that detects changes in resource metadata and runs user-specified actions when a change is detected. This allows you to make configuration updates on your running Amazon EC2 instances through the UpdateStack API action.</p> 
<p>Let’s demonstrate the power of the cfn-hup configuration that’s in our CloudFormation stack. In our files definition, we provided the following configuration:</p> 
<code class="lang-yaml">'/etc/cfn/hooks.d/cfn-auto-reloader.conf':  
content: !Sub |
[cfn-auto-reloader-hook]
triggers=post.update
path=Resources.EC2Instance.Metadata.AWS::CloudFormation::Init
action=/opt/aws/bin/cfn-init --verbose --stack=${AWS::StackName} --region=${AWS::Region} --resource=EC2Instance
runas=root 
</code> 
<p>This configuration tells cfn-hup to re-run cfn-init after the stack has been updated.</p> 
<p>In our case, we’ll make two changes to our EC2 instance. First, we’ll add an additional software package to install: jq. Imagine that there’s a part of our software stack that’s only invoked rarely, and we’re either missing a package or wish to upgrade a version in our running system. Secondly, we’ll add an additional log file export, cloud to our CloudWatch Logs configuration.</p> 
<p>These changes have been made for you, in another CloudFormation template: &nbsp;run-ec2-instance-changed.yaml. To execute this change through the console, do the following steps.</p> 
<ol> 
<li>In the CloudFormation console, select your nested “EC2InstanceStack”.</li> 
<li>Choose Actions&nbsp;&nbsp;-&gt; Update Stack.</li> 
<li>You’ll receive a warning that “Performing operations directly on a nested stack may result in an unstable state where it is out-of-sync with the root stack to which it belongs.” But we’ll be very careful here, so select the option “Yes, Update.”</li> 
<li>Next, select the revised template. Enter the following URL: <code>https://management-tools-blog-cf-template-storage.s3.amazonaws.com/cloudwatchlogsexport2s3/run-ec2-instance-changed.yaml</code>, and choose Next.</li> 
<li>Click through the next two pages that show the existing template parameters. &nbsp;We won’t be modifying any of them.</li> 
<li>On the next page, CloudFormation shows the results of analyzing the differences between the new CloudFormation template and the currently running one. The following screenshot shows the differences. We are modifying the EC2 instance only. The changes we’ve made result in “Replacement: False”, telling us that the existing EC2 instance will be modified. Other results there are “True,” which causes the resource to be replaced; or, “Conditional,” which means the resource property will be dynamically evaluated at execution time to determine if it requires replacement or not.</li> 
</ol> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/30/cwmod-1.png" /><br /> 7. Choose “Update”.</p> 
<p>Then, in the CloudFormation console, you can see the update actions as they occur, and their results, as in the screenshot below.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/30/Cwconsoleduringupdate-1.png" /></p> 
<p>After waiting a little while for the changes and logs to propagate, you can check the CloudWatch log group. You’ll see a new log stream there, for the cloud-init.log definition we added.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/06/Cloudwatch-loggroup-cappostchng.png" /></p> 
<p>In our CloudWatch log group (or in S3), you can review cfn-hup.log and see the moment it’s notified of the CloudFormation template change, and starts the cfn-auto-reloader-hook action.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/06/cfn-hup-log.png" /></p> 
<p>Then, in cfn-init.log, you can see the installation of the jq software package, and the rewriting of the other files specified in our CloudFormation template.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/30/cfn-init-log-1.png" /></p> 
<p>Now we’ve successfully updated our running EC2 instance, with additional software and changed configurations. All through our CloudFormation stack. And, we know that the CloudFormation template we now have reflects our running environment. Sweet!</p> 
<p>Remember to delete the CloudFormation stack when you’re done, to stop incurring fees. If you delete the stack right way, testing the solution will cost only a few cents.</p> 
<h4>Adapting for production use</h4> 
<p>To implement, copy the files from s3://management-tools-blog-cf-template-storage.s3.amazonaws.com/cwexportlogs2s3/, and modify as needed for your environment.</p> 
<p>This implementation demonstrates useful capabilities. However, you should consider modifying some details for production use.</p> 
<p>In <code>cloudwatchlogsexport.yaml</code>, we’ve created a new log group. Since for demo purposes we’ll be deleting the log group when the CloudFormation stack is removed, we’ve added a commented out line <code>“#DeletionPolicy: Retain”</code> at the end of the definition. Because we’re writing the logs to S3, we don’t need to retain the log group. However, you may also choose to retain the group for some time after the run before expiring it, for additional validation. Also, because there is a delay in writing out the logs created, if you aggressively delete &nbsp;the CloudFormation stack as soon as the EC2 instance is terminated you might remove the Lambda function before the last logs have made it to the S3 bucket. We recommend that you wait a few minutes before deleting the CloudFormation stack.</p> 
<p>You can also choose to use one log group for many CloudFormation stacks and EC2 instance executions. Using that approach, you would create the CloudWatch Log group and Lambda function once (run <code>Cloudwatchlogsexport.yaml</code> alone), and leave them in place for the long term. As each EC2 instance gets created (<code>run-ec2-instance.yaml</code>), pass it the name of the log group to use. Since we are using the instance ID in the log stream ID, the different executions will still be clearly identified in CloudWatch and in Amazon S3.</p> 
<h3>Conclusion</h3> 
<p>By integrating the CloudWatch Logs agent into our CloudFormation stack, your EC2 instance logs can easily be exported to an S3 bucket. After the logs are in S3, you have a myriad of additional options. You can make the EC2 instance logs part of your data lake. You can process them using some analytics tools, such as <a title="undefined" href="https://quicksight.aws/" target="_blank" rel="noopener noreferrer">Amazon QuickSight</a>. You can set up S3 lifecycle rules to automatically archive them for audit purposes, using <a title="undefined" href="https://aws.amazon.com/glacier/" target="_blank" rel="noopener noreferrer">Amazon Glacier</a>. Because all the components are automated using a CloudFormation stack, you can ensure that the logs are being exported and stored consistently. For example, you can integrate this solution into <a title="undefined" href="https://aws.amazon.com/blogs/compute/how-to-provision-complex-on-demand-infrastructures-by-using-amazon-api-gateway-and-aws-lambda/" target="null">requests to provision infrastructure</a>, to ensure that audit trails for all such requests are created in a consistent fashion.</p> 
<p>The same CloudFormation components can be used to install, configure, and customize many other combinations of software.You’re limited only by your imagination. We hope this blog inspires you to extend your use to other use cases beyond the ones we’ve described here.</p> 
<h4>About the Author</h4> 
<p><strong>Veronika Megler, PhD, is a Senior Consultant, Big Data, Analytics &amp; Data Science, for AWS Professional Services.</strong> She enjoys helping customers adopt new technologies to solve new problems and to solve old problems more efficiently and effectively. In her spare time she is passionate about conservation, travel to interesting, beautiful or historic places, expanding her knowledge of arcane subjects, and searching for ultimate expression in Argentine tango.</p> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">The Virtues of YAML CloudFormation and Using CloudFormation Designer to Convert JSON to YAML</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Aaron Fagan</span></span> | on 
<time property="datePublished" datetime="2017-11-10T09:19:38+00:00">10 NOV 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/aws-cloudformation/" title="View all posts in AWS CloudFormation*"><span property="articleSection">AWS CloudFormation*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools*"><span property="articleSection">Management Tools*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/the-virtues-of-yaml-cloudformation-and-using-cloudformation-designer-to-convert-json-to-yaml/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><a href="https://aws.amazon.com/cloudformation/">AWS CloudFormation</a> provides the framework to define infrastructure-as-code in AWS and, until last year, this could only be written in JSON. However, in 2016, AWS added <a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/template-formats.html">YAML 1.1</a> support for CloudFormation. Let’s take a look at some of the advantages of using YAML over JSON, as well as how to overcome some of the challenges in getting started writing CloudFormation in YAML.</p> 
<h3>The virtues of YAML</h3> 
<p>YAML CloudFormation fully supports all of the same features and functions as JSON CloudFormation with some additional features to reduce the length of code and increase readability. Say goodbye to the curly braces and most of the quotation marks of JSON when you use YAML.&nbsp;YAML uses parent nodes, child nodes, and indentation to denote hierarchy rather than curly braces and commas as in JSON.</p> 
<p>YAML also supports comments using the # character. CloudFormation templates can get complex. Including key comments in the code can make it easier to understand, especially as teams get started with CloudFormation and develop templates together.</p> 
<p>Let’s look at a code sample. The following YAML and JSON CloudFormation templates perform the same function, they deploy an Amazon Linux EC2 instance serving a webpage via Apache HTTP Server.<span id="more-1918"></span></p> 
<h3>JSON template</h3> 
<code class="lang-json">{
&quot;AWSTemplateFormatVersion&quot;: &quot;2010-09-09&quot;,
&quot;Parameters&quot;: {
&quot;SubnetID&quot;: {
&quot;Type&quot;: &quot;AWS::EC2::Subnet::Id&quot;,
&quot;Description&quot;: &quot;Subnet to deploy EC2 instance into&quot;
},
&quot;SecurityGroupIDs&quot;: {
&quot;Type&quot;: &quot;List&lt;AWS::EC2::SecurityGroup::Id&gt;&quot;,
&quot;Description&quot;: &quot;List of Security Groups to add to EC2 instance&quot;
},
&quot;KeyName&quot;: {
&quot;Type&quot;: &quot;AWS::EC2::KeyPair::KeyName&quot;,
&quot;Description&quot;: &quot;Name of an existing EC2 KeyPair to enable SSH access to the instance&quot;
},
&quot;InstanceType&quot;: {
&quot;Description&quot;: &quot;EC2 instance type&quot;,
&quot;Type&quot;: &quot;String&quot;,
&quot;Default&quot;: &quot;t2.micro&quot;
}
},
&quot;Mappings&quot;: {
&quot;AWSRegionToAMI&quot;: {
&quot;us-east-1&quot;: {
&quot;AMIID&quot;: &quot;ami-0b33d91d&quot;
},
&quot;us-east-2&quot;: {
&quot;AMIID&quot;: &quot;ami-c55673a0&quot;
}
}
},
&quot;Resources&quot;: {
&quot;EC2Instance&quot;: {
&quot;Type&quot;: &quot;AWS::EC2::Instance&quot;,
&quot;Properties&quot;: {
&quot;ImageId&quot;: {
&quot;Fn::FindInMap&quot;: [
&quot;AWSRegionToAMI&quot;,
{
&quot;Ref&quot;: &quot;AWS::Region&quot;
},
&quot;AMIID&quot;
]
},
&quot;InstanceType&quot;: {
&quot;Ref&quot;: &quot;InstanceType&quot;
},
&quot;KeyName&quot;: {
&quot;Ref&quot;: &quot;KeyName&quot;
},
&quot;SecurityGroupIds&quot;: {
&quot;Ref&quot;: &quot;SecurityGroupIDs&quot;
},
&quot;SubnetId&quot;: {
&quot;Ref&quot;: &quot;SubnetID&quot;
},
&quot;UserData&quot;: {
&quot;Fn::Base64&quot;: {
&quot;Fn::Sub&quot;: &quot;#!/bin/bash -ex\nyum install -y httpd;\necho \&quot;&lt;html&gt;I love YAML CloudFormation!!&lt;/html&gt;\&quot; &gt; /var/www/html/index.html;\ncd /var/www/html;\nchmod 755 index.html;\nservice httpd start;\nchkconfig httpd on;\n&quot;
}
},
&quot;Tags&quot;: [
{
&quot;Key&quot;: &quot;Name&quot;,
&quot;Value&quot;: &quot;CloudFormation Test - YAML&quot;
},
{
&quot;Key&quot;: &quot;Environment&quot;,
&quot;Value&quot;: &quot;Development&quot;
}
]
}
}
}
}
</code> 
<img style="border: 0px;width: 32px;height: 32px;margin-right: 5px !important" src="https://aws-support-gm.s3.amazonaws.com/prod/tiny-url-shrinker/TinyURLShortener-icon-64x64.png" /> 
<h3 title="Shrink this URL">YAML template</h3> 
<code class="lang-yaml">AWSTemplateFormatVersion: 2010-09-09
Parameters:
SubnetID:
Type: AWS::EC2::Subnet::Id
Description: Subnet to deploy EC2 instance into
SecurityGroupIDs:
Type: List&lt;AWS::EC2::SecurityGroup::Id&gt;
Description: List of Security Groups to add to EC2 instance
KeyName:
Type: AWS::EC2::KeyPair::KeyName
Description: &gt;-
Name of an existing EC2 KeyPair to enable SSH access to the instance
InstanceType:
Description: EC2 instance type
Type: String
Default: t2.micro
Mappings:
AWSRegionToAMI:
us-east-1:
AMIID: ami-0b33d91d
us-east-2:
AMIID: ami-c55673a0
Resources:
EC2Instance:
Type: AWS::EC2::Instance                     
Properties:
ImageId:
!FindInMap                                 # This is an example of the short form YAML FindInMap function
- AWSRegionToAMI                         # It accepts three parameters each denoted by a hyphen (-)
- !Ref AWS::Region
- AMIID
InstanceType: !Ref InstanceType
KeyName: !Ref KeyName
SecurityGroupIds: !Ref SecurityGroupIDs
SubnetId: !Ref SubnetID
UserData:
Fn::Base64:                                # YAML makes userdata much cleaner
!Sub |
#!/bin/bash -ex
yum install -y httpd;
echo &quot;&lt;html&gt;I love YAML CloudFormation!!&lt;/html&gt;&quot; &gt; /var/www/html/index.html;
cd /var/www/html;
chmod 755 index.html;
service httpd start;
chkconfig httpd on;
Tags:                                      # Tags are an example of a sequence of mappings in YAML,
-                                        # each key/value pair is separated by a hyphen
Key: Name
Value: CloudFormation Test - YAML      
-
Key: Environment
Value: Development
</code> 
<p>From a readability perspective, it’s pretty clear YAML is the winner. The JSON template is 1200 characters with whitespace removed. The YAML template is 972 characters for the exact same functionality with whitespace and comments removed. Shorter templates are not only more readable and make troubleshooting errors easier, but they also allow more resources to be deployed in a single template without hitting <a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/cloudformation-limits.html">CloudFormation limits</a> for template body size.</p> 
<h3>Converting a JSON CloudFormation template to YAML</h3> 
<p>We’ve established there are some advantages to using YAML, but many organizations already have libraries of JSON-formatted CloudFormation templates and employees with expertise writing JSON. Additionally, many publically available code samples are written in JSON along with many <a href="https://aws.amazon.com/quickstart/">AWS QuickStarts</a>. If only there were an easy, secure way to convert JSON CloudFormation to YAML. Old JSON templates could be reused and public samples could be converted to make learning YAML easier.</p> 
<p>Enter <a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/working-with-templates-cfn-designer.html">CloudFormation Designer</a></p> 
<p>CloudFormation Designer is an easy-to-use graphical user interface to create, edit, and view CloudFormation templates. The Designer is free and is part of the AWS Management Console. One fantastic feature is the ability to convert CloudFormation templates from JSON to YAML, and back again, with the click of a button. There are other online converters out there but the Designer is part of your AWS Management Console, so the code never leaves your possession.</p> 
<p>&nbsp;</p> 
<p>Let’s convert our JSON template to YAML:</p> 
<p>1. Open the AWS Management Console and navigate to the <strong>CloudFormation service</strong>.</p> 
<p>2. Choose the <strong>Design template</strong> button to open the Designer.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/02/step2.png" /></p> 
<p>&nbsp;</p> 
<p>3. Open the JSON CloudFormation template by choosing the File icon, then choosing <strong>Open</strong> from the menu.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/02/step3.png" /></p> 
<p>&nbsp;</p> 
<p>4. <strong>Select the file</strong>, either a local file on your workstation or a file in an Amazon S3 bucket. This opens the CloudFormation template in Designer. We see the familiar JSON code of our template in the bottom pane. In the upper-right pane, we see a graphical representation of the EC2 instance described in our template. Finally, in the upper-left pane, we can optionally drag and drop a variety of Resource Types onto the canvas to include them in our template.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/02/step4.png" /></p> 
<p>&nbsp;</p> 
<p>5. In the upper right-hand corner of the code pane, note the <strong>Choose template language</strong> radio button. Choose the button next to YAML to convert the template to YAML. Just like that our JSON is perfectly formatted YAML. Choosing the JSON button will convert the template back to JSON.</p> 
<p>Caution: <em>Converting a commented YAML template to JSON will remove all comments. Comments will not re-appear if the template is toggled back to YAML</em>.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/02/step51.png" /></p> 
<p>&nbsp;</p> 
<p>6. <strong>Save</strong> the template in YAML format by once again choosing the File icon and choosing Save from the menu.</p> 
<p style="text-align: center"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/03/step61-1.png" /></p> 
<h3>Conclusion</h3> 
<p>In this blog post, we discussed some reasons to convert CloudFormation templates from JSON to YAML format and to code in YAML. We also did a side-by-side comparison of the readability of JSON and YAML using a sample template. Finally, we walked through how to convert existing JSON CloudFormation templates to YAML using CloudFormation Designer. There’s no better time than the present to dive in and get started with CloudFormation YAML. Happy coding!</p> 
<hr /> 
<h3>About the Author</h3> 
<p style="text-align: left"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/02/badgephotobw-200x300.jpg" />Aaron Fagan is a Senior Cloud Infrastructure Architect on the Boston AWS Professional Services team where he works with Enterprises to accelerate and optimize their adoption of the AWS public cloud. When not coding CloudFormation in YAML, he enjoys weightlifting and cooking.</p> 
<img style="border: 0px;width: 32px;height: 32px;margin-right: 5px !important" src="https://aws-support-gm.s3.amazonaws.com/prod/tiny-url-shrinker/TinyURLShortener-icon-64x64.png" /> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">Controlling Projected User Costs Through Monthly Budget Policies</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Adam Westrich</span></span> | on 
<time property="datePublished" datetime="2017-11-06T16:10:43+00:00">06 NOV 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/mt/category/aws-cost-management/" title="View all posts in AWS Cost Management*"><span property="articleSection">AWS Cost Management*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/compute/aws-lambda/" title="View all posts in AWS Lambda*"><span property="articleSection">AWS Lambda*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools*"><span property="articleSection">Management Tools*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/controlling-projected-user-costs-through-monthly-budget-policies/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<h3 style="text-align: left">Introduction</h3> 
<p>With the announcement of our new AWS Price List Query APIs, let’s discuss a use-case that you can deploy directly to your AWS account. Customers often ask for ways to proactively control costs while having the flexibility to experiment with different AWS resource sizes and types. The solution we’ll discuss in this blog post gives you the ability to project monthly <a href="https://aws.amazon.com/ec2/">Amazon EC2</a> costs for individual Identity and Access Management (IAM) users and receive alerts when user projected costs exceed their configured thresholds. You can deploy this solution to your AWS account using <a href="https://aws.amazon.com/cloudformation/">AWS CloudFormation</a>&nbsp;below.</p> 
<p>When a user launches or starts EC2 instances, the solution calculates the projected monthly cost using the Price List Query API, and aggregates those costs for each AWS user. Likewise, when a user stops or terminates instances, the user’s projected cost is reduced. The solution also allows user budget targets to be set, which gives Operational Management the ability to intervene when projected thresholds are exceeded before the actual monthly costs are accrued.</p> 
<p><span id="more-1745"></span></p> 
<h3>Architecture</h3> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/blog_westrich_1-1.png" /></p> 
<h3>Walkthrough</h3> 
<ol> 
<li>When a user launches an EC2 instance, user and launch details are logged in <a href="https://aws.amazon.com/cloudtrail/">AWS CloudTrail</a>, which triggers an <a href="http://docs.aws.amazon.com/AmazonCloudWatch/latest/events/LogEC2InstanceState.html">Amazon CloudWatch event</a>.</li> 
<li>The CloudWatch event triggers a <a href="https://aws.amazon.com/lambda/">Lambda function</a>, which performs three&nbsp;tasks: 
<li>Calls the AWS Price List Query API to retrieve the price of EC2 instance on which action was taken.</li> 
<li>Based on event type (Launch/Start or Stop/Terminate), edits the <a href="https://aws.amazon.com/dynamodb/">DynamoDB</a> table with new price based upon the continued projection for the month.</li> 
<li>Sends a trigger to another Lambda function which will check for a policy breach.</li> 
</ul> </li> 
<li>The policy breach Lambda function checks if the user in the DynamoDB table has breached the budgeted&nbsp;threshold 
<li style="text-align: left">If the budget threshold is breached, the Lambda function generates an Amazon SNS notification to email alert the IT operations team.</li> 
</ul> </li> 
</ol> 
<p>Here is an example of the notification email sent to stakeholders:</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/blog_westrich_2.png" /></p> 
<p>The AWS Price List API makes this process easy to obtain accurate EC2 price information.</p> 
<p>The following CloudFormation templates below can be deployed in your environment with CloudTrail enabled by simply filling in a few parameters:</p> 
<table align="center"> 
<tbody> 
<tr> 
<td><strong>Region</strong></td> 
<td style="text-align: center"><strong>Launch Template</strong></td> 
</tr> 
<tr> 
<td><strong>N. Virginia&nbsp;</strong>(us-east-1)</td> 
<td><a href="https://console.aws.amazon.com/cloudformation/home?region=us-east-1#/stacks/new?stackName=UserCostControl&amp;templateURL=https://s3.us-east-1.amazonaws.com/cost-control-us-east-1/cost_control_v1.yaml"><strong><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/blog_westrich_5.png" /></strong></a></td> 
</tr> 
<tr> 
<td><strong>Ohio&nbsp;</strong>(us-east-2)</td> 
<td><a href="https://console.aws.amazon.com/cloudformation/home?region=us-east-2#/stacks/new?stackName=UserCostControl&amp;templateURL=https://s3.us-east-2.amazonaws.com/cost-control-us-east-2/cost_control_v1.yaml"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/blog_westrich_5.png" /></a></td> 
</tr> 
<tr> 
<td><strong>Oregon&nbsp;</strong>(us-west-2)</td> 
<td><a href="https://console.aws.amazon.com/cloudformation/home?region=us-west-2#/stacks/new?stackName=UserCostControl&amp;templateURL=https://s3.us-west-2.amazonaws.com/cost-control-us-west-2/cost_control_v1.yaml"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/blog_westrich_5.png" /></a></td> 
</tr> 
<tr> 
<td><strong>Asia Pacific – Mumbai</strong> (ap-south-1)</td> 
<td><a href="https://console.aws.amazon.com/cloudformation/home?region=ap-south-1#/stacks/new?stackName=UserCostControl&amp;templateURL=https://s3.ap-south-1.amazonaws.com/cost-control-ap-south-1/cost_control_v1.yaml"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/blog_westrich_5.png" /></a></td> 
</tr> 
<tr> 
<td><strong>Asia Pacific – Sydney</strong> (ap-southeast-2)</td> 
<td><a href="https://console.aws.amazon.com/cloudformation/home?region=ap-southeast-2#/stacks/new?stackName=UserCostControl&amp;templateURL=https://s3.ap-southeast-2.amazonaws.com/cost-control-ap-southeast-2/cost_control_v1.yaml"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/blog_westrich_5.png" /></a></td> 
</tr> 
<tr> 
<td><strong>Asia Pacific – Tokyo</strong> (ap-northeast-1)</td> 
<td><a href="https://console.aws.amazon.com/cloudformation/home?region=ap-northeast-1#/stacks/new?stackName=UserCostControl&amp;templateURL=https://s3.ap-northeast-1.amazonaws.com/cost-control-ap-northeast-1/cost_control_v1.yaml"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/blog_westrich_5.png" /></a></td> 
</tr> 
<tr> 
<td><strong>EU – Ireland</strong> (eu-west-1)</td> 
<td><a href="https://console.aws.amazon.com/cloudformation/home?region=eu-west-1#/stacks/new?stackName=UserCostControl&amp;templateURL=https://s3.eu-west-1.amazonaws.com/cost-control-eu-west-1/cost_control_v1.yaml"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/blog_westrich_5.png" /></a></td> 
</tr> 
<tr> 
<td><strong>EU – London </strong>(eu-west-2)</td> 
<td><a href="https://console.aws.amazon.com/cloudformation/home?region=eu-west-2#/stacks/new?stackName=UserCostControl&amp;templateURL=https://s3.eu-west-2.amazonaws.com/cost-control-eu-west-2/cost_control_v1.yaml"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/blog_westrich_5.png" /></a></td> 
</tr> 
</tbody> 
</table> 
<h4>Notes:</h4> 
<li>This solution should be used as an addition to the AWS Billing and Cost Management tools. The solution calculations are based upon on-demand EC2 costs per second for non-Windows operating systems and per hour for Windows operating systems. They don’t include instances with pre-installed software or AWS Marketplace software licenses.</li> 
<li>The monthly cost of the AWS resources to deploy this cost-control solution&nbsp;is in most scenarios, &lt; $5.</li> 
<li>These projections are only estimates, and monthly charges will be based on your actual usage of AWS services, and may vary from the projections provided.</li> 
<h3>Conclusion</h3> 
<p>As organizations are given freedoms to experiment with computing resources in the AWS cloud, they often need governance controls for an effective solution. The AWS Management Tools and partner ecosystem enable you to deploy or even build the right governance solution for your organization’s needs.</p> 
<h3>About the Author:</h3> 
<table> 
<tbody> 
<tr> 
<td><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/blog_westrich_4.png" /></td> 
<td>Adam Westrich is a Solutions Architect based in Southern California. He is passionate about working with customers on their AWS Cloud journey, especially leveraging AWS managed services, including serverless technologies.</td> 
</tr> 
</tbody> 
</table> 
<p><em>Thank you to Shashi Prabhakar for his contributions to this post.</em></p> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">Run Scripts Stored in Private or Public GitHub Repositories Using Amazon EC2 Systems Manager</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Ananth Vaidyanathan</span></span> | on 
<time property="datePublished" datetime="2017-11-06T09:28:29+00:00">06 NOV 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/amazon-ec2-systems-manager/" title="View all posts in Amazon EC2 Systems Manager*"><span property="articleSection">Amazon EC2 Systems Manager*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools*"><span property="articleSection">Management Tools*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/run-scripts-stored-in-private-or-public-github-repositories-using-amazon-ec2-systems-manager/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><em>By Melonia Mendonca, Software Development Engineer at Amazon Web Services</em></p> 
<p><a href="https://aws.amazon.com/ec2/systems-manager/">Amazon EC2 Systems Manager</a> (SSM) lets you configure, manage and automate your AWS and on-premises resources at scale. You can perform safe and secure operations without SSH access or bastion hosts using Systems Manager Run Command, mitigate configuration drift using Systems Manager State Manager, and create an access-controlled environment with full auditing. With SSM Documents, you can author your configurations as code and enable centralized management across accounts, enforcing best practices. Systems Manger provides a number of public documents for common management scenarios, or you can create your own.</p> 
<p>We recently <a href="https://aws.amazon.com/about-aws/whats-new/2017/10/amazon-ec2-systems-manager-now-integrates-with-github/">announced</a> the ability to run scripts from remote locations such as GitHub or Amazon S3. This simplifies how you automate environments by letting you use existing scripts or toolsets without having to port them over to Systems Manager or create Documents as wrapper around those scripts or tools. For information, please read our partner and product integration documentation <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/systems-manager-integration.html">here</a>. &nbsp;For example, you can:</p> 
<li><span style="text-decoration: underline">Execute various types of scripts</span> written in Python, Ruby or PowerShell. You can also run configurations such as Ansible playbooks. You can pretty much run anything on your instances as long as the software (e.g., Python 2.7 or Ansible) is installed on your instance and recognized by Shell on Linux and PowerShell on Windows</li> 
<li><span style="text-decoration: underline">Download scripts</span> stored in private or public GitHub repositories, or on Amazon S3 onto your instances for execution</li> 
<li><span style="text-decoration: underline">Run multiple files</span> by downloading a complete GitHub directory or an S3 bucket</li> 
<p><span id="more-1905"></span></p> 
<p>Systems Manager now provides a new public Document, <strong>AWS-RunRemoteScript</strong> that runs scripts from GitHub or Amazon S3 on specified instances. It does this using the new plugin from <a href="https://github.com/aws/amazon-ssm-agent">Amazon SSM Agent</a>, <a href="https://docs.aws.amazon.com/systems-manager/latest/userguide/ssm-plugins.html#aws-downloadContent">aws:downloadContent</a>, which downloads content from locations such as public or private GitHub repositories, S3 buckets, and Documents already created on SSM. If you create your own documents, you can use the <strong>aws:downloadContent</strong> plugin, and the existing <a href="https://docs.aws.amazon.com/systems-manager/latest/userguide/ssm-plugins.html#aws-runShellScript"><strong>aws:runShellScript</strong></a> (on Linux) or<a href="https://docs.aws.amazon.com/systems-manager/latest/userguide/ssm-plugins.html#aws-runPowerShellScript"><strong> aws:runPowerShellScript</strong></a> (on Windows) to execute the scripts.</p> 
<p>In this blog post, I’ll show you how to run an Ansible playbook located in a public or private GitHub repository using the AWS-RunRemoteScript Document. This lets you run Ansible from an external location without requiring SSH access on your instances.</p> 
<h3>Walkthrough 1 – Run an Ansible playbook from a public GitHub repository</h3> 
<p><strong>Pre-requisites</strong></p> 
<p>We will run an Ansible playbook that installs and configures NGINX from a GitHub public repository. The playbook is expressed in server.yml and this main playbook calls the nginx role.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/02/playbook.png" /></p> 
<p>Before you get started, ensure you have reviewed the Ansible license and then install it on your instances. You can install Ansible using Run Command with the commands below:</p> 
<p>Amazon Linux:</p> 
<code class="lang-bash">sudo pip install ansible</code> 
<p>Ubuntu:</p> 
<code class="lang-bash">sudo apt-get install ansible –y</code> 
<p><strong>Step 1: Find the AWS-RunRemoteScript document for execution</strong></p> 
<p>On the EC2 console, on the navigation pane at the left, under Systems Manager Services, choose <strong>Run Command</strong>. Choose <strong>Run a Command</strong>, and then select the AWS-RunRemoteScript document and the instances you want to execute this document on (whether a list of instances or tag-queries).</p> 
<p><strong>Step 2: Reference the Ansible playbook located on GitHub</strong></p> 
<p>Enter the parameters for the AWS-RunRemoteScript Document to reference the Ansible playbook.</p> 
<li><span style="text-decoration: underline">Source Type</span>: Location of the script – GitHub, S3. In this case, choose GitHub.</li> 
<li><span style="text-decoration: underline">Source Info</span>: Provides location information for accessing the content. &nbsp;In this example, since the repository is public, you only need to provide the owner, repository and the path to the playbook. The playbook needs to access the nginx directory shown in the structure that follows. So we’ll download the entire directory, which includes server.yml and the nginx directory.</li> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/02/github-structure.png" /></p> 
<li><span style="text-decoration: underline">Command Line</span>: The command needed to execute the playbook</li> 
<p>When you are done, the console will look like this:</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/02/console-string-map.png" /></p> 
<p><strong>Step 3: Run the command</strong></p> 
<p>Because you referenced the top-level directory, Systems Manager downloads all the playbook YAML scripts inside the nginx directory as well as the server.yml and user-data.sh files. The server.yml is then executed based on command line parameters, which then installs and configures NGINX.</p> 
<p>You can then view the output and see that NGINX was installed on the specified instances.</p> 
<p>&nbsp;</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/02/public-output.png" /></p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/02/public-script-ouput.png" /></p> 
<p>You can also perform this operation using the AWS CLI by running the following command:</p> 
<code class="lang-bash">aws ssm send-command --document-name &quot;AWS-RunRemoteScript&quot; --parameters '{&quot;sourceType&quot;:[&quot;GitHub&quot;],&quot;sourceInfo&quot;:[&quot;{\&quot;owner\&quot; : \&quot;owner-name\&quot;, \&quot;repository\&quot;:\&quot;repository-name\&quot;, \&quot;path\&quot;:\&quot;path/to/directory\&quot;}&quot;], &quot;commandLine&quot;:[&quot;ansible-playbook -i \&quot;localhost,\&quot; --check -c local server.yml&quot;]}'</code> 
<h3>Walkthrough 2 – Run Ansible playbook from private GitHub repository</h3> 
<p>Now, I’ll show you how to execute scripts from private GitHub repositories. Let’s assume that the playbook in the previous example is stored in a private GitHub repository. To access this playbook, you need to create a private access token on GitHub and store it in Amazon EC2 Systems Manager Parameter Store.</p> 
<p><strong>Step 1: Create your GitHub personal access token</strong></p> 
<p>Create a personal access token for your private GitHub repo to give Systems Manager access to the playbook. <a href="https://github.com/blog/1509-personal-api-tokens">Personal API tokens</a> are a way to provide access to systems to access information from your private GitHub repository. These tokens provide limited access to a subset of repository data as well as the ability to revoke access when needed. You can create a personal access token from information provided <a href="https://help.github.com/articles/creating-a-personal-access-token-for-the-command-line/">here</a> and then save the token value.</p> 
<p><strong>Step 2: Store the tokens in Parameter Store</strong></p> 
<p>After creating the personal access token, go to Parameter Store on the EC2 console. On the Parameter Store page, create a parameter and add the token you created on GitHub here, in the Value text box.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/02/create-parameter.png" /></p> 
<p>If you have an AWS Key Management Service (KMS) key ID, you can add this key ID in the <strong>KMS Key ID</strong> text box. &nbsp;After this, choose <strong>Create Parameter</strong>. You can also perform this operation using the AWS CLI, as follows:</p> 
<code class="lang-bash">aws ssm put-parameter --name example-token --value xxxxxxx --type SecureString</code> 
<p><strong>Step 3: Reference the Ansible playbook located on GitHub</strong></p> 
<p>Along with owner, repository and path, we will add “tokenInfo” that refers to the example-token secure string parameter that we just created. The reference is made using the <strong>ssm-secure</strong> prefix.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/02/stringmap-private.png" /></p> 
<p><strong>Step 3: Run the command</strong></p> 
<p>This command will use the personal access token to access your private GitHub repository. Everything else is the same as if you were to run the playbook from a public GitHub repository.</p> 
<p>You can also perform this operation using the AWS CLI:</p> 
<code class="lang-bash">aws ssm send-command --document-name &quot;AWS-RunRemoteScript&quot; --parameters '{&quot;sourceType&quot;:[&quot;GitHub&quot;],&quot;sourceInfo&quot;:[&quot;{\&quot;owner\&quot; : \&quot;owner-name\&quot;, \&quot;repository\&quot;:\&quot;repository-name\&quot;,\&quot;path\&quot;:\&quot;path/to/directory\&quot;,\&quot;tokenInfo\&quot; : \&quot;{{ssm-secure:example-token}}\&quot;}&quot;],&quot;commandLine&quot;:[&quot;ansible-playbook -i \&quot;localhost,\&quot; --check -c local server.yml&quot;]}' </code> 
<h3>Conclusion</h3> 
<p>In this blog post, I showed you how EC2 Systems Manager is a management platform that lets you use your existing tools to manage your AWS resources and environments. I showed you how to use Systems Manager to run an Ansible playbook on your EC2 instances from a public and private GitHub repository. Using the AWS-RunRemoteScript public document or the aws:downloadContent and aws:runShellScript plugins, you can run any script such as Python, Ruby, or even PowerShell scripts or modules. In a subsequent blogpost, I’ll show you how to enable modular and reusable configurations using composite Documents.</p> 
<h3>About the Author</h3> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/02/melonia.jpg" />Melonia Mendonca is a Software Development Engineer with the Amazon EC2 Systems Manager team. She is a passionate engineer who enjoys the ability to innovate encouraged by Amazon. Outside of work, Melonia likes traveling, playing board games and trying different restaurants/cuisines.</p> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">AWS OpsWorks for Chef Automate Now Supports Compliance</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Rahul Gulati</span></span> | on 
<time property="datePublished" datetime="2017-11-06T08:19:50+00:00">06 NOV 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/aws-ops-works/" title="View all posts in AWS OpsWorks*"><span property="articleSection">AWS OpsWorks*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools*"><span property="articleSection">Management Tools*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/aws-opsworks-for-chef-automate-now-supports-compliance/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p>AWS OpsWorks&nbsp;for Chef Automate gives you a fully managed Chef server with a suite of automation tools. &nbsp;The release of Chef Automate version 1.6 includes the new <a href="https://blog.chef.io/2017/07/05/chef-automate-release-july-2017/">Compliance view</a> for Chef Automate UI. With AWS OpsWorks for Chef Automate integrated with compliance, you can track the compliance of your infrastructure based on a predefined policy. This allows you to frequently audit your applications for vulnerabilities and remediate violations.</p> 
<p><span id="more-1957"></span></p> 
<p><span style="text-decoration: underline">Use cases and benefits</span></p> 
<p>With this update, you can detect and correct security risks and compliance issues across your entire infrastructure.</p> 
<li>Move from manual compliance to <a href="https://learn.chef.io/tracks/compliance-automation#/">continuous compliance</a> by frequently conducting assessments and managing compliance as code. This means that you can bake compliance into your Chef workflow.</li> 
<li>Select from 88 pre-packaged profiles that meet industry benchmarks, available in Profile Store. Further, you can customize these profiles to fulfill your information security needs.</li> 
<li>Use the <strong>Compliance</strong> pane, which offers a unified dashboard for identifying issues, remediating them, and tracking progress. In addition, you can view <strong>Scan Results</strong> for various Nodes and Profiles.</li> 
<li>Describe compliance controls in InSpec, an open-source testing framework, and integrate these automated tests into any stage of your deployment pipeline.</li> 
<p>To get started, go to the AWS Management Console, and open the OpsWorks console. On the AWS OpsWorks Stacks home page, choose <strong>Go to OpsWorks for Chef Automate</strong>. &nbsp;Then choose <strong>Compliance</strong>. In the left navigation pane, choose <strong>Profile Store</strong>. Then, in the <strong>Available</strong> tab, select a profile such as <a href="https://github.com/dev-sec/ssh-baseline/">DevSec SSH Baseline</a>, and choose <strong>Get</strong> to install.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/03/Screen-Shot-2017-10-22-at-7.03.34-PM.png" /></p> 
<p>On the profile details page, you can view a brief profile description, set of controls, and their severity. Choose <strong>+</strong> to see the expected outcome of a control and code that it executes.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/03/Screen-Shot-2017-10-22-at-7.07.34-PM.png" /></p> 
<p>After it’s installed, configure the <a href="https://supermarket.chef.io/cookbooks/audit">Audit Cookbook</a> with the compliance profile you selected in the previous step. Add the recipe to your node’s run list.</p> 
<p>After the node’s run list is executed with audit attributes set as expected, you can see the profile status on the <strong>Compliance</strong> page.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/03/Screen-Shot-2017-10-22-at-9.31.17-PM.png" /></p> 
<p>Go to the <strong>Profiles</strong> tab, choose <strong>Scan Results</strong>, and select a node to find each failed control with details of what failed within that control. This means you can view the expected and actual outcome of each failed test. With this information, you can reconfigure the nodes to ensure that all test cases pass and a rerun is successful.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/03/Screen-Shot-2017-10-22-at-9.39.26-PM.png" /></p> 
<p>This update is now generally available and you can start using it today. With OpsWorks for Chef Automate, you pay for the Amazon EC2 instance used to run your managed Chef server (<a href="https://aws.amazon.com/opsworks/chefautomate/pricing/">pricing details here</a>). You can launch OpsWorks for Chef Automate today in the following AWS Regions: US East (Northern Virginia), US West (Oregon), and EU (Ireland). To learn more, read <a href="http://docs.aws.amazon.com/opsworks/latest/userguide/opscm-starterkit.html">Configure the Chef Server Using the Starter Kit</a> in the OpsWorks User Guide.</p> 
<p><strong>About the Author</strong></p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/12/22/ragulati.jpeg" />Rahul Gulati is a Product Manager at AWS OpsWorks. He enjoys working with customers and engineering teams to build software products.</p> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">Upgrading SQL Server Using EC2 Systems Manager</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Ananth Vaidyanathan</span></span> | on 
<time property="datePublished" datetime="2017-11-01T12:55:40+00:00">01 NOV 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/amazon-ec2-systems-manager/" title="View all posts in Amazon EC2 Systems Manager*"><span property="articleSection">Amazon EC2 Systems Manager*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools*"><span property="articleSection">Management Tools*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/upgrading-sql-server-using-ec2-systems-manager/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><em>This post was written by Alan Cranfield, Systems Engineer at Amazon Web Services</em></p> 
<p>This is the first in a series of blog posts aimed at the enterprise SQL Server DBA. I’ll demonstrate how to administer your SQL Server workloads on Amazon EC2 using practical examples and best practices.</p> 
<h3>Using Run Command</h3> 
<p>In this post I’ll show you how to use <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/execute-remote-commands.html">Run Command</a> from <a href="https://aws.amazon.com/ec2/systems-manager">Amazon EC2 Systems Manager</a> to update one or many of your SQL Servers to the latest service pack.</p> 
<p>Microsoft SQL Server is a popular workload on Amazon EC2. Keeping your SQL Server instances up to date with the latest service pack is important for the stability and security of your critical data. If you need to support multiple versions and editions of SQL Server keeping track of all the latest service packs can be cumbersome.</p> 
<p>Run Command provides a simple and secure way to remotely execute commands or run scripts against EC2 instances or on-premises servers.&nbsp;With Run Command, you can perform commands that make it easy to accomplish common administrative tasks like upgrading SQL service packs!</p> 
<p><span id="more-1694"></span></p> 
<h3>Pre-requisites</h3> 
<p>When you use EC2 Systems Manager you’ll need to first work through some <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/systems-manager-setting-up.html">prerequisites</a>. The most important prerequisite is that you’ll need the SSM agent installed on your instances. The <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/ssm-agent.html#sysman-install-ssm-win">SSM agent</a> is installed by default on Windows Server 2016 instances and instances created from Windows Server 2003-2012 R2 Amazon Machine Images (AMIs) published in November 2016 or later.</p> 
<p>Another pre-requisite is that your instances need to be assigned an AWS Identity and Access Management (IAM) role. The IAM role is used to secure the permission policies needed to communicate with the Systems Manager API. Instances are usually added to an IAM role on launch, but you can also add existing instances using the <a href="https://aws.amazon.com/blogs/security/new-attach-an-aws-iam-role-to-an-existing-amazon-ec2-instance-by-using-the-aws-cli/?sc_channel=sm&amp;sc_campaign=rolesforrunninginstances&amp;sc_publisher=tw&amp;sc_medium=social&amp;sc_content=read-post&amp;sc_country=global&amp;sc_geo=global&amp;sc_category=ec2&amp;sc_outcome=launch">AWS CLI</a>.</p> 
<h3>Using PowerShell modules</h3> 
<p>For this exercise we’ll use the Run Command native support for PowerShell modules to download and import a PowerShell module from an Amazon S3 bucket. This module will be called to identify the version of SQL that is running and then download and install the latest service pack. I’ll walk you through updating the SQL service pack by using the AWS Management Console and by using AWS Tools for PowerShell.</p> 
<h3>Updating the SQL service pack from the EC2 console</h3> 
<li>Sign In to the AWS Management Console. To confirm that your instances are in a state to be managed, make sure they are listed in the EC2 console under EC2 Dashboard\Managed Instances.</li> 
<li>Navigate to the Run Command and choose Run a command. Then select the AWS-InstallPowershellModule document, and the servers you’d like to upgrade.<img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/27/install-ps-module.png" /></li> 
<li>For Source enter the location of the S3 bucket that holds the PowerShell module: <a href="https://s3.amazonaws.com/sql-service-pack/InstallSqlServicePack.zip">https://s3.amazonaws.com/sql-service-pack/InstallSqlServicePack.zip</a></li> 
<li>Paste the following PowerShell script into the Commands Window 
<code class="lang-powershell">Set-ExecutionPolicy -ExecutionPolicy Unrestricted -Force
Import-Module InstallSqlServicePack
Install-SQLUpdate -Action &quot;Yes&quot;</code> 
<li>Choose the <strong>Run</strong> button and check the <strong>Status</strong> column for the instance progress.<img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/27/command-success.png" /></li> 
<li>Choose a specific Instance ID in the top pane, and then in the bottom pane choose the Output tab and then choose View Output.</li> 
<li>The results of the service pack upgrade are shown in the Output results window.<img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/27/output.png" /></li> 
<h3>Updating the SQL service pack using the AWS Tools for PowerShell</h3> 
<p>For those who prefer a scripted solution you can call Run Command using the <a href="http://docs.aws.amazon.com/powershell/latest/userguide/pstools-getting-set-up.html">AWS Tools for Windows PowerShell</a>.</p> 
<li>Download and install the latest AWS Tools for Windows PowerShell.</li> 
<code class="lang-powershell">$AWSPSURL = &quot;http://sdk-for-net.amazonwebservices.com/latest/AWSToolsAndSDKForNet.msi&quot; 
$AWSPSSetup = &quot;C:\Windows\Temp\AWSPowerShellSetup.msi&quot;
(New-Object System.Net.WebClient).DownloadFile($AWSPSURL, $AWSPSSetup)
Start-Process -FilePath msiexec.exe -Argument List &quot;/i $AWSPSSetup&quot;
Remove-Item $AWSPSSetup -Force</code> 
<li>Set your credentials and AWS Region</li> 
<code class="lang-powershell"># set credentials
Set-AWSCredentials -StoreAs SQL -AccessKey &lt;your access key&gt; -SecretKey &lt;your secret key&gt;
Set-AWSCredentials -ProfileName SQL
Set-DefaultAWSRegion &quot;us-west-2&quot; 
Get-IAMUser</code> 
<li>Confirm that your instances are managed by SSM</li> 
<p><code class="lang-powershell">Get-SSMInstanceInformation -InstanceInformationFilterList @{Key=&quot;PingStatus&quot;;ValueSet=&quot;Online&quot;} | select ComputerName, InstanceId<br /> </code></p> 
<li>Run a Command against your instances to upgrade the SQL service pack. (Tagging can also be used to group servers.)</li> 
<code class="lang-powershell"></code><code class="lang-powershell">$InstanceIds = (Get-SSMInstanceInformation).InstanceId
$InstanceIds.count
$source = 'https://s3.amazonaws.com/sql-service-pack/InstallSqlServicePack.zip'
$commands = @(
'Set-ExecutionPolicy -ExecutionPolicy Unrestricted -Force',
'Import-Module InstallSqlServicePack',
'Install-SQLUpdate -Action &quot;Yes&quot;'
)
$parameter = @{
source = $source;
commands = $commands;
}
$document = 'AWS-InstallPowerShellModule'
$cmd = Send-SSMCommand –InstanceId $InstanceIds –DocumentName $document –Parameter $parameter </code> 
<li>Check the progress.</li> 
<code class="lang-powershell">Get-SSMCommandInvocation -CommandId $cmd.CommandId -Details $true | select InstanceId, status </code> 
<code class="lang-powershell">InstanceId          Status    
----------          ------    
i-0fff59f73e94a0449 InProgress
i-0f1f7afc2b605b4d1 Success   
i-0ee0c157a87ede81f InProgress
i-0daa300d38d9c42b1 InProgress
i-0b861190458f9381f InProgress
i-09dc29e6a093ac14c InProgress
i-09aee29b50203cf3c Success
</code> 
<li>Check the results.</li> 
<p><code class="lang-powershell">Get-SSMCommandInvocation -CommandId $cmd.CommandId -Details $true | select -ExpandProperty CommandPlugins</code></p> 
<p><code class="lang-powershell">== Install SQL Update ==<br /> </code></p> 
<code class="lang-powershell">2017-08-18 23:54:38.760 Test-SQLInstallation
2017-08-18 23:54:38.856 - SQL server service is installed and started
2017-08-18 23:54:38.866 - Importing SQLPS Module
2017-08-18 23:54:41.048 Check if Clustered
2017-08-18 23:54:41.227 - Not Clustered
2017-08-18 23:54:41.232 Get-InstallableUpdate
2017-08-18 23:54:41.245 - Read current installed version...
2017-08-18 23:54:41.254 - Found Microsoft SQL Server 2016 (RTM-CU3-GDR) (KB3194717) - 13.0.2186.6 (RTM)
2017-08-18 23:54:41.275 - Looking for latest Service Pack...
2017-08-18 23:54:41.351 - Found Microsoft SQL Server 2016 - 13.0.4001.0 (SP1)
2017-08-18 23:54:41.359 Test-DownloadDestinationFolder
2017-08-18 23:54:41.377 - Get disk information on C: drive
2017-08-18 23:54:41.400 - Free space is 27 GB
2017-08-18 23:54:41.410 - Destination folder C:\Windows\temp was successfully created.
2017-08-18 23:54:41.415 Downloading Microsoft SQL Server 2016 - 13.0.4001.0 (SP1) from Microsoft...
2017-08-18 23:54:49.100 - Downloading Update bits completed
2017-08-18 23:54:49.106 Installing Microsoft SQL Server 2016 - 13.0.4001.0 (SP1)
2017-08-18 23:59:01.504 - Installing Microsoft SQL Server 2016 - 13.0.4001.0 (SP1) Completed
2017-08-18 23:59:01.510 Verify SQL version after update
2017-08-18 23:59:01.525 - Version after update 13.0.4001.0
2017-08-18 23:59:01.530 Update Successful!</code> 
<h3>Conclusion</h3> 
<p>Amazon EC2 Systems Manager offers a suite of tools to help you manage both your EC2 and on-premises SQL Server instances. In this post, I showed you how to use the Run Command feature of Systems Manager to easily upgrade SQL Server to the latest service pack.</p> 
<p>In a critical production environment, when you upgrade you might have extra steps to perform before and after, such as database backups, failovers, failbacks, etc. So, in the next post I’ll show you how to use the Automation feature of Systems Manager to achieve custom maintenance workflows.</p> 
<h3>About the Author</h3> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/28/alan_cranfield.jpg" />Alan Cranfield is a Senior Systems Engineer on the EC2 Windows team where he uses his extensive experience managing critical enterprise environments to help make AWS the best cloud platform for running Windows workloads. He spends his spare time in the garage restoring and customizing old motorcycles.</p> 
<p><code class="lang-powershell"></code><code class="lang-powershell"></code></p> 
</article> 
<p>
© 2018 Amazon Web Services, Inc. or its affiliates. All rights reserved.
</p>

    </div>
  </div>
</div>


    <div id="footer" class="navigation hidden-print">
      <div class="container">
        <div class="row">
          <div class="col-xs-12">
            <ul class="footer-links nav navbar-nav">
              <li><a href="../aws.html">AWS</a></li>
              <li><a href="../linux.html">Linux</a></li>
              <li><a href="../docker.html">Docker</a></li>
              <li><a href="../ibmpower.html">IBM Power</a></li>
              <li><a href="blogsataws1.html">Blogs@AWS (Kindle Friendly)</a></li>
            </ul>
            <ul class="footer-links nav navbar-nav navbar-right">
              <li><a href="../comments.html">Comments?</a></li>
            </ul>
          </div>
        </div>
      </div>
    </div>
  </body>
</html>
