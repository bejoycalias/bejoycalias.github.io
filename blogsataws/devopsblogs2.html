<!DOCTYPE html>
<html lang="en">
  <head>
<!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-593498H');</script>
<!-- End Google Tag Manager -->

    <meta charset="utf-8">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">

    <meta name="msapplication-config" content="/microsoft-tile.xml" />
    <meta name="theme-color" content="#ffffff">

    <meta property="og:url" content="https://bejoycalias.github.io/blogsataws/devopsblogs1.html" />
    <meta property="og:site_name" content="Bejoy's TechNotes"/>
    <meta property="og:title" content="Bejoy's TechNotes - Kindle Friendly AWS DevOps Blogs" />
    <meta property="og:image" content="https://bejoycalias.github.io/assets/images/og-image.png"/>
    <meta property="og:image:width" content="1200"/>
    <meta property="og:image:height" content="1200"/>
    <meta property="og:description" content="" />

    <title>Bejoy's TechNotes - Kindle Friendly AWS DevOps Blogs</title>
    <link href="../assets/stylesheets/application-832aa42c.css" rel="stylesheet" />

    <!--[if lt IE 9]>
      <script src="../assets/javascripts/ie-compat-c141a02d.js"></script>
    <![endif]-->
    <script src="../assets/javascripts/application-ff53d307.js"></script>

    <!-- Typekit script to import Klavika font -->
    <script src="https://use.typekit.net/wxf7mfi.js"></script>
    <script>try{Typekit.load({ async: true });}catch(e){}</script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-100043608-1', 'auto');
  ga('send', 'pageview');

</script>

    
  </head>

  <body id="aws-blogs" class="layout-inner aws-blogs">
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-593498H"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->


    <div id="header" class="navigation navbar-static-top hidden-print">
      <div class="container">
        <div class="row">
          <div class="col-xs-12">
            <div class="navbar-header">
              <div class="navbar-brand">
                <a href="/">
                  <svg version="1.0" xmlns="http://www.w3.org/2000/svg" width="135.000000pt" height="50" viewbox="0 0 135.000000 45.000000" preserveaspectratio="xMidYMid meet" class="logo">

<g transform="translate(0.000000,45.000000) scale(0.100000,-0.100000)" fill="#000000" stroke="none">
<path class="text" fill="#000000" d="M527 384 c-4 -4 -7 -18 -7 -31 0 -21 4 -24 28 -21 21 2 27 8 27 28 0
18 -6 26 -20 28 -12 2 -24 0 -28 -4z"></path>
<path class="text" fill="#000000" d="M1080 335 c0 -48 2 -55 20 -55 18 0 20 7 20 55 0 48 -2 55 -20 55
-18 0 -20 -7 -20 -55z"></path>
<path class="text" fill="#000000" d="M54 357 c-2 -7 -3 -69 -2 -138 l3 -124 65 -3 c90 -3 130 20 130 77 0
29 -6 44 -20 54 -20 14 -20 15 -3 45 14 25 15 34 5 56 -6 15 -23 31 -38 36
-38 15 -134 13 -140 -3z m110 -33 c19 -7 21 -45 4 -62 -7 -7 -22 -12 -35 -12
-20 0 -23 5 -23 40 0 41 13 50 54 34z m20 -130 c19 -18 19 -20 6 -45 -8 -13
-21 -19 -45 -19 -34 0 -35 1 -35 40 0 38 2 40 29 40 16 0 37 -7 45 -16z"></path>
<path class="text" fill="#000000" d="M319 271 c-23 -24 -29 -38 -29 -74 0 -25 3 -53 6 -62 20 -50 164 -64
164 -15 0 15 -7 17 -45 12 -46 -5 -75 8 -75 34 0 11 16 14 65 14 l65 0 0 35
c0 80 -92 114 -151 56z m99 -33 c3 -15 -4 -18 -37 -18 -43 0 -50 7 -29 28 18
18 62 11 66 -10z"></path>
<path class="text" fill="#000000" d="M520 184 c0 -107 -1 -116 -20 -121 -11 -3 -20 -12 -20 -19 0 -21 76
-19 84 2 3 9 6 69 6 135 l0 119 -25 0 -25 0 0 -116z"></path>
<path class="text" fill="#000000" d="M649 271 c-24 -25 -29 -37 -29 -78 1 -70 34 -103 105 -103 55 0 95
44 95 103 0 60 -7 75 -41 92 -47 25 -96 19 -130 -14z m111 -30 c25 -48 2 -111
-40 -111 -45 0 -69 80 -34 114 21 22 61 20 74 -3z"></path>
<path class="text" fill="#000000" d="M850 287 c0 -8 16 -57 36 -110 28 -76 33 -100 25 -116 -16 -28 -14
-31 18 -31 27 0 29 4 70 123 23 67 41 128 41 135 0 6 -11 12 -24 12 -21 0 -26
-8 -41 -65 -10 -36 -21 -68 -25 -70 -3 -2 -16 27 -29 66 -19 60 -25 69 -47 69
-13 0 -24 -6 -24 -13z"></path>
<path class="text" fill="#000000" d="M1192 284 c-17 -12 -22 -24 -20 -47 2 -26 10 -36 45 -52 49 -23 59
-55 17 -55 -14 0 -34 5 -45 10 -16 9 -19 7 -19 -13 0 -17 7 -27 23 -31 69 -18
117 6 117 60 0 32 -4 37 -45 55 -60 26 -62 54 -4 46 37 -5 40 -3 37 16 -2 18
-11 23 -43 25 -25 2 -49 -3 -63 -14z"></path>
</g>
</svg>

                </a>
              </div>
              <button class="navbar-toggle" type="button">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
              </button>
            </div>
            <div class="buttons hidden-xs">
              <nav class="navigation-links" role="navigation">
                <ul class="main-links nav navbar-nav navbar-right">
                  <li><a href="../aws.html">AWS</a></li>
                  <li><a href="../linux.html">Linux</a></li>
                  <li><a href="../docker.html">Docker</a></li>
                  <li><a href="../ibmpower.html">IBM Power</a></li>
                  <li><a href="blogsataws1.html">Blogs@AWS (Kindle Friendly)</a></li>
                </ul>
              </nav>
            </div>
          </div>
        </div>
      </div>
    </div>

    <div class="sidebar-overlay"></div>

<aside class="sidebar" role="navigation">
  <div class="sidebar-header">
    <svg version="1.0" xmlns="http://www.w3.org/2000/svg" width="135.000000pt" height="42" viewbox="0 0 135.000000 45.000000" preserveaspectratio="xMidYMid meet">

<g transform="translate(0.000000,45.000000) scale(0.100000,-0.100000)" fill="#000000" stroke="none">
<path class="text" fill="#000000" d="M527 384 c-4 -4 -7 -18 -7 -31 0 -21 4 -24 28 -21 21 2 27 8 27 28 0
18 -6 26 -20 28 -12 2 -24 0 -28 -4z"></path>
<path class="text" fill="#000000" d="M1080 335 c0 -48 2 -55 20 -55 18 0 20 7 20 55 0 48 -2 55 -20 55
-18 0 -20 -7 -20 -55z"></path>
<path class="text" fill="#000000" d="M54 357 c-2 -7 -3 -69 -2 -138 l3 -124 65 -3 c90 -3 130 20 130 77 0
29 -6 44 -20 54 -20 14 -20 15 -3 45 14 25 15 34 5 56 -6 15 -23 31 -38 36
-38 15 -134 13 -140 -3z m110 -33 c19 -7 21 -45 4 -62 -7 -7 -22 -12 -35 -12
-20 0 -23 5 -23 40 0 41 13 50 54 34z m20 -130 c19 -18 19 -20 6 -45 -8 -13
-21 -19 -45 -19 -34 0 -35 1 -35 40 0 38 2 40 29 40 16 0 37 -7 45 -16z"></path>
<path class="text" fill="#000000" d="M319 271 c-23 -24 -29 -38 -29 -74 0 -25 3 -53 6 -62 20 -50 164 -64
164 -15 0 15 -7 17 -45 12 -46 -5 -75 8 -75 34 0 11 16 14 65 14 l65 0 0 35
c0 80 -92 114 -151 56z m99 -33 c3 -15 -4 -18 -37 -18 -43 0 -50 7 -29 28 18
18 62 11 66 -10z"></path>
<path class="text" fill="#000000" d="M520 184 c0 -107 -1 -116 -20 -121 -11 -3 -20 -12 -20 -19 0 -21 76
-19 84 2 3 9 6 69 6 135 l0 119 -25 0 -25 0 0 -116z"></path>
<path class="text" fill="#000000" d="M649 271 c-24 -25 -29 -37 -29 -78 1 -70 34 -103 105 -103 55 0 95
44 95 103 0 60 -7 75 -41 92 -47 25 -96 19 -130 -14z m111 -30 c25 -48 2 -111
-40 -111 -45 0 -69 80 -34 114 21 22 61 20 74 -3z"></path>
<path class="text" fill="#000000" d="M850 287 c0 -8 16 -57 36 -110 28 -76 33 -100 25 -116 -16 -28 -14
-31 18 -31 27 0 29 4 70 123 23 67 41 128 41 135 0 6 -11 12 -24 12 -21 0 -26
-8 -41 -65 -10 -36 -21 -68 -25 -70 -3 -2 -16 27 -29 66 -19 60 -25 69 -47 69
-13 0 -24 -6 -24 -13z"></path>
<path class="text" fill="#000000" d="M1192 284 c-17 -12 -22 -24 -20 -47 2 -26 10 -36 45 -52 49 -23 59
-55 17 -55 -14 0 -34 5 -45 10 -16 9 -19 7 -19 -13 0 -17 7 -27 23 -31 69 -18
117 6 117 60 0 32 -4 37 -45 55 -60 26 -62 54 -4 46 37 -5 40 -3 37 16 -2 18
-11 23 -43 25 -25 2 -49 -3 -63 -14z"></path>
</g>
</svg>

  </div>

  <ul class="nav sidebar-nav">
    <li><a href="../aws.html">AWS</a></li>
    <li><a href="../linux.html">Linux</a></li>
    <li><a href="../docker.html">Docker</a></li>
    <li><a href="../ibmpower.html">IBM Power</a></li>
    <li><a href="blogsataws1.html">Blogs@AWS (Kindle Friendly)</a></li>
  </ul>
</aside>


    <div class="container">
  <div class="row">
    <div id="docs-sidebar" class="col-sm-3 col-md-3 col-xs-12 hidden-print" role="complementary">
      <ul class="nav docs-sidenav">
      <li><a href="blogsataws1.html">Blogs @ AWS</a></li>
      <li><a href="whatsnew1.html">What's New @ AWS</a></li>
      <li><a href="mgmtblogs1.html">Management Tools Blogs @ AWS</a></li>
      <li><a href="computeblogs1.html">Compute Blogs @ AWS</a></li>
      <li class="active"><a href="devopsblogs1.html">DevOps Blogs @ AWS</a></li>
      <li><a href="secblogs1.html">Security Blogs @ AWS</a></li>
      <li><a href="apnblogs1.html">APN Blogs @ AWS</a></li>

    </ul>
    </div>

    <div id="inner" class="col-sm-9 col-md-9 col-xs-12" role="main">
<p></p>
<p><i>Contents of this page is copied directly from AWS blog sites to make it Kindle friendly. Some styles & sections from these pages are removed to render this properly in 'Article Mode' of Kindle e-Reader browser. All the contents of this page is property of AWS.</i></p>
<p><a href="devopsblogs1.html">Page 1</a>|<a href="devopsblogs2.html">Page 2</a>|<a href="devopsblogs3.html">Page 3</a>|<a href="devopsblogs4.html">Page 4</a></p>
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">UI Testing at Scale with AWS Lambda</b> 
<p style="margin: 0; padding:0;">=======================<p>
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Stas Neyman</span></span> | on 
<time property="datePublished" datetime="2017-11-24T13:45:14+00:00">24 NOV 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/devops/category/compute/aws-lambda/" title="View all posts in AWS Lambda*"><span property="articleSection">AWS Lambda*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/compute/" title="View all posts in Compute*"><span property="articleSection">Compute*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/devops/" title="View all posts in DevOps*"><span property="articleSection">DevOps*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/devops/ui-testing-at-scale-with-aws-lambda/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><em>This is a guest blog post by Wes Couch and Kurt Waechter from the Blackboard Internal Product Development team about their experience using AWS Lambda.</em></p> 
<p>One year ago, one of our UI test suites took hours to run. Last month, it took 16 minutes. Today, it takes <strong>39 seconds</strong>. Here’s how we did it.</p> 
<h4>The backstory:</h4> 
<p>Blackboard is a global leader in delivering robust and innovative education software and services to clients in higher education, government, K12, and corporate training. We have a large product development team working across the globe in at least 10 different time zones, with an internal tools team providing support for quality and workflows. We have been using Selenium Webdriver to perform automated cross-browser UI testing since 2007. Because we are now practicing continuous delivery, the automated UI testing challenge has grown due to the faster release schedule. On top of that, every commit made to each branch triggers an execution of our automated UI test suite. If you have ever implemented an automated UI testing infrastructure, you know that it can be very challenging to scale and maintain. Although there are services that are useful for testing different browser/OS combinations, they don’t meet our scale needs.</p> 
<p>It used to take three hours to synchronously run our functional UI suite, which revealed the obvious need for parallel execution. Previously, we used Mesos to orchestrate a Selenium Grid Docker container for each test run. This way, we were able to run eight concurrent threads for test execution, which took an average of 16 minutes. Although this setup is fine for a single workflow, the cracks started to show when we reached the scale required for Blackboard’s mature product lines. Going beyond eight concurrent sessions on a single container introduced performance problems that impact the reliability of tests (for example, issues in Webdriver or the browser popping up frequently). We tried Mesos and considered Kubernetes for Selenium Grid orchestration, but the answer to scaling a Selenium Grid was to think smaller, not larger. This led to our breakthrough with AWS Lambda.</p> 
<p><span id="more-1936"></span></p> 
<h4>The solution:</h4> 
<p>We started using AWS Lambda for UI testing because it doesn’t require costly infrastructure or countless man hours to maintain. The steps we outline in this blog post took one work day, from inception to implementation. By simply packaging the UI test suite into a Lambda function, we can execute these tests in parallel on a massive scale. We use a custom JUnit test runner that invokes the Lambda function with a request to run each test from the suite. The runner then aggregates the results returned from each Lambda test execution.</p> 
<p>Selenium is the industry standard for testing UI at scale. Although there are other options to achieve the same thing in Lambda, we chose this mature suite of tools. Selenium is backed by Google, Firefox, and others to help the industry drive their browsers with code. This makes Lambda and Selenium a compelling stack for achieving UI testing at scale.</p> 
<h4>Making Chrome Run in Lambda</h4> 
<p>Currently, Chrome for Linux will not run in Lambda due to an absent mount point. By rebuilding Chrome with a slight modification, as Marco L&uuml;thy originally <a href="https://github.com/adieuadieu/serverless-chrome/tree/master/chrome">demonstrated</a>, you can run it inside Lambda anyway! It took about two hours to build the current master branch of Chromium to build on a c4.4xlarge. Unfortunately, the current version of ChromeDriver, 2.33, does not support any version of Chrome above 62, so we’ll be using Marco’s modified version of version 60 for the near future.</p> 
<h4>Required System Libraries</h4> 
<p>The Lambda runtime environment comes with a subset of common shared libraries. This means we need to include some extra libraries to get Chrome and ChromeDriver to work. Anything that exists in the java resources folder during compile time is included in the base directory of the compiled jar file. When this jar file is deployed to Lambda, it is placed in the /var/task/ directory. This allows us to simply place the libraries in the java resources folder under a folder named lib/ so they are <a href="http://docs.aws.amazon.com/lambda/latest/dg/current-supported-versions.html">right where they need to be</a> when the Lambda function is invoked.</p> 
<p>To get these libraries, create an EC2 instance and choose the Amazon Linux AMI.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/24/Choose_an_AMI.png" /></p> 
<p>Next, use ssh to connect to the server. After you connect to the new instance, search for the libraries to find their locations.</p> 
<code class="lang-markup">sudo find / -name libgconf-2.so.4
sudo find / -name libORBit-2.so.0
</code> 
<p>Now that you have the locations of the libraries, copy these files from the EC2 instance and place them in the java resources folder under lib/.</p> 
<h4>Packaging the Tests</h4> 
<p>To deploy the test suite to Lambda, we used a simple Gradle tool called <a href="https://github.com/johnrengelman/shadow">ShadowJar</a>, which is similar to the <a href="https://maven.apache.org/plugins/maven-shade-plugin/">Maven Shade Plugin</a>. It packages the libraries and dependencies inside the jar that is built. Usually test dependencies and sources aren’t included in a jar, but for this instance we want to include them. To include the test dependencies, add this section to the build.gradle file.</p> 
<code class="lang-markup">shadowJar {
from sourceSets.test.output
configurations = [project.configurations.testRuntime]
}
</code> 
<h4>Deploying the Test Suite</h4> 
<p>Now that our tests are packaged with the dependencies in a jar, we need to get them into a running Lambda function. We use &nbsp;simple SAM &nbsp;templates to upload the packaged jar into S3, and then deploy it to Lambda with our settings.</p> 
<code class="lang-json">{
&quot;AWSTemplateFormatVersion&quot;: &quot;2010-09-09&quot;,
&quot;Transform&quot;: &quot;AWS::Serverless-2016-10-31&quot;,
&quot;Resources&quot;: {
&quot;LambdaTestHandler&quot;: {
&quot;Type&quot;: &quot;AWS::Serverless::Function&quot;,
&quot;Properties&quot;: {
&quot;CodeUri&quot;: &quot;./build/libs/your-test-jar-all.jar&quot;,
&quot;Runtime&quot;: &quot;java8&quot;,
&quot;Handler&quot;: &quot;com.example.LambdaTestHandler::handleRequest&quot;,
&quot;Role&quot;: &quot;&lt;YourLambdaRoleArn&gt;&quot;,
&quot;Timeout&quot;: 300,
&quot;MemorySize&quot;: 1536
}
}
}
}</code> 
<p>We use the maximum timeout available to ensure our tests have plenty of time to run. We also use the maximum memory size because this ensures our Lambda function can support Chrome and other resources required to run a UI test.</p> 
<p>Specifying the handler is important because this class executes the desired test. The test handler should be able to receive a test class and method. With this information it will then execute the test and respond with the results.</p> 
<code class="lang-json">public LambdaTestResult handleRequest(TestRequest testRequest, Context context) {
LoggerContainer.LOGGER = new Logger(context.getLogger());
BlockJUnit4ClassRunner runner = getRunnerForSingleTest(testRequest);
Result result = new JUnitCore().run(runner);
return new LambdaTestResult(result);
}
</code> 
<h4>Creating a Lambda-Compatible ChromeDriver</h4> 
<p>We provide developers with an easily accessible ChromeDriver for local test writing and debugging. When we are running tests on AWS, we have configured ChromeDriver to run them in Lambda.</p> 
<p>To configure ChromeDriver, we first need to tell ChromeDriver where to find the Chrome binary. Because we know that ChromeDriver is going to be unzipped into the root task directory, we should point the ChromeDriver configuration at that location.</p> 
<p>The settings for getting ChromeDriver running are mostly related to Chrome, which must have its working directories pointed at the tmp/ folder.</p> 
<p>Start with the default DesiredCapabilities for ChromeDriver, and then add the following settings to enable your ChromeDriver to start in Lambda.</p> 
<code class="lang-json">public ChromeDriver createLambdaChromeDriver() {
ChromeOptions options = new ChromeOptions();
// Set the location of the chrome binary from the resources folder
options.setBinary(&quot;/var/task/chrome&quot;);
// Include these settings to allow Chrome to run in Lambda
options.addArguments(&quot;--disable-gpu&quot;);
options.addArguments(&quot;--headless&quot;);
options.addArguments(&quot;--window-size=1366,768&quot;);
options.addArguments(&quot;--single-process&quot;);
options.addArguments(&quot;--no-sandbox&quot;);
options.addArguments(&quot;--user-data-dir=/tmp/user-data&quot;);
options.addArguments(&quot;--data-path=/tmp/data-path&quot;);
options.addArguments(&quot;--homedir=/tmp&quot;);
options.addArguments(&quot;--disk-cache-dir=/tmp/cache-dir&quot;);
DesiredCapabilities desiredCapabilities = DesiredCapabilities.chrome();
desiredCapabilities.setCapability(ChromeOptions.CAPABILITY, options);
return new ChromeDriver(desiredCapabilities);
}
</code> 
<h4>Executing Tests in Parallel</h4> 
<p>You can approach parallel test execution in Lambda in many different ways. Your approach depends on the structure and design of your test suite. For our solution, we implemented a custom test runner that uses reflection and JUnit libraries to create a list of test cases we want run. When we have the list, we create a TestRequest object to pass into the Lambda function that we have deployed. In this TestRequest, we place the class name, test method, and the test run identifier. When the Lambda function receives this TestRequest, our LambdaTestHandler generates and runs the JUnit test. After the test is complete, the test result is sent to the test runner. The test runner compiles a result after all of the tests are complete. By executing the same Lambda function multiple times with different test requests, we can effectively run the entire test suite in parallel.</p> 
<p>To get screenshots and other test data, we pipe those files during test execution to an S3 bucket under the test run identifier prefix. When the tests are complete, we link the files to each test execution in the report generated from the test run. This lets us easily investigate test executions.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/24/Parallell_testing.png" /></p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/24/Parallell_testing2.png" /></p> 
<h4>Pro Tip: Dynamically Loading Binaries</h4> 
<p><a href="http://docs.aws.amazon.com/lambda/latest/dg/limits.html">AWS Lambda has a limit of 250 MB of uncompressed space</a> for packaged Lambda functions. Because we have libraries and other dependencies to our test suite, we hit this limit when we tried to upload a function that contained Chrome and ChromeDriver (~140 MB). This test suite was not originally intended to be used with Lambda. Otherwise, we would have scrutinized some of the included libraries. To get around this limit, we used the Lambda functions temporary directory, which allows up to 500 MB of space at runtime. Downloading these binaries at runtime moves some of that space requirement into the temporary directory. This allows more room for libraries and dependencies. You can do this by grabbing Chrome and ChromeDriver from an S3 bucket and marking them as executable using built-in Java libraries. If you take this route, be sure to point to the new location for these executables in order to create a ChromeDriver.</p> 
<code class="lang-json">private static void downloadS3ObjectToExecutableFile(String key) throws IOException {
File file = new File(&quot;/tmp/&quot; + key);
GetObjectRequest request = new GetObjectRequest(&quot;s3-bucket-name&quot;, key);
FileUtils.copyInputStreamToFile(s3client.getObject(request).getObjectContent(), file);
file.setExecutable(true);
}
</code> 
<h4>Lambda-Selenium Project Source</h4> 
<p>We have compiled an open source example that you can grab from the Blackboard Github repository. Grab the code and try it out!</p> 
<p><a href="https://blackboard.github.io/lambda-selenium/">https://blackboard.github.io/lambda-selenium/</a></p> 
<h4>Conclusion</h4> 
<p>One year ago, one of our UI test suites took hours to run. Last month, it took 16 minutes. Today, it takes <strong>39 seconds</strong>. Thanks to AWS Lambda, we can reduce our build times and perform automated UI testing at scale!</p> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<meta property="image" content="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/02/CodeBuild-social.jpg" /> 
<b class="lb-b blog-post-title" property="name headline">How to Enable Caching for AWS CodeBuild</b> 
<p style="margin: 0; padding:0;">=======================<p>
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Karthik Thirugnanasambandam</span></span> | on 
<time property="datePublished" datetime="2017-11-21T11:35:36+00:00">21 NOV 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/devops/category/developer-tools/aws-codebuild/" title="View all posts in AWS CodeBuild*"><span property="articleSection">AWS CodeBuild*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/developer-tools/" title="View all posts in Developer Tools*"><span property="articleSection">Developer Tools*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/devops/" title="View all posts in DevOps*"><span property="articleSection">DevOps*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/how-to/" title="View all posts in How-To*"><span property="articleSection">How-To*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/devops/how-to-enable-caching-for-aws-codebuild/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><a href="https://aws.amazon.com/codebuild/">AWS CodeBuild</a> is a fully managed build service. There are no servers to provision and scale, or software to install, configure, and operate. You just specify the location of your source code, choose your build settings, and CodeBuild runs build scripts for compiling, testing, and packaging your code.</p> 
<p>A typical application build process includes phases like preparing the environment, updating the configuration, downloading dependencies, running unit tests, and finally, packaging the built artifact.</p> 
<p>Downloading dependencies is a critical phase in the build process.&nbsp;These dependent files can range in size from a few KBs to multiple MBs. Because most of the dependent files do not change frequently between builds, you can noticeably reduce your build time by caching dependencies.</p> 
<p>In this post, I will show you how to enable caching for AWS CodeBuild.</p> 
<b>Requirements</b> 
<li>Create an <a href="http://docs.aws.amazon.com/AmazonS3/latest/gsg/CreatingABucket.html">Amazon S3</a> bucket&nbsp;for storing cache archives (You can use existing s3 bucket as well).</li> 
<li>Create a <a href="https://github.com/">GitHub account</a>&nbsp;(if you don’t have one).</li> 
<b>Create a sample build project:</b> 
<p>1. Open the AWS CodeBuild console at&nbsp;<a href="https://console.aws.amazon.com/codebuild/">https://console.aws.amazon.com/codebuild/</a>.</p> 
<p>2. If a welcome page is displayed, choose&nbsp;<strong>Get started</strong>.</p> 
<p>If a welcome page is not displayed, on the navigation pane, choose&nbsp;<strong>Build projects</strong>, and then choose&nbsp;<strong>Create project</strong>.</p> 
<p>3. On the&nbsp;<strong>Configure your project</strong>&nbsp;page, for&nbsp;<strong>Project name</strong>, type a name for this build project. Build project names must be unique across each AWS account.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/18/project.png" /></p> 
<p>4. <strong>In&nbsp;Source</strong>: <strong>What to build</strong>, for&nbsp;<strong>Source provider</strong>, choose <strong>GitHub</strong>.</p> 
<li><strong>For Repository</strong>,&nbsp;select <strong>Use a public repository</strong></li> 
<li>For&nbsp;<strong>Repository URL</strong>, type <a href="https://github.com/jenkinsci/aws-codebuild-plugin">https://github.com/jenkinsci/aws-codebuild-plugin</a></li> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/18/Screen-Shot-2017-11-18-at-12.12.01-PM.png" /></p> 
<p>5. <strong>In&nbsp;Environment</strong>: <strong>How to build</strong>, for&nbsp;<strong>Environment image</strong>, select <strong>Use an image managed by AWS CodeBuild</strong>.</p> 
<li>For <strong>Operating system</strong>, choose <strong>Ubuntu</strong>.</li> 
<li>For <strong>Runtime</strong>, choose <strong>Java</strong>.</li> 
<li>For <strong>Version</strong>, &nbsp;choose <strong>aws/codebuild/java:openjdk-8</strong>.</li> 
<li>For <strong>Build specification</strong>, select <strong>Insert build commands</strong>.</li> 
<p><strong>Note:</strong> The&nbsp;build specification file (<strong>buildspec.yml</strong>) can be configured in two ways. You can package it along with your source root directory, or you can override it by using a project environment configuration. In this example, I will use the override option and will use the console editor to specify the build specification.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/18/environment.png" /></p> 
<p>6. Under <strong>Build commands</strong>, click <strong>Switch to editor</strong> to enter the build specification.</p> 
<p>Copy the following text.</p> 
<code class="lang-yaml">version: 0.2
phases:
build:
commands:
- mvn install
cache:
paths:
- '/root/.m2/**/*'</code> 
<p><strong>Note:</strong> The cache section in the build specification instructs AWS CodeBuild about the paths to be cached. Like the&nbsp;artifacts section, the cache paths are relative to&nbsp;$CODEBUILD_SRC_DIR and specify the directories to be cached. In this example, Maven stores the downloaded dependencies to the /root/.m2/ folder, but other tools use different folders. For example, pip uses the /root/.cache/pip folder, and Gradle uses the /root/.gradle/caches folder. You might need to configure the cache paths based on your language platform.</p> 
<p>7. <strong>In Artifacts:&nbsp;</strong>Where to put the artifacts from this build project:</p> 
<li>For <strong>Type</strong>, choose <strong>No artifacts</strong>.</li> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/18/Screen-Shot-2017-11-18-at-12.08.08-PM.png" /></p> 
<p>8. In <strong>Cache</strong>:</p> 
<li>For <strong>Type</strong>, choose <strong>Amazon S3</strong>.</li> 
<li>For <strong>Bucket</strong>, choose your S3 bucket.</li> 
<li>For <strong>Path prefix</strong>, type cache/archives/</li> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/18/cache.png" /></p> 
<p>9. In&nbsp;<strong>Service role</strong>, the <strong>Create a service role in your account option</strong> will display a default role name. &nbsp;You can accept the default name or type your own.</p> 
<p>If you already have an AWS CodeBuild service role, choose&nbsp;<strong>Choose an existing service role from your account</strong>.</p> 
<p>10. Choose&nbsp;<strong>Continue</strong>.</p> 
<p>11. On the&nbsp;<strong>Review</strong>&nbsp;page, to run a build, choose&nbsp;<strong>Save and build</strong>.</p> 
<code class="lang-yaml"></code> 
<b>Review build and cache behavior:</b> 
<p>Let us review our first build for the project.</p> 
<p>In the first run, where no cache exists, overall build time would look something like&nbsp;below (notice the time for <strong>DOWNLOAD_SOURCE</strong>, <strong>BUILD</strong> and <strong>POST_BUILD</strong>):</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/18/pre-build-img.png" /></p> 
<p>If you check the build logs, you will see log entries for dependency downloads. The dependencies are downloaded directly from&nbsp;configured&nbsp;external repositories. At the end of the log, you will see an entry for the cache uploaded to your S3 bucket.</p> 
<p>Let’s review the S3 bucket for the cached archive. You’ll see the cache from our first successful build is uploaded to the configured S3 path.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/18/s3-preview.png" /></p> 
<p>Let’s try another build with the same CodeBuild project. This time the build should pick up the dependencies from the cache.</p> 
<p>In the second run, there was a cache hit (cache was generated from the first run):</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/18/post-build-img.png" /></p> 
<p>You’ll notice a few things:</p> 
<ol> 
<li><strong>DOWNLOAD_SOURCE</strong> took slightly longer. Because, in addition to the source code, this time the build also downloaded the cache from user’s s3 bucket.</li> 
<li><strong>BUILD</strong> time was faster. As the dependencies didn’t need to get downloaded, but were reused from cache.</li> 
<li><strong>POST_BUILD</strong> took slightly longer, but was relatively the same.</li> 
</ol> 
<p>Overall, build duration was improved with cache.</p> 
<b>Best practices for cache</b> 
<li style="text-align: left">By default, the cache archive is encrypted on the server side with the customer’s artifact <a href="https://aws.amazon.com/kms/">KMS</a> key.</li> 
<li style="text-align: left">You can expire the cache by manually removing the cache archive from S3. Alternatively, you can expire the cache by using an <a href="http://docs.aws.amazon.com/AmazonS3/latest/user-guide/create-lifecycle.html">S3 lifecycle policy</a>.</li> 
<li style="text-align: left">You can override cache behavior by updating the project. You can use the AWS CodeBuild <a href="https://aws.amazon.com/Users/allysona/AppData/Local/Temp/docs.aws.amazon.com/codebuild/latest/userguide/change-project.html">the AWS CodeBuild console, AWS CLI, or AWS SDKs</a> to update the project. You can also invalidate cache setting by using the new <strong>InvalidateProjectCache</strong> API. This API forces a new InvalidationKey to be generated, ensuring that future builds receive an empty cache. This API does&nbsp;not&nbsp;remove the existing cache, because this could cause inconsistencies with builds currently in flight.</li> 
<li style="text-align: left">The cache can be enabled for any folders in the build environment, but we recommend you only cache dependencies/files that will not change frequently between builds. Also, to avoid unexpected application behavior, don’t cache configuration and sensitive information.</li> 
<b>Conclusion</b> 
<p>In this blog post, I showed you how to enable and configure cache setting for AWS CodeBuild. As you see, this can save considerable build time. It also improves resiliency by avoiding external network connections to an artifact repository.</p> 
<p>I hope you found this post useful. Feel free to leave your feedback or suggestions in the comments.</p> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<meta property="image" content="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/02/CodeBuild-social.jpg" /> 
<b class="lb-b blog-post-title" property="name headline">Access Resources in a VPC from AWS CodeBuild Builds</b> 
<p style="margin: 0; padding:0;">=======================<p>
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">John Pignata</span></span> | on 
<time property="datePublished" datetime="2017-11-21T11:32:09+00:00">21 NOV 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/devops/category/developer-tools/aws-codebuild/" title="View all posts in AWS CodeBuild*"><span property="articleSection">AWS CodeBuild*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/developer-tools/" title="View all posts in Developer Tools*"><span property="articleSection">Developer Tools*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/news/launch/" title="View all posts in Launch*"><span property="articleSection">Launch*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/news/" title="View all posts in News*"><span property="articleSection">News*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/devops/access-resources-in-a-vpc-from-aws-codebuild-builds/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-1886" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-devops-blog&amp;disqus_identifier=1886&amp;disqus_title=Access+Resources+in+a+VPC+from+AWS+CodeBuild+Builds&amp;disqus_url=https://aws.amazon.com/blogs/devops/access-resources-in-a-vpc-from-aws-codebuild-builds/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-1886');
});
</script> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><em>John Pignata, Startup Solutions Architect, Amazon Web Services</em></p> 
<p>In this blog post we’re going to discuss a new <a href="https://aws.amazon.com/codebuild/">AWS CodeBuild</a> feature that is available starting today. CodeBuild&nbsp;builds can now access resources in a VPC&nbsp;directly without these resources being exposed to the public internet. These resources include <a href="https://aws.amazon.com/rds">Amazon Relational Database Service (Amazon RDS)</a>&nbsp;databases, <a href="https://aws.amazon.com/elasticache">Amazon ElastiCache</a> clusters, internal services running on <a href="https://aws.amazon.com/ec2/">Amazon Elastic Compute Cloud (Amazon EC2)</a>, and <a href="https://aws.amazon.com/ecs/">Amazon EC2 Container Service (Amazon ECS)</a>, or any service endpoints that are only reachable from within a specific VPC.</p> 
<p>CodeBuild is a fully managed build service that compiles source code, runs tests, and produces software packages that are ready to deploy. As part of the build process, developers often require access to resources that should be isolated from the public Internet. Now CodeBuild builds can be optionally configured to have VPC connectivity and access these resources directly.</p> 
<p><strong>Accessing Resources in a VPC</strong></p> 
<p>You can configure builds to have access to a VPC when you create a CodeBuild project or you can update an existing CodeBuild project with VPC configuration attributes. Here’s how it looks in the console:</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/16/Picture1.png" /></p> 
<p>To configure VPC connectivity: select a VPC, one or more subnets within that VPC, and one or more VPC security groups that CodeBuild should apply when attaching to your VPC. Once configured, commands running as part of your build will be able to access resources in your VPC without transiting across the public Internet.</p> 
<p><strong>Use Cases</strong></p> 
<p>The availability of VPC connectivity from CodeBuild builds unlocks many potential uses. For example, you can:</p> 
<li>Run integration tests from your build against data in an Amazon RDS instance that’s isolated on a private subnet.</li> 
<li>Query data in an ElastiCache cluster directly from tests.</li> 
<li>Interact with internal web services hosted on Amazon EC2, Amazon ECS, or services that use internal Elastic Load Balancing.</li> 
<li>Retrieve dependencies from self-hosted, internal artifact repositories such as PyPI for Python, Maven for Java, npm for Node.js, and so on.</li> 
<li>Access objects in an Amazon S3 bucket configured to allow access only through a VPC endpoint.</li> 
<li>Query external web services that require fixed IP addresses through the Elastic IP address of the NAT gateway associated with your subnet(s).</li> 
<p>… and more! Your builds can now access any resource that’s hosted in your VPC without any compromise on network isolation.</p> 
<p><strong>Internet Connectivity</strong></p> 
<p>CodeBuild requires access to resources on the public Internet to successfully execute builds. At a minimum, it must be able to reach your source repository system (such as <a href="https://aws.amazon.com/codecommit/">AWS CodeCommit</a>, <a href="https://github.com">GitHub</a>, <a href="https://www.bitbucket.org">Bitbucket</a>), <a href="https://aws.amazon.com/s3/">Amazon Simple Storage Service (Amazon S3)</a> to deliver build artifacts, and <a href="http://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/WhatIsCloudWatchLogs.html">Amazon CloudWatch Logs</a> to stream logs from the build process. The interface attached to your VPC will not be assigned a public IP address so to enable Internet access from your builds, you will need to set up a managed <a href="http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/vpc-nat-gateway.html">NAT Gateway</a> or <a href="http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_NAT_Instance.html">NAT instance</a> for the subnets you configure. You must also ensure your security groups allow outbound access to these services.</p> 
<p><strong>IP Address Space</strong></p> 
<p>Each running build will be assigned an IP address from one of the subnets in your VPC that you designate for CodeBuild to use. As CodeBuild scales to meet your build volume, ensure that you select subnets with enough address space to accommodate your expected number of concurrent builds.</p> 
<p><strong>Service Role Permissions</strong></p> 
<p>CodeBuild requires new permissions in order to manage network interfaces on your VPCs. If you create a service role for your new projects, these permissions will be included in that role’s policy automatically. For existing service roles, you can edit the policy document to include the additional actions. For the full policy document to apply to your service role, see <a href="http://docs.aws.amazon.com/codebuild/latest/userguide/setting-up.html#setting-up-service-permissions-group">Advanced Setup</a> in the CodeBuild documentation.</p> 
<p>For more information, see <a href="https://docs.aws.amazon.com/codebuild/latest/userguide/vpc-support.html">VPC Support</a> in the CodeBuild documentation. We hope you find the ability to access internal resources on a VPC useful&nbsp;in your build processes! If you have any questions or feedback, feel free to reach out to us through the <a href="https://forums.aws.amazon.com/forum.jspa?forumID=230">AWS CodeBuild forum</a> or leave a comment!</p> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-1886');
});
</script> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">Using AWS CodeCommit Pull Requests to request code reviews and discuss code</b> 
<p style="margin: 0; padding:0;">=======================<p>
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Chris Barclay</span></span> | on 
<time property="datePublished" datetime="2017-11-20T13:27:15+00:00">20 NOV 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/devops/category/developer-tools/aws-codecommit/" title="View all posts in AWS CodeCommit*"><span property="articleSection">AWS CodeCommit*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/how-to/" title="View all posts in How-To*"><span property="articleSection">How-To*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/devops/using-aws-codecommit-pull-requests-to-request-code-reviews-and-discuss-code/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p>Thank you to Michael Edge, Senior Cloud Architect, for a great blog on CodeCommit pull requests.</p> 
<p>~~~~~~~</p> 
<p><a href="http://aws.amazon.com/codecommit">AWS CodeCommit</a> is a fully managed service for securely hosting private Git repositories. CodeCommit now supports pull requests, which allows repository users to review, comment upon, and interactively iterate on code changes. Used as a collaboration tool between team members, pull requests help you to review potential changes to a CodeCommit repository before merging those changes into the repository. Each pull request goes through a simple lifecycle, as follows:</p> 
<li>The new features to be merged are added as one or more commits to a feature branch. The commits are not merged into the destination branch.</li> 
<li>The pull request is created, usually from the difference between two branches.</li> 
<li>Team members review and comment on the pull request. The pull request might be updated with additional commits that contain changes made in response to comments, or include changes made to the destination branch.</li> 
<li>Once team members are happy with the pull request, it is merged into the destination branch. The commits are applied to the destination branch in the same order they were added to the pull request.</li> 
<p>Commenting is an integral part of the pull request process, and is used to collaborate between the developers and the reviewer. Reviewers add comments and questions to a pull request during the review process, and developers respond to these with explanations. Pull request comments can be added to the overall pull request, a file within the pull request, or a line within a file.</p> 
<p>To make the comments more useful, sign in to the AWS Management Console as an AWS Identity and Access Management (IAM) user. The username will then be associated with the comment, indicating the owner of the comment. Pull request comments are a great quality improvement tool as they allow the entire development team visibility into what reviewers are looking for in the code. They also serve as a record of the discussion between team members at a point in time, and shouldn’t be deleted.</p> 
<p>AWS CodeCommit is also introducing the ability to add comments to a commit, another useful collaboration feature that allows team members to discuss code changed as part of a commit. This helps you discuss changes made in a repository, including why the changes were made, whether further changes are necessary, or whether changes should be merged. As is the case with pull request comments, you can comment on an overall commit, on a file within a commit, or on a specific line or change within a file, and other repository users can respond to your comments. Comments are not restricted to commits, they can also be used to comment on the differences between two branches, or between two tags. Commit comments are separate from pull request comments, i.e. you will not see commit comments when reviewing a pull request – you will only see pull request comments.</p> 
<b>A pull request example</b> 
<p>Let’s get started by running through an example. We’ll take a typical pull request scenario and look at how we’d use CodeCommit and the AWS Management Console for each of the steps.</p> 
<p>To try out this scenario, you’ll need:</p> 
<li>An AWS CodeCommit repository with some sample code in the master branch. We’ve provided sample code below.</li> 
<li>Two AWS Identity and Access Management (IAM) users, both with the <a href="http://docs.aws.amazon.com/codecommit/latest/userguide/auth-and-access-control-iam-identity-based-access-control.html#managed-policies">AWSCodeCommitPowerUser managed policy</a> applied to them.</li> 
<li>Git installed on your local computer, and access configured for AWS CodeCommit.</li> 
<li>A clone of the AWS CodeCommit repository on your local computer.</li> 
<p>In the course of this example, you’ll sign in to the AWS CodeCommit console as one IAM user to create the pull request, and as the other IAM user to review the pull request. To learn more about how to set up your IAM users and how to connect to AWS CodeCommit with Git, see the following topics:</p> 
<li>Information on <a href="http://docs.aws.amazon.com/IAM/latest/UserGuide/id_users_create.html#id_users_create_console">creating an IAM user</a> with AWS Management Console access.</li> 
<li>Instructions on how to <a href="http://docs.aws.amazon.com/codecommit/latest/userguide/setting-up-gc.html">access CodeCommit using Git</a>.</li> 
<li>If you’d like to use the same ‘hello world’ application as used in this article, here is the source code:</li> 
<code class="lang-java">package com.amazon.helloworld;
public class Main {
public static void main(String[] args) {
System.out.println(&quot;Hello, world&quot;);
}
}</code> 
<p>The scenario below uses the us-east-2 region.</p> 
<h3>Creating the branches</h3> 
<p>Before we jump in and create a pull request, we’ll need at least two branches. In this example, we’ll follow a branching strategy similar to the one <a href="https://datasift.github.io/gitflow/IntroducingGitFlow.html">described in GitFlow</a>. We’ll create a new branch for our feature from the main development branch (the default branch). We’ll develop the feature in the feature branch. Once we’ve written and tested the code for the new feature in that branch, we’ll create a pull request that contains the differences between the feature branch and the main development branch. Our team lead (the second IAM user) will review the changes in the pull request. Once the changes have been reviewed, the feature branch will be merged into the development branch.</p> 
<p><img src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/16/pull-request-1a.png" /></p> 
<p style="text-align: center">Figure 1: Pull request link</p> 
<p>Sign in to the AWS CodeCommit console with the IAM user you want to use as the developer. You can use an existing repository or you can go ahead and <a href="http://docs.aws.amazon.com/codecommit/latest/userguide/how-to-create-repository.html#how-to-create-repository-console">create a new one</a>. We won’t be merging any changes to the master branch of your repository, so it’s safe to use an existing repository for this example. You’ll find the Pull requests link has been added just above the Commits link (see Figure 1), and below Commits you’ll find the Branches link. Click <strong>Branches</strong> and create a new branch called ‘develop’, branched from the ‘master’ branch. Then create a new branch called ‘feature1’, branched from the ‘develop’ branch. You’ll end up with three branches, as you can see in Figure 2. (Your repository might contain other branches in addition to the three shown in the figure).</p> 
<p><img src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/16/Picture2.png" /></p> 
<p style="text-align: center">Figure 2: Create a feature branch</p> 
<p>If you haven’t cloned your repo yet, go to the <strong>Code</strong> link in the CodeCommit console and click the <strong>Connect</strong> button. Follow the instructions to clone your repo (<a href="http://docs.aws.amazon.com/codecommit/latest/userguide/how-to-connect.html">detailed instructions are here</a>). Open a terminal or command line and paste the git clone command supplied in the Connect instructions for your repository. The example below shows cloning a repository named codecommit-demo:</p> 
<code class="lang-bash">git clone https://git-codecommit.us-east-2.amazonaws.com/v1/repos/codecommit-demo</code> 
<p>If you’ve previously cloned the repo you’ll need to update your local repo with the branches you created. Open a terminal or command line and make sure you’re in the root directory of your repo, then run the following command:</p> 
<code class="lang-bash">git remote update origin</code> 
<p>You’ll see your new branches pulled down to your local repository.</p> 
<code class="lang-bash">$ git remote update origin
Fetching origin
From https://git-codecommit.us-east-2.amazonaws.com/v1/repos/codecommit-demo
* [new branch]      develop    -&gt; origin/develop
* [new branch]      feature1   -&gt; origin/feature1</code> 
<p>You can also see your new branches by typing:</p> 
<code class="lang-bash">git branch --all
$ git branch --all
* master
remotes/origin/develop
remotes/origin/feature1
remotes/origin/master</code> 
<p>Now we’ll make a change to the ‘feature1’ branch. Open a terminal or command line and check out the feature1 branch by running the following command:</p> 
<code class="lang-bash">git checkout feature1
$ git checkout feature1
Branch feature1 set up to track remote branch feature1 from origin.
Switched to a new branch 'feature1'</code> 
<h3>Make code changes</h3> 
<p>Edit a file in the repo using your favorite editor and save the changes. Commit your changes to the local repository, and push your changes to CodeCommit. For example:</p> 
<code class="lang-bash">git commit -am 'added new feature'
git push origin feature1
$ git commit -am 'added new feature'
[feature1 8f6cb28] added new feature
1 file changed, 1 insertion(+), 1 deletion(-)
$ git push origin feature1
Counting objects: 9, done.
Delta compression using up to 4 threads.
Compressing objects: 100% (4/4), done.
Writing objects: 100% (9/9), 617 bytes | 617.00 KiB/s, done.
Total 9 (delta 2), reused 0 (delta 0)
To https://git-codecommit.us-east-2.amazonaws.com/v1/repos/codecommit-demo
2774a53..8f6cb28  feature1 -&gt; feature1</code> 
<h3>Creating the pull request</h3> 
<p>Now we have a ‘feature1’ branch that differs from the ‘develop’ branch. At this point we want to merge our changes into the ‘develop’ branch. We’ll create a pull request to notify our team members to review our changes and check whether they are ready for a merge.</p> 
<p>In the AWS CodeCommit console, click <strong>Pull requests</strong>. Click <strong>Create pull request</strong>. On the next page select ‘develop’ as the destination branch and ‘feature1’ as the source branch. Click <strong>Compare</strong>. CodeCommit will check for merge conflicts and highlight whether the branches can be automatically merged using the fast-forward option, or whether a manual merge is necessary. A pull request can be created in both situations.</p> 
<p><img src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/16/Picture3.png" /></p> 
<p style="text-align: center">Figure 3: Create a pull request</p> 
<p>After comparing the two branches, the CodeCommit console displays the information you’ll need in order to create the pull request. In the ‘Details’ section, the ‘Title’ for the pull request is mandatory, and you may optionally provide comments to your reviewers to explain the code change you have made and what you’d like them to review. In the ‘Notifications’ section, there is an option to set up notifications to notify subscribers of changes to your pull request. Notifications will be sent on creation of the pull request as well as for any pull request updates or comments. And finally, you can review the changes that make up this pull request. This includes both the individual commits (a pull request can contain one or more commits, available in the Commits tab) as well as the changes made to each file, i.e. the diff between the two branches referenced by the pull request, available in the Changes tab. After you have reviewed this information and added a title for your pull request, click the <strong>Create</strong> button. You will see a confirmation screen, as shown in Figure 4, indicating that your pull request has been successfully created, and can be merged without conflicts into the ‘develop’ branch.</p> 
<p><img src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/16/Picture4.png" /></p> 
<p style="text-align: center">Figure 4: Pull request confirmation page</p> 
<h3>Reviewing the pull request</h3> 
<p>Now let’s view the pull request from the perspective of the team lead. If you set up notifications for this CodeCommit repository, creating the pull request would have sent an email notification to the team lead, and he/she can use the links in the email to navigate directly to the pull request. In this example, sign in to the AWS CodeCommit console as the IAM user you’re using as the team lead, and click <strong>Pull requests</strong>. You will see the same information you did during creation of the pull request, plus a record of activity related to the pull request, as you can see in Figure 5.</p> 
<p><img src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/16/Picture5.png" /></p> 
<p style="text-align: center">Figure 5: Team lead reviewing the pull request</p> 
<h3>Commenting on the pull request</h3> 
<p>You now perform a thorough review of the changes and make a number of comments using the new pull request comment feature. To gain an overall perspective on the pull request, you might first go to the Commits tab and review how many commits are included in this pull request. Next, you might visit the Changes tab to review the changes, which displays the differences between the feature branch code and the develop branch code. At this point, you can add comments to the pull request as you work through each of the changes. Let’s go ahead and review the pull request. During the review, you can add review comments at three levels:</p> 
<li>The overall pull request</li> 
<li>A file within the pull request</li> 
<li>An individual line within a file</li> 
<p><strong>The overall pull request</strong><br /> In the Changes tab near the bottom of the page you’ll see a ‘Comments on changes’ box. We’ll add comments here related to the overall pull request. Add your comments as shown in Figure 6 and click the <strong>Save</strong> button.</p> 
<p><img src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/16/Picture6.png" /></p> 
<p style="text-align: center">Figure 6: Pull request comment</p> 
<p><strong>A specific file in the pull request</strong><br /> Hovering your mouse over a filename in the Changes tab will cause a blue ‘comments’ icon to appear to the left of the filename. Clicking the icon will allow you to enter comments specific to this file, as in the example in Figure 7. Go ahead and add comments for one of the files changed by the developer. Click the <strong>Save</strong> button to save your comment.</p> 
<p><img src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/16/Picture7.png" /></p> 
<p style="text-align: center">Figure 7: File comment</p> 
<p><strong>A specific line in a file in the pull request</strong><br /> A blue ‘comments’ icon will appear as you hover over individual lines within each file in the pull request, allowing you to create comments against lines that have been added, removed or are unchanged. In Figure 8, you add comments against a line that has been added to the source code, encouraging the developer to review the naming standards. Go ahead and add line comments for one of the files changed by the developer. Click the <strong>Save</strong> button to save your comment.</p> 
<p><img src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/16/Picture8.png" /></p> 
<p style="text-align: center">Figure 8: Line comment</p> 
<p>A pull request that has been commented at all three levels will look similar to Figure 9. The pull request comment is shown expanded in the ‘Comments on changes’ section, while the comments at file and line level are shown collapsed. A ‘comment’ icon indicates that comments exist at file and line level. Clicking the icon will expand and show the comment. Since you are expecting the developer to make further changes based on your comments, you won’t merge the pull request at this stage, but will leave it open awaiting feedback. Each comment you made results in a notification being sent to the developer, who can respond to the comments. This is great for remote working, where developers and team lead may be in different time zones.</p> 
<p><img src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/16/Picture9.png" /></p> 
<p style="text-align: center">Figure 9: Fully commented pull request</p> 
<h3>Adding a little complexity</h3> 
<p>A typical development team is going to be creating pull requests on a regular basis. It’s highly likely that the team lead will merge other pull requests into the ‘develop’ branch while pull requests on feature branches are in the review stage. This may result in a change to the ‘Mergable’ status of a pull request. Let’s add this scenario into the mix and check out how a developer will handle this.</p> 
<p>To test this scenario, we could create a new pull request and ask the team lead to merge this to the ‘develop’ branch. But for the sake of simplicity we’ll take a shortcut. Clone your CodeCommit repo to a new folder, switch to the ‘develop’ branch, and make a change to one of the same files that were changed in your pull request. Make sure you change a line of code that was also changed in the pull request. Commit and push this back to CodeCommit. Since you’ve just changed a line of code in the ‘develop’ branch that has also been changed in the ‘feature1’ branch, the ‘feature1’ branch cannot be cleanly merged into the ‘develop’ branch. Your developer will need to resolve this merge conflict.</p> 
<p>A developer reviewing the pull request would see the pull request now looks similar to Figure 10, with a ‘Resolve conflicts’ status rather than the ‘Mergable’ status it had previously (see Figure 5).</p> 
<p><img src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/16/Picture10.png" /></p> 
<p style="text-align: center">Figure 10: Pull request with merge conflicts</p> 
<h3>Reviewing the review comments</h3> 
<p>Once the team lead has completed his review, the developer will review the comments and make the suggested changes. As a developer, you’ll see the list of review comments made by the team lead in the pull request Activity tab, as shown in Figure 11. The Activity tab shows the history of the pull request, including commits and comments. You can reply to the review comments directly from the Activity tab, by clicking the Reply button, or you can do this from the Changes tab. The Changes tab shows the comments for the latest commit, as comments on previous commits may be associated with lines that have changed or been removed in the current commit. Comments for previous commits are available to view and reply to in the Activity tab.</p> 
<p>In the Activity tab, use the shortcut link (which looks like this &lt;/&gt;) to move quickly to the source code associated with the comment. In this example, you will make further changes to the source code to address the pull request review comments, so let’s go ahead and do this now. But first, you will need to resolve the ‘Resolve conflicts’ status.</p> 
<p><img src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/16/Picture11.png" /></p> 
<p style="text-align: center">Figure 11: Pull request activity</p> 
<h3>Resolving the ‘Resolve conflicts’ status</h3> 
<p>The ‘Resolve conflicts’ status indicates there is a merge conflict between the ‘develop’ branch and the ‘feature1’ branch. This will require manual intervention to restore the pull request back to the ‘Mergable’ state. We will resolve this conflict next.</p> 
<p>Open a terminal or command line and check out the develop branch by running the following command:</p> 
<code class="lang-bash">git checkout develop
$ git checkout develop
Switched to branch 'develop'
Your branch is up-to-date with 'origin/develop'.</code> 
<p>To incorporate the changes the team lead made to the ‘develop’ branch, merge the remote ‘develop’ branch with your local copy:</p> 
<code class="lang-bash">git pull
$ git pull
remote: Counting objects: 9, done.
Unpacking objects: 100% (9/9), done.
From https://git-codecommit.us-east-2.amazonaws.com/v1/repos/codecommit-demo
af13c82..7b36f52  develop    -&gt; origin/develop
Updating af13c82..7b36f52
Fast-forward
src/main/java/com/amazon/helloworld/Main.java | 2 +-
1 file changed, 1 insertion(+), 1 deletion(-)</code> 
<p>Then checkout the ‘feature1’ branch:</p> 
<code class="lang-bash">git checkout feature1
$ git checkout feature1
Switched to branch 'feature1'
Your branch is up-to-date with 'origin/feature1'.</code> 
<p>Now merge the changes from the ‘develop’ branch into your ‘feature1’ branch:</p> 
<code class="lang-bash">git merge develop
$ git merge develop
Auto-merging src/main/java/com/amazon/helloworld/Main.java
CONFLICT (content): Merge conflict in src/main/java/com/amazon/helloworld/Main.java
Automatic merge failed; fix conflicts and then commit the result.</code> 
<p>Yes, this fails. The file Main.java has been changed in both branches, resulting in a merge conflict that can’t be resolved automatically. However, Main.java will now contain markers that indicate where the conflicting code is, and you can use these to resolve the issues manually. Edit Main.java using your favorite IDE, and you’ll see it looks something like this:</p> 
<code class="lang-java">package com.amazon.helloworld;
import java.util.*;
/**
* This class prints a hello world message
*/
public class Main {
public static void main(String[] args) {
&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD
Date todaysdate = Calendar.getInstance().getTime();
System.out.println(&quot;Hello, earthling. Today's date is: &quot; + todaysdate);
=======
System.out.println(&quot;Hello, earth&quot;);
&gt;&gt;&gt;&gt;&gt;&gt;&gt; develop
}
}</code> 
<p>The code between HEAD and ‘===’ is the code the developer added in the ‘feature1’ branch (HEAD represents ‘feature1’ because this is the current checked out branch). The code between ‘===’ and ‘&gt;&gt;&gt; develop’ is the code added to the ‘develop’ branch by the team lead. We’ll resolve the conflict by manually merging both changes, resulting in an updated Main.java:</p> 
<code class="lang-java">package com.amazon.helloworld;
import java.util.*;
/**
* This class prints a hello world message
*/
public class Main {
public static void main(String[] args) {
Date todaysdate = Calendar.getInstance().getTime();
System.out.println(&quot;Hello, earth. Today's date is: &quot; + todaysdate);
}
}</code> 
<p>After saving the change you can add and commit it to your local repo:</p> 
<code class="lang-bash">git add src/
git commit -m 'fixed merge conflict by merging changes'</code> 
<h3>Fixing issues raised by the reviewer</h3> 
<p>Now you are ready to address the comments made by the team lead. If you are no longer pointing to the ‘feature1’ branch, check out the ‘feature1’ branch by running the following command:</p> 
<code class="lang-bash">git checkout feature1
$ git checkout feature1
Branch feature1 set up to track remote branch feature1 from origin.
Switched to a new branch 'feature1'</code> 
<p>Edit the source code in your favorite IDE and make the changes to address the comments. In this example, the developer has updated the source code as follows:</p> 
<code class="lang-java">package com.amazon.helloworld;
import java.util.*;
/**
*  This class prints a hello world message
*
* @author Michael Edge
* @see HelloEarth
* @version 1.0
*/
public class Main {
public static void main(String[] args) {
Date todaysDate = Calendar.getInstance().getTime();
System.out.println(&quot;Hello, earth. Today's date is: &quot; + todaysDate);
}
}</code> 
<p>After saving the changes, commit and push to the CodeCommit ‘feature1’ branch as you did previously:</p> 
<code class="lang-bash">git commit -am 'updated based on review comments'
git push origin feature1</code> 
<h3>Responding to the reviewer</h3> 
<p>Now that you’ve fixed the code issues you will want to respond to the review comments. In the AWS CodeCommit console, check that your latest commit appears in the pull request Commits tab. You now have a pull request consisting of more than one commit. The pull request in Figure 12 has four commits, which originated from the following activities:</p> 
<li>8th Nov: the original commit used to initiate this pull request</li> 
<li>10th Nov, 3 hours ago: the commit by the team lead to the ‘develop’ branch, merged into our ‘feature1’ branch</li> 
<li>10th Nov, 24 minutes ago: the commit by the developer that resolved the merge conflict</li> 
<li>10th Nov, 4 minutes ago: the final commit by the developer addressing the review comments</li> 
<p><img src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/16/Picture12.png" /></p> 
<p style="text-align: center">Figure 12: Pull request with multiple commits</p> 
<p>Let’s reply to the review comments provided by the team lead. In the Activity tab, reply to the pull request comment and save it, as shown in Figure 13.</p> 
<p><img src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/16/Picture13.png" /></p> 
<p style="text-align: center">Figure 13: Replying to a pull request comment</p> 
<p>At this stage, your code has been committed and you’ve updated your pull request comments, so you are ready for a final review by the team lead.</p> 
<h3>Final review</h3> 
<p>The team lead reviews the code changes and comments made by the developer. As team lead, you own the ‘develop’ branch and it’s your decision on whether to merge the changes in the pull request into the ‘develop’ branch. You can close the pull request with or without merging using the Merge and Close buttons at the bottom of the pull request page (see Figure 13). Clicking Close will allow you to add comments on why you are closing the pull request without merging. Merging will perform a fast-forward merge, incorporating the commits referenced by the pull request. Let’s go ahead and click the Merge button to merge the pull request into the ‘develop’ branch.</p> 
<p><img class="aligncenter" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/16/Picture14.png" /></p> 
<p style="text-align: center">Figure 14: Merging the pull request</p> 
<p>After merging a pull request, development of that feature is complete and the feature branch is no longer needed. It’s common practice to delete the feature branch after merging. CodeCommit provides a check box during merge to automatically delete the associated feature branch, as seen in Figure 14. Clicking the <strong>Merge</strong> button will merge the pull request into the ‘develop’ branch, as shown in Figure 15. This will update the status of the pull request to ‘Merged’, and will close the pull request.</p> 
<p><img src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/20/Picture16.png" /></p> 
<b>Conclusion</b> 
<p>This blog has demonstrated how pull requests can be used to request a code review, and enable reviewers to get a comprehensive summary of what is changing, provide feedback to the author, and merge the code into production. For more information on pull requests, <a href="http://docs.aws.amazon.com/codecommit/latest/userguide/pull-requests.html">see the documentation</a>.</p> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<meta property="image" content="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/12/codepipeline_statemachine-1-1260x623.png" /> 
<b class="lb-b blog-post-title" property="name headline">Using AWS Step Functions State Machines to Handle Workflow-Driven AWS CodePipeline Actions</b> 
<p style="margin: 0; padding:0;">=======================<p>
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Marcilio Mendonca</span></span> | on 
<time property="datePublished" datetime="2017-10-18T08:40:39+00:00">18 OCT 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/devops/category/developer-tools/aws-codepipeline/" title="View all posts in AWS CodePipeline*"><span property="articleSection">AWS CodePipeline*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/application-services/aws-step-functions/" title="View all posts in AWS Step Functions*"><span property="articleSection">AWS Step Functions*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/devops/using-aws-step-functions-state-machines-to-handle-workflow-driven-aws-codepipeline-actions/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><a href="https://aws.amazon.com/codepipeline/">AWS&nbsp;CodePipeline</a>&nbsp;is a continuous integration and continuous delivery service for fast and reliable application and infrastructure updates. It offers powerful integration with other AWS services, such as <a href="https://aws.amazon.com/codebuild/">AWS&nbsp;CodeBuild</a>,&nbsp;<a href="https://aws.amazon.com/codedeploy/">AWS&nbsp;CodeDeploy</a>,&nbsp;<a href="https://aws.amazon.com/codecommit/">AWS CodeCommit</a>, <a href="https://aws.amazon.com/cloudformation/">AWS&nbsp;CloudFormation</a>&nbsp;and with third-party tools such as&nbsp;<a href="https://jenkins.io/">Jenkins</a>&nbsp;and&nbsp;<a href="https://github.com/">GitHub</a>.&nbsp;These services make it possible for AWS customers to successfully automate various tasks, including infrastructure provisioning, blue/green deployments,&nbsp;serverless&nbsp;deployments, AMI baking, database provisioning, and release management.</p> 
<p>Developers have been able to use&nbsp;CodePipeline&nbsp;to build sophisticated automation pipelines that often require a single&nbsp;CodePipeline&nbsp;action to perform multiple tasks, fork into different execution paths, and deal with asynchronous behavior. For example, to deploy a Lambda function, a&nbsp;CodePipeline&nbsp;action might first inspect the changes pushed to the code repository. If only the Lambda code has changed, the action can simply update the Lambda code package, create a new version, and point the Lambda alias to the new version. If the changes also affect infrastructure resources managed by AWS CloudFormation, the pipeline action might have to create a stack or update an existing one through the use of a&nbsp;change set. In addition, if an update is required, the pipeline action might enforce a safety policy to infrastructure resources that prevents the deletion and replacement of resources.&nbsp;You can do this by creating a <a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-cfn-updating-stacks-changesets-create.html">change set</a> and having the pipeline action inspect its changes before updating the stack.&nbsp;Change sets that do not conform to the policy are deleted.</p> 
<p>This use case is a good illustration of&nbsp;<em>workflow-driven&nbsp;pipeline actions</em>. These are actions that run multiple tasks, deal with&nbsp;async&nbsp;behavior and loops, need to maintain and propagate state, and fork into different execution paths. Implementing&nbsp;workflow-driven&nbsp;actions directly in&nbsp;CodePipeline&nbsp;can lead to complex pipelines that are hard for developers to understand and maintain. Ideally, a pipeline action should perform a single task and delegate the complexity of dealing with&nbsp;workflow-driven&nbsp;behavior associated with that task to a state machine engine. This would make it possible for developers to build simpler, more intuitive pipelines and allow them to use state machine execution logs to visualize and troubleshoot their pipeline actions.</p> 
<p>In this blog post, we discuss how&nbsp;<a href="https://aws.amazon.com/step-functions/">AWS Step Functions</a>&nbsp;state machines can be used to handle&nbsp;workflow-driven&nbsp;actions. We show how a&nbsp;CodePipeline&nbsp;action can trigger a Step Functions state machine and how the pipeline and the state machine are kept decoupled through a Lambda function. The advantages of using state machines include:</p> 
<li>Simplified logic (complex tasks are broken into multiple smaller tasks).</li> 
<li>Ease of handling asynchronous behavior (through state machine&nbsp;wait&nbsp;states).</li> 
<li>Built-in support for choices and processing different execution paths (through state machine&nbsp;choices).</li> 
<li>Built-in visualization and logging of the state machine execution.</li> 
<p>The source code for the sample pipeline, pipeline actions, and state machine used in this post is available at&nbsp;<a href="https://github.com/awslabs/aws-codepipeline-stepfunctions">https://github.com/awslabs/aws-codepipeline-stepfunctions</a>.</p> 
<b>Overview</b> 
<p>This figure shows the components in the CodePipeline-Step Functions integration that will be described in this post. The pipeline contains two stages: a Source stage represented by a CodeCommit Git repository and a Prod stage with a single Deploy action that represents the workflow-driven action.</p> 
<p><img src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/11/codepipeline_statemachine.png" /></p> 
<p>This action invokes a Lambda function (1) called the&nbsp;State Machine Trigger Lambda, which, in turn, triggers a Step Functions State Machine to process the request (2). The Lambda function sends a continuation token back to the pipeline (3) to continue its execution later and terminates. Seconds later, the pipeline invokes the Lambda function again (4), passing the continuation token received. The Lambda function checks the execution state of the state machine (5,6) and communicates the status to the pipeline. The process is repeated until the state machine execution is complete. Then the Lambda function notifies the pipeline that the corresponding pipeline action is complete (7). If the state machine has failed, the Lambda function will then fail the pipeline action and stop its execution (7). While running, the state machine triggers various Lambda functions to perform different tasks. The state machine and the pipeline are fully decoupled. Their interaction is handled by the Lambda function.</p> 
<b>The&nbsp;Deploy&nbsp;State Machine</b> 
<p>The sample state machine used in this post is a simplified version of the use case, with emphasis on infrastructure deployment. The state machine will follow distinct execution paths and thus have different outcomes, depending on:</p> 
<li>The current state of the AWS&nbsp;CloudFormation&nbsp;stack.</li> 
<li>The nature of the code changes made to the AWS&nbsp;CloudFormation&nbsp;template and pushed into the pipeline.</li> 
<p>If the stack does not exist, it will be created. If the stack exists, a change set will be created and its resources inspected by the state machine. The inspection consists of parsing the change set results and detecting whether any resources will be deleted or replaced. If no resources are being deleted or replaced, the change set is allowed to be executed and the state machine completes successfully. Otherwise, the change set is deleted and the state machine completes execution with a failure as the terminal state.</p> 
<p>Let’s dive into each of these execution paths.</p> 
<h3>Path 1: Create a Stack and Succeed Deployment</h3> 
<p>The Deploy state machine is shown here. It is triggered by the Lambda function using the following input parameters stored in an S3 bucket.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/12/create_stack_statemachine-1.png" /></p> 
<code class="lang-json">{
&quot;environmentName&quot;: &quot;prod&quot;,
&quot;stackName&quot;: &quot;sample-lambda-app&quot;,
&quot;templatePath&quot;: &quot;infra/Lambda-template.yaml&quot;,
&quot;revisionS3Bucket&quot;: &quot;codepipeline-us-east-1-418586629775&quot;,
&quot;revisionS3Key&quot;: &quot;StepFunctionsDrivenD/CodeCommit/sjcmExZ&quot;
}</code> 
<p>Note that some values used here are for the use case example only. Account-specific parameters like <em>revisionS3Bucket</em>&nbsp;and&nbsp;<em>revisionS3Key</em>&nbsp;will be different when you deploy this use case in your account.</p> 
<p>These input parameters are used by various states in the state machine and passed to the corresponding Lambda functions to perform different tasks. For example,&nbsp;<em>stackName</em>&nbsp;is used to create a stack, check the status of stack creation, and create a change set. The&nbsp;<em>environmentName</em>&nbsp;represents the environment (for example, dev, test, prod) to which the code is being deployed. It is used to prefix the name of stacks and change sets.</p> 
<p>With the exception of built-in states such as&nbsp;<em>wait</em>&nbsp;and&nbsp;<em>choice</em>, each state in the state machine invokes a specific Lambda function.&nbsp;&nbsp;The results received from the Lambda invocations are appended to the state machine’s original input. When the state machine finishes its execution, several parameters will have been added to its original input.</p> 
<p>The first stage in the state machine is “Check Stack Existence”. It checks whether a stack with the input name specified in the&nbsp;<em>stackName</em>&nbsp;input parameter already exists. The output of the state adds a Boolean value called&nbsp;<em>doesStackExist</em>&nbsp;to the original state machine input as follows:</p> 
<code class="lang-json">{
&quot;doesStackExist&quot;: true,
&quot;environmentName&quot;: &quot;prod&quot;,
&quot;stackName&quot;: &quot;sample-lambda-app&quot;,
&quot;templatePath&quot;: &quot;infra/lambda-template.yaml&quot;,
&quot;revisionS3Bucket&quot;: &quot;codepipeline-us-east-1-418586629775&quot;,
&quot;revisionS3Key&quot;: &quot;StepFunctionsDrivenD/CodeCommit/sjcmExZ&quot;,
}</code> 
<p>The following stage, “Does Stack Exist?”, is represented by Step Functions built-in&nbsp;<em>choice</em>&nbsp;state. It checks the value of&nbsp;<em>doesStackExist</em>&nbsp;to determine whether a new stack needs to be created (<em>doesStackExist=true</em>) or a change set needs to be created and inspected (<em>doesStackExist=false</em>).</p> 
<p>If the stack does not exist, the states illustrated in green in the preceding figure are executed. This execution path creates the stack, waits until the stack is created, checks the status of the stack’s creation, and marks the deployment successful after the stack has been created. Except for “Stack Created?” and “Wait Stack Creation,” each of these stages invokes a Lambda function. “Stack Created?” and “Wait Stack Creation” are implemented by using the built-in&nbsp;<em>choice</em>&nbsp;state (to decide which path to follow) and the&nbsp;<em>wait</em> state&nbsp;(to wait a few seconds before proceeding), respectively. Each stage adds the results of their Lambda function executions to the initial input of the state machine, allowing future stages to process them.</p> 
<h3>Path 2: Safely Update a Stack and Mark Deployment as Successful</h3> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/12/create_changeset_statemachine.png" /></p> 
<p>If the stack indicated by the&nbsp;<em>stackName</em>&nbsp;parameter already exists, a different path is executed. (See the green states in the figure.) This path will create a change set and use&nbsp;<em>wait</em>&nbsp;and&nbsp;<em>choice</em>&nbsp;states to wait until the change set is created. Afterwards, a stage in the execution path will&nbsp;inspect&nbsp; the resources affected before the change set is executed.</p> 
<p>The inspection procedure represented by the “Inspect Change Set Changes” stage consists of parsing the resources affected by the change set and checking whether any of the existing resources are being deleted or replaced. The following is an excerpt of the algorithm, where&nbsp;<em>changeSetChanges.Changes</em>&nbsp;is the object representing the change set changes:</p> 
<code class="lang-js">...
var RESOURCES_BEING_DELETED_OR_REPLACED = &quot;RESOURCES-BEING-DELETED-OR-REPLACED&quot;;
var CAN_SAFELY_UPDATE_EXISTING_STACK = &quot;CAN-SAFELY-UPDATE-EXISTING-STACK&quot;;
for (var i = 0; i &lt; changeSetChanges.Changes.length; i++) {
var change = changeSetChanges.Changes[i];
if (change.Type == &quot;Resource&quot;) {
if (change.ResourceChange.Action == &quot;Delete&quot;) {
return RESOURCES_BEING_DELETED_OR_REPLACED;
}
if (change.ResourceChange.Action == &quot;Modify&quot;) {
if (change.ResourceChange.Replacement == &quot;True&quot;) {
return RESOURCES_BEING_DELETED_OR_REPLACED;
}
}
}
}
return CAN_SAFELY_UPDATE_EXISTING_STACK;</code> 
<p>The algorithm returns different values to indicate whether the change set can be safely executed (<em>CAN_SAFELY_UPDATE_EXISTING_STACK</em>&nbsp;or&nbsp;<em>RESOURCES_BEING_DELETED_OR_REPLACED</em>). This value is used later by the state machine to decide whether to execute the change set and update the stack or interrupt the deployment.</p> 
<p>The output of the “Inspect Change Set” stage is shown here.</p> 
<code class="lang-json">{
&quot;environmentName&quot;: &quot;prod&quot;,
&quot;stackName&quot;: &quot;sample-lambda-app&quot;,
&quot;templatePath&quot;: &quot;infra/lambda-template.yaml&quot;,
&quot;revisionS3Bucket&quot;: &quot;codepipeline-us-east-1-418586629775&quot;,
&quot;revisionS3Key&quot;: &quot;StepFunctionsDrivenD/CodeCommit/sjcmExZ&quot;,
&quot;doesStackExist&quot;: true,
&quot;changeSetName&quot;: &quot;prod-sample-lambda-app-change-set-545&quot;,
&quot;changeSetCreationStatus&quot;: &quot;complete&quot;,
&quot;changeSetAction&quot;: &quot;CAN-SAFELY-UPDATE-EXISTING-STACK&quot;
}</code> 
<p>At this point, these parameters have been added to the state machine’s original input:</p> 
<li><em>changeSetName</em>,&nbsp;which is added by the “Create Change Set” state.</li> 
<li><em>changeSetCreationStatus</em>,&nbsp;which is added by the “Get Change Set Creation Status” state.</li> 
<li><em>changeSetAction</em>,&nbsp;which is added by the “Inspect Change Set Changes” state.</li> 
<p>The “Safe to Update Infra?” step is a&nbsp;choice&nbsp;state (its JSON spec follows) that simply checks the value of the&nbsp;changeSetAction&nbsp;parameter. If the value is equal to&nbsp;“<em>CAN-SAFELY-UPDATE-EXISTING-STACK</em>“, meaning that no resources will be deleted or replaced, the step will execute the change set by proceeding to the “Execute Change Set” state. The deployment is successful (the state machine completes its execution successfully).</p> 
<code class="lang-json">&quot;Safe to Update Infra?&quot;: {
&quot;Type&quot;: &quot;Choice&quot;,
&quot;Choices&quot;: [
{
&quot;Variable&quot;: &quot;$.taskParams.changeSetAction&quot;,
&quot;StringEquals&quot;: &quot;CAN-SAFELY-UPDATE-EXISTING-STACK&quot;,
&quot;Next&quot;: &quot;Execute Change Set&quot;
}
],
&quot;Default&quot;: &quot;Deployment Failed&quot;
}</code> 
<h3>Path 3: Reject Stack Update and Fail Deployment</h3> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/12/deployment_failed_statemachine-1.png" /></p> 
<p>If the <em>changeSetAction</em> parameter is different from “<em>CAN-SAFELY-UPDATE-EXISTING-STACK</em>“, the state machine will interrupt the deployment by deleting the change set and proceeding to the “Deployment Fail” step, which is a built-in <em>Fail</em> state. (Its JSON spec follows.) This state causes the state machine to stop in a failed state and serves to indicate to the Lambda function that the pipeline deployment should be interrupted in a fail state as well.</p> 
<code class="lang-json"> &quot;Deployment Failed&quot;: {
&quot;Type&quot;: &quot;Fail&quot;,
&quot;Cause&quot;: &quot;Deployment Failed&quot;,
&quot;Error&quot;: &quot;Deployment Failed&quot;
}</code> 
<p>In all three scenarios, there’s a state machine’s visual representation available in the AWS Step Functions console that makes it very easy for developers to identify what tasks have been executed or why a deployment has failed. Developers can also inspect the inputs and outputs of each state and look at the state machine Lambda function’s logs for details. Meanwhile, the corresponding CodePipeline action remains very simple and intuitive for developers who only need to know whether the deployment was successful or failed.</p> 
<b>The State Machine Trigger Lambda Function</b> 
<p>The <em>Trigger Lambda function</em> is invoked directly by the <em>Deploy</em> action in CodePipeline. The CodePipeline action must pass a JSON structure to the trigger function through the UserParameters attribute, as follows:</p> 
<code class="lang-json">{
&quot;s3Bucket&quot;: &quot;codepipeline-StepFunctions-sample&quot;,
&quot;stateMachineFile&quot;: &quot;state_machine_input.json&quot;
}</code> 
<p>The&nbsp;<em>s3Bucket</em>&nbsp;parameter specifies the S3 bucket location for the state machine input parameters file. The&nbsp;<em>stateMachineFile</em>&nbsp;parameter specifies the file holding the input parameters. By being able to specify different input parameters to the state machine, we make the Trigger Lambda function and the state machine reusable across environments. For example, the same state machine could be called from a&nbsp;<em>test</em>&nbsp;and&nbsp;<em>prod</em>&nbsp;pipeline action by specifying a different S3 bucket or state machine input file for each environment.</p> 
<p>The Trigger Lambda function performs two main tasks: triggering the state machine and checking the execution state of the state machine. Its core logic is shown here:</p> 
<code class="lang-javascript">exports.index = function (event, context, callback) {
try {
console.log(&quot;Event: &quot; + JSON.stringify(event));
console.log(&quot;Context: &quot; + JSON.stringify(context));
console.log(&quot;Environment Variables: &quot; + JSON.stringify(process.env));
if (Util.isContinuingPipelineTask(event)) {
monitorStateMachineExecution(event, context, callback);
}
else {
triggerStateMachine(event, context, callback);
}
}
catch (err) {
failure(Util.jobId(event), callback, context.invokeid, err.message);
}
}</code> 
<p><em>Util.isContinuingPipelineTask(event)</em> is a utility function that checks if the Trigger Lambda function is being called for the first time (that is, no continuation token is passed by CodePipeline) or as a continuation of a previous call. In its first execution, the Lambda function will trigger the state machine and send a continuation token to CodePipeline that contains the state machine execution ARN. The state machine ARN is exposed to the Lambda function through a Lambda environment variable called <em>stateMachineArn</em>. Here is the code that triggers the state machine:</p> 
<code class="lang-javascript">function triggerStateMachine(event, context, callback) {
var stateMachineArn = process.env.stateMachineArn;
var s3Bucket = Util.actionUserParameter(event, &quot;s3Bucket&quot;);
var stateMachineFile = Util.actionUserParameter(event, &quot;stateMachineFile&quot;);
getStateMachineInputData(s3Bucket, stateMachineFile)
.then(function (data) {
var initialParameters = data.Body.toString();
var stateMachineInputJSON = createStateMachineInitialInput(initialParameters, event);
console.log(&quot;State machine input JSON: &quot; + JSON.stringify(stateMachineInputJSON));
return stateMachineInputJSON;
})
.then(function (stateMachineInputJSON) {
return triggerStateMachineExecution(stateMachineArn, stateMachineInputJSON);
})
.then(function (triggerStateMachineOutput) {
var continuationToken = { &quot;stateMachineExecutionArn&quot;: triggerStateMachineOutput.executionArn };
var message = &quot;State machine has been triggered: &quot; + JSON.stringify(triggerStateMachineOutput) + &quot;, continuationToken: &quot; + JSON.stringify(continuationToken);
return continueExecution(Util.jobId(event), continuationToken, callback, message);
})
.catch(function (err) {
console.log(&quot;Error triggering state machine: &quot; + stateMachineArn + &quot;, Error: &quot; + err.message);
failure(Util.jobId(event), callback, context.invokeid, err.message);
})
}</code> 
<p>The Trigger Lambda function fetches the state machine input parameters from an S3 file, triggers the execution of the state machine using the input parameters and the&nbsp;<em>stateMachineArn</em>&nbsp;environment variable, and signals to&nbsp;CodePipeline&nbsp;that the execution should continue later by passing a continuation token that contains the state machine execution ARN. In case any of these operations fail and an exception is thrown, the Trigger Lambda function will fail the pipeline immediately by signaling a pipeline failure through the&nbsp;<em>putJobFailureResult</em>&nbsp;CodePipeline&nbsp;API.</p> 
<p>If the Lambda function is continuing a previous execution, it will extract the state machine execution ARN from the continuation token and check the status of the state machine, as shown here.</p> 
<code class="lang-javascript">function monitorStateMachineExecution(event, context, callback) {
var stateMachineArn = process.env.stateMachineArn;
var continuationToken = JSON.parse(Util.continuationToken(event));
var stateMachineExecutionArn = continuationToken.stateMachineExecutionArn;
getStateMachineExecutionStatus(stateMachineExecutionArn)
.then(function (response) {
if (response.status === &quot;RUNNING&quot;) {
var message = &quot;Execution: &quot; + stateMachineExecutionArn + &quot; of state machine: &quot; + stateMachineArn + &quot; is still &quot; + response.status;
return continueExecution(Util.jobId(event), continuationToken, callback, message);
}
if (response.status === &quot;SUCCEEDED&quot;) {
var message = &quot;Execution: &quot; + stateMachineExecutionArn + &quot; of state machine: &quot; + stateMachineArn + &quot; has: &quot; + response.status;
return success(Util.jobId(event), callback, message);
}
// FAILED, TIMED_OUT, ABORTED
var message = &quot;Execution: &quot; + stateMachineExecutionArn + &quot; of state machine: &quot; + stateMachineArn + &quot; has: &quot; + response.status;
return failure(Util.jobId(event), callback, context.invokeid, message);
})
.catch(function (err) {
var message = &quot;Error monitoring execution: &quot; + stateMachineExecutionArn + &quot; of state machine: &quot; + stateMachineArn + &quot;, Error: &quot; + err.message;
failure(Util.jobId(event), callback, context.invokeid, message);
});
}</code> 
<p>If the state machine is in the&nbsp;<em>RUNNING</em>&nbsp;state, the Lambda function will send the continuation token back to the&nbsp;CodePipeline&nbsp;action. This will cause CodePipeline to call the Lambda function again a few seconds later. If the state machine has&nbsp;<em>SUCCEEDED</em>, then the Lambda function will notify the CodePipeline action that the action has succeeded. In any other case (<em>FAILURE,&nbsp;TIMED-OUT, or&nbsp;ABORT</em>), the Lambda function will fail the pipeline action.</p> 
<p>This behavior is especially useful for developers who are building and debugging a new state machine because a bug in the state machine can potentially leave the pipeline action hanging for long periods of time until it times out. The Trigger Lambda function prevents this.</p> 
<p>Also, by having the Trigger Lambda function as a means to decouple the pipeline and state machine, we make the state machine more reusable. It can be triggered from anywhere, not just from a&nbsp;CodePipeline&nbsp;action.</p> 
<b>The Pipeline in CodePipeline</b> 
<p>Our sample pipeline contains two simple stages: the <em>Source</em> stage represented by a CodeCommit Git repository and the <em>Prod</em> stage, which contains the Deploy action that invokes the Trigger Lambda function. When the state machine decides that the change set created must be rejected (because it replaces or deletes some the existing production resources), it fails the pipeline without performing any updates to the existing infrastructure. (See the failed Deploy action in red.) Otherwise, the pipeline action succeeds, indicating that the existing provisioned infrastructure was either created (first run) or updated without impacting any resources. (See the green Deploy stage in the pipeline on the left.)</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/12/codepipeline_pipeline-1.png" /></p> 
<p>The JSON spec for the pipeline’s Prod stage is shown here. We use the <em>UserParameters</em> attribute to pass the S3 bucket and state machine input file to the Lambda function. These parameters are action-specific, which means that we can reuse the state machine in another pipeline action.</p> 
<code class="lang-json">{
&quot;name&quot;: &quot;Prod&quot;,
&quot;actions&quot;: [
{
&quot;inputArtifacts&quot;: [
{
&quot;name&quot;: &quot;CodeCommitOutput&quot;
}
],
&quot;name&quot;: &quot;Deploy&quot;,
&quot;actionTypeId&quot;: {
&quot;category&quot;: &quot;Invoke&quot;,
&quot;owner&quot;: &quot;AWS&quot;,
&quot;version&quot;: &quot;1&quot;,
&quot;provider&quot;: &quot;Lambda&quot;
},
&quot;outputArtifacts&quot;: [],
&quot;configuration&quot;: {
&quot;FunctionName&quot;: &quot;StateMachineTriggerLambda&quot;,
&quot;UserParameters&quot;: &quot;{\&quot;s3Bucket\&quot;: \&quot;codepipeline-StepFunctions-sample\&quot;, \&quot;stateMachineFile\&quot;: \&quot;state_machine_input.json\&quot;}&quot;
},
&quot;runOrder&quot;: 1
}
]
}</code> 
<b>Conclusion</b> 
<p>In this blog post, we discussed how state machines in AWS Step Functions can be used to handle&nbsp;workflow-driven&nbsp;actions. We showed how a Lambda function can be used to fully decouple the pipeline and the state machine and manage their interaction. The use of a state machine greatly simplified the associated CodePipeline action, allowing us to build a much simpler and cleaner pipeline while drilling down into the state machine’s execution for troubleshooting or debugging.</p> 
<p>Here are two exercises you can complete by using the&nbsp;source code.</p> 
<p><strong>Exercise #1</strong>: Do not fail the state machine and pipeline action after inspecting a change set that deletes or replaces resources. Instead, create a stack with a different name (think of blue/green deployments). You can do this by creating a state machine transition between the “Safe to Update Infra?” and “Create Stack” stages and passing a new stack name as input to the “Create Stack” stage.</p> 
<p><strong>Exercise #2</strong>: Add wait logic to the state machine to wait until the change set completes its execution before allowing the state machine to proceed to the “Deployment Succeeded” stage. Use the stack creation case as an example. You’ll have to create a Lambda function (similar to the Lambda function that checks the creation status of a stack) to get the creation status of the change set.</p> 
<p>Have fun and share your thoughts!</p> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">AWS Developer Tools Expands Integration to Include GitHub</b> 
<p style="margin: 0; padding:0;">=======================<p>
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Balaji Iyer</span></span> | on 
<time property="datePublished" datetime="2017-10-11T11:37:09+00:00">11 OCT 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/devops/category/developer-tools/aws-codebuild/" title="View all posts in AWS CodeBuild*"><span property="articleSection">AWS CodeBuild*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/developer-tools/aws-codedeploy/" title="View all posts in AWS CodeDeploy*"><span property="articleSection">AWS CodeDeploy*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/developer-tools/aws-codepipeline/" title="View all posts in AWS CodePipeline*"><span property="articleSection">AWS CodePipeline*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/developer-tools/aws-codestar/" title="View all posts in AWS CodeStar*"><span property="articleSection">AWS CodeStar*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/developer-tools/" title="View all posts in Developer Tools*"><span property="articleSection">Developer Tools*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/devops/" title="View all posts in DevOps*"><span property="articleSection">DevOps*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/how-to/" title="View all posts in How-To*"><span property="articleSection">How-To*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/management-tools/" title="View all posts in Management Tools*"><span property="articleSection">Management Tools*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/devops/aws-developer-tools-expands-integration-to-include-github/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p>AWS Developer Tools is a set of services that include <a href="https://aws.amazon.com/codecommit/">AWS CodeCommit</a>, <a href="https://aws.amazon.com/codepipeline/">AWS CodePipeline</a>, <a href="https://aws.amazon.com/codebuild/">AWS CodeBuild</a>, and <a href="https://aws.amazon.com/codedeploy/">AWS CodeDeploy</a>. Together, these services help you securely store and maintain version control of your application’s source code and automatically build, test, and deploy your application to AWS or your on-premises environment. These services are designed to enable developers and IT professionals to rapidly and safely deliver software.</p> 
<p>As part of our continued commitment to extend the AWS Developer Tools ecosystem to third-party tools and services, we’re pleased to announce <a href="https://aws.amazon.com/codestar/">AWS CodeStar</a> and <a href="https://aws.amazon.com/codebuild/">AWS CodeBuild</a> now integrate with GitHub. This will make it easier for GitHub users to set up a continuous integration and continuous delivery toolchain as part of their release process using AWS Developer Tools.</p> 
<p>In this post, I will walk through the following:</p> 
<li><a href="https://aws.amazon.com/about-aws/whats-new/2017/10/announcing-aws-codestar-integration-with-github/">Integrating GitHub as a source repository for your AWS CodeStar projects</a></li> 
<li><a href="https://aws.amazon.com/about-aws/whats-new/2017/09/aws-codebuild-now-supports-building-github-pull-requests/">Enabling GitHub pull requests to automatically trigger a build in AWS CodeBuild</a></li> 
<p><u><strong>Prerequisites</strong>:</u></p> 
<p>You’ll need an AWS account, a <a href="http://github.com/join">GitHub account</a>, an&nbsp;<a href="https://aws.amazon.com/ec2/">Amazon EC2</a>&nbsp;key pair, and administrator-level permissions for AWS&nbsp;<a href="https://aws.amazon.com/iam/">Identity and Access Management (IAM)</a>, <a href="https://aws.amazon.com/codestar/">AWS CodeStar</a>, <a href="https://aws.amazon.com/codebuild/">AWS CodeBuild</a>, <a href="https://aws.amazon.com/codepipeline/">AWS CodePipeline</a>, <a href="https://aws.amazon.com/ec2/">Amazon EC2</a>, <a href="https://aws.amazon.com/s3/">Amazon S3</a>.</p> 
<b>Integrating GitHub with AWS CodeStar</b> 
<p>AWS CodeStar enables you to quickly develop, build, and deploy applications on AWS. Its unified user interface helps you easily manage your software development activities in one place. With AWS CodeStar, you can set up your entire&nbsp;<a href="https://aws.amazon.com/devops/continuous-delivery/">continuous delivery</a>&nbsp;toolchain in minutes, so you can start releasing code faster.</p> 
<p>When AWS CodeStar <a href="https://aws.amazon.com/blogs/aws/new-aws-codestar/">launched</a> in April of this year, it used AWS CodeCommit as the hosted source repository. You can now choose between AWS CodeCommit or GitHub as the source control service for your CodeStar projects. In addition, your CodeStar project dashboard lets you centrally track GitHub activities, including commits, issues, and pull requests. This makes it easy to manage project activity across the components of your CI/CD toolchain. Adding the GitHub dashboard view will simplify development of your AWS applications.</p> 
<p>In this section, I will show you how to use GitHub as the source provider for your CodeStar projects. I’ll also show you how to work with recent commits, issues, and pull requests in the CodeStar dashboard.</p> 
<p>Sign in to the AWS Management Console and from the <strong>Services</strong> menu, choose <strong>CodeStar</strong>. In the CodeStar console, choose <strong>Create a new project</strong>. You should see the <strong>Choose a project template</strong> page.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/10/Picture1.png" /></p> 
<p>Choose an option by programming language, application category, or AWS service. I am going to choose the Ruby on Rails web application that will be running on Amazon EC2.</p> 
<p>On the <strong>Project details </strong>page, you’ll now see the GitHub option. Type a name for your project, and then choose <strong>Connect to GitHub</strong>.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/10/Picture2.png" /></p> 
<p>You’ll see a message requesting authorization to connect to your GitHub repository. When prompted, choose <strong>Authorize</strong>, and then type your GitHub account password.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/10/Picture3-2.png" /></p> 
<p>This connects your GitHub identity to AWS CodeStar through OAuth. You can always review your settings by navigating to your <a href="https://github.com/settings/applications">GitHub application settings</a>.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/11/Screen-Shot-2017-10-11-at-1.30.54-PM.png" /></p> 
<p>You’ll see <strong>AWS CodeStar is now connected to GitHub</strong>:</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/10/Picture5.png" /></p> 
<p>You can choose a public or private repository. GitHub offers free accounts for users and organizations working on public and open source projects and paid accounts that offer unlimited private repositories and optional user management and security features.</p> 
<p>In this example, I am going to choose the public repository option. Edit the repository description, if you like, and then choose <strong>Next</strong>.</p> 
<p>Review your CodeStar project details, and then choose <strong>Create Project</strong>. On <strong>Choose an Amazon EC2 Key Pair</strong>, choose <strong>Create Project</strong>.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/10/Picture6-1.png" /></p> 
<p>On the <strong>Review project details</strong> page, you’ll see <strong>Edit Amazon EC2 configuration.</strong> Choose this link to configure instance type, VPC, and subnet options. AWS CodeStar requires a <a href="http://docs.aws.amazon.com/codestar/latest/userguide/access-permissions.html#access-permissions-service-role">service role</a> to create and manage AWS resources and IAM permissions. This role will be created for you when you select the <strong>AWS CodeStar would like permission to administer AWS resources on your behalf </strong>check box.</p> 
<p>Choose <strong>Create Project</strong>. It might take a few minutes to create your project and resources.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/10/Picture7.png" /></p> 
<p>When you create a CodeStar project, you’re added to the project team as an owner. If this is the first time you’ve used AWS CodeStar, you’ll be asked to provide the following information, which will be shown to others:</p> 
<li>Your display name.</li> 
<li>Your email address.</li> 
<p>This information is used in your AWS CodeStar user profile. User profiles are not project-specific, but they are limited to a single AWS region. If you are a team member in projects in more than one region, you’ll have to create a user profile in each region.</p> 
<img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/11/2017-10-04_08-20-52-1.png" /> 
<p class="wp-caption-text">User settings</p> 
<p>Choose <strong>Next</strong>. AWS CodeStar will create a GitHub repository with your configuration settings (for example, <a href="https://github.com/biyer/ruby-on-rails">https://github.com/biyer/ruby-on-rails</a>-service).</p> 
<p>When you integrate your integrated development environment (IDE) with AWS CodeStar, you can continue to write and develop code in your preferred environment. The changes you make will be included in the AWS CodeStar project each time you commit and push your code.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/11/GitHub-Blog2.png" /></p> 
<p>After setting up your IDE, choose <strong>Next</strong> to go to the CodeStar dashboard. Take a few minutes to familiarize yourself with the dashboard. You can easily track progress across your entire software development process, from your backlog of work items to recent code deployments.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/10/Picture10.png" /></p> 
<p>After the application deployment is complete, choose the endpoint that will display the application.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/10/Picture11-1.png" /></p> 
<p>This is what you’ll see when you open the application endpoint:</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/10/Picture12.png" /></p> 
<p>The<strong> Commit history </strong>section of the dashboard lists the commits made to the Git repository. If you choose the commit ID or the <strong>Open in GitHub </strong>option, you can use a hotlink to your GitHub repository.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/10/Picture13.png" /></p> 
<p>Your AWS CodeStar project dashboard is where you and your team view the status of your project resources, including the latest commits to your project, the state of your continuous delivery pipeline, and the performance of your instances. This information is displayed on tiles that are dedicated to a particular resource. To see more information about any of these resources, choose the details link on the tile. The console for that AWS service will open on the details page for that resource.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/10/Picture14.png" /></p> 
<p>You can also filter issues based on their status and the assigned user.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/10/Picture15-1.png" /></p> 
<b id="codebuild">AWS CodeBuild Now Supports Building GitHub Pull Requests</b> 
<p>CodeBuild is a fully managed build service that compiles source code, runs tests, and produces software packages that are ready to deploy. With CodeBuild, you don’t need to provision, manage, and scale your own build servers. CodeBuild scales continuously and processes multiple builds concurrently, so your builds are not left waiting in a queue. You can use prepackaged build environments to get started quickly or you can create custom build environments that use your own build tools.</p> 
<p>We recently <a href="https://aws.amazon.com/about-aws/whats-new/2017/09/aws-codebuild-now-supports-building-github-pull-requests/">announced</a> support for GitHub pull requests in AWS CodeBuild. This functionality makes it easier to collaborate across your team while editing and building your application code with CodeBuild. You can use the AWS CodeBuild or AWS CodePipeline consoles to run AWS CodeBuild. You can also automate the running of AWS CodeBuild by using the AWS Command Line Interface (AWS CLI), the AWS SDKs, or the <a href="https://aws.amazon.com/blogs/devops/simplify-your-jenkins-builds-with-aws-codebuild/">AWS CodeBuild Plugin for Jenkins</a>.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/10/Picture16.png" /></p> 
<p>In this section, I will show you how to trigger a build in AWS CodeBuild with a pull request from GitHub through webhooks.</p> 
<p>Open the AWS CodeBuild console at&nbsp;<a href="https://console.aws.amazon.com/codebuild/">https://console.aws.amazon.com/codebuild/</a>. Choose&nbsp;<strong>Create project</strong>. If you already have a CodeBuild project, you can choose <strong>Edit project</strong>, and then follow along. CodeBuild can connect to AWS CodeCommit, S3, BitBucket, and GitHub to pull source code for builds. For <strong>Source provider</strong>, choose <strong>GitHub</strong>, and then choose <strong>Connect to GitHub</strong>.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/10/Picture17.png" /></p> 
<p>After you’ve successfully linked GitHub and your CodeBuild project, you can choose a repository in your GitHub account. CodeBuild also supports connections to any public repository. You can review your settings by navigating to your <a href="https://github.com/settings/applications">GitHub application settings</a>.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/10/Picture18.png" /></p> 
<p>On <strong>Source: What to Build</strong>, for&nbsp;<strong>Webhook</strong>, select&nbsp;the <strong>Rebuild every time a code change is pushed to this repository </strong>check box.</p> 
<p><strong>Note</strong>: You can select this option only if, under<strong>&nbsp;Repository</strong>, you chose&nbsp;<strong>Use a repository in my account</strong>.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/10/Picture19.png" /></p> 
<p>In&nbsp;<strong>Environment: How to build</strong>, for <strong>Environment image</strong>, select <strong>Use an image managed by AWS CodeBuild</strong>. For <strong>Operating system</strong>, choose <strong>Ubuntu</strong>. For <strong>Runtime</strong>, choose <strong>Base</strong>. For <strong>Version</strong>, choose the latest available version. For <strong>Build specification</strong>, you can provide a collection of build commands and related settings, in YAML format (buildspec.yml) or you can override the build spec by inserting build commands directly in the console. AWS CodeBuild uses these commands to run a build. In this example, the output is the string “hello.”</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/10/Picture20-1.png" /></p> 
<p><strong>On Artifacts: Where to put the artifacts from this build project</strong>, for <strong>Type</strong>, choose <strong>No artifacts</strong>. (This is also the type to choose if you are just running tests or pushing a Docker image to Amazon ECR.) You also need an AWS CodeBuild service role so that AWS CodeBuild can interact with dependent AWS services on your behalf. Unless you already have a role, choose <strong>Create a role</strong>, and for <strong>Role name</strong>, type a name for your role.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/10/Picture21.png" /></p> 
<p>In this example, leave the advanced settings at their defaults.</p> 
<p>If you expand <strong>Show advanced settings</strong>, you’ll see options for customizing your build, including:</p> 
<li>A build timeout.</li> 
<li>A KMS key to encrypt all the artifacts that the builds for this project will use.</li> 
<li>Options for building a Docker image.</li> 
<li>Elevated permissions during your build action (for example, accessing Docker inside your build container to build a Dockerfile).</li> 
<li>Resource options for the build compute type.</li> 
<li>Environment variables (built-in or custom). For more information, see <a href="http://jburdon.aka.corp.amazon.com/AWSCodeFactoryDocs/src/AWSCodeFactoryDocs/build/server-root/codebuild/latest/userguide/create-project.html">Create a Build Project</a> in the AWS CodeBuild User Guide.</li> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/10/Picture22.png" /></p> 
<p>You can use the AWS CodeBuild console to create a parameter in Amazon EC2 Systems Manager. Choose&nbsp;<strong>Create a parameter</strong>, and then follow the instructions in the dialog box. (In that dialog box, for&nbsp;<strong>KMS key</strong>, you can optionally specify the ARN of an AWS KMS key in your account. Amazon EC2 Systems Manager uses this key to encrypt the parameter’s value during storage and decrypt during retrieval.)</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/10/Picture23-1.png" /></p> 
<p>Choose&nbsp;<strong>Continue</strong>. On the&nbsp;<strong>Review</strong>&nbsp;page, either choose&nbsp;<strong>Save and build</strong>&nbsp;or choose&nbsp;<strong>Save</strong>&nbsp;to run the build later.</p> 
<p>Choose <strong>Start build</strong>. When the build is complete, the <strong>Build logs </strong>section should display detailed information about the build.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/10/Picture24.png" /></p> 
<p>To demonstrate a pull request, I will fork the repository as a different GitHub user, make commits to the forked repo, check in the changes to a newly created branch, and then open a pull request.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/10/Picture25.png" /></p> 
<p>As soon as the pull request is submitted, you’ll see CodeBuild start executing the build.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/10/Picture26.png" /></p> 
<p>GitHub sends an HTTP POST payload to the webhook’s configured URL (highlighted here), which CodeBuild uses to download the latest source code and execute the build phases.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/10/Picture27.png" /></p> 
<p>If you expand the <strong>Show all checks</strong> option for the GitHub pull request, you’ll see that CodeBuild has completed the build, all checks have passed, and a deep link is provided in <strong>Details</strong>, which opens the build history in the CodeBuild console.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/10/Picture28.png" /></p> 
<b>Summary:</b> 
<p>In this post, I showed you how to use GitHub as the source provider for your CodeStar projects and how to work with recent commits, issues, and pull requests in the CodeStar dashboard. I also showed you how you can use GitHub pull requests to automatically trigger a build in AWS CodeBuild — specifically, how this functionality makes it easier to collaborate across your team while editing and building your application code with CodeBuild.</p> 
<hr /> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">Using AWS CodePipeline, AWS CodeBuild, and AWS Lambda for Serverless Automated UI Testing</b> 
<p style="margin: 0; padding:0;">=======================<p>
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Prakash Palanisamy</span></span> | on 
<time property="datePublished" datetime="2017-09-18T21:23:54+00:00">18 SEP 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/devops/category/developer-tools/aws-codebuild/" title="View all posts in AWS CodeBuild*"><span property="articleSection">AWS CodeBuild*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/developer-tools/aws-codecommit/" title="View all posts in AWS CodeCommit*"><span property="articleSection">AWS CodeCommit*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/developer-tools/aws-codepipeline/" title="View all posts in AWS CodePipeline*"><span property="articleSection">AWS CodePipeline*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/compute/aws-lambda/" title="View all posts in AWS Lambda*"><span property="articleSection">AWS Lambda*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/how-to/" title="View all posts in How-To*"><span property="articleSection">How-To*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/devops/using-aws-codepipeline-aws-codebuild-and-aws-lambda-for-serverless-automated-ui-testing/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p>Testing the user interface of a web application is an important part of the development lifecycle. In this post, I’ll explain how to automate UI testing using serverless technologies, including <a href="https://aws.amazon.com/codepipeline/" target="_blank" rel="noopener noreferrer">AWS CodePipeline</a>, <a href="https://aws.amazon.com/codebuild/" target="_blank" rel="noopener noreferrer">AWS CodeBuild</a>, and <a href="https://aws.amazon.com/lambda/" target="_blank" rel="noopener noreferrer">AWS Lambda</a>.</p> 
<p>I built a website for UI testing that is hosted in S3. I used Selenium to perform cross-browser UI testing on Chrome, Firefox, and PhantomJS, a headless WebKit browser with <a href="https://github.com/detro/ghostdriver" target="_blank" rel="noopener noreferrer">Ghost Driver</a>, an implementation of the WebDriver Wire Protocol. I used Python to create test cases for ChromeDriver, FirefoxDriver, or PhatomJSDriver based the browser against which the test is being executed.</p> 
<p>Resources referred to in this post, including the AWS CloudFormation template, test and status websites hosted in S3, AWS CodeBuild build specification files, AWS Lambda function, and the Python script that performs the test are available in the <a href="https://github.com/awslabs/serverless-automated-ui-testing" target="_blank" rel="noopener noreferrer">serverless-automated-ui-testing</a> GitHub repository.</p> 
<p><span id="more-1588"></span></p> 
<p><strong>S3 Hosted Test Website:</strong></p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/09/13/Test_website.png" /></p> 
<p>AWS CodeBuild supports custom containers so we can use the Selenium/standalone-Firefox and Selenium/standalone-Chrome containers, which include prebuild Firefox and Chrome browsers, respectively. <a href="https://www.x.org/releases/X11R7.7/doc/man/man1/Xvfb.1.xhtml" target="_blank" rel="noopener noreferrer">Xvfb</a> performs the graphical operation in virtual memory without any display hardware. It will be installed in the CodeBuild containers during the install phase.</p> 
<p><strong>Build Spec for Chrome and Firefox</strong></p> 
<p>The build specification for Chrome and Firefox testing includes multiple phases:</p> 
<li>The environment variables section contains a set of default variables that are overridden while creating the build project or triggering the build.</li> 
<li>As part of install phase, required packages like Xvfb and Selenium are installed using yum.</li> 
<li>During the pre_build phase, the test bed is prepared for test execution.</li> 
<li>During the build phase, the appropriate DISPLAY is set and the tests are executed.</li> 
<code class="lang-yaml">version: 0.2
env:
&nbsp; variables:
&nbsp; &nbsp; BROWSER: &quot;chrome&quot;
&nbsp; &nbsp; WebURL: &quot;https://sampletestweb.s3-eu-west-1.amazonaws.com/website/index.html&quot;
&nbsp; &nbsp; ArtifactBucket: &quot;codebuild-demo-artifact-repository&quot;
&nbsp; &nbsp; MODULES: &quot;mod1&quot;
&nbsp; &nbsp; ModuleTable: &quot;test-modules&quot;
&nbsp; &nbsp; StatusTable: &quot;blog-test-status&quot;
phases:
&nbsp; install:
&nbsp; &nbsp; commands:
&nbsp; &nbsp; &nbsp; - apt-get update
&nbsp; &nbsp; &nbsp; - apt-get -y upgrade
&nbsp; &nbsp; &nbsp; - apt-get install xvfb python python-pip build-essential -y
&nbsp; &nbsp; &nbsp; - pip install --upgrade pip
&nbsp; &nbsp; &nbsp; - pip install selenium
&nbsp; &nbsp; &nbsp; - pip install awscli
&nbsp; &nbsp; &nbsp; - pip install requests
&nbsp; &nbsp; &nbsp; - pip install boto3
&nbsp; &nbsp; &nbsp; - cp xvfb.init /etc/init.d/xvfb
&nbsp; &nbsp; &nbsp; - chmod +x /etc/init.d/xvfb
&nbsp; &nbsp; &nbsp; - update-rc.d xvfb defaults
&nbsp; &nbsp; &nbsp; - service xvfb start
&nbsp; &nbsp; &nbsp; - export PATH=&quot;$PATH:`pwd`/webdrivers&quot;
&nbsp; pre_build:
&nbsp; &nbsp; commands:
&nbsp; &nbsp; &nbsp; - python prepare_test.py
&nbsp; build:
&nbsp; &nbsp; commands:
&nbsp; &nbsp; &nbsp; - export DISPLAY=:5
&nbsp; &nbsp; &nbsp; - cd tests
&nbsp; &nbsp; &nbsp; - echo &quot;Executing simple test...&quot;
&nbsp; &nbsp; &nbsp; - python testsuite.py</code> 
<p>Because Ghost Driver runs headless, it can be executed on AWS Lambda. In keeping with a fire-and-forget model, I used CodeBuild to create the PhantomJS Lambda function and trigger the test invocations on Lambda in parallel. This is powerful because many tests can be executed in parallel on Lambda.</p> 
<p><strong>Build Spec for PhantomJS</strong></p> 
<p>The build specification for PhantomJS testing also includes multiple phases. It is a little different from the preceding example because we are using AWS Lambda for the test execution.</p> 
<li>The environment variables section contains a set of default variables that are overridden while creating the build project or triggering the build.</li> 
<li>As part of install phase, the required packages like Selenium and the AWS CLI are installed using yum.</li> 
<li>During the pre_build phase, the test bed is prepared for test execution.</li> 
<li>During the build phase, a zip file that will be used to create the PhantomJS Lambda function is created and tests are executed on the Lambda function.</li> 
<code class="lang-yaml">version: 0.2
env:
&nbsp; variables:
&nbsp; &nbsp; BROWSER: &quot;phantomjs&quot;
&nbsp; &nbsp; WebURL: &quot;https://sampletestweb.s3-eu-west-1.amazonaws.com/website/index.html&quot;
&nbsp; &nbsp; ArtifactBucket: &quot;codebuild-demo-artifact-repository&quot;
&nbsp; &nbsp; MODULES: &quot;mod1&quot;
&nbsp; &nbsp; ModuleTable: &quot;test-modules&quot;
&nbsp; &nbsp; StatusTable: &quot;blog-test-status&quot;
&nbsp; &nbsp; LambdaRole: &quot;arn:aws:iam::account-id:role/role-name&quot;
phases:
&nbsp; install:
&nbsp; &nbsp; commands:
&nbsp; &nbsp; &nbsp; - apt-get update
&nbsp; &nbsp; &nbsp; - apt-get -y upgrade
&nbsp; &nbsp; &nbsp; - apt-get install python python-pip build-essential -y
&nbsp; &nbsp; &nbsp; - apt-get install zip unzip -y
&nbsp; &nbsp; &nbsp; - pip install --upgrade pip
&nbsp; &nbsp; &nbsp; - pip install selenium
&nbsp; &nbsp; &nbsp; - pip install awscli
&nbsp; &nbsp; &nbsp; - pip install requests
&nbsp; &nbsp; &nbsp; - pip install boto3
&nbsp; pre_build:
&nbsp; &nbsp; commands:
&nbsp; &nbsp; &nbsp; - python prepare_test.py
&nbsp; build:
&nbsp; &nbsp; commands:
&nbsp; &nbsp; &nbsp; - cd lambda_function
&nbsp; &nbsp; &nbsp; - echo &quot;Packaging Lambda Function...&quot;
&nbsp; &nbsp; &nbsp; - zip -r /tmp/lambda_function.zip ./*
&nbsp; &nbsp; &nbsp; - func_name=`echo $CODEBUILD_BUILD_ID | awk -F ':' '{print $1}'`-phantomjs
&nbsp; &nbsp; &nbsp; - echo &quot;Creating Lambda Function...&quot;
&nbsp; &nbsp; &nbsp; - chmod 777 phantomjs
&nbsp; &nbsp; &nbsp; - |
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; func_list=`aws lambda list-functions | grep FunctionName | awk -F':' '{print $2}' | tr -d ', &quot;'`
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; if echo &quot;$func_list&quot; | grep -qw $func_name
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; then
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; echo &quot;Lambda function already exists.&quot;
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; else
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; aws lambda create-function --function-name $func_name --runtime &quot;python2.7&quot; --role $LambdaRole --handler &quot;testsuite.lambda_handler&quot; --zip-file fileb:///tmp/lambda_function.zip --timeout 150 --memory-size 1024 --environment Variables=&quot;{WebURL=$WebURL, StatusTable=$StatusTable}&quot; --tags Name=$func_name
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; fi
&nbsp; &nbsp; &nbsp; - export PhantomJSFunction=$func_name
&nbsp; &nbsp; &nbsp; - cd ../tests/
&nbsp; &nbsp; &nbsp; - python testsuite.py
</code> 
<p>The list of test cases and the test modules that belong to each case are stored in an <a href="https://aws.amazon.com/dynamodb/" target="_blank" rel="noopener noreferrer">Amazon DynamoDB</a> table. Based on the list of modules passed as an argument to the CodeBuild project, CodeBuild gets the test cases from that table and executes them. The test execution status and results are stored in another Amazon DynamoDB table. It will read the test status from the status table in DynamoDB and display it.</p> 
<p>AWS CodeBuild and AWS Lambda perform the test execution as individual tasks. AWS CodePipeline plays an important role here by enabling continuous delivery and parallel execution of tests for optimized testing.</p> 
<p>Here’s how to do it:</p> 
<p>In AWS CodePipeline, create a pipeline with four stages:</p> 
<li>Source (AWS CodeCommit)</li> 
<li>UI testing (AWS Lambda and AWS CodeBuild)</li> 
<li>Approval (manual approval)</li> 
<li>Production (AWS Lambda)</li> 
<p>Pipeline stages, the actions in each stage, and transitions between stages are shown in the following diagram.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/09/13/Automated_UI_Testing.png" /></p> 
<p>This design implemented in AWS CodePipeline looks like this:</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/09/13/CodePipeline_Flow.png" /></p> 
<p>CodePipeline automatically detects a change in the source repository and triggers the execution of the pipeline.</p> 
<p>In the UITest stage, there are two parallel actions:</p> 
<li>DeployTestWebsite invokes a Lambda function to deploy the test website in S3 as an S3 website.</li> 
<li>DeployStatusPage invokes another Lambda function to deploy in parallel the status website in S3 as an S3 website.</li> 
<p>Next, there are three parallel actions that trigger the CodeBuild project:</p> 
<li>TestOnChrome launches a container to perform the Selenium tests on Chrome.</li> 
<li>TestOnFirefox launches another container to perform the Selenium tests on Firefox.</li> 
<li>TestOnPhantomJS creates a Lambda function and invokes individual Lambda functions per test case to execute the test cases in parallel.</li> 
<p>You can monitor the status of the test execution on the status website, as shown here:</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/09/13/Test_Status.png" /></p> 
<p>When the UI testing is completed successfully, the pipeline continues to an Approval stage in which a notification is sent to the configured SNS topic. The designated team member reviews the test status and approves or rejects the deployment. Upon approval, the pipeline continues to the Production stage, where it invokes a Lambda function and deploys the website to a production S3 bucket.</p> 
<p>I used a CloudFormation template to set up my continuous delivery pipeline. The <a href="https://github.com/awslabs/serverless-automated-ui-testing/blob/master/automated-ui-testing.yaml" target="_blank" rel="noopener noreferrer">automated-ui-testing.yaml</a> template, available from GitHub, sets up a full-featured pipeline.</p> 
<p>When I use the template to create my pipeline, I specify the following:</p> 
<li>AWS CodeCommit repository.</li> 
<li>SNS topic to send approval notification.</li> 
<li>S3 bucket name where the artifacts will be stored.</li> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/09/13/CFN_Params.png" /></p> 
<p>The stack name should follow the <a href="http://docs.aws.amazon.com/AmazonS3/latest/dev/BucketRestrictions.html" target="_blank" rel="noopener noreferrer">rules for S3 bucket naming</a> because it will be part of the S3 bucket name.</p> 
<p>When the stack is created successfully, the URLs for the test website and status website appear in the Outputs section, as shown here:</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/09/13/CFN_Output.png" /></p> 
<p><strong>Conclusion</strong></p> 
<p>In this post, I showed how you can use AWS CodePipeline, AWS CodeBuild, AWS Lambda, and a manual approval process to create a continuous delivery pipeline for serverless automated UI testing. Websites running on Amazon EC2 instances or AWS Elastic Beanstalk can also be tested using similar approach.</p> 
<hr /> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">Simplify Your Jenkins Builds with AWS CodeBuild</b> 
<p style="margin: 0; padding:0;">=======================<p>
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Paul Roberts</span></span> | on 
<time property="datePublished" datetime="2017-09-15T09:20:26+00:00">15 SEP 2017</time> | 
<a href="https://aws.amazon.com/blogs/devops/simplify-your-jenkins-builds-with-aws-codebuild/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p>Jeff Bezos<a href="http://archive.oreilly.com/network/2006/12/20/web-20-bezos.html"> famously said</a>, “There’s a lot of undifferentiated heavy lifting that stands between your idea and that success.” He went on to say, “…70% of your time, energy, and dollars go into the undifferentiated heavy lifting and only 30% of your energy, time, and dollars gets to go into the core kernel of your idea.”</p> 
<p>If you subscribe to this maxim, you should not be spending valuable time focusing on operational issues related to maintaining the Jenkins build infrastructure. Companies such as Riot Games have over <a href="https://youtu.be/YViFZBoKqjg?t=203">1.25 million builds per year</a>&nbsp;and have written several lengthy&nbsp;<a href="https://engineering.riotgames.com/news/jenkins-ephemeral-docker-tutorial">blog </a>posts about their experiences designing a complex, custom Docker-powered Jenkins build farm. Dealing with Jenkins slaves at scale is a job in itself and Riot has engineers focused on managing the build infrastructure.</p> 
<img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/09/15/codebuild-fit-1024x465.png" /> 
<p class="wp-caption-text">Typical Jenkins Build Farm</p> 
<p>As with all technology, the Jenkins build farm architectures have evolved. Today, instead of manually building your own container infrastructure, there are Jenkins Docker <a href="https://wiki.jenkins.io/display/JENKINS/CloudBees+Docker+Custom+Build+Environment+Plugin">plugins</a>&nbsp;available to help reduce the operational burden of maintaining these environments. There is also a community-contributed <a href="https://aws.amazon.com/ecs/">Amazon EC2 Container Service</a> (Amazon ECS) <a href="https://wiki.jenkins.io/display/JENKINS/Amazon+EC2+Container+Service+Plugin">plugin</a> that helps remove some of the overhead, but you still need to configure and manage the overall Amazon ECS environment.</p> 
<p>There are various ways to create and manage your Jenkins build farm, but there has to be a way that significantly reduces your operational overhead.</p> 
<h3>Introducing AWS CodeBuild</h3> 
<p><a href="https://aws.amazon.com/codebuild">AWS CodeBuild</a> is a fully managed build service that removes the undifferentiated heavy lifting of provisioning, managing, and scaling your own build servers. With CodeBuild, there is no software to install, patch, or update. CodeBuild scales up automatically to meet the needs of your development teams. In addition, CodeBuild is an on-demand service where you pay as you go. You are charged based only on the number of minutes it takes to complete your build.</p> 
<p>One AWS customer, <a href="https://aws.amazon.com/codebuild/customer-testimonials/">Recruiterbox</a>, helps companies hire simply and predictably through their software platform. Two years ago, they began feeling the operational pain of maintaining their own Jenkins build farms. They briefly considered moving to Amazon ECS, but chose an even easier path forward instead. Recuiterbox transitioned to using Jenkins with CodeBuild and are very happy with the results. You can read more about their journey <a href="https://inside.recruiterbox.com/constant-time-ci-with-codebuild-eb3b22a111a5">here</a>.</p> 
<h3>Solution Overview: Jenkins and CodeBuild</h3> 
<p>To remove the heavy lifting from managing your Jenkins build farm, AWS has developed a Jenkins AWS CodeBuild <a href="https://wiki.jenkins.io/display/JENKINS/AWS+CodeBuild+Plugin">plugin</a>. After the plugin has been enabled, a developer can configure a Jenkins project to pick up new commits from their chosen source code repository and automatically run the associated builds. After the build is successful, it will create an artifact that is stored inside an S3 bucket that you have configured. If an error is detected somewhere, CodeBuild will capture the output and send it to <a href="https://aws.amazon.com/cloudwatch/">Amazon CloudWatch</a> logs. In addition to storing the logs on CloudWatch, Jenkins also captures the error so you do not have to go hunting for log files for your build.</p> 
<img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/09/15/jenkins-codebuild-1024x522.png" /> 
<p class="wp-caption-text">AWS CodeBuild with Jenkins Plugin</p> 
<p>The following example uses AWS CodeCommit (Git) as the source control management (SCM) and Amazon S3 for build artifact storage. Logs are stored in CloudWatch. A development pipeline that uses Jenkins with CodeBuild plugin architecture looks something like this:</p> 
<img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/09/15/codebuild-diagram-1024x368.png" /> 
<p class="wp-caption-text">AWS CodeBuild Diagram</p> 
<h3>Initial Solution Setup</h3> 
<p>To keep this blog post succinct, I assume that you are using the following components on AWS already and have applied the appropriate IAM policies:</p> 
<p>&middot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; AWS CodeCommit repo.</p> 
<p>&middot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Amazon S3 bucket for CodeBuild artifacts.</p> 
<p>&middot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; SNS notification for text messaging of the Jenkins admin password.</p> 
<p>&middot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; IAM user’s key and secret.</p> 
<p>&middot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; A role that has a policy with <a href="https://s3.amazonaws.com/proberts-public/example_policy.json">these permissions</a>. Be sure to edit the ARNs with your region, account, and resource name. Use this role in the AWS CloudFormation template referred to later in this post.</p> 
<h3>Jenkins Installation with CodeBuild Plugin Enabled</h3> 
<p>To make the integration with Jenkins as frictionless as possible, I have created an AWS CloudFormation template here: <a href="https://s3.amazonaws.com/proberts-public/jenkins.yaml">https://s3.amazonaws.com/proberts-public/jenkins.yaml</a>. Download the template, sign in the AWS CloudFormation console, and then use the template to create a stack.</p> 
<img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/09/15/jenkins1.png" /> 
<p class="wp-caption-text">CloudFormation Inputs</p> 
<h3>Jenkins Project Configuration</h3> 
<p>After the stack is complete, log in to the Jenkins EC2 instance using the user name “admin” and the password sent to your mobile device. Now that you have logged in to Jenkins, you need to create your first project. Start with a Freestyle project and configure the parameters based on your CodeBuild and CodeCommit settings.</p> 
<img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/09/15/jenkins2.png" /> 
<p class="wp-caption-text">AWS CodeBuild Plugin Configuration in Jenkins</p> 
<img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/09/15/jenkins3.png" /> 
<p class="wp-caption-text">Additional Jenkins AWS CodeBuild Plugin Configuration</p> 
<p>After you have configured the Jenkins project appropriately you should be able to check your build status on the Jenkins polling log under your project settings:</p> 
<img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/09/15/jenkins4-1024x252.png" /> 
<p class="wp-caption-text">Jenkins Polling Log</p> 
<p>Now that Jenkins is polling CodeCommit, you can check the CodeBuild dashboard under your Jenkins project to confirm your build was successful:</p> 
<img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/09/15/jenkins5-1024x335.png" /> 
<p class="wp-caption-text">Jenkins AWS CodeBuild Dashboard</p> 
<h3>Wrapping Up</h3> 
<p>In a matter of minutes, you have been able to provision Jenkins with the AWS CodeBuild plugin. This will greatly simplify your build infrastructure management. Now kick back and relax while CodeBuild does all the heavy lifting!</p> 
<hr /> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">Ensuring Security of Your Code in a Cross-Region/Cross-Account Deployment Solution</b> 
<p style="margin: 0; padding:0;">=======================<p>
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">BK Chaurasiya</span></span> | on 
<time property="datePublished" datetime="2017-08-16T12:03:10+00:00">16 AUG 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/devops/category/how-to/" title="View all posts in How-To*"><span property="articleSection">How-To*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/devops/ensuring-security-of-your-code-in-a-cross-regioncross-account-deployment-solution/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p>There are multiple ways you can protect your data while it is in transit and at rest. You can protect your data in transit by using SSL or by using client-side encryption.&nbsp;<a href="https://aws.amazon.com/kms/">AWS Key Management Service (AWS KMS)</a> is a managed service that makes it easy for you to create, control, rotate, and use your encryption keys. AWS KMS allows you to create custom keys. You can then share these keys with <a href="https://aws.amazon.com/iam/">AWS Identity and Access Management (IAM)</a> users and roles in your AWS account or in an AWS account owned by someone else.</p> 
<p>In my previous <a href="https://aws.amazon.com/blogs/devops/building-a-cross-regioncross-account-code-deployment-solution-on-aws/">post</a>, I described a solution for building a cross-region/cross-account code deployment solution on AWS. In this post, I describe a few options for&nbsp;protecting your source code as it travels between regions and between AWS accounts.</p> 
<p>To recap, you deployed the infrastructure as&nbsp;shown in the following diagram.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/24/Diagram10.png" /></p> 
<li>You had your development environment running in Region A in AWS Account A.</li> 
<li>You had your QA environment running in Region B in AWS Account B.</li> 
<li>You had a staging or production environment running in Region C in AWS Account C.</li> 
<p>An update to the source code in Region A triggered validation and deployment of source code changes in the pipeline in Region A. A successful processing of source code in all of its AWS CodePipeline states invoked a Lambda function, which copied the source code into an S3 bucket in Region B. After the source code was copied into this bucket, it triggered a similar chain of processes into the different AWS CodePipeline stages in Region B.</p> 
<h3><strong>Ensuring Security for Your Source Code</strong></h3> 
<p>You might&nbsp;choose to encrypt the source code .zip file before uploading to the S3 bucket that is in Account A, Region A, using Amazon S3 server-side encryption:</p> 
<h4><strong>1. Using the Amazon S3 service master key</strong></h4> 
<p>Refer back to the Lambda function created for you by the CloudFormation stack in the previous <a href="https://aws.amazon.com/blogs/devops/building-a-cross-regioncross-account-code-deployment-solution-on-aws/">post</a>. Go to the AWS Lambda console and your function name should be &lt;stackname&gt;-CopytoDest-XXXXXXX.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/07/23/Lambda_BK.png" /></p> 
<p>Use the following parameter for the copyObject function – <em>ServerSideEncryption: ‘AES256’</em></p> 
<p><strong>Note</strong>: The set-up already uses this option by default.</p> 
<p>The <em>copyObject</em> function decrypts the .zip file and copies the object into account B.</p> 
<h4><strong>2. Using an AWS KMS master key</strong></h4> 
<p>Since the KMS keys are constrained in a region, copying the object (source code .zip file) into a different account across the region requires&nbsp;cross-account access to the KMS key. This must occur before Amazon S3 can use that key for encryption and decryption.</p> 
<p>Use the following parameter for the&nbsp;<em>copyObject</em> function – <em>ServerSideEncryption: ‘aws:kms’</em> and provide an&nbsp;<em>SSEKMSKeyId: ‘&lt;keyeid&gt;’</em></p> 
<p><strong>To enable cross-account access for the KMS key and use it in Lambda function</strong></p> 
<p>a. Create a KMS key in the source account (Account A), region B – for example,&nbsp;<strong><em>XRDepTestKey</em></strong></p> 
<p><strong>Note</strong>: This key must&nbsp;be created in region B. This is because the source code will&nbsp;be copied in an S3 bucket that exists in region B and the KMS key must&nbsp;be accessible in this region.</p> 
<p>b. To enable the&nbsp;Lambda function to be able to use this KMS key, add <strong><em>lambdaS3CopyRole</em></strong>&nbsp;as a user for this key. The Lambda function and associated role and policies are defined in the <a href="https://s3-us-west-2.amazonaws.com/aws-xregion-xaccount-sample/template/XregionCodePipeLineCF.template">CloudFormation template</a>.</p> 
<p>c. Note the ARN of the key that you generated.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/07/23/keyARN.jpg" /></p> 
<p>d. Provide the external account (Account B) permission to use this key. For more information, see <a href="https://blogs.aws.amazon.com/security/post/Tx2N2SRHXSNEX91/Share-Custom-Encryption-Keys-More-Securely-Between-Accounts-by-Using-AWS-Key-Man">Sharing custom encryption keys securely between accounts</a>.</p> 
<p><em> arn:aws:iam::&lt;Account B ID&gt;:root</em></p> 
<p>e. In Account B, delegate the permission to use this key to the role that AWS CodePipeline is using. In the&nbsp;CloudFormation template, you can see&nbsp;that <em><strong>CodePipelineTrustRole</strong></em>&nbsp;is used. Attach the following policy to the role. Ensure that you update the region and Account ID accordingly.</p> 
<code class="lang-js">{
&nbsp;&nbsp;&nbsp; &quot;Version&quot;: &quot;2012-10-17&quot;,
&nbsp;&nbsp;&nbsp; &quot;Statement&quot;: [
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; {
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;Sid&quot;: &quot;AllowUseOfTheKey&quot;,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;Effect&quot;: &quot;Allow&quot;,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;Action&quot;: [
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;kms:Encrypt&quot;,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;kms:Decrypt&quot;,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;kms:ReEncrypt*&quot;,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;kms:GenerateDataKey*&quot;,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;kms:DescribeKey&quot;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ],
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;Resource&quot;: [
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;arn:aws:kms:&lt;regionB&gt;:&lt;AccountA ID&gt;:key/&lt;KMS Key in Region B ID&gt;&quot;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ]
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; },
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; {
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;Sid&quot;: &quot;AllowAttachmentOfPersistentResources&quot;,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;Effect&quot;: &quot;Allow&quot;,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;Action&quot;: [
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;kms:CreateGrant&quot;,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;kms:ListGrants&quot;,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;kms:RevokeGrant&quot;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ],
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;Resource&quot;: [
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;arn:aws:kms:&lt;regionB&gt;:&lt;AccountA ID&gt;:key/&lt;KMS Key in Region B ID&gt;&quot;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ],
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;Condition&quot;: {
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;Bool&quot;: {
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;kms:GrantIsForAWSResource&quot;: true
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }
&nbsp;&nbsp;&nbsp; ]
}</code> 
<p>f. Update the Lambda function, <strong><em>CopytoDest</em></strong>, to use the following in the parameter definition.</p> 
<code class="lang-js">ServerSideEncryption: 'aws:kms',\n&quot;,
SSEKMSKeyId: '&lt; keyeid &gt;'&nbsp;&nbsp;
//ServerSideEncryption: 'AES256'\n&quot;,</code> 
<p>And there you go! You have enabled secure delivery of your source code into your cross-region/cross-account deployment solution.</p> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<meta property="image" content="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/08/10/devsecops2_1.jpg" /> 
<b class="lb-b blog-post-title" property="name headline">Automating Blue/Green Deployments of Infrastructure and Application Code using AMIs, AWS Developer Tools, &amp; Amazon EC2 Systems Manager</b> 
<p style="margin: 0; padding:0;">=======================<p>
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Ramesh Adabala</span></span> | on 
<time property="datePublished" datetime="2017-08-10T16:59:05+00:00">10 AUG 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/devops/category/management-tools/amazon-ec2-systems-manager/" title="View all posts in Amazon EC2 Systems Manager*"><span property="articleSection">Amazon EC2 Systems Manager*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/compute/amazon-ec2/" title="View all posts in Amazon EC2*"><span property="articleSection">Amazon EC2*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/compute/auto-scaling/" title="View all posts in Auto Scaling*"><span property="articleSection">Auto Scaling*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/management-tools/aws-cloudformation/" title="View all posts in AWS CloudFormation*"><span property="articleSection">AWS CloudFormation*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/developer-tools/aws-codebuild/" title="View all posts in AWS CodeBuild*"><span property="articleSection">AWS CodeBuild*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/developer-tools/aws-codecommit/" title="View all posts in AWS CodeCommit*"><span property="articleSection">AWS CodeCommit*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/developer-tools/aws-codedeploy/" title="View all posts in AWS CodeDeploy*"><span property="articleSection">AWS CodeDeploy*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/developer-tools/aws-codepipeline/" title="View all posts in AWS CodePipeline*"><span property="articleSection">AWS CodePipeline*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/developer-tools/" title="View all posts in Developer Tools*"><span property="articleSection">Developer Tools*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/devops/bluegreen-infrastructure-application-deployment-blog/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p>Previous <a href="https://aws.amazon.com/devops/">DevOps </a>blog posts have covered the following use cases for infrastructure and application deployment automation:</p> 
<li><a href="https://aws.amazon.com/blogs/apn/category/aws-codebuild/">Deploy to Production Using AWS CodeBuild and the AWS Developer Tools Suite</a>: Deploying a simple Java application in an in-place deployment model using <a href="https://aws.amazon.com/codecommit/">AWS CodeCommit</a>, <a href="https://aws.amazon.com/codebuild/">AWS CodeBuild</a>, and <a href="https://aws.amazon.com/codedeploy/">AWS CodeDeploy</a> orchestrated by <a href="https://aws.amazon.com/codepipeline/">AWS CodePipeline</a>.</li> 
<li><a href="https://aws.amazon.com/blogs/devops/performing-bluegreen-deployments-with-aws-codedeploy-and-auto-scaling-groups/">Performing Blue/Green Deployments with AWS CodeDeploy and Auto Scaling Groups</a>: Extending the CI/CD model by using the CodeDeploy blue/green deployment feature to create a production environment and make it easier to roll back to the previous environment if problems arise.</li> 
<li><a href="https://aws.amazon.com/blogs/aws/streamline-ami-maintenance-and-patching-using-amazon-ec2-systems-manager-automation/">Streamline AMI Maintenance and Patching Using Amazon EC2 Systems Manager | Automation</a>: Using EC2 Systems Manager and automation to patch, update agents, or bake applications into an Amazon Machine Image (AMI) and avoid the time and effort associated with manual image updates.</li> 
<p>An <a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AMIs.html">AMI </a>provides the information required to launch an instance, which is a virtual server in the cloud. You can use one AMI to launch as many instances as you need. It is security best practice to customize and harden your base AMI with required operating system updates and, if you are using AWS native services for continuous security monitoring and operations, you are strongly encouraged to bake into the base AMI agents such as those for <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/ssm-agent.html">Amazon EC2 Systems Manager (SSM)</a>, <a href="http://docs.aws.amazon.com/inspector/latest/userguide/inspector_agents.html">Amazon Inspector</a>, <a href="http://docs.aws.amazon.com/codedeploy/latest/userguide/codedeploy-agent-operations.html">CodeDeploy</a>, and <a href="http://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/QuickStartEC2Instance.html">CloudWatch Logs</a>. A customized and hardened AMI is often referred to as a “golden AMI.” The use of golden AMIs to create EC2 instances in your AWS environment allows for fast and stable application deployment and scaling, secure application stack upgrades, and versioning.</p> 
<p>In this post, using the DevOps automation capabilities of <a href="https://aws.amazon.com/ec2/systems-manager/">Systems Manager</a>,<a href="https://aws.amazon.com/products/developer-tools/"> AWS developer tools</a> (<a href="https://aws.amazon.com/codepipeline/">CodePipeLine</a>, <a href="https://aws.amazon.com/codedeploy/">CodeDeploy</a>, <a href="https://aws.amazon.com/codecommit/">CodeCommit</a>, <a href="https://aws.amazon.com/codebuild/">CodeBuild</a>), I will show you how to use <a href="https://aws.amazon.com/codepipeline/">AWS CodePipeline</a> to orchestrate the end-to-end <a href="https://aws.amazon.com/about-aws/whats-new/2017/01/aws-codedeploy-introduces-blue-green-deployments/">blue/green deployments</a> of a golden AMI and application code. Systems Manager Automation is a powerful security feature for enterprises that want to mature their DevSecOps practices.</p> 
<p>Here are the high-level phases and primary services covered in this use case:</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/08/10/devsecops2_1.jpg" /></p> 
<p>You can access the source code for the sample used in this post here: <a href="https://github.com/awslabs/automating-governance-sample/tree/master/Bluegreen-AMI-Application-Deployment-blog">https://github.com/awslabs/automating-governance-sample/tree/master/Bluegreen-AMI-Application-Deployment-blog</a>.</p> 
<p>This sample will create a pipeline in AWS CodePipeline with the building blocks to support the blue/green deployments of infrastructure and application. The sample includes a custom Lambda step in the pipeline to execute Systems Manager Automation to build a golden AMI and update the Auto Scaling group with the golden AMI ID for every rollout of new application code. This guarantees that every new application deployment is on a fully patched and customized AMI in a continuous integration and deployment model. This enables the automation of hardened AMI deployment with every new version of application deployment.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/08/10/devopsblog_conceptual_diagram.png" /></p> 
<p>We will build and run this sample in three parts.</p> 
<p><strong><u>Part 1</u></strong>: <strong>Setting up the AWS developer tools and deploying a base web application</strong> <a href="https://console.aws.amazon.com/cloudformation/home?region=us-east-1#/stacks/new?stackName=devsecopspart1&amp;templateURL=https://s3.amazonaws.com/devsecopsblog/blog_template_part1.json"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/08/10/devsecops2_3.jpg" /></a></p> 
<p>Part 1 of the <a href="https://s3.amazonaws.com/devsecopsblog/blog_template_part1.json">AWS CloudFormation</a> template creates the initial Java-based web application environment in a VPC. It also creates all the required components of Systems Manager Automation, CodeCommit, CodeBuild, and CodeDeploy to support the blue/green deployments of the infrastructure and application resulting from ongoing code releases.</p> 
<p>Part 1 of the AWS CloudFormation stack creates these resources:</p> 
<li>A Java-based web application running on <a href="https://aws.amazon.com/ec2/">EC2 </a>instances loaded with <a href="http://docs.aws.amazon.com/codedeploy/latest/userguide/codedeploy-agent.html">CodeDeploy agents</a> in an <a href="http://docs.aws.amazon.com/autoscaling/latest/userguide/AutoScalingGroup.html">Auto Scaling group</a> behind an <a href="https://aws.amazon.com/elasticloadbalancing/">Elastic Load Balancing load balancer</a>.</li> 
<li>A <a href="https://aws.amazon.com/ec2/systems-manager/automation/">Systems Manager Automation</a> document that patches the supplied base AMI and creates the <a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AMIs.html">golden AMI</a>.</li> 
<li>A <a href="http://docs.aws.amazon.com/codecommit/latest/userguide/repositories.html">CodeCommit repository</a> to securely store code and files for your application.</li> 
<li>A <a href="http://docs.aws.amazon.com/codebuild/latest/userguide/build-projects-working.html">CodeBuild project</a> with configuration details about how AWS CodeBuild builds your source code.</li> 
<li>A <a href="http://docs.aws.amazon.com/codedeploy/latest/userguide/deployment-groups.html">CodeDeploy deployment group</a> with Auto Scaling group details about the web application EC2 instances.</li> 
<li>A <a href="http://docs.aws.amazon.com/codedeploy/latest/userguide/applications-create.html">CodeDeploy application</a> with a deployment group configured with the <strong>Automatically copy Auto Scaling group</strong> setting.</li> 
<li>The following Lambda functions: 
<ol> 
<li>A function to get the Amazon-provided source AMI ID based on region and architecture.</li> 
<li>A function to update the Systems Manager parameter with the golden AMI ID.</li> 
<li>A function to update the <a href="http://docs.aws.amazon.com/codedeploy/latest/userguide/integrations-aws-auto-scaling.html">CodeDeploy deployment group</a> with required blue/green configurations. (Currently AWS CloudFormation does not support creating a deployment group with blue/green deployment configurations.)</li> 
</ol> </li> 
<p>After Part 1 of the AWS CloudFormation stack creation is complete, go to the Outputs tab and click the Elastic Load Balancing link. You will see the following home page for the base web application:</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/08/10/devsecops2_4-1.jpg" /></p> 
<p>Make sure you have all the outputs from the Part 1 stack handy. You need to supply them as parameters in Part 3 of the stack.</p> 
<p><strong><u>Part 2</u></strong>: <strong>Setting up your CodeCommit repository</strong></p> 
<p>In this part, you will commit and push your sample application code into the CodeCommit repository created in Part 1. To access the initial git commands to clone the empty repository to your local machine, click Connect to go to the AWS CodeCommit console. Make sure you have the <a href="http://docs.aws.amazon.com/codecommit/latest/userguide/access-permissions.html">IAM permissions</a> required to access AWS CodeCommit from command line interface (CLI).</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/08/10/devsecops2_5.jpg" /></p> 
<p>After you’ve cloned the repository locally, download the sample application files from the <a href="https://github.com/awslabs/automating-governance-sample/tree/master/Bluegreen-AMI-Application-Deployment-blog/part2">part2 folder</a> of the Git repository and place the files directly into your local repository. Do not include the aws-codedeploy-sample-tomcat folder. Go to the local directory and type the following commands to commit and push the files to the CodeCommit repository:</p> 
<code class="lang-git">git add .
git commit -a -m &quot;add all files from the AWS Java Tomcat CodeDeploy application&quot;
git push</code> 
<p>After all the files are pushed successfully, the repository should look like this:</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/08/10/devsecops2_6.jpg" /></p> 
<p><strong><u>Part 3</u></strong>: <strong>Setting up CodePipeline to enable blue/green deployments</strong>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <a href="https://console.aws.amazon.com/cloudformation/home?region=us-east-1#/stacks/new?stackName=devsecopspart3&amp;templateURL=https://s3.amazonaws.com/devsecopsblog/blog_template_part3.json"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/08/10/devsecops2_3.jpg" /></a></p> 
<p>Part 3 of the <a href="https://s3.amazonaws.com/devsecopsblog/blog_template_part3.json">AWS CloudFormation</a> template creates the pipeline in AWS CodePipeline and all the required components.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/08/10/devsecops2_7.jpg" /></p> 
<p>a) <strong>Source</strong>: The pipeline is triggered by any change to the CodeCommit repository.</p> 
<p>b) <strong>BuildGoldenAMI</strong>: This Lambda step executes the Systems Manager Automation document to build the golden AMI. After the golden AMI is successfully created, a new launch configuration with the new AMI details will be updated into the Auto Scaling group of the application deployment group. You can watch the progress of the automation in the EC2 console from the <strong>Systems Manager –&gt; Automations</strong> menu.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/08/10/devsecops2_8.jpg" /></p> 
<p>c) <strong>Build</strong>: This step uses the application <a href="http://docs.aws.amazon.com/codebuild/latest/userguide/build-spec-ref.html">build spec</a> file to build the application build artifact. Here are the CodeBuild execution steps and their status:</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/08/10/devsecops2_9.jpg" /></p> 
<p>d) <strong>Deploy</strong>: This <a href="http://docs.aws.amazon.com/codedeploy/latest/userguide/deployment-groups-create-blue-green.html">step </a>clones the Auto Scaling group, launches the new instances with the new AMI, deploys the application changes, reroutes the traffic from the elastic load balancer to the new instances and terminates the old Auto Scaling group. You can see the execution steps and their status in the CodeDeploy console.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/08/10/devsecops2_10.jpg" /></p> 
<p>After the CodePipeline execution is complete, you can access the application by clicking the Elastic Load Balancing link. You can find it in the output of Part 1 of the AWS CloudFormation template. Any consecutive commits to the application code in the CodeCommit repository trigger the pipelines and deploy the infrastructure and code with an updated AMI and code.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/08/15/Screen-Shot-2017-08-15-at-1.01.37-PM-1024x102.png" /></p> 
<p>If you have feedback about this post, add it to the Comments section below. If you have questions about implementing the example used in this post, open a thread on the <a href="https://forums.aws.amazon.com/category.jspa?categoryID=21">Developer Tools forum</a>.</p> 
<hr /> 
</article> 
<p>
© 2018 Amazon Web Services, Inc. or its affiliates. All rights reserved.
</p>

    </div>
  </div>
</div>


    <div id="footer" class="navigation hidden-print">
      <div class="container">
        <div class="row">
          <div class="col-xs-12">
            <ul class="footer-links nav navbar-nav">
              <li><a href="../aws.html">AWS</a></li>
              <li><a href="../linux.html">Linux</a></li>
              <li><a href="../docker.html">Docker</a></li>
              <li><a href="../ibmpower.html">IBM Power</a></li>
              <li><a href="blogsataws1.html">Blogs@AWS (Kindle Friendly)</a></li>
            </ul>
            <ul class="footer-links nav navbar-nav navbar-right">
              <li><a href="../comments.html">Comments?</a></li>
            </ul>
          </div>
        </div>
      </div>
    </div>
  </body>
</html>
