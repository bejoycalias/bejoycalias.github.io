<!DOCTYPE html>
<html lang="en">
  <head>
<!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-593498H');</script>
<!-- End Google Tag Manager -->

    <meta charset="utf-8">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">

    <meta name="msapplication-config" content="/microsoft-tile.xml" />
    <meta name="theme-color" content="#ffffff">

    <meta property="og:url" content="https://bejoycalias.github.io/blogsataws/apnblogs1.html" />
    <meta property="og:site_name" content="Bejoy's TechNotes"/>
    <meta property="og:title" content="Bejoy's TechNotes - Kindle Friendly AWS APN Blogs" />
    <meta property="og:image" content="https://bejoycalias.github.io/assets/images/og-image.png"/>
    <meta property="og:image:width" content="1200"/>
    <meta property="og:image:height" content="1200"/>
    <meta property="og:description" content="" />

    <title>Bejoy's TechNotes - Kindle Friendly AWS APN Blogs</title>
    <link href="../assets/stylesheets/application-832aa42c.css" rel="stylesheet" />

    <!--[if lt IE 9]>
      <script src="../assets/javascripts/ie-compat-c141a02d.js"></script>
    <![endif]-->
    <script src="../assets/javascripts/application-ff53d307.js"></script>

    <!-- Typekit script to import Klavika font -->
    <script src="https://use.typekit.net/wxf7mfi.js"></script>
    <script>try{Typekit.load({ async: true });}catch(e){}</script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-100043608-1', 'auto');
  ga('send', 'pageview');

</script>

    
  </head>

  <body id="uh-oh-" class="layout-inner page-uh-oh-">
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-593498H"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->


    <div id="header" class="navigation navbar-static-top hidden-print">
      <div class="container">
        <div class="row">
          <div class="col-xs-12">
            <div class="navbar-header">
              <div class="navbar-brand">
                <a href="/">
                  <svg version="1.0" xmlns="http://www.w3.org/2000/svg" width="135.000000pt" height="50" viewbox="0 0 135.000000 45.000000" preserveaspectratio="xMidYMid meet" class="logo">

<g transform="translate(0.000000,45.000000) scale(0.100000,-0.100000)" fill="#000000" stroke="none">
<path class="text" fill="#000000" d="M527 384 c-4 -4 -7 -18 -7 -31 0 -21 4 -24 28 -21 21 2 27 8 27 28 0
18 -6 26 -20 28 -12 2 -24 0 -28 -4z"></path>
<path class="text" fill="#000000" d="M1080 335 c0 -48 2 -55 20 -55 18 0 20 7 20 55 0 48 -2 55 -20 55
-18 0 -20 -7 -20 -55z"></path>
<path class="text" fill="#000000" d="M54 357 c-2 -7 -3 -69 -2 -138 l3 -124 65 -3 c90 -3 130 20 130 77 0
29 -6 44 -20 54 -20 14 -20 15 -3 45 14 25 15 34 5 56 -6 15 -23 31 -38 36
-38 15 -134 13 -140 -3z m110 -33 c19 -7 21 -45 4 -62 -7 -7 -22 -12 -35 -12
-20 0 -23 5 -23 40 0 41 13 50 54 34z m20 -130 c19 -18 19 -20 6 -45 -8 -13
-21 -19 -45 -19 -34 0 -35 1 -35 40 0 38 2 40 29 40 16 0 37 -7 45 -16z"></path>
<path class="text" fill="#000000" d="M319 271 c-23 -24 -29 -38 -29 -74 0 -25 3 -53 6 -62 20 -50 164 -64
164 -15 0 15 -7 17 -45 12 -46 -5 -75 8 -75 34 0 11 16 14 65 14 l65 0 0 35
c0 80 -92 114 -151 56z m99 -33 c3 -15 -4 -18 -37 -18 -43 0 -50 7 -29 28 18
18 62 11 66 -10z"></path>
<path class="text" fill="#000000" d="M520 184 c0 -107 -1 -116 -20 -121 -11 -3 -20 -12 -20 -19 0 -21 76
-19 84 2 3 9 6 69 6 135 l0 119 -25 0 -25 0 0 -116z"></path>
<path class="text" fill="#000000" d="M649 271 c-24 -25 -29 -37 -29 -78 1 -70 34 -103 105 -103 55 0 95
44 95 103 0 60 -7 75 -41 92 -47 25 -96 19 -130 -14z m111 -30 c25 -48 2 -111
-40 -111 -45 0 -69 80 -34 114 21 22 61 20 74 -3z"></path>
<path class="text" fill="#000000" d="M850 287 c0 -8 16 -57 36 -110 28 -76 33 -100 25 -116 -16 -28 -14
-31 18 -31 27 0 29 4 70 123 23 67 41 128 41 135 0 6 -11 12 -24 12 -21 0 -26
-8 -41 -65 -10 -36 -21 -68 -25 -70 -3 -2 -16 27 -29 66 -19 60 -25 69 -47 69
-13 0 -24 -6 -24 -13z"></path>
<path class="text" fill="#000000" d="M1192 284 c-17 -12 -22 -24 -20 -47 2 -26 10 -36 45 -52 49 -23 59
-55 17 -55 -14 0 -34 5 -45 10 -16 9 -19 7 -19 -13 0 -17 7 -27 23 -31 69 -18
117 6 117 60 0 32 -4 37 -45 55 -60 26 -62 54 -4 46 37 -5 40 -3 37 16 -2 18
-11 23 -43 25 -25 2 -49 -3 -63 -14z"></path>
</g>
</svg>

                </a>
              </div>
              <button class="navbar-toggle" type="button">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
              </button>
            </div>
            <div class="buttons hidden-xs">
              <nav class="navigation-links" role="navigation">
                <ul class="main-links nav navbar-nav navbar-right">
                  <li><a href="../aws.html">AWS</a></li>
                  <li><a href="../linux.html">Linux</a></li>
                  <li><a href="../docker.html">Docker</a></li>
                  <li><a href="../ibmpower.html">IBM Power</a></li>
                  <li><a href="blogsataws1.html">Blogs@AWS (Kindle Friendly)</a></li>
                </ul>
              </nav>
            </div>
          </div>
        </div>
      </div>
    </div>

    <div class="sidebar-overlay"></div>

<aside class="sidebar" role="navigation">
  <div class="sidebar-header">
    <svg version="1.0" xmlns="http://www.w3.org/2000/svg" width="135.000000pt" height="42" viewbox="0 0 135.000000 45.000000" preserveaspectratio="xMidYMid meet">

<g transform="translate(0.000000,45.000000) scale(0.100000,-0.100000)" fill="#000000" stroke="none">
<path class="text" fill="#000000" d="M527 384 c-4 -4 -7 -18 -7 -31 0 -21 4 -24 28 -21 21 2 27 8 27 28 0
18 -6 26 -20 28 -12 2 -24 0 -28 -4z"></path>
<path class="text" fill="#000000" d="M1080 335 c0 -48 2 -55 20 -55 18 0 20 7 20 55 0 48 -2 55 -20 55
-18 0 -20 -7 -20 -55z"></path>
<path class="text" fill="#000000" d="M54 357 c-2 -7 -3 -69 -2 -138 l3 -124 65 -3 c90 -3 130 20 130 77 0
29 -6 44 -20 54 -20 14 -20 15 -3 45 14 25 15 34 5 56 -6 15 -23 31 -38 36
-38 15 -134 13 -140 -3z m110 -33 c19 -7 21 -45 4 -62 -7 -7 -22 -12 -35 -12
-20 0 -23 5 -23 40 0 41 13 50 54 34z m20 -130 c19 -18 19 -20 6 -45 -8 -13
-21 -19 -45 -19 -34 0 -35 1 -35 40 0 38 2 40 29 40 16 0 37 -7 45 -16z"></path>
<path class="text" fill="#000000" d="M319 271 c-23 -24 -29 -38 -29 -74 0 -25 3 -53 6 -62 20 -50 164 -64
164 -15 0 15 -7 17 -45 12 -46 -5 -75 8 -75 34 0 11 16 14 65 14 l65 0 0 35
c0 80 -92 114 -151 56z m99 -33 c3 -15 -4 -18 -37 -18 -43 0 -50 7 -29 28 18
18 62 11 66 -10z"></path>
<path class="text" fill="#000000" d="M520 184 c0 -107 -1 -116 -20 -121 -11 -3 -20 -12 -20 -19 0 -21 76
-19 84 2 3 9 6 69 6 135 l0 119 -25 0 -25 0 0 -116z"></path>
<path class="text" fill="#000000" d="M649 271 c-24 -25 -29 -37 -29 -78 1 -70 34 -103 105 -103 55 0 95
44 95 103 0 60 -7 75 -41 92 -47 25 -96 19 -130 -14z m111 -30 c25 -48 2 -111
-40 -111 -45 0 -69 80 -34 114 21 22 61 20 74 -3z"></path>
<path class="text" fill="#000000" d="M850 287 c0 -8 16 -57 36 -110 28 -76 33 -100 25 -116 -16 -28 -14
-31 18 -31 27 0 29 4 70 123 23 67 41 128 41 135 0 6 -11 12 -24 12 -21 0 -26
-8 -41 -65 -10 -36 -21 -68 -25 -70 -3 -2 -16 27 -29 66 -19 60 -25 69 -47 69
-13 0 -24 -6 -24 -13z"></path>
<path class="text" fill="#000000" d="M1192 284 c-17 -12 -22 -24 -20 -47 2 -26 10 -36 45 -52 49 -23 59
-55 17 -55 -14 0 -34 5 -45 10 -16 9 -19 7 -19 -13 0 -17 7 -27 23 -31 69 -18
117 6 117 60 0 32 -4 37 -45 55 -60 26 -62 54 -4 46 37 -5 40 -3 37 16 -2 18
-11 23 -43 25 -25 2 -49 -3 -63 -14z"></path>
</g>
</svg>

  </div>

  <ul class="nav sidebar-nav">
    <li><a href="../aws.html">AWS</a></li>
    <li><a href="../linux.html">Linux</a></li>
    <li><a href="../docker.html">Docker</a></li>
    <li><a href="../ibmpower.html">IBM Power</a></li>
    <li><a href="blogsataws1.html">Blogs@AWS (Kindle Friendly)</a></li>
  </ul>
</aside>


    <div class="container">
  <div class="row">
    <div id="docs-sidebar" class="col-sm-3 col-md-3 col-xs-12 hidden-print" role="complementary">
      <ul class="nav docs-sidenav">
      <li><a href="blogsataws1.html">Blogs @ AWS</a></li>
      <li><a href="whatsnew1.html">What's New @ AWS</a></li>
      <li><a href="secblogs1.html">Security Blogs @ AWS</a></li>
      <li><a href="computeblogs1.html">Compute Blogs @ AWS</a></li>
      <li class="active"><a href="apnblogs1.html">APN Blogs @ AWS</a></li>
      <li><a href="devopsblogs1.html">DevOps Blogs @ AWS</a></li>
      <li><a href="mgmtblogs1.html">Management Tools Blogs @ AWS</a></li>

    </ul>
    </div>

    <div id="inner" class="col-sm-9 col-md-9 col-xs-12" role="main">
<p></p>
<p><i>Contents of this page is copied directly from AWS blog sites to make it Kindle friendly. Some styles & sections from these pages are removed to render this properly in 'Article Mode' of Kindle e-Reader browser. All the contents of this page is property of AWS.</i></p>
<p><a href="apnblogs1.html">Page 1</a>|<a href="apnblogs2.html">Page 2</a>|<a href="apnblogs3.html">Page 3</a>|<a href="apnblogs4.html">Page 4</a</p>
<br>
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">New APN Partner Training Courses Available</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Sara Snedeker</span></span> | on 
<time property="datePublished" datetime="2017-09-06T17:02:04+00:00">06 SEP 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/apn/category/apn-launches/" title="View all posts in APN Launches"><span property="articleSection">APN Launches</span></a></span> | 
<a href="https://aws.amazon.com/blogs/apn/new-apn-partner-training-courses-available/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-4986" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-apn-blog&amp;disqus_identifier=4986&amp;disqus_title=New+APN+Partner+Training+Courses+Available&amp;disqus_url=https://aws.amazon.com/blogs/apn/new-apn-partner-training-courses-available/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-4986');
});
</script> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p>Amazon Web Services (AWS) offers training resources at no cost designed for AWS Partner Network (APN) Partners so you can more effectively help customers leverage the AWS cloud. We regularly update and release new Solutions Training for Partners content so you can be sure you are learning the latest about AWS. We are expanding our online training availability to give you more flexibility for completing training.</p> 
<p><img class="aligncenter wp-image-5000 size-full" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/09/06/Unknown.png" alt="" width="600" height="200" /></p> 
<h3>Solutions Training for Partners: Foundations: New Web-Based Training and Updated Instructor-Led Training</h3> 
<p>We now have a web-based training version of our popular&nbsp;<a href="https://aws.amazon.com/partners/training/solutions/" target="_blank" rel="noopener noreferrer">Solutions Training for Partners: Foundations</a>&nbsp;course. We’ve also updated the instructor-led training version of the course to include interactive role play sessions and information about recently released and updated AWS services. This training is recommended for APN Consulting Partner business professionals who want to learn more about AWS best practices to build their business and better meet customer business challenges.</p> 
<h3>Solutions Training for Partners: Windows Technical: New Instructor-Led and Web-Based Training</h3> 
<p>Our newest course,<a href="https://aws.amazon.com/partners/training/windows-technical/" target="_blank" rel="noopener noreferrer">&nbsp;Solutions Training for Partners: AWS for Windows Technical</a>, is available in both instructor-led and web-based training modalities. This course trains APN Consulting Partners on the technical foundations for running Windows-based workloads on AWS. You will learn about the technical advantages and positioning for Windows on AWS, and learn how to provide guidance to customers on architecting common Microsoft workloads for AWS. We recommend you achieve the&nbsp;<a href="https://aws.amazon.com/partners/training/accreditation/" target="_blank" rel="noopener noreferrer">AWS Technical Professional</a>&nbsp;accreditation before registering for this class.</p> 
<p>You can explore more training resources for APN Partners&nbsp;<a href="https://aws.amazon.com/partners/training/" target="_blank" rel="noopener noreferrer">here</a>, and you can search for classes near you by logging into the AWS Training and Certification Portal with your&nbsp;<a href="https://partnercentral.awspartner.com/SiteLogin" target="_blank" rel="noopener noreferrer">APN Portal credentials</a>. APN Partners have access to partner-specific training at no cost and are eligible for a 20% discount on customer-facing public AWS training delivered by AWS. You can also request a private onsite training for your team by&nbsp;<a href="https://aws.amazon.com/contact-us/aws-training/" target="_blank" rel="noopener noreferrer">contacting us</a>.</p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/apn/tag/aws-training-certification/" rel="tag">AWS Training &amp; Certification</a>, <a href="https://aws.amazon.com/blogs/apn/tag/aws-training-and-certification/" rel="tag">AWS Training and Certification</a></span> 
</footer> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-4986');
});
</script> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">Building Serverless SaaS Applications on AWS</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Tod Golding</span></span> | on 
<time property="datePublished" datetime="2017-09-06T10:26:28+00:00">06 SEP 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/apn/category/compute/aws-lambda/" title="View all posts in AWS Lambda*"><span property="articleSection">AWS Lambda*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/apn/building-serverless-saas-applications-on-aws/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-4979" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-apn-blog&amp;disqus_identifier=4979&amp;disqus_title=Building+Serverless+SaaS+Applications+on+AWS&amp;disqus_url=https://aws.amazon.com/blogs/apn/building-serverless-saas-applications-on-aws/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-4979');
});
</script> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p>Software as a service (SaaS) solutions often present architects with a diverse mix of scaling and optimization requirements. With SaaS, your application’s architecture must accommodate a continually shifting landscape of customers and load profiles. The number of customers in the system and their usage patterns can change dramatically on a daily—or even hourly—basis. These dynamics make it challenging for SaaS architects to identify a model that can efficiently anticipate and respond to these variations.</p> 
<p>Dynamically scaling servers and containers have certainly given SaaS architects a range of tools to accommodate these scaling patterns. And now, with the advent of serverless computing and AWS Lamba functions, architects have a computing and consumption model that aligns more precisely with the demands of SaaS environments.</p> 
<p>In this blog post, we’ll discuss how serverless computing and AWS Lambda influence the compute, deployment, management, and operational profiles of your SaaS solution.</p> 
<h3>It’s All About Managed Functions</h3> 
<p>Adopting a serverless model requires developers to adopt a new mindset. Serverless touches nearly every dimension of how developers decompose application domains, build and package code, deploy services, version releases, and manage environments. The key contributor to this shift is the notion that serverless computing relies on a much more granular decomposition of your system, requiring each function of a service to be built, deployed, and managed independently. In many respects, serverless takes the spirit of microservices to the extreme.</p> 
<p>While making this move make requires a paradigm shift, the payoff is significant—especially for SaaS solutions. This more granular model provides us with a much richer set of opportunities to align tenant activity with resource consumption. It is at the core of enabling your ability to tackle many of the challenges associated with SaaS cost and performance optimization.</p> 
<p>The impact of serverless reaches beyond your code and services. It completely removes the notion of servers from your view. Gone is the need to provision, configure, patch, and manage instances or containers. In fact, as a developer of serverless applications, you are intentionally shielded from the details of how and where your application’s functions are executed. Instead, you must rely on the managed service—AWS Lambda—to control and scale the execution of your functions.</p> 
<p>This notion of moving away from the awareness of any specific instance or container sets the stage for all the goodness we are looking for in our SaaS environments. It also frees you up to &nbsp;focus more of your attention on the functionality of your system.</p> 
<h3>Escaping the Policy Challenge</h3> 
<p>The ability to dynamically scale environments is essential to SaaS. Being able to respond quickly to changes in tenant load is key to maximizing a customer experience while still optimizing the cost footprint of your solution. Achieving these scaling goals with server-based environments can be challenging. With instances and containers, the responsibility for defining effective and efficient scaling policies lands squarely on your shoulders. The diagram below illustrates the complexity that is often associated with configuring the policies in traditional server-based SaaS environments.</p> 
<p><img class="wp-image-4980 size-full aligncenter" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/08/28/serverlesssaas1.png" alt="" width="680" height="620" /><br /> In this example, we have decomposed an e-commerce application into a set of services. This decomposition was partly motivated by the desire to have each service scale independently. This is illustrated by the specific policies that are attached to each service. Here, for example, the search service might be scaling on memory, while the checkout service might be scaling on CPU.</p> 
<p>This is a perfectly valid model. However, it puts significant pressure on the SaaS architect to continually refine and tune these policies to align them with the evolving usage patterns of your multi-tenant environment. The policies that are valid today might not be valid tomorrow. As new tenants come on board, the profile and behavior of the system can change. Ultimately, you might end up over-allocating resources to accommodate these variations in load. The end result is often higher per-tenant costs.</p> 
<p>Now, as you move beyond thinking about instances and start implementing your solutions as a series of serverless methods, you can imagine how this influences your approach to managing scale. With AWS Lambda, you can mostly remove yourself from the policy management equation. Instead, scaling and responding effectively to load becomes the job of the managed service.</p> 
<h3>The Power of Granularity</h3> 
<p>The sections above outlined the value and impact of decomposing your system into a series of independent functions. Let’s dig a bit deeper into a real world example that provides a more detailed view of how a serverless model influences the profile of an application service that is implemented with Lambda.</p> 
<p>The image below provides and example of an order management service that might be deployed as a REST service hosted on an instance or container. This service supports a collection of methods that encapsulate the basic operations needed to store, retrieve, and control the state of orders in an e-commerce system.</p> 
<p><img class="aligncenter wp-image-4981 size-full" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/08/28/serverlesssaas2.png" alt="" width="731" height="399" /></p> 
<p>This service includes a range of straightforward capabilities. In a typical scenario, the service would likely support a more detailed set of operations. Still, as you look at the scope of this service, it seems to meet most of the reasonable criteria. It’s relatively focused and is likely loosely coupled to other services.</p> 
<p>While the service seems fine, it could present problems when it comes to scaling in a SaaS environment. Suppose, for example, that the DELETE operation of this service is very CPU-intensive while the PUT operation tends to be more memory-intensive. &nbsp;And, from our profiling, we see that some tenants are pushing the GET operation hard while others are using PUT operations more heavily. This creates a challenge when figuring out how to scale this service effectively without over-allocating resources. Essentially, with this more coarse-grained surface, your options for scaling the service can be somewhat limited. Without more control over your scaling granularity, you’ll be unable to match usage of the service to potential variations in tenant activity. Instead, you’re left with a best guess approach to picking a scaling model with the hope that it might represent an efficient consumption of resources.</p> 
<p>Now, let’s see what it would mean to deliver this order management service in a serverless model. The following diagram illustrates how scale would be achieved in an environment where each of the service’s operations (functions) is implemented as a separate Lambda function.</p> 
<p><img class="aligncenter wp-image-4982 size-full" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/08/28/serverlessaas3.png" alt="" width="975" height="277" /></p> 
<p>As load is placed on an operation, that operation can scale out independently of the others. More calls to GetOrders(), for example, force the scale out of that function. Meanwhile, DeleteOrder() consumes almost no resources. The beauty of this model is that you no longer need to think about how best to decompose your services to find the right balance of consumption and scale. Instead, by representing your service as a series of separately deployed functions, you directly align the consumption of each function with the real-time activity of tenants. If there’s tremendous demand for order searches right now, the system will scale that specific method to meet the demands of that load. Meanwhile, if other functions are going untouched, these functions will not generate any compute costs.</p> 
<p>You can imagine the value this model brings to SaaS environments where the activity of existing and new tenants is constantly changing. With traditional SaaS implementations, it would not be uncommon to have idle services that are rarely exercised or only pushed during specific windows of the day. Now, with a serverless architecture, this is no longer an issue. You can simply deploy your functions and let them to respond actual tenant load. If a group of functions are not called for a day they will incur no costs for remaining idle. Then, if a new tenant suddenly pushes these same functions, Lambda will be responsible for providing the required scale.</p> 
<h3>Serverless Management and Monitoring</h3> 
<p>The more granular nature of serverless applications also adds value to the SaaS management and monitoring experience. With SaaS applications, it’s essential to proactively detect—with precision—any anomalies that may exist in your system. Imagine the dashboard and operational view that could show you the health of your system at the function level. The following image provides a conceptual view of how a serverless system could help you analyze your system’s health and activity more effectively:<img class="aligncenter wp-image-4983 size-full" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/08/28/serverlesssaas4.png" alt="" width="975" height="415" /></p> 
<p>The heat map on the left provides a coarse-grained representation of the services. The health of each service is represented by a range of colors that convey the current status of a service. In this example, you’ll notice that the order management service is red, indicating that there is some kind of issue with the health of that service. However, we won’t know which aspect of this service is actually failing without drilling into logs and other metrics.</p> 
<p>The view on the right represents the health of the system in a serverless model. Here, each square in the grid corresponds to a Lambda function. Now, when the health of any aspect of the system starts to diminish, you get a more granular view of what may be failing. This makes it easier to develop proactive policies and streamlines the troubleshooting process, both of which are essential in SaaS environments where an outage could impact all your customers.</p> 
<h3>More Chances to Impact Availability</h3> 
<p>With SaaS applications, you’re always looking for opportunities to improve the availability profile of your application. Most SaaS solutions lean heavily on building in fault tolerance mechanisms that allow an application to continue to function, even when some portions of the system could be failing.</p> 
<p>Imagine, for example, that your e-commerce application has a ratings service that provides customer reviews about products. Although this feature is valuable to customers, the system could continue to function when this service is down. In this scenario, your system could either temporarily remove the display of the ratings or use a cached copy of the latest ratings data during the failure.</p> 
<p>This approach to fault tolerance is a common technique that is used in many SaaS architectures. However, more coarse-grained services often undermine your ability to introduce effective fault tolerance strategies. The outage of an entire service can be more difficult to overcome. This is an area where the serverless model shines. The decomposition of your system into independently executable functions now gives you a much more diverse set of options for introducing fault tolerant policies.</p> 
<h3>Supporting Siloed Tenants</h3> 
<p>SaaS providers are often required to deliver some or all of their system in a siloed model where each tenant has its own unique set of infrastructure resources. This may be driven by any number of factors, including compliance, regulatory, or legacy architecture requirements. There are a number of downsides to operating a SaaS product in this model. Cost often rises to the top of this list, because the overhead associated with provisioning, operating, and managing separate tenant infrastructure can be substantial.</p> 
<p>Serverless computing often represents a compelling alternative for these siloed solutions. With this model, the execution of each tenant’s functions can be completely isolated from other tenants. In fact, you can leverage AWS Identity and Access Management (IAM) policies to ensure that a Lambda function is executed in the context of a specific tenant, which helps address any concerns customers may have about cross-tenant access.</p> 
<p>The other key upside of using serverless computing in a siloed SaaS model is its impact on costs. If you’ve used virtual machine or containers as your underlying infrastructure, this will require each tenant to have some idle footprint—even if the tenant isn’t exercising any of the system’s functionality. Meanwhile, with serverless computing, your tenant costs will be directly correlated to their consumption of the functions you’ve deployed. And, if there are areas of the system that tenants aren’t using, there will be no compute costs associated with these unused features. This can amount to a significant savings in a siloed environment.</p> 
<h3>The API Gateway and SaaS Agility</h3> 
<p>The Amazon API Gateway is a key piece of the AWS serverless model. It provides a managed REST entry point to the functions of your application. It also offloads issues like metering, DDoS, and throttling, allowing your services to focus more on their implementation and less on managing and routing requests.</p> 
<p>In addition to providing API fundamentals, API Gateway also includes mechanisms to manage the deployment of functions to one or more environments. API Gateway includes support for stage variables that allow you to associate functions with a specific environment. So, for example, you could define separate DEV and PROD stages in the gateway and point these stage at specific versions of your functions. This can simplify both deployment and rollback of releases. It can also simplify the tooling you’ll need to build for your deployment pipeline.</p> 
<p>As you move into a serverless model, you’ll also find that the function-based model aligns nicely with your SaaS agility goals. The following diagram illustrates how the move to more granular functions impacts your continuous delivery pipeline. Since each function is executed in isolation, they can also be deployed separately.</p> 
<p><img class="wp-image-4984 size-full aligncenter" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/08/28/serverlesssaas5.png" alt="" width="904" height="294" /></p> 
<p>This smaller unit of deployment is especially helpful in SaaS environments where there is an even higher premium on maximizing up time. It also narrows the scope of potential impact for each item you deploy, promoting more frequent releases of product features and fixes.</p> 
<h3>Focus on What Matters</h3> 
<p>While there are a number of technical, agility, and economic advantages to building a SaaS solution with a serverless architecture, the biggest advantage of serverless is that frees you up to focus more of your energy on your application’s features and functionality. Serverless computing takes the entire notion of managing servers off your plate, allowing you to create applications that can continually change their scaling profile based on the real-time activity of your tenants.</p> 
<p>For many teams, the real challenge of serverless computing is making the shift to a function-based application decomposition. This transition represents a fairly fundamental change in the mental model for building solutions. It may also have you reconsidering your choice of languages and tooling.</p> 
<p>Challenges aside, the natural alignment between the values of SaaS and the principles of the serverless model are very compelling. The upsides of cost, fault tolerance, deployment agility, and managed scale make serverless computing an attractive model for SaaS providers</p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/apn/tag/aws-lambda/" rel="tag">AWS Lambda</a>, <a href="https://aws.amazon.com/blogs/apn/tag/aws-partner-solutions-architect-sa-guest-post/" rel="tag">AWS Partner Solutions Architect (SA) Guest Post</a>, <a href="https://aws.amazon.com/blogs/apn/tag/partner-sa-post/" rel="tag">Partner SA Post</a>, <a href="https://aws.amazon.com/blogs/apn/tag/saas/" rel="tag">SaaS</a>, <a href="https://aws.amazon.com/blogs/apn/tag/saas-on-aws/" rel="tag">SaaS on AWS</a></span> 
</footer> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-4979');
});
</script> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">Calculating Tenant Costs in SaaS Environments</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Tod Golding</span></span> | on 
<time property="datePublished" datetime="2017-08-25T15:08:40+00:00">25 AUG 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/apn/category/apn-launches/" title="View all posts in APN Launches"><span property="articleSection">APN Launches</span></a></span> | 
<a href="https://aws.amazon.com/blogs/apn/calculating-tenant-costs-in-saas-environments/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-4955" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-apn-blog&amp;disqus_identifier=4955&amp;disqus_title=Calculating+Tenant+Costs+in+SaaS+Environments&amp;disqus_url=https://aws.amazon.com/blogs/apn/calculating-tenant-costs-in-saas-environments/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-4955');
});
</script> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p>In traditional single-tenant environments, calculating and aggregating infrastructure costs is a pretty straightforward exercise. Typically, each application or customer has its own collection of dedicated resources and tallying the costs is simply a matter of categorizing and summing those costs. However, in multi-tenant software as a service (SaaS) environments, this becomes a much more challenging problem.</p> 
<p>With SaaS, tenants often share some or all of a system’s infrastructure resources. A database, for example, may hold all the data for all tenants. How, then, do you apportion costs to each tenant? This gets even more complicated with other forms of tenant consumption like compute or bandwidth. Generally, with the varying flavors of system partitioning that are used to build SaaS systems, it becomes increasingly difficult to associate tenants with specific infrastructure costs.</p> 
<p>While the challenges of calculating tenant costs continue to get more complex, the need for tenant cost data is still essential for many SaaS businesses. SaaS organizations often rely on some understanding of the cost per tenant as a key element of their broader economic and business model. This cost data can directly influence the pricing dimensions and tiering strategies that are adopted by a SaaS provider.</p> 
<p>This blog post examines some of the strategies that you can use to capture and analyze tenant consumption data in multi-tenant environments. It highlights some of the challenges associated with instrumenting your services and architecture to enable a more granular view of consumption that you can use to inform your price modeling.</p> 
<h3>Do I Really Need Cost Per Tenant?</h3> 
<p>For some SaaS teams, the calculation of per-tenant costs can seem like overkill. It’s easy to assume that the energy expended to gather and analyze this data may not be worthy of the investment. Even when technical teams might be advocating this direction, the business may resist moving this requirement ahead of other features and functions that are essential to customers. These factors generally conspire to push cost-per-tenant calculations to the back burner.</p> 
<p>The challenge here is that—without this data—you may be missing key insights into your system’s profile that may directly impact both the technical and business dimensions of your offering. Imagine, for example, that you have a tiered product offering with basic, advanced, and professional tiers. Let’s presume that the basic tier is somewhat inexpensive, while the professional tier is more on the pricey end of the spectrum. Without a clear picture of your system’s underlying cost metrics, the business might pick some consumption dimension to define the boundary between each tier.</p> 
<p>Let’s say, for example, we’re an e-commerce product and we’ve used catalog size as the defining metric that separates the tiers of our system. In this scenario, the business would simply begin acquiring customers and pouring them into the system without any concern for how this might impact the bottom line. Now, if we take this system and begin to collect cost per tenant data, the infrastructure consumption breakdown might end up looking like the bar chart shown below. Here, you’ll notice that most of the tenants have signed up for the basic tier. However, the infrastructure costs associated with the basic tier far exceed that of the other two tiers.</p> 
<p><img class="aligncenter wp-image-4956 size-full" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/08/24/Screen-Shot-2017-08-24-at-1.01.11-PM.png" alt="" width="938" height="528" /></p> 
<p>&nbsp;</p> 
<p>Diving deeper, we see that a flaw in the pricing model assumed that infrastructure consumption would correlate directly to catalog size. However, in reality, consumption ended up being driven by the mix of products that were for sale at a store. This created a significant imbalance between revenue and costs where the lowest revenue customers were generating a disproportionate level of expenses.</p> 
<p>This scenario highlights a very common challenge for SaaS organizations where their business model and tiering strategies don’t always align with the overhead associated with each tenant. So, while the business may not always be focused on the cost-per-tenant number, it’s still essential to give it visibility since its impact can often go overlooked.</p> 
<h3>Giving the Business Options</h3> 
<p>The previous example highlights the tight linkage that often exists between the business and technical SaaS teams. The architectural choices that are made by SaaS developers have the potential to shape and influence the menu of pricing and packaging options offered by the business. The more flexibility you are able to provide the business, the more likely it is that you’ll be able to rapidly respond to the diverse requirements of tenants—each of which may have their own scale, performance, and consumption profiles.</p> 
<p>Equipped with cost data, SaaS architects are in a much better position to make tradeoffs that will consider the current and, potentially, future needs of the business. This data becomes a tool that can be used to offer the business options that may have otherwise been outside the view of product managers and strategists who are responsible for defining packaging and pricing options. Teams will often find points of inflection in their cost dynamics that can translate directly into differentiators that separate the tiers of their SaaS system.</p> 
<p>The broader goal here is to make choices in your SaaS architecture that better align a tenant’s expectations with their experience. If a tenant is a $29/month, basic tier tenant, they are likely to understand that their experience will be different than that of the $5000/month, professional tier tenant. Supporting this model often means introducing variations in policies and—in some cases—architectural models that offer distinct tenant experiences for each tier of your solution. Examples of how this can be achieved is outlined in a blog post on <a href="https://aws.amazon.com/blogs/apn/optimizing-saas-tenant-workflows-and-costs/" target="_blank" rel="noopener noreferrer">Optimizing SaaS Tenant Workflows and Costs</a> as well as a presentation on <a href="https://www.youtube.com/watch?v=D-8fTCz8_Yo" target="_blank" rel="noopener noreferrer">Optimizing SaaS Solutions on AWS</a>.</p> 
<p>Ultimately, this is all about giving the business options. If, tomorrow, the business comes to you with some new way they’d like to package your solution to address a new opportunity or market segment, you’d want to be in a position to understand how this new offering might impact costs. The data you provide to this discussion could be fundamental to determining the viability of the new offering.</p> 
<h3>The Hard Part: Instrumenting Your Solution</h3> 
<p>While the value of cost per tenant data is easy to grasp, capturing and aggregating this data can be a bit more involved. The nature of your tenant partitioning model, the compute model you’re using, and any number of other factors could influence your approach to assembling your view of tenant costs. The following sections provide a breakdown of common considerations that might affect how you instrument your solution to capture tenant cost data.</p> 
<h4>Analyzing Costs in a Silo Model</h4> 
<p>Some SaaS providers rely exclusively on a siloed partitioning model where each tenant is housed in a mostly isolated infrastructure. This isolation might be mandatory for some domains that have strict regulations that prohibit shared infrastructure. For these environments, more pronounced boundaries between each tenant can simplify the efforts to aggregate and derive cost analytics.</p> 
<p>Amazon Web Services (AWS) offers architects a few constructs for implementing tenant isolation. Two common strategies involve the usage of AWS accounts and virtual private clouds (VPCs). With the account model, each tenant is provisioned into a completely separate account. This account creates a distinct view of all the resources associated with the tenant. These accounts can also use the AWS linked account model, which associates an account with a master account. This enables all tenant consumption to be rolled up to a single account while giving you a view of consumption at the linked account level so you can easily identify all the costs associated with a single tenant.</p> 
<p>The other common isolation scheme involves creating separate VPCs for each tenant. With this approach, you can isolate tenants without creating separate accounts for each tenant. This often scales better and simplifies the provisioning model. However, it also adds a degree of complexity to the cost instrumentation. Instead of relying on linked accounts to summarize tenant spend, you’ll need to apply AWS tags to your infrastructure to associate it with your tenants. These tags will then be used to aggregate the spend of each tenant.</p> 
<p>In a more siloed model, you may want to consider leveraging partner solutions to simplify the aggregation and analytics of your tenant costs. AWS Partner Network (APN) Partners like CloudHealth and Cloudability, for example, provide cost analytics tools that can streamline your ability to perform tenant analytics.</p> 
<h4>Analyzing Costs in a Pooled Model</h4> 
<p>In a pooled model, where tenant resources are shared, the attribution of tenant costs can be more challenging. Here, you must employ more specialized strategies to properly capture and classify tenant activity. You’ll need to rely on measurements of actual tenant interactions with your systems resources to apportion load and consumption, and derive an approximation of tenant costs. This typically demands more effort to both instrument your solution and to aggregate the resulting metrics.</p> 
<p>Further complicating the pooled model is the reality that each resource type may require a slightly different approach to instrumenting and aggregating cost information for individual tenants. Compute, for example, will likely require a very different approach than storage. The different types of storage (block, object, relational, and NoSQL), for example, might demand separate strategies for measuring consumption.</p> 
<p>Let’s consider how, in a pooled environment, you might derive a tenant’s consumption from their activity. The diagram below depicts a simplified view of an Amazon EC2 Container Service (Amazon ECS) cluster running services in a pooled, multi-tenant environment. This cluster includes two services that are running in containers (Checkout and Catalog), both of which are being invoked by individual tenants.</p> 
<p>&nbsp;</p> 
<p><img class="aligncenter wp-image-4957 size-full" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/08/24/CostTenant2.png" alt="" width="482" height="433" /></p> 
<p>&nbsp;</p> 
<p>As the tenants use these services, they consume compute resources. The question is: How much of these resources are actually being consumed by each tenant? Tenant 1, for example, may be pushing the system very hard and selling lots of items, forcing the scale out of the cluster, or consuming a disproportionate number of the containers in the cluster. Tenant 2, on the other hand, may be imposing minimal load.</p> 
<p>The challenge, then, is to instrument these services to surface metrics data that can be used to infer the level of consumption for each tenant. Ultimately, this comes down to selecting a strategy that best maps activity to consumption for a service. You might decide to track changes in CPU activity, or you might track the frequency of calls to a&nbsp;service—there’s no absolute model that can universally characterize consumption for all your services. However, with some notion of frequency, you should be able to get close to a reasonable approximation of consumption for many of the services that are part of your SaaS solution.</p> 
<p>Fortunately, instrumenting your compute services will likely mesh nicely with other logging and metrics gathering mechanisms you already employ. The general strategy here would be to instrument all the entry points of your services with log events. With this data, you’ll be able to determine which methods are being called and with what frequency. If you add the tenant context to these logging calls, you’ll have the foundational elements that can be used to infer tenant consumption of these services.</p> 
<p>The diagram below provides a conceptual model for how you might aggregate a series of calls to a service and use that data to determine a tenant’s consumption. Here, we’ve simply used the frequency of calls to determine a percentage of activity for a tenant. This gives you a model for apportioning the compute costs associated with this service to each tenant based on these percentages.</p> 
<p>&nbsp;</p> 
<p><img class="aligncenter wp-image-4969 size-full" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/08/25/Screen-Shot-2017-08-25-at-12.55.43-PM.png" alt="" width="788" height="586" /></p> 
<p>&nbsp;</p> 
<p>This represents a highly simplified version of what you might build. Still, it gives you a sense of what might be involved in arriving at a reasonable distribution of tenant compute costs. The good news here is that the mechanisms needed to support the collection of this data overlap heavily with the general analytics tooling that you’ll want to put in place to analyze and evaluate tenant activity. The key is to ensure you’ve collected the data you need with the context that is required to support your cost allocation model.</p> 
<h3>Calculating Storage Costs</h3> 
<p>While the previous example gave us some sense of how we might calculate compute consumption, this same model may not be a good fit for analyzing storage costs. A tenant could, for example, consume significant amounts of compute and still have a minimal impact on storage costs. There is no guaranteed correlation between compute and storage consumption in SaaS environments.</p> 
<p>Storage also adds some new wrinkles to the cost equation. With storage, you may need to consider how both the size of the data and the IOPS impact a given tenant’s costs.&nbsp; This means your cost analytics must apportion all the elements of storage costs that may appear in your AWS bill to the tenants of your system.</p> 
<p>The analysis of a metric like IOPS has parallels to what we’ve discussed for analyzing compute consumption. The goal would be to derive some notion of tenant storage activity from a tenant’s interactions with the data. These metrics could be derived from each tenant’s interactions with a data access layer that is employed by your solution (as depicted in the following diagram). With this approach, each call to acquire or manage data would be processed by a common framework that would capture and aggregate tenant storage activity. This activity would then be used to apportion costs to each tenant.</p> 
<p>&nbsp;</p> 
<p><img class="aligncenter wp-image-4958 size-full" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/08/24/CostTenant3.png" alt="" width="722" height="654" /></p> 
<p>&nbsp;</p> 
<p>Determining a tenant’s impact on the system’s storage footprint is a less dynamic process. Here, you may have data stored in some AWS services (Amazon DynamoDB, Amazon Simple Storage Service (Amazon S3), Amazon Redshift, Amazon Elastic Block Store (Amazon EBS), and so on) and you’ll need to determine what percentage of that storage belongs to each tenant. Assessing this data will typically require a process that can periodically analyze the data distribution to determine a tenant’s storage consumption. The mechanism used for this analysis will vary based on your data partitioning model and the type of storage resource being evaluated. Amazon S3 and DynamoDB, for example, would require very different strategies for analyzing tenant storage consumption.</p> 
<p>As you put these storage metrics into place, you’ll need to determine how best to aggregate these costs. Should there be one flat cost that aggregates all the aspects of storage, or should you provide a more detailed breakdown of the costs that provides access to all the dimensions of storage? There is no one right answer here. However, having the details could help inform some of the choices you might make with your architecture.</p> 
<h3>Being Good Enough</h3> 
<p>Accuracy is certainly important when you’re capturing metric data. At the same time, when working with tenant cost calculations, it’s important to remember that—in most cases—you’re not attempting to achieve a perfect level of accounting that tracks every ounce of consumption. Unless this data is directly driving billing, which it often is not, the goal is to get data that is good enough. The focus should be on building a model that accurately represents the general distribution of tenant consumption. Equipped with this data, you and the business will be in a much better position to assess the effects of the product and architecture changes you’re considering.</p> 
<p>As you start down this path, you may choose to incrementally introduce elements of metrics collection into the different aspects of your system. You may find compromises and tradeoffs along the way that can simplify your approach and still return enough data to give you a manageable level of insight into customer spending profiles.</p> 
<h3>Bonus Operational Value</h3> 
<p>The added effort to instrument your application with these tenant metrics has value beyond the economics of understanding tenant spend. The data captured can also have operational value, providing tenant-centric views into system activity that may be used to detect or troubleshoot issues that might arise.</p> 
<p>The data captured can also be used to help shape your operational policies. Suppose you see that a tenant’s activity is imposing load at a rate that is stretching the scaling policies of your environment. With the tenant view of consumption, you can see how tenant-specific usage patterns are exercising the architecture of your environment and react with more precision.</p> 
<h3>Billing Metering vs. Tenant Consumption</h3> 
<p>Metering is an essential aspect of many SaaS environments. SaaS providers will often develop a billing and tiering strategy around some dimension of consumption. These consumption dimensions cover a wide range of possibilities. Bandwidth, number of users, storage usage—these are all flavors of billing models that are used to correlate tenant activity with some billing construct.</p> 
<p>On the surface, this sounds like the same model of consumption we’ve been discussing, and there can be some conceptual overlap. However, this notion of metering is targeted at capturing just those metrics that are meant to derive a tenant’s bill. They may not map to the notion of tenant infrastructure consumption, which is focused squarely on determining the actual cost associated with each tenant’s activity. It’s essential for SaaS businesses to understand and separate these two concepts as they develop pricing and packaging models.</p> 
<h3>Correlating AWS with Billing Data</h3> 
<p>There are two parts to the tenant consumption equation. So far, we’ve focused on the instrumentation and allocation of tenant consumption. This data tells us the portion of the system’s resources that are being used by a given tenant. What it doesn’t tell you is the actual costs that a tenant is incurring. Getting to this next level of insight could be viewed as optional, but having the full picture of consumption mapped to cost represents the real payoff.</p> 
<p>Acquiring and correlating the data will require you become familiar with the AWS billing data. You’ll need to dig into your AWS bill and consider how best to correlate the detailed billing information with your consumption data. There are a number of options and approaches, ranging from a high-level allocation of overall costs to more granular, detailed mappings of line items in your bill. Generally, in the spirit of being “good enough” as outlined above, you might want to start with a fairly basic model that eliminates the need to dig into the details of AWS billing reports. Again, this is more about having some approximation of the cost—not building an accounting system.</p> 
<h3>The Business May Not Ask—But They’ll care</h3> 
<p>Often, in the rush to address customer and market needs, it’s very easy for SaaS providers to push tenant costs to the background. This might make sense in the fail fast mindset of getting a product out the door. The business is rarely going to make infrastructure costs—especially before they have lots of customers—a central part of their thinking.</p> 
<p>While tenant costs may not be at the forefront of your product strategy, the business often pays closer attention when they begin to see how this data can impact the bottom line. Once organizations see the numbers, they will begin to ask more informed questions about how new features and product strategies might impact the cost per tenant. You’ll also find that technical teams will begin to use this data to find new and creative ways to evolve an application’s architecture without over-inflating the operational costs.</p> 
<h3>Metrics Matter</h3> 
<p>Most SaaS businesses rely heavily on metrics. Having the pulse of your customer’s often-complex usage patterns is essential to understanding how to market, price, position, and build your solution. Infrastructure overhead often represents a significant percentage of a SaaS provider’s costs. So, having a precise view of how tenants are imposing load on your system gives the business and technical teams another variable that can shape the pricing and tiering strategies you choose to offer.</p> 
<p>As you look at strategies for capturing and analyzing cost metrics, you should view this as an iterative process. You can start with some very basic mechanisms to gain insights into tenant footprints that might otherwise go overlooked. Then, with time, you can evolve and mature this model to add depth to your cost analytics.</p> 
<p>The key is to bring visibility to the cost per tenant metric and make it part of the mental math of the business.</p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/apn/tag/aws-partner-solutions-architect-sa-guest-post/" rel="tag">AWS Partner Solutions Architect (SA) Guest Post</a>, <a href="https://aws.amazon.com/blogs/apn/tag/aws-saas-partner-program/" rel="tag">AWS SaaS Partner Program</a>, <a href="https://aws.amazon.com/blogs/apn/tag/partner-solutions-architect-sa-post/" rel="tag">Partner Solutions Architect (SA) Post</a>, <a href="https://aws.amazon.com/blogs/apn/tag/saas/" rel="tag">SaaS</a>, <a href="https://aws.amazon.com/blogs/apn/tag/saas-on-aws/" rel="tag">SaaS on AWS</a></span> 
</footer> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-4955');
});
</script> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">How to create an approval flow for an AWS Service Catalog product launch using AWS Lambda</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Karthik Thirugnanasambandam</span></span> | on 
<time property="datePublished" datetime="2017-08-17T09:12:06+00:00">17 AUG 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/apn/category/application-services/amazon-api-gateway-application-services/" title="View all posts in Amazon API Gateway*"><span property="articleSection">Amazon API Gateway*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/messaging/amazon-simple-notification-service-sns/" title="View all posts in Amazon Simple Notification Service (SNS)*"><span property="articleSection">Amazon Simple Notification Service (SNS)*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/management-tools/aws-cloudformation/" title="View all posts in AWS CloudFormation*"><span property="articleSection">AWS CloudFormation*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/compute/aws-lambda/" title="View all posts in AWS Lambda*"><span property="articleSection">AWS Lambda*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/management-tools/aws-service-catalog/" title="View all posts in AWS Service Catalog*"><span property="articleSection">AWS Service Catalog*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/apn/how-to-create-an-approval-flow-for-an-aws-service-catalog-product-launch-using-aws-lambda/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-4904" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-apn-blog&amp;disqus_identifier=4904&amp;disqus_title=How+to+create+an+approval+flow+for+an+AWS+Service+Catalog+product+launch+using+AWS+Lambda&amp;disqus_url=https://aws.amazon.com/blogs/apn/how-to-create-an-approval-flow-for-an-aws-service-catalog-product-launch-using-aws-lambda/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-4904');
});
</script> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><a href="http://docs.aws.amazon.com/servicecatalog/latest/adminguide/introduction.html" target="_blank" rel="noopener noreferrer">AWS Service Catalog</a> allows organizations to centrally manage commonly deployed IT services, achieve consistent governance, and help meet compliance requirements. AWS Service Catalog provides a standardized landscape for product provisioning. Users browse listings of products (services or applications) that they have access to, locate the product that they want to use, and launch it on their own as a provisioned product. The AWS Service Catalog API also provides programmatic control over all user actions.</p> 
<p>Let’s say you need to build an approval workflow for a launch request from a user. Many solutions are available that use AWS Service Catalog APIs to build complex custom workflows are available (for example, <a href="https://www.servicenow.com/" target="_blank" rel="noopener noreferrer">ServiceNow</a>). In this blog post, I will describe how to build a simple workflow approval process using AWS Lambda, Amazon API Gateway, AWS CloudFormation, and Amazon Simple Notification Service (Amazon SNS), &nbsp;from the perspective of an AWS Service Catalog administrator.</p> 
<p>To build this approval process, I’ll be using AWS CloudFormation features like <a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-waitcondition.html" target="_blank" rel="noopener noreferrer">WaitCondition</a> and <a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-waitconditionhandle.html" target="_blank" rel="noopener noreferrer">WaitHandle</a>, along with AWS Lambda as a <a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/template-custom-resources.html" target="_blank" rel="noopener noreferrer">custom resource</a> to create a simple approval workflow. This approach is beneficial if you are looking for an AWS native solution to extend existing AWS Service Catalog features. This will also help retain the AWS Service Catalog user interface for product launch.</p> 
<h3>Architecture Overview:<br /> <a href="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/08/09/servicecatalog1.png"><img class="alignnone size-full wp-image-4905" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/08/09/servicecatalog1.png" alt="" width="740" height="475" /></a></h3> 
<p>&nbsp;</p> 
<p>&nbsp;</p> 
<ol> 
<li>The user launches a product from their available product list and fills in all required data &nbsp;via the AWS Service Catalog interface. You can obtain the user’s email address through this input.</li> 
<li>For products that require administrator approval, there will be three additional CloudFormation resources: a WaitHandle, the WaitCondition, and the custom resource. The Lambda custom resource is called to notify the admin who is responsible for approving the product launch. The stack will be in a waiting state until it receives a response from the admin.</li> 
<li>The admin receives an email notification about the product launch and an approval URL to allow stack creation. The URL contains the WaitHandle pre-signed URL as a parameter for signaling the stack to continue.</li> 
<li>When the admin clicks the URL, a Lambda function behind API Gateway receives the admin approval to proceed.</li> 
<li>If the admin approves the product launch, the Lambda approval function sends the confirmation for the WaitHandle to proceed with stack creation. Otherwise, the stack is rolled back after the maximum wait time of 12 hours.</li> 
<li>The user receives either a completion or rolled back status on the AWS Service Catalog console. Additionally, the admin could reach out to the user to ask for more information on the launch request before proceeding with the approval.</li> 
</ol> 
<h3>Build Steps:</h3> 
<p>Now that we’ve covered the steps, let’s build the required resources for the approval flow. I have attached an <a href="https://s3.amazonaws.com/service-catalog-approval-flow/v1/resources_for_approval_template.yaml" target="_blank" rel="noopener noreferrer">AWS CloudFormation template</a> for your convenience so you can follow along. When you launch the template, you will be prompted to enter an email address for the approval flow. After stack completion, the following resources will be created:</p> 
<p><strong>SNS topic</strong>: An SNS topic along with the provided email subscription. You will be getting an email to confirm your subscription. Subscribe to the topic to receive messages.</p> 
<p><strong>SNS notification function</strong>: A Lambda function to send the approval mail. Whenever a new product launch requires approval, this Lambda function will be called. This function will get the WaitHandle pre-signed URL and user email address as input.</p> 
<p><strong>Approval function</strong>: A Lambda function to notify the CloudFormation stack by sending the status of the WaitHandle pre-signed URL.</p> 
<p>In addition to these resources, an API Gateway API and IAM roles will also be created.</p> 
<p>Note the ARN for the Lambda function from the output. You will need this later to test the setup.</p> 
<h3>Testing:</h3> 
<p>To test the setup, you can use the attached <a href="https://s3.amazonaws.com/service-catalog-approval-flow/v1/sample_wordpress_for_approval_template.yaml" target="_blank" rel="noopener noreferrer">sample CloudFormation template</a>. This is a standard template provided by Amazon that deploys WordPress on AWS, but I’ve modified it to introduce approval flow and added three additional resources: WaitCondition, WaitConditionHandle, and NotificationFunction.</p> 
<p>WaitCondition and WaitConditionHandle are used to pause the creation of a stack and to wait for a signal before continuing to create the stack.&nbsp;All other resources in the template depend on WaitCondition for approval status.</p> 
<pre><code class="lang-python">  WaitHandle:
Type: 'AWS::CloudFormation::WaitConditionHandle'
WaitCondition:
Type: 'AWS::CloudFormation::WaitCondition'
Properties:
Handle:
Ref: 'WaitHandle'
Timeout: '43200'</code></pre> 
<p>NotificationFunction is a custom resource that triggers the Lambda function responsible for sending approval email.</p> 
<pre><code class="lang-python">  NotificationFunction:
Type: Custom::NotificationFunction
Properties:
ServiceToken: '&lt;REPLACE YOUR LAMBDA ARN&gt;'
Region: !Ref &quot;AWS::Region&quot;
WaitUrl: !Ref WaitHandle
EmailID: !Ref UserEmail</code></pre> 
<p>You’ll need to download the template and modify the NotificationFunction resource’s ServiceToken parameter to specify the ARN you obtained in the previous section. Once you have updated the Lambda ARN, you can add this template as a new product to your existing catalog or test the template in the CloudFormation console.</p> 
<p>When the template has launched successfully, you’ll receive email requesting approval to proceed, similar to this:</p> 
<p><a href="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/08/09/servicecatalog2.png"><img class="alignnone size-full wp-image-4907" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/08/09/servicecatalog2.png" alt="" width="975" height="473" /></a></p> 
<p>When you choose the approval link, the Lambda function behind the API will send a confirmation for WaitHandle to proceed with stack creation. Otherwise, the stack will be rolled back after the maximum wait time of 12 hours.</p> 
<h3>Troubleshooting:</h3> 
<p>If you don’t receive the approval mail, check the SNS topic subscription status. Also, verify that you’ve specified the correct Lambda ARN in the template. Check Amazon CloudWatch logs for any exceptions or errors launching the stack. Additionally, you can check the following sources for general troubleshooting help with services such as Amazon SNS, API Gateway, and AWS Lambda:</p> 
<li><a href="http://docs.aws.amazon.com/sns/latest/dg/SubscribeTopic.html" target="_blank" rel="noopener noreferrer">Check your SNS Topic subscription</a></li> 
<li><a href="http://docs.aws.amazon.com/apigateway/latest/developerguide/monitoring_overview.html" target="_blank" rel="noopener noreferrer">Monitoring and Troubleshooting in API Gateway</a></li> 
<li><a href="http://docs.aws.amazon.com/lambda/latest/dg/monitoring-functions-logs.html" target="_blank" rel="noopener noreferrer">Accessing Amazon CloudWatch Logs for AWS Lambda</a></li> 
<h3>Conclusion:</h3> 
<p>You can now add a simple approval workflow to your Service Catalog stack by adding the three resources from the sample test template. For more information about managing portfolios, products, and constraints from an administrator console, check this <a href="http://docs.aws.amazon.com/servicecatalog/latest/adminguide/catalogs.html" target="_blank" rel="noopener noreferrer">documentation</a>.</p> 
<p>I hope this post and sample templates were useful in helping you extend AWS Service Catalog features. Feel free to leave your feedback or suggestions in the comments.</p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/apn/tag/apn-launches/" rel="tag">APN Launches</a>, <a href="https://aws.amazon.com/blogs/apn/tag/aws-cloudformation/" rel="tag">AWS CloudFormation</a>, <a href="https://aws.amazon.com/blogs/apn/tag/aws-lambda/" rel="tag">AWS Lambda</a>, <a href="https://aws.amazon.com/blogs/apn/tag/aws-partner-solutions-architect-sa-guest-post/" rel="tag">AWS Partner Solutions Architect (SA) Guest Post</a>, <a href="https://aws.amazon.com/blogs/apn/tag/aws-service-catalog/" rel="tag">AWS Service Catalog</a>, <a href="https://aws.amazon.com/blogs/apn/tag/aws-sns/" rel="tag">AWS SNS</a>, <a href="https://aws.amazon.com/blogs/apn/tag/partner-sa-post/" rel="tag">Partner SA Post</a>, <a href="https://aws.amazon.com/blogs/apn/tag/partner-solutions-architect-sa-post/" rel="tag">Partner Solutions Architect (SA) Post</a></span> 
</footer> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-4904');
});
</script> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">Testing AWS GameDay with the AWS Well-Architected Framework – Review</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Ian Scofield</span></span> | on 
<time property="datePublished" datetime="2017-08-15T11:14:23+00:00">15 AUG 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/apn/category/database/amazon-dynamodb/" title="View all posts in Amazon DynamoDB*"><span property="articleSection">Amazon DynamoDB*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/messaging/amazon-simple-notification-service-sns/" title="View all posts in Amazon Simple Notification Service (SNS)*"><span property="articleSection">Amazon Simple Notification Service (SNS)*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/apn/testing-aws-gameday-with-the-aws-well-architected-framework/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-4922" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-apn-blog&amp;disqus_identifier=4922&amp;disqus_title=Testing+AWS+GameDay+with+the+AWS+Well-Architected+Framework+%E2%80%93+Review&amp;disqus_url=https://aws.amazon.com/blogs/apn/testing-aws-gameday-with-the-aws-well-architected-framework/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-4922');
});
</script> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<h5><em>By Ian Scofield, Juan Villa, and Mike Ruiz</em></h5> 
<p>&nbsp;</p> 
<p>GameDay is an immersive, team-based event we’ve hosted at AWS Summits and re:Invent over the past few years. The event has teams of players settling into a challenging—and hopefully entertaining—scenario as DevOps leads at Unicorn.Rentals, a popular startup minutes away from the very public launch of a widely anticipated product. For more information, see the <a href="https://reinvent.awsevents.com/learn/gameday/" target="_blank" rel="noopener noreferrer">GameDay website</a>.</p> 
<p>Of course, we have a lot going on behind the scenes to make GameDay work. Beyond all the enthusiastic acting and silly props, you’ll find a complex AWS infrastructure that includes a live score tracking engine, a single-instance load generator capable of dynamically varying the load over the course of the game, and various command and control functions. Overall, the infrastructure is simplistic in design but complex to operate, with room for improvement by incorporating the same best practices we encourage players to adopt during the course of the game.</p> 
<p>Today, in an attempt to improve the player experience (and our quality of life), we have invited a team of AWS Partner Solutions Architects to review the GameDay architecture against a standard benchmark: the <a href="https://aws.amazon.com/architecture/well-architected/" target="_blank" rel="noopener noreferrer">AWS Well-Architected Framework</a>. The review team will work to understand the details of our architecture, ask detailed questions about our design and intent, and then deliver a document with prioritized findings.</p> 
<p>In this post, we’ll cover the initial architecture review and the findings delivered from the review team. In future posts, we will share the process of making improvements and our plans to refine our architecture through continuous improvement and collaboration with AWS Solutions Architects.</p> 
<p>&nbsp;</p> 
<h3>Architecture Overview</h3> 
<p>We began the review session by providing the review team with an architectural overview of GameDay, using diagrams and other collateral to highlight various components and relationships where appropriate. To help you follow along, here’s a summary of the high-level details we shared regarding the architecture of GameDay:</p> 
<p>The GameDay infrastructure runs in a master AWS account, with each team having their own player AWS account (Figure 1). Various components in the master account serve load to player accounts, and host other services such as the scoreboard and cost calculator.&nbsp; The master account utilizes an <a href="http://docs.aws.amazon.com/IAM/latest/UserGuide/tutorial_cross-account-with-roles.html" target="_blank" rel="noopener noreferrer">IAM Cross-Account Role</a> in each player account that gives it the required permissions to perform administrative tasks throughout the day.</p> 
<p><a href="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/08/11/GameDay1.png"><img class="size-full wp-image-4924 aligncenter" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/08/11/GameDay1.png" alt="" width="453" height="339" /></a></p> 
<p style="text-align: center"><em>Figure 1: Master – player account relationship</em></p> 
<p>The master account has the following components:</p> 
<ol> 
<li><strong>Scoreboard</strong> – This is a static site hosted in an <a href="https://aws.amazon.com/s3/" target="_blank" rel="noopener noreferrer">Amazon Simple Storage Service</a> (Amazon S3) bucket, written in JavaScript and HTML.</li> 
<li><strong>Cost calculator</strong> – In order to encourage players to take cost optimization into account, we charge players for their <a href="https://aws.amazon.com/ec2/" target="_blank" rel="noopener noreferrer">Amazon Elastic Computer Cloud</a> (Amazon EC2) utilization (as in the real world!). The cost calculator includes three AWS Lambda functions that deduct points proportional to their consumption.</li> 
<li><strong>Amazon DynamoDB</strong> – We use several <a href="https://aws.amazon.com/dynamodb/" target="_blank" rel="noopener noreferrer">Amazon DynamoDB</a> tables to hold team information, score information, generic game configuration values, and other supporting information that is used by the master account components.</li> 
<li><strong>Load generator</strong> – This is the heart of the game implementation. It is made up of a single EC2 instance. &nbsp;The load generator controls the game and initiates administrative actions. 
<ol> 
<li>When player accounts are dynamically created, a message is posted to an <a href="https://aws.amazon.com/sns/" target="_blank" rel="noopener noreferrer">Amazon Simple Notification Service</a> (Amazon SNS) topic in the master account with a notification of the account creation.&nbsp; On the load generator, PHP scripts run to do the account registration/provisioning based on the SNS messages.</li> 
<li>The load generator runs one process per team that initiates connections to the infrastructure running in each player’s account.</li> 
<li>The number of messages delivered to player accounts is scaled by creating additional processes per team within this load generator instance.</li> 
</ol> </li> 
</ol> 
<p>Figure 2 shows a high-level overview of the master account architecture:</p> 
<p><a href="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/08/11/GameDay2.png"><img class="size-full wp-image-4925 aligncenter" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/08/11/GameDay2.png" alt="" width="540" height="463" /></a></p> 
<p style="text-align: center"><em>Figure 2: Initial architecture</em></p> 
<p>&nbsp;</p> 
<h3>Deep Dive</h3> 
<p>Once they understood the architecture, the review team began a deep dive and asked clarifying questions on the various components based on the questions in the appendix of the <a href="https://d0.awsstatic.com/whitepapers/architecture/AWS_Well-Architected_Framework.pdf" target="_blank" rel="noopener noreferrer">Well-Architected Framework whitepaper</a>.&nbsp; In particular, they were very interested in manual operations (especially in the operation of the load generator), disaster recovery (specifically the recovery timing for assets lost before an event), and the security of the application as a whole (specifically the security of customer data and credentials). On the whole, the review was comprehensive and took approximately three hours to complete.</p> 
<h3>Review Findings</h3> 
<p>The review team consolidated the data and provided us with a written report that outlined the various findings.&nbsp; In addition, they provided us with notes and prioritized recommendations for each finding, which would serve as a starting point for us to develop our remediation plan.</p> 
<p>Looking at GameDay through the lens of the Well-Architected Framework, it was obvious that there were many opportunities for improvement. The AWS review team prioritized the findings into two sets: critical and recommended. Most of the findings were classified as recommended—these don’t pose an immediate risk and will be incorporated into our roadmap.&nbsp; However, the three elements that were identified as critical needed to be addressed immediately.</p> 
<p>Here’s the text of the findings from the review team:</p> 
<p>&nbsp;</p> 
<hr /> 
<b></b> 
<h3>SEC11. How are you managing keys?</h3> 
<p><strong>Critical finding:</strong></p> 
<p>The legacy administrative scripts for GameDay use AWS access keys and secret access keys and are stored in plain text in an Amazon DynamoDB table.</p> 
<p><strong>Notes:</strong></p> 
<p>The legacy administrative scripts require the use of an AWS access key and secret access key in order to interact with the AWS API on the player’s account, and do not support cross-account roles. Currently, these keys are being stored in plain text in an Amazon DynamoDB table, which the scripts query to retrieve the keys.&nbsp; AWS access keys and secret access keys are long-lived credentials that do not expire until they are explicitly revoked. Storing them in plain text increases the probability of the keys being compromised, and in the current design, any person with read access to the DynamoDB table (though the application or application administrative interface, indirectly via backups or logs, or directly via the AWS DynamoDB API) can read and exploit the keys.</p> 
<p><strong>Recommendation:</strong></p> 
<p>Modify the legacy administrative scripts to support cross-account roles in order to avoid the need to store and use AWS access keys and secret access Keys.</p> 
<h3>REL 7. How are you planning for disaster recovery?</h3> 
<p><strong>Critical finding:</strong></p> 
<p>There is no clearly defined disaster recovery plan, recovery point objectives (RPO), or recovery time objectives (RTO).&nbsp; Additionally due to not having a plan, it cannot be periodically tested against the RPO and RTO objectives.</p> 
<p><strong>Notes:</strong></p> 
<p>GameDay was originally conceived as a set of instructions players would iteratively execute in a minimally configured account. As tooling and additional features were added over time, they have failed to step back and consider the entire stack and how to protect it from accidental, malicious, or environmental faults. Although it’s just a game, GameDay customers invest a whole day to attend and deserve as good an experience as can be delivered; having to scramble to invent a recovery process in the run-up to an event or, worse, in the middle of a live game would be a bad experience for all involved.</p> 
<p><strong>Recommendation:</strong></p> 
<ol> 
<li>Define a disaster recovery plan, including RPO and RTO.</li> 
<li>Periodically test the plan against the defined objectives.</li> 
</ol> 
<h3>REL 2. How does your system withstand component failures?</h3> 
<p><strong>Critical finding:</strong></p> 
<p>Currently the load generator is a single instance in a single <a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html" target="_blank" rel="noopener noreferrer">Availability Zone</a>, and no recovery options have been configured.</p> 
<p><strong>Notes:</strong></p> 
<p>If this load generator instance were to fail or become unavailable either due to a hardware fault or in the (unlikely) event of an Availability Zone failure, the game would no longer be able to continue, because there is no automated process to recover the failed node.&nbsp; The load generator is currently not in an <a href="http://docs.aws.amazon.com/autoscaling/latest/userguide/AutoScalingGroup.html" target="_blank" rel="noopener noreferrer">Auto Scaling group</a>, nor does it have <a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-recover.html" target="_blank" rel="noopener noreferrer">EC2 instance recovery</a> configured.&nbsp; Additionally, the instance has been configured manually and doesn’t contain all the necessary settings and scripts. &nbsp;Lastly, all state is stored locally on the instance and will need to be broken out when implementing a multi-instance architecture.&nbsp; By storing state externally, this will also alleviate the issue of losing state in the event of an instance failure.</p> 
<p><strong>Recommendation:</strong></p> 
<ol> 
<li>Implement an EC2 Auto Scaling group with a launch configuration by creating an Amazon Machine Image (AMI) which self-contains all necessary components.&nbsp; Optionally, you can utilize user data to pull down all necessary components.</li> 
<li>Configure your Auto Scaling group to span multiple Availability Zones to increase the resiliency and fault tolerance of your architecture.</li> 
<li>Make your instances stateless to reduce the chance of losing information in the event of a failure.</li> 
</ol> 
<p>&nbsp;</p> 
<hr /> 
<h3></h3> 
<h3>Next Steps</h3> 
<p>Now that the review team has given us this feedback and the list of critical items that need to be resolved, we need to construct our remediation plan to correct these deficiencies.&nbsp; In our next blog post, we’ll go through this remediation plan and explain in depth how we plan to correct these items to improve the security and reliability of the GameDay application.</p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/apn/tag/aws-partner-solutions-architect-sa-guest-post/" rel="tag">AWS Partner Solutions Architect (SA) Guest Post</a>, <a href="https://aws.amazon.com/blogs/apn/tag/partner-solutions-architect-sa-post/" rel="tag">Partner Solutions Architect (SA) Post</a></span> 
</footer> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-4922');
});
</script> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">Announcing the Addition of four AWS Management Tools to the AWS Service Delivery Program</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Lauren Small</span></span> | on 
<time property="datePublished" datetime="2017-08-14T13:30:14+00:00">14 AUG 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/apn/category/management-tools/amazon-ec2-systems-manager/" title="View all posts in Amazon EC2 Systems Manager*"><span property="articleSection">Amazon EC2 Systems Manager*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/management-tools/aws-cloudformation/" title="View all posts in AWS CloudFormation*"><span property="articleSection">AWS CloudFormation*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/management-tools/aws-cloudtrail/" title="View all posts in AWS CloudTrail*"><span property="articleSection">AWS CloudTrail*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/management-tools/aws-config/" title="View all posts in AWS Config*"><span property="articleSection">AWS Config*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/management-tools/" title="View all posts in Management Tools*"><span property="articleSection">Management Tools*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/apn/announcing-the-addition-of-four-aws-management-tools-to-the-aws-service-delivery-program/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-4928" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-apn-blog&amp;disqus_identifier=4928&amp;disqus_title=Announcing+the+Addition+of+four+AWS+Management+Tools+to+the+AWS+Service+Delivery+Program&amp;disqus_url=https://aws.amazon.com/blogs/apn/announcing-the-addition-of-four-aws-management-tools-to-the-aws-service-delivery-program/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-4928');
});
</script> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<h6>By Ben Perak, APN Global Segment Leader</h6> 
<p>&nbsp;</p> 
<p><a href="https://aws.amazon.com/partners/service-delivery/" target="_blank" rel="noopener noreferrer">The Amazon Web Services (AWS) Service Delivery Program</a> launched in November 2016 with one simple goal: to help customers easily identify AWS Partner Network (APN) Partners with a successful track record of delivering specific AWS services and a demonstrated ability to provide expertise in a particular service or skill area.</p> 
<p>Nineteen AWS services are included in the AWS Service Delivery Program, including many database services, compute services, content delivery services, security services, serverless computing services, and analytics services. This program also highlights APN Partners who deliver workloads in the AWS GovCloud (US) Region.</p> 
<p>Today, we’re excited to announce the addition of four AWS Management Tools to the program: AWS CloudFormation, Amazon EC2 Systems Manager, AWS Config and AWS CloudTrail.</p> 
<p><a href="https://aws.amazon.com/partners/service-delivery/" target="_blank" rel="noopener noreferrer"><img class="size-full wp-image-4936 aligncenter" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/08/12/800x200_Management-01.png" alt="" width="3334" height="834" /></a></p> 
<h3>Raising the Bar in Cloud Management with AWS Management Tools Service Delivery Partners</h3> 
<p>Cloud operations are quickly shifting from ‘How do I do it’ to ‘How do I do it BETTER.’ That is why AWS has developed an extensive portfolio of <a href="https://aws.amazon.com/products/management/?nc2=h_l3_db" target="_blank" rel="noopener noreferrer">Management Tools</a> that provide APN Partners and customers with leading cloud-management capabilities. These services –whether used individually or combined as an end-to-end solution—provide cloud operations teams with the solutions they need to keep pace with their agile businesses. Whether it is provisioning resources or a group of resources called stacks via AWS CloudFormation, pushing OS patches at scale with Amazon EC2 Systems Manager, tracking configuration changes in a highly regulated environment using AWS Config, or keeping track of user activity with AWS CloudTrail—these services have you covered. Combined with our APN Partners’ deep domain knowledge, customers can be assured they are getting a world class cloud management solution.</p> 
<blockquote> 
<p>“AWS Management Tools solutions let our customers access the big advantage of cloud: the ability to provision, query and compare the current to desired state,” says Flux7 Chief Technology Officer Ali Hussain. “These services allow us to easily move from an early stage proof of concept to an enterprise-ready product, adding in compliance, security, and long-term maintenance controls.”</p> 
</blockquote> 
<h3>Congratulations to our Launch Partners:</h3> 
<p>The following APN Consulting Partners have demonstrated their ability to raise the bar in delivering results with these services and have become Management Tools Service Delivery launch partners:</p> 
<h4><a href="https://aws.amazon.com/cloudformation/partners/" target="_blank" rel="noopener noreferrer">AWS CloudFormation Partners</a></h4> 
<li>2nd Watch</li> 
<li>Cognizant</li> 
<li>Datapipe</li> 
<li>Flux7</li> 
<li>Foghorn Consulting</li> 
<li>Stelligent</li> 
<h4><a href="https://aws.amazon.com/cloudtrail/partners/" target="_blank" rel="noopener noreferrer">AWS CloudTrail Partners</a></h4> 
<li>2nd Watch</li> 
<li>Cloudreach</li> 
<li>Cognizant</li> 
<li>Datapipe</li> 
<li>Flux7</li> 
<li>Foghorn Consulting</li> 
<li>Stelligent</li> 
<h4><a href="https://aws.amazon.com/config/partners/" target="_blank" rel="noopener noreferrer">AWS Config Partners</a></h4> 
<li>2nd Watch</li> 
<li>Cloudreach</li> 
<li>Cognizant</li> 
<li>Flux7</li> 
<li>Stelligent</li> 
<h4><a href="https://aws.amazon.com/ec2/systems-manager/partners/" target="_blank" rel="noopener noreferrer">Amazon EC2 Systems Manager Partners</a></h4> 
<li>Cloudnexa</li> 
<li>Cloudreach</li> 
<li>Cloudticity</li> 
<li>Flux7</li> 
<li>Logicworks</li> 
<li>REAN Cloud</li> 
<li>Stelligent</li> 
<h3>Why should APN Consulting Partners with expertise in Management Tools join?</h3> 
<p>Joining the program enables you to promote your firm as an AWS-validated expert in AWS Management tools. By becoming an AWS Management Tools Delivery Partner, with a focus on one or more of the included services, you can increase your firm’s visibility to customers seeking your type of expertise through a number of channels, such as the AWS Service Delivery website. Additionally, you’ll be distinguished as an expert in the applicable service in the Partner Solutions Finder and will be featured on the services partner page.</p> 
<h3>What are the requirements?</h3> 
<p>In addition to meeting the minimum requirements of the program listed on <a href="https://aws.amazon.com/partners/service-delivery/" target="_blank" rel="noopener noreferrer">this page</a>, your company must pass service-specific verification of customer references and a technical review. This instills confidence in prospective customers that they are working with partners who provide recent and relevant experience.</p> 
<h3>Want to learn more?</h3> 
<p>Learn more about the Service Deliver program and the partners participating in it by visiting the <a href="https://aws.amazon.com/partners/service-delivery/" target="_blank" rel="noopener noreferrer">Service Delivery Program homepage</a>. If you are a partner and would like to join the AWS Service Delivery Program, apply within the <a href="https://partnercentral.awspartner.com/apex/partnerAccount" target="_blank" rel="noopener noreferrer">APN Portal</a>.</p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/apn/tag/apn-launch/" rel="tag">APN Launch</a>, <a href="https://aws.amazon.com/blogs/apn/tag/apn-launches/" rel="tag">APN Launches</a>, <a href="https://aws.amazon.com/blogs/apn/tag/aws-service-delivery-program/" rel="tag">AWS Service Delivery Program</a>, <a href="https://aws.amazon.com/blogs/apn/tag/aws-summits/" rel="tag">AWS Summits</a></span> 
</footer> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-4928');
});
</script> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">Meet our Financial Services Competency Partners at the AWS New York Summit</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Lauren Small</span></span> | on 
<time property="datePublished" datetime="2017-08-11T13:50:50+00:00">11 AUG 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/apn/category/apn-launches/" title="View all posts in APN Launches"><span property="articleSection">APN Launches</span></a></span> | 
<a href="https://aws.amazon.com/blogs/apn/meet-our-financial-services-competency-partners-at-the-aws-new-york-summit/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<h6><em>By Renata Melnyk, AWS Financial Services Competency Program Manager</em></h6> 
<p>&nbsp;</p> 
<p>AWS is enabling scalable, flexible, and cost-effective solutions for banking and payments, capital markets, and insurance organizations of all sizes, from startups to global enterprises. To support the seamless integration and deployment of these solutions, AWS established the <a href="https://aws.amazon.com/financial-services/partner-solutions/" target="_blank" rel="noopener noreferrer">Financial Services Partner Competency Program</a> to identify AWS Partner Network (APN) Consulting and Technology partners with deep industry experience to assist our customers in their migration to the AWS Cloud. AWS Financial Services Competency Partners have demonstrated industry expertise, readily implemented solutions that align with AWS architectural best practices, and have AWS-certified staff.</p> 
<p>This year at the <a href="https://aws.amazon.com/summits/new-york/" target="_blank" rel="noopener noreferrer">AWS NY Summit</a>, some of our AWS Competency Partners are demonstrating the unique and innovative work they’ve done with customers. If you are attending the NY Summit on August 14th, don’t miss these sessions:</p> 
<p>&nbsp;</p> 
<h3>AWS Financial Services Competency Partners and the 2017 AWS New York Summit</h3> 
<p>&nbsp;</p> 
<h4>Summit Keynote – FICO</h4> 
<p>Our AWS Financial Services Competency Partner, FICO will be presenting during the Summit keynote this year. FICO’s CIO Claus Moldt, will speak about how the company uses data, advanced analytics, and mathematical algorithms to help clients transform their business. FICO is a leading analytics software company, helping businesses in more than 90 countries make better decisions that drive higher levels of growth, profitability, and customer satisfaction.</p> 
<p>As an APN Technology Partner, FICO was also one of the first APN Partners to achieve the <a href="https://aws.amazon.com/financial-services/partner-solutions/" target="_blank" rel="noopener noreferrer">AWS Financial Services Competency</a> in the Risk Management category. This category validates solutions that help financial institutions identify, model, and assess risk; ensure monitoring and compliance with industry regulations; or help in surveillance or fraud monitoring.</p> 
<h4></h4> 
<h4>Migration Journey of AIG’s Global Claims Web Application from Mainframe to Public Cloud – Deloitte</h4> 
<p>The New York Summit will also feature AWS Financial Services Competency Partners through sessions, such as <a href="https://awsnyc17.smarteventscloud.com/connect/agenda.ww" target="_blank" rel="noopener noreferrer">Migration Journey of AIG’s Global Claims Web Application from Mainframe to Public Cloud</a>, with speakers from AWS, AIG, and Deloitte.</p> 
<p>This session will detail the successful migration of a critical AIG business application from mainframe to the cloud. Global Insurance companies such as AIG are taking the lead in ensuring that their business applications are agile and cost efficient. AWS provided the necessary services to enable AIG to architect an optimum solution to migrate their application from private data centers to AWS. AIG collaborated with Deloitte, AWS Financial Services Competency and Premier APN Consulting Partner, and AWS teams to enable successful execution of the initiative, which entailed an end-to-end application migration with outcomes that included operational cost optimization, enhanced application performance, and flexibility improvements. AWS offered a variety of architectural choices, allowing the AIG project teams to structure a migration in the most effective way. The migration and right-sizing helped AIG’s application team realize substantial cost savings through the reduction of compute costs and reduction of infrastructure footprint, which has lowered operation costs. Over the course of 12 months, the program team developed and implemented a migration roadmap, a solution architecture leveraging AWS cloud native services, a testing strategy, operationalization for production, and a cutover plan.</p> 
<h4></h4> 
<h4>Machine Learning in Capital Markets – IHS Markit</h4> 
<p>Financial services companies are using machine learning to reduce fraud, streamline processes, and improve their bottom line. AWS provides tools that help them easily use AI tools like MXNet and Tensor Flow to perform predictive analytics, clustering, and more advanced data analyses. If you’re at the New York Summit, <a href="https://awsnyc17.smarteventscloud.com/connect/agenda.ww" target="_blank" rel="noopener noreferrer">stop by this session</a> to learn how IHS Markit, an Advanced APN Technology Partner and AWS Financial Services Competency Partner, has used machine learning on AWS to help global banking institutions manage their commodities portfolios. You will also learn how the Amazon Machine Learning service can take the hassle out of AI.</p> 
<p>To learn more about AWS Financial Services Competency Partners, please visit our <a href="https://aws.amazon.com/financial-services/partner-solutions/" target="_blank" rel="noopener noreferrer">AWS Financial Services Partner Solutions page</a>.</p> 
<h4>About the AWS Competency Program</h4> 
<p>The <a href="https://aws.amazon.com/partners/competencies/" target="_blank" rel="noopener noreferrer">AWS Competency Program</a> is designed to highlight APN Partners who have demonstrated technical proficiency and proven customer success in specialized solution areas. Attaining an AWS Competency allows partners to differentiate themselves to customers by showcasing expertise in a specific solution area.</p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/apn/tag/apn-competency-partner/" rel="tag">APN Competency Partner</a>, <a href="https://aws.amazon.com/blogs/apn/tag/aws-competency-partners/" rel="tag">AWS Competency Partners</a>, <a href="https://aws.amazon.com/blogs/apn/tag/aws-summits/" rel="tag">AWS Summits</a>, <a href="https://aws.amazon.com/blogs/apn/tag/financial-services/" rel="tag">Financial Services</a></span> 
</footer> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">Get AWS Certified at the AWS Summit – New York</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Lauren Small</span></span> | on 
<time property="datePublished" datetime="2017-08-08T09:39:12+00:00">08 AUG 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/apn/category/apn-launches/" title="View all posts in APN Launches"><span property="articleSection">APN Launches</span></a></span> | 
<a href="https://aws.amazon.com/blogs/apn/get-aws-certified-at-the-aws-summit-new-york/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-4897" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-apn-blog&amp;disqus_identifier=4897&amp;disqus_title=Get+AWS+Certified+at+the+AWS+Summit+%E2%80%93+New+York&amp;disqus_url=https://aws.amazon.com/blogs/apn/get-aws-certified-at-the-aws-summit-new-york/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-4897');
});
</script> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<h5><em>Post by Lisa Learoyd, Head of AWS Global Events</em></h5> 
<p>&nbsp;</p> 
<h3>Join us at the AWS Summit – New York</h3> 
<p>Join us for the AWS Summit—New York on August 14 at the Javits Center to get access to AWS education, training, and certification exams. <a href="https://aws.amazon.com/summits/new-york" target="_blank" rel="noopener noreferrer">Register</a> for the AWS Summit for free.</p> 
<p>AWS Training can help APN Partners develop deeper AWS knowledge and skills to more effectively help customers leverage AWS, and AWS Certifications can help you gain visibility and credibility for your proven experience working with AWS. Certifications also help fulfill <a href="https://aws.amazon.com/partners/consulting/" target="_blank" rel="noopener noreferrer">APN Consulting Partner Requirements</a>.</p> 
<p>&nbsp;</p> 
<h3>Get AWS Certified</h3> 
<p>We are offering onsite AWS Certification exams at the AWS Summit—New York. Onsite certification exams are offered from 9am-5pm on August 14 at the AWS Summit. We encourage you to schedule your exam in advance and plan enough time to complete your exam. Associate exams take 80 minutes to complete and cost $150.00. The Professional and Specialty Exams take 170 minutes to complete and cost $300.00. Learn more about certification exams at the AWS Summit—New York <a href="https://aws.amazon.com/summits/new-york/certification/" target="_blank" rel="noopener noreferrer">here</a>.</p> 
<p>Please be aware registration for the AWS Summit—New York is required to take an onsite certification exam. Register <a href="https://aws.amazon.com/summits/new-york" target="_blank" rel="noopener noreferrer">here</a> for the summit for free.</p> 
<p><a href="https://www.aws.training/CertMetrics/Sso" target="_blank" rel="noopener noreferrer">Onsite AWS Certification Exams</a><a href="https://www.aws.training/CertMetrics/Sso" target="_blank" rel="noopener noreferrer">– Schedule your exam today</a><br /> Offered August 14</p> 
<p>Select the “AWS Summit New York” Testing Location<br /> to register</p> 
<p>&nbsp;</p> 
<h3>AWS Certification Activities</h3> 
<p>AWS Certified individuals (including those who pass an exam onsite) get access to special event benefits. Come hang out in the AWS Certification Lounge where you can re-charge and meet other certified professionals. In addition, join us for food and drinks at the AWS Certification Appreciation Reception August 14 from 6:00pm-7:00pm Learn more <a href="https://aws.amazon.com/summits/new-york/activities/" target="_blank" rel="noopener noreferrer">here</a>.</p> 
<p>We look forward to seeing you in New York!</p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/apn/tag/aws-certifications/" rel="tag">AWS Certifications</a>, <a href="https://aws.amazon.com/blogs/apn/tag/aws-events/" rel="tag">AWS Events</a>, <a href="https://aws.amazon.com/blogs/apn/tag/aws-marketing/" rel="tag">AWS Marketing</a>, <a href="https://aws.amazon.com/blogs/apn/tag/aws-summits/" rel="tag">AWS Summits</a>, <a href="https://aws.amazon.com/blogs/apn/tag/aws-training-certification/" rel="tag">AWS Training &amp; Certification</a>, <a href="https://aws.amazon.com/blogs/apn/tag/aws-training-and-certification/" rel="tag">AWS Training and Certification</a></span> 
</footer> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-4897');
});
</script> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">How Implementing a Real World Evidence Platform on AWS Drives Real World Business Value</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Pi Zonooz</span></span> | on 
<time property="datePublished" datetime="2017-08-02T14:05:50+00:00">02 AUG 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/apn/category/compute/amazon-vpc/" title="View all posts in Amazon VPC*"><span property="articleSection">Amazon VPC*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/management-tools/aws-cloudformation/" title="View all posts in AWS CloudFormation*"><span property="articleSection">AWS CloudFormation*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/apn/how-implementing-a-real-world-evidence-platform-on-aws-drives-real-world-business-value/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-4873" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-apn-blog&amp;disqus_identifier=4873&amp;disqus_title=How+Implementing+a+Real+World+Evidence+Platform+on+AWS+Drives+Real+World+Business+Value&amp;disqus_url=https://aws.amazon.com/blogs/apn/how-implementing-a-real-world-evidence-platform-on-aws-drives-real-world-business-value/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-4873');
});
</script> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><em>Guest post by Scot Johnson, a Solution Architect for ConvergeHEALTH by Deloitte, part of Deloitte Consulting LLP’s Innovation group (DCI).</em></p> 
<p>In light of new laws such as the <a href="https://www.congress.gov/bill/114th-congress/house-bill/6" target="_blank" rel="noopener noreferrer">21st Century Cures Act</a> and evolving scientific insights, life sciences companies are being pressed to demonstrate clinical value to payers and health authorities.&nbsp; As a result, life sciences companies are shifting the way they develop and bring their pharmaceutical and medical products to market through the application of Real World Evidence (RWE). In order to discover, optimize, and demonstrate the value of RWE, life sciences companies are embracing new strategies, deeper partnerships, and innovative technology solutions. Industry-wide shifts, such as the move from volume-based to value-based payment models and more personalized healthcare, have helped fuel interest in RWE to demonstrate the value of drug and device innovations.</p> 
<p>In this blog post, I will discuss the business drivers behind the rising importance of RWE to life sciences companies for research and product development, and how Deloitte’s ConvergeHEALTH Evidence Lifecycle Management Platform on the AWS Cloud enables RWE use cases to drive real world business value.</p> 
<h3></h3> 
<h3>Delivering Value to Pharmas through RWE</h3> 
<p>The biopharmaceutical landscape has transformed due to significant advancements in science, increases in the amounts and types of data, shifts in market economics, legislation, and reimbursements. The rise of data volumes and disparate data sources, including health records, lab results, sensors, images, genomics, and claims data, have resulted in a shift from traditional research and development approaches to new collaborative models that integrate non-traditional partners across geographically dispersed resources and participants. A growing number of life sciences organizations are accommodating these disruptions with scalable on-demand storage and compute capabilities necessary to accelerate the shift toward data-driven insights and end-to-end evidence management.</p> 
<p><a href="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/07/27/rwe1.png"><img class="size-full wp-image-4874 aligncenter" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/07/27/rwe1.png" alt="" width="882" height="410" /></a></p> 
<p style="text-align: center"><em>Figure 1: Business value increases as RWE is leveraged across research, clinical development, and commercialization business functions</em></p> 
<h3></h3> 
<h3>Deloitte’s ConvergeHEALTH Evidence Lifecycle Management Platform</h3> 
<p>In response to the growing demand for data-driven insights and evidence lifecycle management (ELM), Deloitte developed the ConvergeHEALTH Evidence Lifecycle Management Platform on the AWS Cloud. &nbsp;The ConvergeHEALTH ELM Platform leverages an integrated AWS Cloud environment preconfigured with the relevant data and tools. &nbsp;The ConvergeHEALTH ELM Platform consists of three main configurable layers, designed to help our clients in their efforts to quickly realize the promise of RWE and big data analytics: data layer, analysis layer, and knowledge layer.&nbsp; The platform’s flexible, modular design and open architectures empower domain experts and facilitate business function integration into existing and emerging plug-in analytic services from vendors and open source communities.</p> 
<h3></h3> 
<h3>High-Level Architecture<br /> <a href="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/07/27/rwe2.png"><img class="alignnone size-full wp-image-4875" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/07/27/rwe2.png" alt="" width="1125" height="521" /></a></h3> 
<p style="text-align: center"><em>Figure 2: Reference architecture for the ConvergeHEALTH ELM Platform</em></p> 
<p><strong>Data layer</strong> – Facilitates the organization, governance, and usability of disparate datasets in support of the life science organization’s mission.</p> 
<p><strong>Analysis layer</strong> – Houses the analytic tools and processes for data exploration and analysis.</p> 
<p><strong>Knowledge management layer</strong> – Defines and powers RWE governance policies, tools, roles, and processes across the platform.</p> 
<h3></h3> 
<h3>Platform Products and Accelerators</h3> 
<p>The ConvergeHEALTH ELM Platform includes several components to give enterprises visibility into information that exists within the organization and enable stakeholders to collaborate across their enterprise.</p> 
<p><strong>Cohort Insight</strong> – Cohort selection service (available as an API) with a web UI that allows cohort querying against datasets stored in the AWS Cloud. Allows users to iteratively apply inclusion/exclusion cohort selection criteria and facilitate interactive cohort exploration.</p> 
<p><strong>Cohort Integrator</strong> – Cohort synchronization service (available as an API) that synchronizes cohorts across multiple datasets, accelerating data exploration and reducing time to insights.</p> 
<p><strong>Data Asset Explorer &amp; Characterization Service</strong> – A microservices API that collects domain-specific dataset profiling results for data search, discovery, and profiling.</p> 
<p><strong>Research Trust for Big Data</strong> – A standards-based data linkage and semantic governance model and repository built on the big data technologies Hadoop, Hive, Impala, and Spark.&nbsp; Research Trust facilitates the organization, linkage, semantic standardization, and exploration of data across multiple datasets.</p> 
<h3></h3> 
<h3>ConvergeHEALTH Evidence Lifecycle Management Platform Implementation on AWS<br /> <a href="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/07/27/rwe3.png"><img class="size-full wp-image-4876 aligncenter" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/07/27/rwe3.png" alt="" width="1125" height="454" /></a></h3> 
<p style="text-align: center"><em>Figure 3: High-level AWS reference architecture for the ConvergeHEALTH ELM Platform</em></p> 
<p>The following section highlights some key concepts of the ConvergeHealth ELM Platform and its implementation on AWS.</p> 
<h4>Security Elements</h4> 
<p>Protecting and managing patient health information (e.g., data encryption, authorized access, transporting of patient data across networks and borders) is managed by the ConvergeHEALTH ELM Platform through AWS services.</p> 
<h4>HIPAA Considerations</h4> 
<p>AWS aligns its HIPAA risk management program with FedRAMP and NIST 800-53, which are higher security standards that map to the HIPAA Security Rule. AWS provides a standard Business Associate agreement (called the “Business Associate Addendum,” or BAA) for customers deploying on the platform. &nbsp;Customers can use any AWS service in an account designated as a HIPAA Account under the BAA, but they must only process, store, and transmit protected health information (PHI) using certain <a href="https://aws.amazon.com/compliance/hipaa-eligible-services-reference/" target="_blank" rel="noopener noreferrer">HIPAA Eligible Services</a> defined in the BAA.</p> 
<h4>Encryption</h4> 
<p>Consistent with the AWS BAA, PHI on the ConvergeHEALTH ELM Platform is encrypted both in-transit and at-rest. Data at-rest on Amazon Elastic Block Store (Amazon EBS) is encrypted using AWS Key Management Service (AWS KMS), and data in-transit is encrypted using [256-bit SSL].</p> 
<h4>Identity and Access Management</h4> 
<p>The AWS environment for the ConvergeHEALTH ELM Platform relies on AWS Identity and Access Management (IAM) to authorize, authenticate, and enforce user policies. IAM policies and roles allow resource access to be fine-tuned for the myriad roles within the enterprise.</p> 
<h3></h3> 
<h3>Configuration Management</h3> 
<h4>Virtual Private Clouds</h4> 
<p>The ConvergeHEALTH ELM Platform leverages Amazon Virtual Private Cloud (Amazon VPC), which allows customers to launch their AWS resources into a virtual network that closely resembles an on-premises environment combined with the benefits of using the scalable AWS infrastructure.</p> 
<h4>Automated Deployment</h4> 
<p>Using AWS CloudFormation templates, we’ve pre-defined and automated the deployment of the Cohort Insight application (see Figure 4). The CloudFormation template for Cohort Insight includes launch configurations and Auto Scaling groups of EC2 instances coupled with AWS Elastic Load Balancing.&nbsp; The template provides rapid, repeatable, and reliable on-demand deployment of Cohort Insight to handle unpredictable analytic workloads to reduce query response times and shorten time to insight.</p> 
<p><a href="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/07/27/rwe4.png"><img class="size-full wp-image-4877 aligncenter" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/07/27/rwe4.png" alt="" width="875" height="458" /></a></p> 
<p style="text-align: center"><em>Figure 4: AWS CloudFormation template for Cohort Insight</em></p> 
<h4>High Availability</h4> 
<p>AWS services have been designed to natively leverage multiple Availability Zones to build highly available, fault tolerant, and scalable solutions. For customers who desire highly available RWE applications for improved uptime necessary to meet internal stakeholders’ SLAs, the ConvergeHEALTH architecture can be configured with either a single AWS Region composed of multiple Availability Zones, or across multiple AWS Regions with multiple Availability Zones. Each Availability Zone consists of one or more discrete data centers with redundant power, networking, and connectivity.</p> 
<p>The ConvergeHEALTH ELM Platform also uses native service features for high-availability deployment such as the Amazon Relational Database Service (Amazon RDS) and its out-of-the-box high availability and replication features.</p> 
<h3></h3> 
<h3>Example Big Pharma Deployment</h3> 
<h4>Vision</h4> 
<p>A Big Pharma organization was seeking opportunities to shift to value-based, personalized health care to help patients live longer, healthier lives.</p> 
<h4>Cloud Strategy</h4> 
<p>Their cloud strategy provides end-to-end visibility across the information value chain with connected processes and platforms across all functions to improve R&amp;D productivity, product launch effectiveness, and overall operational excellence.</p> 
<h4>Solution</h4> 
<p>They chose the ConvergeHEALTH ELM Platform on AWS to serve as the global foundation for facilitating information discovery, access, analysis, governance, collaborations, and partnerships, both internally and externally.</p> 
<h4>Impact</h4> 
<p>The ConvergeHEALTH ELM Platform provides transparency into available data across the enterprise, facilitating the sharing of insights and enabling researchers to collaborate.&nbsp; Multiple disparate datasets are connected to gain new insights. And by developing new coordinated partner strategies, they are able to build networks of strategic partners with advanced and integrated expertise.</p> 
<h3></h3> 
<h3>Realizing the Business Benefits from RWE and Next Steps</h3> 
<p>Managing the shift from volume-based to value-based payment models and the move to personalized health care will require more agile real-world evidence capabilities along with new strategies, partnerships, and technologies. Pharmas that manage the transformative shift to operationally utilize RWE will be positioned to realize the potential and business value of RWE. Deloitte focuses on helping companies achieve these results/objectives through its relationship with AWS and the blending of our skills and capabilities to make our client’s transformative shift to RWE a manageable journey.</p> 
<p>To learn more about the ConvergeHEALTH Evidence Lifecycle Management Platform, <a href="https://www2.deloitte.com/us/en/pages/consulting/solutions/clinical-performance-data.html" target="_blank" rel="noopener noreferrer">see the ConvergeHEALTH website</a>.</p> 
<h4>About Deloitte</h4> 
<p>Deloitte professionals guide traditional health care and life sciences companies and new market entrants in navigating the complexities of the US and global health care system. As market, political, and legislative changes alter the industry, we help our clients develop innovative and practical solutions.</p> 
<p>As used in this document, “Deloitte” means Deloitte Consulting LLP, a subsidiary of Deloitte LLP. Please see <a href="http://www.deloitte.com/us/about" target="_blank" rel="noopener noreferrer">www.deloitte.com/us/</a>&nbsp;about for a detailed description of our legal structure. Certain services may not be available to attest clients under the rules and regulations of public accounting.</p> 
<p><em>The content and opinions in this blog are those of the third party author and AWS is not responsible for the content or accuracy of this post.</em></p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/apn/tag/apn-partner-guest-post/" rel="tag">APN Partner Guest Post</a>, <a href="https://aws.amazon.com/blogs/apn/tag/apn-partner-highlight/" rel="tag">APN Partner Highlight</a>, <a href="https://aws.amazon.com/blogs/apn/tag/aws-partner-solutions-architect-sa-guest-post/" rel="tag">AWS Partner Solutions Architect (SA) Guest Post</a>, <a href="https://aws.amazon.com/blogs/apn/tag/healthcare/" rel="tag">Healthcare</a>, <a href="https://aws.amazon.com/blogs/apn/tag/iam/" rel="tag">IAM</a>, <a href="https://aws.amazon.com/blogs/apn/tag/life-sciences/" rel="tag">Life Sciences</a>, <a href="https://aws.amazon.com/blogs/apn/tag/partner-sa-post/" rel="tag">Partner SA Post</a></span> 
</footer> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-4873');
});
</script> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">Getting the “Ops” Half of DevOps Right: Automation and Self-Service Infrastructure</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Barbara Kessler</span></span> | on 
<time property="datePublished" datetime="2017-08-01T17:05:02+00:00">01 AUG 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/apn/category/devops/" title="View all posts in DevOps*"><span property="articleSection">DevOps*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/apn/getting-the-ops-half-of-devops-right-automation-and-self-service-infrastructure/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-4883" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-apn-blog&amp;disqus_identifier=4883&amp;disqus_title=Getting+the+%E2%80%9COps%E2%80%9D+Half+of+DevOps+Right%3A+Automation+and+Self-Service+Infrastructure&amp;disqus_url=https://aws.amazon.com/blogs/apn/getting-the-ops-half-of-devops-right-automation-and-self-service-infrastructure/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-4883');
});
</script> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><a href="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/07/06/MSPLogoTransparent-01.png"><img class="wp-image-4714 size-medium alignleft" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/07/06/MSPLogoTransparent-01-300x180.png" alt="" width="300" height="180" /></a>Next generation Managed Services Providers (MSPs) are able to offer customers significant value today, above and beyond the basics of retroactive notifications or outsourced helpdesk services that were common with early, traditional MSPs. Today’s cloud evolved MSPs are able to drive revolutionizing business outcomes, even including DevOps transformations. This week in the MSP Partner Spotlight series, we hear from Jason McKay, CTO of Logicworks, as he writes about the importance of automation in operations and helping their customers meet their DevOps goals.</p> 
<p>&nbsp;</p> 
<p>&nbsp;</p> 
<h3>Getting the “Ops” Half of DevOps Right: Automation and Self-Service Infrastructure</h3> 
<h4>By Jason McKay, CTO of Logicworks</h4> 
<p>DevOps has been a major cultural force in IT for the past ten years. But a <a href="http://info.xmatters.com/rs/178-CPU-592/images/atlassian_devops_survey.pdf?_ga=2.9256501.1430386044.1498589892-589850621.1498589892" target="_blank" rel="noopener noreferrer">gap remains</a> between what companies expect to get out of DevOps and the day-to-day realities of working on a IT team.</p> 
<p>Over the past ten years, I’ve helped hundreds of IT teams manage a DevOps cultural shift as part of my role as CTO of Logicworks. Many of the companies we work with have established a customer-focused culture and have made some investments in application delivery and automation, such as building a CI/CD pipeline, automating code testing, and more.</p> 
<p>But the vast majority of those companies still struggle with IT operations. Their systems engineers spend far too much time putting out fires and manually building, configuring, and maintaining infrastructure. A <a href="http://www.prnewswire.com/news-releases/qualis-survey-offers-insights-about-it-challenges-in-cloud-and-devops-300423438.html" target="_blank" rel="noopener noreferrer">recent survey</a> found that it takes more than a month to deliver new infrastructure for 33 percent of companies, and more than half had no access to self-service infrastructure. The result is that systems engineers burn out quickly, developers are frustrated, and new projects are delayed. Add to the mix a constantly shifting regulatory landscape and dozens of new platforms and tools to support, and chances are that your operations team is pretty overwhelmed.</p> 
<p>Migrating to Amazon Web Services (AWS) is often the first step to improving infrastructure and security operations for DevOps teams. AWS is the foundation for infrastructure delivery for the largest and most mature DevOps teams in the world, but running IT operations on AWS the same way you did on traditional infrastructure is simply not going to work.</p> 
<h3>The Power of Automation</h3> 
<p>Transforming operations teams for DevOps begins with a cultural shift in the way engineers perceive infrastructure. You’ve no doubt heard it before: Operations can no longer be the culture of “no.” Keeping the lights on is no longer enough.</p> 
<p>The key technology and process change that supports this cultural change is infrastructure automation. If you’re already running on AWS, there is no better cloud service for building a mature infrastructure automation practice—it integrates with what your developers are doing to automate code deployment, and makes it easier for your company to launch and test new software.</p> 
<p>AWS has all the tools you need. But you also need people who know how to use those tools. That’s what Logicworks helps companies do. We are an extension of our clients’ IT teams, helping them figure out IT operations on AWS in this new world of DevOps and constant change.</p> 
<p>Our corporate history mirrors the journey most companies are going through today. Ten years ago, the engineers at Logicworks also spent most of their time nurturing physical systems back to health, responding to crises, and manually maintaining systems. When Amazon Web Services launched, we initially wondered if we would have a place in this new paradigm. Where does infrastructure maintenance fit in a world where companies want infrastructure “out of the way” of their fast-moving development teams? Then we realized that not only could we keep managing infrastructure, but we could do something an order of magnitude more sophisticated and elegant for our clients. We started to approach the business not as racking and stacking hardware, but instead using AWS to create responsive and customized infrastructure without human intervention. That really changed the business model.</p> 
<p>Today our engineers spend their time writing and maintaining automation scripts that orchestrate AWS infrastructure, not manually maintaining the thousands of instances under our control. In many ways, we have become a software company. We write custom software for each client that makes it easier for their operations teams to deliver AWS infrastructure quickly and securely. Of course we still have 24x7x365 NOC teams, networking professionals, DBAs, etc., but all of our teams approach every infrastructure problem with this question: How can we perform this (repetitive, manual) task smarter? How can we stop doing this over and over and focus on solutions that make a substantial difference for our customers?</p> 
<h3>Infrastructure Automation in Practice</h3> 
<p>Many of the best practices of software development — continuous integration, versioning, automated testing — are now the best practices of systems engineers. In enterprises that have embraced the public cloud, servers, switches, and hypervisors are now strings and brackets in JavaScript Object Notation (JSON). The scripts that spin up an instance or configure a network can be standardized, modified over time, and reused. These scripts are essentially software applications that build infrastructure and are maintained much like a piece of software. They are versioned in GitHub and engineers patch the scripts or containers, not the hardware, and test those scripts again and again on multiple projects until they are perfected.</p> 
<p><a href="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/08/01/logicworks1.png"><img class="alignnone size-full wp-image-4884" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/08/01/logicworks1.png" alt="" width="975" height="179" /></a></p> 
<p style="text-align: center"><em>An example of an instance build-out process with AWS CloudFormation and Puppet.</em></p> 
<p>In practice, infrastructure automation usually addresses four principal areas:</p> 
<li>Creating a standard operating environment or baseline infrastructure template in AWS CloudFormation that lives in a code repository and gets versioned and tested.</li> 
<li>Coordinating with security teams to automate key tools, packages, and configurations, usually in a configuration management tool like Puppet or Chef and Amazon &nbsp;EC2 Systems Manager.</li> 
<li>Delivering infrastructure templates to developers in the form of a self-service portal, such as the AWS Service Catalog.</li> 
<li>Ensuring that all templates and configurations are maintained consistently over time and across multiple environments/accounts, usually in the form of automated tests in a central utility hub that can be built with Jenkins, Amazon Inspector, AWS Config, Amazon CloudWatch, AWS Lambda, and Puppet or Chef.</li> 
<p>Together, this set of practices makes it possible for a developer to choose an AWS CloudFormation template in AWS Service Catalog, and in minutes, have a ready-to-use stack that is pre-configured with standard security tools, their desired OS, and packages. Your developers only launch approved infrastructure, never have to touch your infrastructure configuration files, and no longer wait a month to get new infrastructure. Imagine what your developers could test and accomplish when they’re not hampered by lengthy operations cycles.</p> 
<p>This system obviously has a big impact on system availability and security. If an environment fails or breaks during testing, you can just trash it and spin up another testing stack. If you need to make a change to your infrastructure, you change the AWS CloudFormation template or configuration management script, and relaunch the stack. This is the true meaning of “disposable infrastructure”, also known as “immutable infrastructure”—once you instantiate a version of the infrastructure, you never change it. Since your infrastructure is frequently replaced, the potential for outdated configurations or packages that expose security vulnerabilities is significantly reduced.</p> 
<p><a href="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/08/01/logicworks2.png"><img class="alignnone size-full wp-image-4885" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/08/01/logicworks2.png" alt="" width="975" height="308" /></a></p> 
<p style="text-align: center"><em>Example of AWS Service Catalog.</em></p> 
<p>This is why the work we do at Logicworks to automate infrastructure is so appealing to companies in risk-averse industries. Most of our customers are in healthcare, financial services, and software-as-a-service because they want infrastructure configurations to be consistently applied (and can prove that they are applied universally across multiple accounts to auditors) and changes are clearly documented in code. Automated tests ensure that any configuration change is either proactively corrected or alerts a 24&times;7 engineer.</p> 
<h3>Responsibilities and External Support</h3> 
<p>If you’re managing your own infrastructure, your operations team is responsible for everything up to (and including) the Service Catalog layer. Your developers are responsible for making code work. That creates a nice, clear line of responsibility that simplifies communication and usually makes developer and ops relationships less fraught.</p> 
<p>If you’re working with an external cloud managed service provider, look for one that prioritizes infrastructure automation. Companies that work with Logicworks appreciate that we have&nbsp; abandoned the old style of managed services. Long gone are the days when you paid a lot of money just to have a company alert you after something went wrong, or when a managed service provider was little more than an outsourced help desk. AWS fundamentally changed the way the world looks at infrastructure. AWS also has changed what companies expect from outsourced infrastructure support, and has redefined what it means to be a managed services provider. Logicworks is proud to have been among the first group of MSPs to become an audited AWS MSP Partner and to have earned the DevOps and Security Competencies, among others. We have evolved to continue to add more value to our customers and to help them achieve DevOps goals from the operations side—and not just to keep the lights on.</p> 
<p>Whether you outsource infrastructure operations or keep it in-house, the most important thing to remember is that you cannot create a culture that innovates at a higher velocity if your AWS infrastructure is built and maintained manually. Don’t ignore operations in your enthusiasm to build and automate code delivery. Prioritize automation for your operations team so that they can stop firefighting and start delivering value for your business.</p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/apn/tag/apn-consulting-partners/" rel="tag">APN Consulting Partners</a>, <a href="https://aws.amazon.com/blogs/apn/tag/apn-partner-guest-post/" rel="tag">APN Partner Guest Post</a>, <a href="https://aws.amazon.com/blogs/apn/tag/apn-partner-highlight/" rel="tag">APN Partner Highlight</a>, <a href="https://aws.amazon.com/blogs/apn/tag/aws-msp-program/" rel="tag">AWS MSP Program</a>, <a href="https://aws.amazon.com/blogs/apn/tag/aws-msps/" rel="tag">AWS MSPs</a>, <a href="https://aws.amazon.com/blogs/apn/tag/cloud-managed-services/" rel="tag">Cloud Managed Services</a>, <a href="https://aws.amazon.com/blogs/apn/tag/devops/" rel="tag">DevOps</a>, <a href="https://aws.amazon.com/blogs/apn/tag/devops-on-aws/" rel="tag">DevOps on AWS</a>, <a href="https://aws.amazon.com/blogs/apn/tag/msp-partner-spotlight/" rel="tag">MSP Partner Spotlight</a>, <a href="https://aws.amazon.com/blogs/apn/tag/msps-on-aws/" rel="tag">MSPs on AWS</a>, <a href="https://aws.amazon.com/blogs/apn/tag/partner-guest-post/" rel="tag">Partner Guest Post</a></span> 
</footer> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-4883');
});
</script> 
</article> 
<p>
© 2017, Amazon Web Services, Inc. or its affiliates. All rights reserved.
</p>

    </div>
  </div>
</div>


    <div id="footer" class="navigation hidden-print">
      <div class="container">
        <div class="row">
          <div class="col-xs-12">
            <ul class="footer-links nav navbar-nav">
              <li><a href="../aws.html">AWS</a></li>
              <li><a href="../linux.html">Linux</a></li>
              <li><a href="../docker.html">Docker</a></li>
              <li><a href="../ibmpower.html">IBM Power</a></li>
              <li><a href="blogsataws1.html">Blogs@AWS (Kindle Friendly)</a></li>
            </ul>
            <ul class="footer-links nav navbar-nav navbar-right">
              <li><a href="../comments.html">Comments?</a></li>
            </ul>
          </div>
        </div>
      </div>
    </div>
  </body>
</html>
