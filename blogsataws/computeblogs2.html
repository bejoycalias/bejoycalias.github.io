<!DOCTYPE html>
<html lang="en">
  <head>
<!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-593498H');</script>
<!-- End Google Tag Manager -->

    <meta charset="utf-8">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">

    <meta name="msapplication-config" content="/microsoft-tile.xml" />
    <meta name="theme-color" content="#ffffff">

    <meta property="og:url" content="https://bejoycalias.github.io/blogsataws/computeblogs1.html" />
    <meta property="og:site_name" content="Bejoy's TechNotes"/>
    <meta property="og:title" content="Bejoy's TechNotes - Kindle Friendly AWS Compute Blogs" />
    <meta property="og:image" content="https://bejoycalias.github.io/assets/images/og-image.png"/>
    <meta property="og:image:width" content="1200"/>
    <meta property="og:image:height" content="1200"/>
    <meta property="og:description" content="" />

    <title>Bejoy's TechNotes - Kindle Friendly AWS Compute Blogs</title>
    <link href="../assets/stylesheets/application-832aa42c.css" rel="stylesheet" />

    <!--[if lt IE 9]>
      <script src="../assets/javascripts/ie-compat-c141a02d.js"></script>
    <![endif]-->
    <script src="../assets/javascripts/application-ff53d307.js"></script>

    <!-- Typekit script to import Klavika font -->
    <script src="https://use.typekit.net/wxf7mfi.js"></script>
    <script>try{Typekit.load({ async: true });}catch(e){}</script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-100043608-1', 'auto');
  ga('send', 'pageview');

</script>

    
  </head>

  <body id="uh-oh-" class="layout-inner page-uh-oh-">
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-593498H"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->


    <div id="header" class="navigation navbar-static-top hidden-print">
      <div class="container">
        <div class="row">
          <div class="col-xs-12">
            <div class="navbar-header">
              <div class="navbar-brand">
                <a href="/">
                  <svg version="1.0" xmlns="http://www.w3.org/2000/svg" width="135.000000pt" height="50" viewbox="0 0 135.000000 45.000000" preserveaspectratio="xMidYMid meet" class="logo">

<g transform="translate(0.000000,45.000000) scale(0.100000,-0.100000)" fill="#000000" stroke="none">
<path class="text" fill="#000000" d="M527 384 c-4 -4 -7 -18 -7 -31 0 -21 4 -24 28 -21 21 2 27 8 27 28 0
18 -6 26 -20 28 -12 2 -24 0 -28 -4z"></path>
<path class="text" fill="#000000" d="M1080 335 c0 -48 2 -55 20 -55 18 0 20 7 20 55 0 48 -2 55 -20 55
-18 0 -20 -7 -20 -55z"></path>
<path class="text" fill="#000000" d="M54 357 c-2 -7 -3 -69 -2 -138 l3 -124 65 -3 c90 -3 130 20 130 77 0
29 -6 44 -20 54 -20 14 -20 15 -3 45 14 25 15 34 5 56 -6 15 -23 31 -38 36
-38 15 -134 13 -140 -3z m110 -33 c19 -7 21 -45 4 -62 -7 -7 -22 -12 -35 -12
-20 0 -23 5 -23 40 0 41 13 50 54 34z m20 -130 c19 -18 19 -20 6 -45 -8 -13
-21 -19 -45 -19 -34 0 -35 1 -35 40 0 38 2 40 29 40 16 0 37 -7 45 -16z"></path>
<path class="text" fill="#000000" d="M319 271 c-23 -24 -29 -38 -29 -74 0 -25 3 -53 6 -62 20 -50 164 -64
164 -15 0 15 -7 17 -45 12 -46 -5 -75 8 -75 34 0 11 16 14 65 14 l65 0 0 35
c0 80 -92 114 -151 56z m99 -33 c3 -15 -4 -18 -37 -18 -43 0 -50 7 -29 28 18
18 62 11 66 -10z"></path>
<path class="text" fill="#000000" d="M520 184 c0 -107 -1 -116 -20 -121 -11 -3 -20 -12 -20 -19 0 -21 76
-19 84 2 3 9 6 69 6 135 l0 119 -25 0 -25 0 0 -116z"></path>
<path class="text" fill="#000000" d="M649 271 c-24 -25 -29 -37 -29 -78 1 -70 34 -103 105 -103 55 0 95
44 95 103 0 60 -7 75 -41 92 -47 25 -96 19 -130 -14z m111 -30 c25 -48 2 -111
-40 -111 -45 0 -69 80 -34 114 21 22 61 20 74 -3z"></path>
<path class="text" fill="#000000" d="M850 287 c0 -8 16 -57 36 -110 28 -76 33 -100 25 -116 -16 -28 -14
-31 18 -31 27 0 29 4 70 123 23 67 41 128 41 135 0 6 -11 12 -24 12 -21 0 -26
-8 -41 -65 -10 -36 -21 -68 -25 -70 -3 -2 -16 27 -29 66 -19 60 -25 69 -47 69
-13 0 -24 -6 -24 -13z"></path>
<path class="text" fill="#000000" d="M1192 284 c-17 -12 -22 -24 -20 -47 2 -26 10 -36 45 -52 49 -23 59
-55 17 -55 -14 0 -34 5 -45 10 -16 9 -19 7 -19 -13 0 -17 7 -27 23 -31 69 -18
117 6 117 60 0 32 -4 37 -45 55 -60 26 -62 54 -4 46 37 -5 40 -3 37 16 -2 18
-11 23 -43 25 -25 2 -49 -3 -63 -14z"></path>
</g>
</svg>

                </a>
              </div>
              <button class="navbar-toggle" type="button">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
              </button>
            </div>
            <div class="buttons hidden-xs">
              <nav class="navigation-links" role="navigation">
                <ul class="main-links nav navbar-nav navbar-right">
                  <li><a href="../aws.html">AWS</a></li>
                  <li><a href="../linux.html">Linux</a></li>
                  <li><a href="../docker.html">Docker</a></li>
                  <li><a href="../ibmpower.html">IBM Power</a></li>
                  <li><a href="blogsataws1.html">Blogs@AWS (Kindle Friendly)</a></li>
                </ul>
              </nav>
            </div>
          </div>
        </div>
      </div>
    </div>

    <div class="sidebar-overlay"></div>

<aside class="sidebar" role="navigation">
  <div class="sidebar-header">
    <svg version="1.0" xmlns="http://www.w3.org/2000/svg" width="135.000000pt" height="42" viewbox="0 0 135.000000 45.000000" preserveaspectratio="xMidYMid meet">

<g transform="translate(0.000000,45.000000) scale(0.100000,-0.100000)" fill="#000000" stroke="none">
<path class="text" fill="#000000" d="M527 384 c-4 -4 -7 -18 -7 -31 0 -21 4 -24 28 -21 21 2 27 8 27 28 0
18 -6 26 -20 28 -12 2 -24 0 -28 -4z"></path>
<path class="text" fill="#000000" d="M1080 335 c0 -48 2 -55 20 -55 18 0 20 7 20 55 0 48 -2 55 -20 55
-18 0 -20 -7 -20 -55z"></path>
<path class="text" fill="#000000" d="M54 357 c-2 -7 -3 -69 -2 -138 l3 -124 65 -3 c90 -3 130 20 130 77 0
29 -6 44 -20 54 -20 14 -20 15 -3 45 14 25 15 34 5 56 -6 15 -23 31 -38 36
-38 15 -134 13 -140 -3z m110 -33 c19 -7 21 -45 4 -62 -7 -7 -22 -12 -35 -12
-20 0 -23 5 -23 40 0 41 13 50 54 34z m20 -130 c19 -18 19 -20 6 -45 -8 -13
-21 -19 -45 -19 -34 0 -35 1 -35 40 0 38 2 40 29 40 16 0 37 -7 45 -16z"></path>
<path class="text" fill="#000000" d="M319 271 c-23 -24 -29 -38 -29 -74 0 -25 3 -53 6 -62 20 -50 164 -64
164 -15 0 15 -7 17 -45 12 -46 -5 -75 8 -75 34 0 11 16 14 65 14 l65 0 0 35
c0 80 -92 114 -151 56z m99 -33 c3 -15 -4 -18 -37 -18 -43 0 -50 7 -29 28 18
18 62 11 66 -10z"></path>
<path class="text" fill="#000000" d="M520 184 c0 -107 -1 -116 -20 -121 -11 -3 -20 -12 -20 -19 0 -21 76
-19 84 2 3 9 6 69 6 135 l0 119 -25 0 -25 0 0 -116z"></path>
<path class="text" fill="#000000" d="M649 271 c-24 -25 -29 -37 -29 -78 1 -70 34 -103 105 -103 55 0 95
44 95 103 0 60 -7 75 -41 92 -47 25 -96 19 -130 -14z m111 -30 c25 -48 2 -111
-40 -111 -45 0 -69 80 -34 114 21 22 61 20 74 -3z"></path>
<path class="text" fill="#000000" d="M850 287 c0 -8 16 -57 36 -110 28 -76 33 -100 25 -116 -16 -28 -14
-31 18 -31 27 0 29 4 70 123 23 67 41 128 41 135 0 6 -11 12 -24 12 -21 0 -26
-8 -41 -65 -10 -36 -21 -68 -25 -70 -3 -2 -16 27 -29 66 -19 60 -25 69 -47 69
-13 0 -24 -6 -24 -13z"></path>
<path class="text" fill="#000000" d="M1192 284 c-17 -12 -22 -24 -20 -47 2 -26 10 -36 45 -52 49 -23 59
-55 17 -55 -14 0 -34 5 -45 10 -16 9 -19 7 -19 -13 0 -17 7 -27 23 -31 69 -18
117 6 117 60 0 32 -4 37 -45 55 -60 26 -62 54 -4 46 37 -5 40 -3 37 16 -2 18
-11 23 -43 25 -25 2 -49 -3 -63 -14z"></path>
</g>
</svg>

  </div>

  <ul class="nav sidebar-nav">
    <li><a href="../aws.html">AWS</a></li>
    <li><a href="../linux.html">Linux</a></li>
    <li><a href="../docker.html">Docker</a></li>
    <li><a href="../ibmpower.html">IBM Power</a></li>
    <li><a href="blogsataws1.html">Blogs@AWS (Kindle Friendly)</a></li>
  </ul>
</aside>


    <div class="container">
  <div class="row">
    <div id="docs-sidebar" class="col-sm-3 col-md-3 col-xs-12 hidden-print" role="complementary">
      <ul class="nav docs-sidenav">
      <li><a href="blogsataws1.html">Blogs @ AWS</a></li>
      <li><a href="whatsnew1.html">What's New @ AWS</a></li>
      <li><a href="mgmtblogs1.html">Management Tools Blogs @ AWS</a></li>
      <li class="active"><a href="computeblogs1.html">Compute Blogs @ AWS</a></li>
      <li><a href="devopsblogs1.html">DevOps Blogs @ AWS</a></li>
      <li><a href="secblogs1.html">Security Blogs @ AWS</a></li>
      <li><a href="apnblogs1.html">APN Blogs @ AWS</a></li>

    </ul>
    </div>

    <div id="inner" class="col-sm-9 col-md-9 col-xs-12" role="main">
<p></p>
<p><i>Contents of this page is copied directly from AWS blog sites to make it Kindle friendly. Some styles & sections from these pages are removed to render this properly in 'Article Mode' of Kindle e-Reader browser. All the contents of this page is property of AWS.</i></p>
<p><a href="computeblogs1.html">Page 1</a>|<a href="computeblogs2.html">Page 2</a>|<a href="computeblogs3.html">Page 3</a>|<a href="computeblogs4.html">Page 4</a></p>
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<meta property="image" content="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/24/ECS_social_loading.png" /> 
<b class="lb-b blog-post-title" property="name headline">Building Blocks of Amazon ECS</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">tiffany jernigan</span></span> | on 
<time property="datePublished" datetime="2018-01-24T13:57:33+00:00">24 JAN 2018</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/compute/category/compute/amazon-ec2-container-service/" title="View all posts in Amazon EC2 Container Service*"><span property="articleSection">Amazon EC2 Container Service*</span></a>, <a href="https://aws.amazon.com/blogs/compute/category/compute/amazon-ec2/" title="View all posts in Amazon EC2*"><span property="articleSection">Amazon EC2*</span></a>, <a href="https://aws.amazon.com/blogs/compute/category/amazon-ecs/" title="View all posts in Amazon ECS"><span property="articleSection">Amazon ECS</span></a>, <a href="https://aws.amazon.com/blogs/compute/category/compute/aws-fargate/" title="View all posts in AWS Fargate"><span property="articleSection">AWS Fargate</span></a></span> | 
<a href="https://aws.amazon.com/blogs/compute/building-blocks-of-amazon-ecs/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-3710" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-compute&amp;disqus_identifier=3710&amp;disqus_title=Building+Blocks+of+Amazon+ECS&amp;disqus_url=https://aws.amazon.com/blogs/compute/building-blocks-of-amazon-ecs/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-3710');
});
</script> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p>So, what’s <a href="https://aws.amazon.com/ecs/">Amazon Elastic Container Service (ECS)</a>? ECS is a managed service for running containers on AWS, designed to make it easy to run applications in the cloud without worrying about configuring the environment for your code to run in. Using ECS, you can easily deploy containers to host a simple website or run complex distributed microservices using thousands of containers.</p> 
<p>Getting started with ECS isn’t too difficult. To fully understand how it works and how you can use it, it helps to understand the basic building blocks of ECS and how they fit together!</p> 
<b style="font-size: 2.4rem;color: #153655;margin-bottom: -.6em">Amazon EC2 building blocks</b> 
<p>We currently provide two launch types: EC2 and <a href="https://aws.amazon.com/fargate/">Fargate</a>. With Fargate, the&nbsp;<a href="https://aws.amazon.com/ec2">Amazon EC2</a>&nbsp;instances are abstracted away and managed for you. Instead of worrying about ECS container instances, you can just worry about tasks. In this post, the infrastructure components used by ECS that&nbsp;are&nbsp;handled by Fargate are marked with a *.</p> 
<b><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/23/region-az-instance2sm.png" /></b> 
<b style="color: #153655;margin-bottom: -.6em">Instance*</b> 
<p><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/Instances.html">EC2 instances</a> are good ol’ virtual machines (VMs). And yes, don’t worry, you can connect to them (via SSH). Because customers have varying needs in memory, storage, and computing power, many different <a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-types.html">instance types</a> are offered. Just want to run a small application or try a <a href="https://aws.amazon.com/free/">free trial</a>? Try t2.micro. Want to run memory-optimized workloads? R3 and X1 instances are a couple options. There are many more instance types as well, which cater to various use cases.</p> 
<h3 style="color: #153655;margin-bottom: -.6em">AMI*</h3> 
<p>Sorry if you wanted to immediately march forward, but <a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instances-and-amis.html">before you create your instance</a>, you need to choose an<a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AMIs.html"> AMI</a>. An AMI stands for Amazon Machine Image. What does that mean? Basically, an AMI provides the information required to launch an instance: root volume, launch permissions, and volume-attachment specifications. You can <a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/finding-an-ami.html">find</a> and choose a Linux or Windows AMI provided by AWS, the user community, the <a href="https://aws.amazon.com/marketplace">AWS Marketplace</a> (for example, the <a href="https://aws.amazon.com/marketplace/pp/B06XS8WHGJ">Amazon ECS-Optimized AMI</a>), or you can create your own.</p> 
<b style="color: #153655;margin-bottom: -.6em">Region</b> 
<p>AWS is divided into<a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html"> regions</a> that are geographic areas around the world (for now it’s just Earth, but maybe someday…). These regions have semi-evocative names such as us-east-1 (N. Virginia), us-west-2 (Oregon), eu-central-1 (Frankfurt), ap-northeast-1 (Tokyo), etc.</p> 
<p>Each region is designed to be completely isolated from the others, and consists of multiple, distinct data centers. This creates a “blast radius” for failure so that even if an entire region goes down, the others aren’t affected. Like many AWS services, to start using ECS, you first need to decide the region in which to operate. Typically, this is the region nearest to you or your users.</p> 
<b style="color: #153655;margin-bottom: -.6em">Availability Zone</b> 
<p>AWS regions are subdivided into <a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html">Availability Zones</a>. A region has at minimum two zones, and up to a handful. Zones are <a href="https://aws.amazon.com/about-aws/global-infrastructure/">physically isolated from each other</a>, spanning one or more different data centers, but are connected through low-latency, fiber-optic networking, and share some common facilities. EC2 is designed so that the most common failures only affect a single zone to prevent region-wide outages. This means you can achieve high availability in a region by spanning your services across multiple zones and distributing across hosts.</p> 
<b style="font-size: 2.4rem;color: #153655;margin-bottom: -.6em">Amazon ECS building blocks</b> 
<b style="color: #153655;margin-bottom: -.6em"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/23/ecs-ec2-instance-sm.png" /></b> 
<b style="color: #153655;margin-bottom: -.6em">Container</b> 
<p>Well, without <a href="https://aws.amazon.com/what-are-containers/">containers</a>, ECS wouldn’t exist!</p> 
<p><strong>Are containers virtual machines?</strong><br /> Nope! Virtual machines virtualize the hardware (benefits), while containers virtualize the operating system (even more benefits!). If you look inside a container, you would see that it is made by processes running on the host, and tied together by kernel constructs like namespaces, cgroups, etc. But you don’t need to bother about that level of detail, at least not in this post!</p> 
<p><strong>Why containers?</strong><br /> Containers give you the ability to build, ship, and run your code anywhere!</p> 
<p>Before the cloud, you needed to self-host and therefore had to buy machines in addition to setting up and configuring the operating system (OS), and running your code. In the cloud, with virtualization, you can just skip to setting up the OS and running your code. Containers make the process even easier—you can just run your code.</p> 
<p>Additionally, all of the dependencies travel in a package with the code, which is called an image. This allows containers to be deployed on any host machine. From the outside, it looks like a host is just holding a bunch of containers. They all look the same, in the sense that they are generic enough to be deployed on any host.</p> 
<p>With ECS, you can easily run your containerized code and applications across a managed cluster of EC2 instances.</p> 
<p><strong>Are containers a fairly new technology?</strong><br /> The concept of containerization is not new. Its origins date back to 1979 with the creation of chroot. However, it wasn’t until the early 2000s that containers became a major technology. The most significant milestone to date was the release of <a href="http://docs.aws.amazon.com/AmazonECS/latest/developerguide/docker-basics.html">Docker</a> in 2013, which led to the popularization and widespread adoption of containers.</p> 
<p><strong>What does ECS use?</strong><br /> While other container technologies exist (LXC, rkt, etc.), because of its massive adoption and use by our customers, ECS was designed first to work natively with Docker containers.</p> 
<b style="color: #153655;margin-bottom: -.6em">Container instance*</b> 
<p>Yep, you are back to instances. An instance is just slightly more complex in the ECS realm though. Here, it is an<a href="http://docs.aws.amazon.com/AmazonECS/latest/developerguide/ECS_instances.html"> ECS container instance</a> that is an EC2 instance running the agent, has a <a href="http://docs.aws.amazon.com/AmazonECS/latest/developerguide/instance_IAM_role.html">specifically defined</a> <a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/UsingIAM.html">IAM policy and role</a>, and has been registered into your cluster.</p> 
<p>And as you probably guessed, in these instances, you are running containers.<strong>&nbsp;</strong></p> 
<h3 style="color: #153655;margin-bottom: -.6em">AMI*</h3> 
<p>These container instances can use any AMI as long as it has <a href="http://docs.aws.amazon.com/AmazonECS/latest/developerguide/container_instance_AMIs.html">the following specifications</a>: a modern Linux distribution with the agent and the Docker Daemon with any Docker runtime dependencies running on it.</p> 
<p>Want it more simplified? Well, AWS created the <a href="http://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-optimized_AMI.html">Amazon ECS-Optimized AMI</a> for just that. Not only does that AMI come preconfigured with all of the previously mentioned specifications, it’s tested and includes the recommended <a href="https://github.com/aws/amazon-ecs-init">ecs-init</a> upstart process to run and monitor the agent.</p> 
<b style="color: #153655;margin-bottom: -.6em">Cluster</b> 
<p>An <a href="http://docs.aws.amazon.com/AmazonECS/latest/developerguide/ECS_clusters.html">ECS cluster</a> is a grouping of (container) instances* (or tasks in Fargate) that lie within a single region, but can span multiple Availability Zones – it’s even a good idea for redundancy. When launching an instance (or tasks in Fargate), unless specified, it registers with the cluster named “default”. If “default” doesn’t exist, it is created. You can also scale and delete your clusters.</p> 
<b style="color: #153655;margin-bottom: -.6em">Agent*</b> 
<p>The<a href="http://docs.aws.amazon.com/AmazonECS/latest/developerguide/ECS_agent.html"> Amazon ECS container agent</a> is a <a href="https://golang.org/">Go</a> program that runs in its own container within each EC2 instance that you use with ECS. (It’s also available open source on <a href="https://github.com/aws/amazon-ecs-agent">GitHub</a>!) The agent is the intermediary component that takes care of the communication between the scheduler and your instances. Want to register your instance into a cluster? (Why wouldn’t you? A cluster is both a logical boundary and provider of pool of resources!) Then you need to run the agent on it.</p> 
<b style="color: #153655;margin-bottom: -.6em">Task</b> 
<p>When you want to start a container, it has to be part of a task. Therefore, you have to create a task first. Succinctly, tasks are a logical grouping of 1 to <em>N</em> containers that run together on the same instance, with <em>N</em> defined by you, up to 10. Let’s say you want to run a custom blog engine. You could put together a web server, an application server, and an in-memory cache, each in their own container. Together, they form a basic frontend unit.</p> 
<h3 style="color: #153655;margin-bottom: -.6em">Task definition</h3> 
<p>Ah, but you cannot create a task directly. You have to create a<a href="http://docs.aws.amazon.com/AmazonECS/latest/developerguide/task_definitions.html"> task definition</a> that tells ECS that “task definition X is composed of this container (and maybe that other container and that other container too!).” It’s kind of like an architectural plan for a city. Some other details it can include are how the containers interact, container CPU and memory constraints, and task permissions using <a href="http://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles.html">IAM roles</a>.</p> 
<p>Then you can tell ECS, “start one task using task definition X.” It might sound like unnecessary planning at first. As soon as you start to deal with multiple tasks, scaling, upgrades, and other “real life” scenarios, you’ll be glad that you have task definitions to keep track of things!</p> 
<b style="color: #153655;margin-bottom: -.6em">Scheduler*</b> 
<p>So, the <a href="http://docs.aws.amazon.com/AmazonECS/latest/developerguide/scheduling_tasks.html">scheduler</a> schedules… sorry, this should be more helpful, huh? The scheduler is part of the “hosted orchestration layer” provided by ECS. Wait a minute, what do I mean by “hosted orchestration”? Simply put, hosted means that it’s operated by ECS on your behalf, without you having to care about it. Your applications are deployed in containers running on your instances, but the managing of tasks is taken care of by ECS. One less thing to worry about!</p> 
<p>Also, the scheduler is the component that decides what (which containers) gets to run where (on which instances), according to a number of constraints. Say that you have a custom blog engine to scale for high availability. You could create a service, which by default, spreads tasks across all zones in the chosen region. And if you want each task to be on a different instance, you can use the <em>distinctInstance</em> <a href="http://docs.aws.amazon.com/AmazonECS/latest/developerguide/task-placement.html">task placement</a> constraint. ECS makes sure that not only this happens, but if a task fails, it starts again.</p> 
<h3 style="color: #153655;margin-bottom: -.6em">Service</h3> 
<p>To ensure that you always have your task running without managing it yourself, you can create a <a href="http://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs_services.html">service</a> based on the task that you defined and ECS ensures that it stays running. A service is a special construct that says, “at any given time, I want to make sure that <em>N</em> tasks using task definition X1 are running.” If <em>N</em>=1, it just means “make sure that this task is running, and restart it if needed!” And with <em>N</em>&gt;1, you’re basically scaling your application until you hit <em>N</em>, while also ensuring each task is running.</p> 
<b style="font-size: 2.4rem;color: #153655;margin-bottom: -.6em">So, what now?</b> 
<p>Hopefully you, at the very least, learned a tiny something. All comments are very welcome!</p> 
<p>Want to discuss ECS with others? Join the <a href="https://join.slack.com/t/amazon-ecs/shared_invite/enQtMjQ3OTk4NTM3ODQyLWViNjhhMDBkM2VmMGRkYzMwOGMxNmU3ODBiYmQyZDk0OTlkMWYxNDJjNzJjMWYyNWY0ZWE4YmMzNmNlNGY0YWU">amazon-ecs</a> slack group, which members of the community created and manage.</p> 
<p>Also, if you’re interested in learning more about the core concepts of ECS and its relation to EC2, here are some resources:</p> 
<p><strong>Pages</strong><br /> <a href="https://aws.amazon.com/ecs/">Amazon ECS landing page<br /> </a><a href="https://aws.amazon.com/fargate/">AWS Fargate landing page<br /> </a><a href="https://aws.amazon.com/ecs/getting-started/">Amazon ECS Getting Started</a><br /> <a href="https://github.com/nathanpeck/awesome-ecs">Nathan Peck’s AWSome ECS</a></p> 
<p><strong>Docs</strong><br /> <a href="https://aws.amazon.com/documentation/ec2/">Amazon EC2</a><br /> <a href="https://aws.amazon.com/documentation/ecs/">Amazon ECS</a></p> 
<p><strong>Blogs</strong><br /> <a href="https://aws.amazon.com/blogs/compute/category/amazon-ecs/">AWS Compute Blog</a><br /> <a href="https://aws.amazon.com/blogs/aws/category/ec2-container-service/">AWS Blog</a></p> 
<p><strong>GitHub code</strong><br /> <a href="https://github.com/aws/amazon-ecs-agent">Amazon ECS container agent</a><br /> <a href="https://github.com/aws/amazon-ecs-cli">Amazon ECS CLI</a></p> 
<p><strong>AWS videos</strong><br /> <a href="https://www.youtube.com/watch?v=eq4wL2MiNqo&amp;list=PLhr1KZpdzukef_4labkwEs9CbK-MvReKS">Learn Amazon ECS</a><br /> <a href="https://www.youtube.com/user/AmazonWebServices/">AWS videos</a><br /> <a href="https://www.youtube.com/playlist?list=PLhr1KZpdzukeUoelFoS68SRfY6pA_Ib6A">AWS webinars</a></p> 
<p>&nbsp;</p> 
<p>— tiffany</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/24/tiffany-120x120bw.png" /></p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/24/twitter-icon-8-15x15.png">@tiffanyfayj</a></p> 
<p>&nbsp;</p> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-3710');
});
</script> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<meta property="image" content="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/17/ECS_windows_container-two.png" /> 
<b class="lb-b blog-post-title" property="name headline">Migrating .NET Classic Applications to Amazon ECS Using Windows Containers</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Sundar Narasiman</span></span> | on 
<time property="datePublished" datetime="2018-01-18T12:46:31+00:00">18 JAN 2018</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/compute/category/compute/amazon-ec2-container-registry/" title="View all posts in Amazon EC2 Container Registry*"><span property="articleSection">Amazon EC2 Container Registry*</span></a>, <a href="https://aws.amazon.com/blogs/compute/category/compute/amazon-ec2-container-service/" title="View all posts in Amazon EC2 Container Service*"><span property="articleSection">Amazon EC2 Container Service*</span></a>, <a href="https://aws.amazon.com/blogs/compute/category/amazon-ecs/" title="View all posts in Amazon ECS"><span property="articleSection">Amazon ECS</span></a></span> | 
<a href="https://aws.amazon.com/blogs/compute/migrating-net-classic-applications-to-amazon-ecs-using-windows-containers/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-3685" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-compute&amp;disqus_identifier=3685&amp;disqus_title=Migrating+.NET+Classic+Applications+to+Amazon+ECS+Using+Windows+Containers&amp;disqus_url=https://aws.amazon.com/blogs/compute/migrating-net-classic-applications-to-amazon-ecs-using-windows-containers/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-3685');
});
</script> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><em>This post contributed by&nbsp;Sundar Narasiman, Arun Kannan, and Thomas Fuller.</em></p> 
<p>AWS <a href="https://aws.amazon.com/about-aws/whats-new/2017/12/amazon-ecs-support-for-windows-server-containers-ga/">recently announced</a> the general availability of Windows container management for Amazon Elastic Container Service (<a href="https://aws.amazon.com/ecs">Amazon ECS</a>). Docker containers and Amazon ECS make it easy to run and scale applications on a virtual machine by abstracting the complex cluster management and setup needed.</p> 
<p>Classic .NET applications are developed with .NET Framework 4.7.1 or older and can run only on a Windows platform. These include Windows Communication Foundation (WCF), ASP.NET Web Forms, and an ASP.NET MVC web app or web API.</p> 
<b>Why classic ASP.NET?</b> 
<p>ASP.NET MVC 4.6 and older versions of ASP.NET occupy a significant footprint in the enterprise web application space. As enterprises move towards microservices for new or existing applications, containers are one of the stepping stones for migrating from monolithic to <a href="https://aws.amazon.com/microservices">microservices</a> architectures. Additionally, the support for Windows containers in Windows 10, Windows Server 2016, and Visual Studio Tooling support for Docker simplifies the containerization of ASP.NET MVC apps.</p> 
<b>Getting started</b> 
<p>In this post, you pick an ASP.NET 4.6.2 MVC application and get step-by-step instructions for migrating to ECS using Windows containers. The detailed steps, AWS CloudFormation template, Microsoft Visual Studio solution, ECS service definition, and ECS task definition are available in the <a href="https://github.com/aws-samples/aws-ecs-windows-aspnet">aws-ecs-windows-aspnet</a> GitHub repository.</p> 
<p>To help you getting started running Windows containers, here is the reference architecture for Windows containers on GitHub: <a href="https://github.com/aws-samples/ecs-refarch-cloudformation-windows">ecs-refarch-cloudformation-windows</a>. This reference architecture is the layered CloudFormation stack, in that it calls the other stacks to create the environment. The CloudFormation YAML template in this reference architecture is referenced to create a single JSON CloudFormation stack, which is used in the steps for the migration.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/17/aspdotNet_1.png" /></p> 
<b>Steps for Migration</b> 
<p>The code and templates to implement this migration can be found on GitHub: <a href="https://github.com/aws-samples/aws-ecs-windows-aspnet">https://github.com/aws-samples/aws-ecs-windows-aspnet</a>.</p> 
<ol> 
<li>Your development environment needs to have the latest version and updates for Visual Studio 2017, Windows 10, and Docker for Windows Stable.<img width="100%" src="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/17/aspdotNet_2.png" /></li> 
<li>Next, containerize the ASP.NET application and test it locally. The size of Windows container application images is generally larger compared to Linux containers. This is because the base image of the Windows container itself is large in size, typically greater than 9 GB.<img width="100%" src="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/17/aspdotNet_3.png" /></li> 
<li>After the application is containerized, the container image needs to be pushed to Amazon Elastic Container Registry (<a href="https://aws.amazon.com/ecr">Amazon ECR</a>). Images stored in ECR are compressed to improve pull times and reduce storage costs. In this case, you can see that ECR compresses the image to around 1 GB, for an optimization factor of 90%.<img width="100%" src="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/17/aspdotNet_4.png" /></li> 
<li>Create a CloudFormation stack using the template in the ‘CloudFormation template’ folder. This creates an ECS service, task definition (referring the containerized ASP.NET application), and other related components mentioned in the ECS reference architecture for Windows containers.<img width="100%" src="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/17/aspdotNet_5.png" /></li> 
<li>After the stack is created, verify the successful creation of the ECS service, ECS instances, running tasks (with the threshold mentioned in the task definition), and the Application Load Balancer’s successful health check against running containers.<img width="100%" src="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/17/aspdotNet_6.png" /></li> 
<li>Navigate to the Application Load Balancer URL and see the successful rendering of the containerized ASP.NET MVC app in the browser.</li> 
</ol> 
<b>Key Notes</b> 
<li>Generally, Windows container images occupy large amount of space (in the order of few GBs).</li> 
<li>All the task definition parameters for Linux containers are not available for Windows containers. For more information, see <a href="http://docs.aws.amazon.com/AmazonECS/latest/developerguide/windows_task_definitions.html">Windows Task Definitions</a>.</li> 
<li>An Application Load Balancer can be configured to route requests to one or more ports on each container instance in a cluster. The dynamic port mapping allows you to have multiple tasks from a single service on the same container instance.</li> 
<li>IAM roles for Windows tasks require extra configuration. For more information, see <a href="http://docs.aws.amazon.com/AmazonECS/latest/developerguide/windows_task_IAM_roles.html">Windows IAM Roles for Tasks</a>. For this post, configuration was handled by the CloudFormation template.</li> 
<li>The ECS container agent log file can be accessed for troubleshooting Windows containers: <code class="lang-bash">C:\ProgramData\Amazon\ECS\log\ecs-agent.log</code></li> 
<b>Summary</b> 
<p>In this post, you migrated an ASP.NET MVC application to ECS using Windows containers.</p> 
<p>The logical next step is to automate the activities for migration to ECS and build a fully automated continuous integration/continuous deployment (CI/CD) pipeline for Windows containers. This can be orchestrated by leveraging services such as AWS CodeCommit, AWS CodePipeline, AWS CodeBuild, Amazon ECR, and Amazon ECS. You can learn more about how this is&nbsp;done in the <a href="https://aws.amazon.com/blogs/compute/set-up-a-continuous-delivery-pipeline-for-containers-using-aws-codepipeline-and-amazon-ecs/">Set Up a Continuous Delivery Pipeline for Containers Using AWS CodePipeline and Amazon ECS</a> post.</p> 
<p>If you have questions or suggestions, please comment below.</p> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-3685');
});
</script> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<meta property="image" content="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/17/nlbECS_2-782x630.png" /> 
<b class="lb-b blog-post-title" property="name headline">Maintaining Transport Layer Security All the Way to Your Container: Using the Network Load Balancer with Amazon ECS</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Nathan Taber</span></span> | on 
<time property="datePublished" datetime="2018-01-17T13:32:23+00:00">17 JAN 2018</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/compute/category/compute/amazon-ec2-container-service/" title="View all posts in Amazon EC2 Container Service*"><span property="articleSection">Amazon EC2 Container Service*</span></a>, <a href="https://aws.amazon.com/blogs/compute/category/networking-content-delivery/elastic-load-balancing/" title="View all posts in Elastic Load Balancing*"><span property="articleSection">Elastic Load Balancing*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/compute/maintaining-transport-layer-security-all-the-way-to-your-container-using-the-network-load-balancer-with-amazon-ecs/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-3668" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-compute&amp;disqus_identifier=3668&amp;disqus_title=Maintaining+Transport+Layer+Security+All+the+Way+to+Your+Container%3A+Using+the+Network+Load+Balancer+with+Amazon+ECS&amp;disqus_url=https://aws.amazon.com/blogs/compute/maintaining-transport-layer-security-all-the-way-to-your-container-using-the-network-load-balancer-with-amazon-ecs/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-3668');
});
</script> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><em>This post contributed by AWS Senior Cloud Infrastructure Architect Anabell St Vincent.</em></p> 
<p>Some systems or applications require Transport Layer Security (TLS) traffic from the client all the way through to the Docker container, without offloading or terminating certificates at a load balancer. Some highly time-sensitive services may require communication over TLS without any decryption and re-encryption in the communication path.</p> 
<p>There are multiple options for this type of implementation on AWS. One option is to use a service discovery tool to implement the requirements, but that creates overhead from an implementation and management perspective. In this post, I examine the option of using Amazon Elastic Container Service (<a href="https://aws.amazon.com/ecs/">Amazon ECS</a>) with a <a href="https://aws.amazon.com/about-aws/whats-new/2017/09/amazon-ec2-container-service-now-integrated-with-network-load-balancer-to-support-high-throughput-and-direct-tcp-connections-with-containers/">Network Load Balancer</a>.</p> 
<p>Amazon ECS is a highly scalable, high-performance service for running Docker containers on AWS. It is integrated with each of the <a href="https://aws.amazon.com/elasticloadbalancing/">Elastic Load Balancing</a> load balancers offered by AWS:</p> 
<li>The Classic Load Balancer supports application or network level traffic and can be used to pass through the TLS traffic when configured with <a href="http://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-listener-config.html">TCP listeners</a>. This approach limits the number of containers to be deployed by Amazon ECS to one per EC2 host. This approach is only available for the ECS launch type of EC2, not Fargate. This is due to Classic Load Balancer not supporting target groups, so dynamic port mapping can’t be leveraged for this type of implementation.</li> 
<li>The Application Load Balancer functions at the application layer, the layer 7 of Open System Interconnection (OSI) and supports HTTP and HTTPS protocols. By operating at layer 7, the Application Load Balancer is able to route traffic based on the request path in the URL. It can also provide SSL offloading or termination of the SSL certificates for applications, by hosting the SSL certificate. The Application Load Balancer integrates well with ECS by providing the functionality of the target groups for the container instances, which allows for port mapping and targeting container groups. Port mappings allows the containers to run on different ports but still be represented by the one port configured on the ALB as part of the target group of the task.</li> 
<li>The Network Load Balancer, which is a high performance, ultra-low latency load balancer that operates at layer 4. It is designed to handle tens of millions of requests per second while maintaining high throughput at ultra-low latency. Operating at layer 4 networking means that the traffic is passed onto the targets based on the IP addresses and ports as oppose to session information or cookies, as is the case with Application Load Balancers. The Network Load Balancer also supports long-lived TCP connections, which are ideal for WebSocket type of applications . Some applications communicate on TCP protocols rather than solely on HTTP and HTTPS. The Network Load Balancer provides the support to load balance between services that require protocols besides HTTP and HTTPS.</li> 
<p>The Network Load Balancer is the best option for managing secure traffic as it provides support for TCP traffic pass through, without decrypting and then re-encrypting the traffic. Additionally, the Network Load Balancer supports target groups, which means port mapping can be used, as well as configuring the load balancer as part of the task definition for the containers.</p> 
<b>Architecture</b> 
<p>The diagram below shows a high-level architecture with TLS traffic coming from the internet that passes through the VPC to the Network Load Balancer, then to a container without offloading or terminating the certificate in the path.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/17/nlbECS_1.png" /></p> 
<p>In this diagram, there are three containers running in an ECS cluster. The ECS cluster can be either the EC2 or <a href="https://aws.amazon.com/fargate/">Fargate</a> launch type.</p> 
<p>The following diagram shows an architecture that contains two different services deployed in two different ECS clusters.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/17/nlbECS_2-1.png" /></p> 
<p>In this architecture, the containers in each of the clusters can reference the other containers securely via the Network Load Balancer without terminating or offloading the certificates until it reaches the destination container.</p> 
<p>This approach addresses the requirements where containers need to communicate securely whether they are deployed in one VPC, across VPCs, or in separate AWS accounts.</p> 
<p>The following diagram below shows both TLS connections from the internet, as well as connections from within the same cluster.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/17/nlbECS_3-2.png" /></p> 
<p>The above approach is achieved by using the same Network Load Balancer for the cluster to serve two different services. Implement this by using two different <a href="http://docs.aws.amazon.com/elasticloadbalancing/latest/network/load-balancer-target-groups.html">target groups</a> (one for each service) and associating them with the ECS task definition. The containers use the DNS name associated with the Network Load Balancer to access the containers in the other service.</p> 
<b>Summary</b> 
<p>The architectures in this post show how the Network Load Balancer integrates seamlessly with ECS and other AWS services, providing end-to-end TLS communication across services without offloading or terminating the certificates. This gives you the ability to use dynamic ports in ECS containers. It can also handle tens of millions of requests per second while maintaining high throughput at ultra-low latency for applications that require the TCP protocol.</p> 
<p>If you have questions or suggestions, please comment below.</p> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-3668');
});
</script> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<meta property="image" content="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/16/Screen-Shot-2018-01-15-at-10.24.11-PM-1064x630.png" /> 
<b class="lb-b blog-post-title" property="name headline">How To Migrate Multi-Tier Environments Using The AWS Server Migration Service</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Chris Munns</span></span> | on 
<time property="datePublished" datetime="2018-01-16T12:30:20+00:00">16 JAN 2018</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/compute/category/compute/amazon-ec2/" title="View all posts in Amazon EC2*"><span property="articleSection">Amazon EC2*</span></a>, <a href="https://aws.amazon.com/blogs/compute/category/networking-content-delivery/amazon-route-53/" title="View all posts in Amazon Route 53*"><span property="articleSection">Amazon Route 53*</span></a>, <a href="https://aws.amazon.com/blogs/compute/category/database/aws-database-migration-service/" title="View all posts in AWS Database Migration Service*"><span property="articleSection">AWS Database Migration Service*</span></a>, <a href="https://aws.amazon.com/blogs/compute/category/migration/aws-database-migration-service-migration/" title="View all posts in AWS Database Migration Service*"><span property="articleSection">AWS Database Migration Service*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/compute/how-to-migrate-multi-tier-environments-using-the-aws-server-migration-service/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-3560" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-compute&amp;disqus_identifier=3560&amp;disqus_title=How+To+Migrate+Multi-Tier+Environments+Using+The+AWS+Server+Migration+Service&amp;disqus_url=https://aws.amazon.com/blogs/compute/how-to-migrate-multi-tier-environments-using-the-aws-server-migration-service/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-3560');
});
</script> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><em>This post courtesy of Shane Baldacchino, Solutions Architect at Amazon Web Services.</em></p> 
<p>Many customers ask for guidance on migrating end-to-end solutions running on virtual machines over to AWS. This post provides an overview of moving a common WordPress blog running on a virtualized platform to AWS, including re-pointing the DNS records associated to with the website.</p> 
<p><a href="https://aws.amazon.com/server-migration-service">AWS Server Migration Service</a> (AWS SMS) is an agentless service that makes it easier and faster for you to migrate thousands of on-premises workloads to AWS. AWS SMS allows you to automate, schedule, and track incremental replications of live server volumes, making it easier for you to coordinate large-scale server migrations.</p> 
<b>Walkthrough</b> 
<p>The key elements of this migration process include the following steps:</p> 
<ol> 
<li>Establish your AWS environment.</li> 
<li>Replicate your database.</li> 
<li>Download the SMS Connector from the AWS Management Console.</li> 
<li>Configure AWS SMS and Hypervisor permissions.</li> 
<li>Install and configure the SMS Connector appliance.</li> 
<li>Import your virtual machine inventory and create a replication job.</li> 
<li>Launch your Amazon EC2 instance.</li> 
<li>Change your DNS records to resolve the WordPress blog to your EC2 instance.</li> 
</ol> 
<p>Before you start, ensure that your source systems OS and hypervisor version are supported by AWS. For more information, see the Server Migration Service FAQ.</p> 
<b>Establish your AWS environment</b> 
<p>For this walkthrough, your WordPress blog is currently running as a two-tier LAMP stack in a corporate data center. You have a frontend running Apache and PHP, plus a backend database running on MySQL. All systems are hosted on a virtualized platform.</p> 
<p>First, establish your AWS environment. If your organization is new to AWS, this may include account or subaccount creation, a new virtual private cloud (VPC), and associated subnets, route tables, internet gateways, and so on. Think of this phase as setting up your software-defined data center. For more information, see&nbsp;<a href="https://aws.amazon.com/ec2/getting-started/">Getting Started with Amazon EC2</a>.</p> 
<p>The blog is a two-tier stack, so go with two private subnets. Because you want it to be highly available, use multiple <a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html#concepts-regions-availability-zones">Availability Zones</a>. A zone resides within an AWS Region. Each zone is isolated, but the zones within a region are connected through low-latency links. This allows architects and solution designers to build highly available solutions.</p> 
<p><a href="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/16/Screen-Shot-2018-01-15-at-10.11.26-PM.png"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/16/Screen-Shot-2018-01-15-at-10.11.26-PM-1024x621.png" /></a></p> 
<b>Replicate your database</b> 
<p>WordPress uses a MySQL relational database. You could continue to manage MySQL and the associated EC2 instances associated with maintaining and scaling a database. For this walkthrough, use this opportunity to migrate to an RDS instance of Amazon Aurora, as it is a MySQL compliant database. Not only is <a href="https://aws.amazon.com/aurora">Amazon Aurora</a> a high-performant database engine but it frees you up to focus on application development by managing time-consuming database administration tasks, including backups, software patching, monitoring, scaling, and replication.</p> 
<p><a href="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/16/Screen-Shot-2018-01-15-at-10.12.56-PM.png"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/16/Screen-Shot-2018-01-15-at-10.12.56-PM-1024x641.png" /></a></p> 
<p>Use <a href="https://aws.amazon.com/dms/">AWS Database Migration Service</a>&nbsp;to migrate your MySQL database to Amazon Aurora easily and securely. After a database migration instance has been instantiated, configure the source and destination endpoints and create a replication task.</p> 
<p><a href="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/16/dms-console.png"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/16/dms-console-1024x327.png" /></a></p> 
<p>By attaching to the MySQL binlog, you can seed in the current data in the database and also capture all future state changes in near real time. For more information, see <a href="http://docs.aws.amazon.com/dms/latest/sbs/CHAP_MySQL2Aurora.html">Migrating a MySQL-Compatible Database to Amazon Aurora</a>.</p> 
<p>Finally, the task shows that you are replicating current data in your WordPress blog database and future changes from MySQL into Amazon Aurora.</p> 
<p><a href="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/16/dms-console-actions.png"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/16/dms-console-actions-1024x564.png" /></a></p> 
<b>Download the SMS Connector from the AWS Management Console</b> 
<p>Now, use AWS SMS to migrate your Apache PHP frontend to EC2. AWS SMS is delivered as an appliance for your hypervisor.</p> 
<p><a href="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/16/Screen-Shot-2018-01-15-at-10.15.54-PM.png"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/16/Screen-Shot-2018-01-15-at-10.15.54-PM-1024x635.png" /></a></p> 
<p>To download the SMS Connector, log in to the console and choose Server Migration Service, Connectors, SMS Connector setup guide.</p> 
<p><a href="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/16/connector-setup.png"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/16/connector-setup-1024x358.png" /></a></p> 
<b>Configure AWS SMS</b> 
<p>Your hypervisor and AWS SMS will need an appropriate user with sufficient privileges to perform migrations.</p> 
<li>AWS SMS – Use the AWS CLI or the IAM console to create an IAM user with the ServerMigrationConnector policy attached.</li> 
<li>Hypervisor – Follow the specific instructions for your hypervisor in the <a href="https://docs.aws.amazon.com/server-migration-service/latest/userguide/SMS_setup.html">Getting Started with AWS Server Migration Service</a>.</li> 
<b>Install and configure the SMS Connector appliance</b> 
<p>Launch a new VM based on the SMS Connector that you downloaded. To configure the connector, connect to it via HTTPS. You can obtain the SMS Connector IP address from your hypervisor.</p> 
<p><a href="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/16/connector-actions.png"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/16/connector-actions-1024x333.png" /></a></p> 
<p>Connect to the SMS Connector via HTTPS. In the example above, the connector IP address is 10.0.0.31. In your browser, enter https://10.0.0.31.</p> 
<p>Configure the connector with the IAM and hypervisor credentials that you created earlier.</p> 
<p><a href="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/16/connector-connection.png"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/16/connector-connection-1024x548.png" /></a></p> 
<p>After it’s configured, and the associated connectivity and authentication checks have passed, return to the console and view your connector in AWS SMS.</p> 
<p>Import your virtual machine inventory and create a replication job<br /> After validating that the SMS Connector is in a “HEALTHY” state, import your server catalog to AWS SMS. This process can take up to a minute.</p> 
<p><a href="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/16/connector-healthy.png"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/16/connector-healthy-1024x391.png" /></a></p> 
<p>Select the server to migrate and choose Create replication job. The console guides you through the process. The time that the initial replication task takes to complete is dependent on the available bandwidth and the size of your VM. After the initial seed replication, network bandwidth is minimized as AWS SMS replicates only incremental changes occurring on the VM.</p> 
<p><a href="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/16/replication-jobs.png"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/16/replication-jobs-1024x290.png" /></a></p> 
<b>Launch your EC2 instance</b> 
<p>When your replication task is complete, the artifact created by AWS SMS is a custom AMI that you can use to deploy an EC2 instance. Follow the usual process to <a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/launching-instance.html">launch your EC2 instance</a>, noting that you may need to replace any host-based firewalls with security groups and NACLs.</p> 
<p><a href="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/16/replication-jobs-status.png"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/16/replication-jobs-status-1024x485.png" /></a></p> 
<p>When you create an EC2 instance, ensure that you pick the most suitable <a href="https://aws.amazon.com/ec2/instance-types/?sc_channel=PS&amp;sc_campaign=acquisition_AU&amp;sc_publisher=google&amp;sc_medium=ec2_b&amp;sc_content=sitelink&amp;sc_detail=ec2%20instance&amp;sc_category=ec2&amp;sc_segment=instance_types&amp;sc_matchtype=p&amp;sc_country=AU&amp;s_kwcid=AL!">EC2 instance type</a> and size to match your performance requirements while optimizing for cost.</p> 
<p>While your new EC2 instance is a replica of your on-premises VM, you should always validate that applications are functioning. How you do this differs on an application-by-application basis. You can use a combination of approaches, such as editing a local host file and testing your application, SSH, or Telnet.</p> 
<p><a href="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/16/ssh-screenshot.png"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/16/ssh-screenshot.png" /></a></p> 
<p>From the RDS console, get your connection string details and update your WordPress configuration file to point to the Amazon Aurora database. As WordPress is expecting a MySQL database and Amazon Aurora is MySQL-compliant, this change of database engine is transparent to WordPress.</p> 
<p><a href="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/16/wp-config.png"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/16/wp-config.png" /></a></p> 
<b>Change your DNS records to resolve the WordPress blog to your EC2 instance</b> 
<p>You have validated that your WordPress application is running correctly, as you are still receiving changes from your on-premises data center via AWS DMS into your Amazon Aurora database.</p> 
<p><a href="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/16/Screen-Shot-2018-01-15-at-10.24.11-PM.png"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/16/Screen-Shot-2018-01-15-at-10.24.11-PM-1024x607.png" /></a></p> 
<p>You can now update your DNS zone file using <a href="https://aws.amazon.com/route53">Amazon Route 53</a>. Route 53 can be driven by multiple methods: console, SDK, or AWS CLI.</p> 
<p>For this walkthrough, update your DNS zone file via the AWS CLI. The JSON example shows upserting the A record in your zone to resolve to your EC2 instance.</p> 
<p><a href="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/16/json-dns.png"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/16/json-dns.png" /></a></p> 
<p>Use the AWS CLI to execute the request and update the record in your zone file.&nbsp; The cut-over period between the original off-cloud location and AWS is defined by the TTL in the SOA (statement of authority) in your DNS zone. During this period, any requests resolving to your off-cloud server that result in database writes are automatically replicated to your Amazon Aurora instance via AWS DMS.</p> 
<p><a href="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/16/route53-cli.png"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/16/route53-cli-1024x331.png" /></a></p> 
<p>You have now successfully migrated your WordPress blog to AWS. Based on the TTL of your DNS zone file, end users slowly resolve the WordPress blog to AWS.</p> 
<p>After you have validated your successful migration, be sure to delete your AWS DMS task and your AWS SMS replication job.</p> 
<b>Summary</b> 
<p>In this post, you moved a WordPress blog to AWS, using AWS SMS and AWS DMS to re-point the associated DNS records.</p> 
<p>Many architectures can be extended to use many of the inherent benefits of AWS, with little effort. For example, by using Amazon CloudWatch metrics to drive Auto Scaling policies, you can use an Application Load Balancer as your frontend. This removes the single point of failure for a single Amazon EC2 instance and ensures that your deployed capacity closely follows customer demand. Think big and get building!</p> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-3560');
});
</script> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<meta property="image" content="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/16/Screen-Shot-2018-01-15-at-9.44.14-PM.png" /> 
<b class="lb-b blog-post-title" property="name headline">Announcing Go Support for AWS Lambda</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Chris Munns</span></span> | on 
<time property="datePublished" datetime="2018-01-15T15:56:16+00:00">15 JAN 2018</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/compute/category/application-services/amazon-api-gateway-application-services/" title="View all posts in Amazon API Gateway*"><span property="articleSection">Amazon API Gateway*</span></a>, <a href="https://aws.amazon.com/blogs/compute/category/developer-tools/aws-codebuild/" title="View all posts in AWS CodeBuild*"><span property="articleSection">AWS CodeBuild*</span></a>, <a href="https://aws.amazon.com/blogs/compute/category/developer-tools/aws-codepipeline/" title="View all posts in AWS CodePipeline*"><span property="articleSection">AWS CodePipeline*</span></a>, <a href="https://aws.amazon.com/blogs/compute/category/compute/aws-lambda/" title="View all posts in AWS Lambda*"><span property="articleSection">AWS Lambda*</span></a>, <a href="https://aws.amazon.com/blogs/compute/category/developer-tools/aws-sdk-for-go/" title="View all posts in AWS SDK for Go*"><span property="articleSection">AWS SDK for Go*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/compute/announcing-go-support-for-aws-lambda/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-3608" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-compute&amp;disqus_identifier=3608&amp;disqus_title=Announcing+Go+Support+for+AWS+Lambda&amp;disqus_url=https://aws.amazon.com/blogs/compute/announcing-go-support-for-aws-lambda/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-3608');
});
</script> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><em>This post courtesy of Paul Maddox, Specialist Solutions Architect (Developer Technologies).</em></p> 
<p><a href="https://aws.amazon.com/about-aws/whats-new/2018/01/aws-lambda-supports-go/">Today</a>, we’re excited to announce <a href="https://golang.org/">Go</a> as a supported language for <a href="https://aws.amazon.com/lambda">AWS Lambda</a>.</p> 
<p>As someone who’s done their fair share of Go development (recent projects include <a href="https://github.com/awslabs/aws-sam-local">AWS SAM Local</a> and <a href="https://github.com/awslabs/goformation">GoFormation</a>), this is a release I’ve been looking forward to for a while. I’m going to take this opportunity to walk you through how it works by creating a Go serverless application, and deploying it to Lambda.</p> 
<h3>Prerequisites</h3> 
<p>This post assumes that you already have Go installed and configured on your development machine, as well as a basic understanding of Go development concepts. For more details, see&nbsp;<a href="https://golang.org/doc/install">https://golang.org/doc/install</a>.</p> 
<b>Creating an example Serverless application with Go</b> 
<p>Lambda functions can be triggered by variety of event sources:</p> 
<li>Asynchronous events (such as an object being put in an <a href="https://aws.amazon.com/s3">Amazon S3</a> bucket)</li> 
<li>Streaming events (for example, new data records on an <a href="https://aws.amazon.com/kinesis">Amazon Kinesis</a> stream)</li> 
<li>Synchronous events (manual invocation, or HTTPS request via <a href="https://aws.amazon.com/apigateway">Amazon API Gateway</a>)</li> 
<p>As an example, you’re going to create an application that uses an API Gateway event source to create a simple Hello World RESTful API.&nbsp;The full source code for this example application can be found on GitHub at:&nbsp;<a href="https://github.com/aws-samples/lambda-go-samples">https://github.com/aws-samples/lambda-go-samples</a>.</p> 
<p>After the application is published, it receives a name via the HTTPS request body, and responds with&nbsp;“Hello &lt;name&gt;.” For example:</p> 
<code class="lang-bash">$ curl -XPOST -d &quot;Paul&quot;&nbsp;&quot;https://my-awesome-api.example.com/&quot;
Hello&nbsp;Paul</code> 
<p>To implement this, create a Lambda handler function in Go.</p> 
<p>Import the <a href="http://github.com/aws/aws-lambda-go">github.com/aws/aws-lambda-go</a>&nbsp;package, which includes helpful Go definitions for Lambda event sources, as well as the <strong>lambda.Start()</strong> method used to register your handler function.</p> 
<p>Start by creating a new project directory in your <strong>$GOPATH</strong>, and then creating a <strong>main.go</strong> file that contains your Lambda handler function:</p> 
<code class="lang-go">package main
import (
&quot;errors&quot;
&quot;log&quot;
&quot;github.com/aws/aws-lambda-go/events&quot;
&quot;github.com/aws/aws-lambda-go/lambda&quot;
)
var (
// ErrNameNotProvided is thrown when a name is not provided
ErrNameNotProvided = errors.New(&quot;no name was provided in the HTTP body&quot;)
)
// Handler is your Lambda function handler
// It uses Amazon API Gateway request/responses provided by the aws-lambda-go/events package,
// However you could use other event sources (S3, Kinesis etc), or JSON-decoded primitive types such as 'string'.
func Handler(request events.APIGatewayProxyRequest) (events.APIGatewayProxyResponse, error) {
// stdout and stderr are sent to AWS CloudWatch Logs
log.Printf(&quot;Processing Lambda request %s\n&quot;, request.RequestContext.RequestID)
// If no name is provided in the HTTP request body, throw an error
if len(request.Body) &lt; 1 {
return events.APIGatewayProxyResponse{}, ErrNameNotProvided
}
return events.APIGatewayProxyResponse{
Body: &nbsp; &nbsp; &nbsp; &quot;Hello &quot; + request.Body,
StatusCode: 200,
}, nil
}
func main() {
lambda.Start(Handler)
}
</code> 
<p>The <strong>lambda.Start()</strong> method takes a handler, and talks to an internal Lambda endpoint to pass Invoke requests to the handler. If a&nbsp;handler does not match one of the supported types, the Lambda package responds to new invocations served by an&nbsp;internal endpoint with an error message such as:</p> 
<code class="lang-bash">json: cannot unmarshal object into Go value of type int32: UnmarshalTypeError</code> 
<p>The&nbsp;<strong>lambda.Start()</strong>&nbsp;method blocks, and does not return after being called, meaning that it’s suitable to run in your Go application’s main entry point.</p> 
<b>More detail on AWS Lambda function handlers with Go</b> 
<p>A handler function passed to <strong>lambda.Start()</strong> must follow these rules:</p> 
<li>It must be a function.</li> 
<li>The function may take between 0 and 2 arguments. 
<li>If there are two arguments, the first argument must implement <strong>context.Context</strong>.</li> 
</ul> </li> 
<li>The function may return between 0 and 2 values. 
<li>If there is one return value, it must implement&nbsp;<strong>error</strong>.</li> 
<li>If there are two return values, the second value must implement&nbsp;<strong>error</strong>.</li> 
</ul> </li> 
<p>The <a href="http://github.com/aws/aws-lambda-go">github.com/aws/aws-lambda-go</a>&nbsp;library automatically unmarshals the Lambda event JSON to the argument type used by your handler function. To do this, it uses Go’s standard <a href="https://golang.org/pkg/encoding/json/#Unmarshal">encoding/json</a>&nbsp;package, so your handler function can use any of the standard types supported for unmarshalling (or custom types containing those):</p> 
<li>bool, for JSON booleans</li> 
<li>float64, for JSON numbers</li> 
<li>string, for JSON strings</li> 
<li>[]interface{}, for JSON arrays</li> 
<li>map[string]interface{}, for JSON objects</li> 
<li>nil, for JSON null</li> 
<p>For example, your Lambda function received a JSON event payload like the following:</p> 
<code class="lang-json">{
&quot;id&quot;:&nbsp;12345,
&quot;value&quot;:&nbsp;&quot;some-value&quot;
}</code> 
<p>It should respond with a JSON response that looks like the following:</p> 
<code class="lang-json">{
&quot;message&quot;:&nbsp;&quot;processed request ID 12345&quot;,
&quot;ok&quot;:&nbsp;true
}</code> 
<p>You could use a Lambda handler function that looks like the following:</p> 
<code class="lang-go">package&nbsp;main
import&nbsp;(
&quot;fmt&quot;
&quot;github.com/aws/aws-lambda-go/lambda&quot;
)
type Request struct {
ID &nbsp; &nbsp; &nbsp; &nbsp;float64 `json:&quot;id&quot;`
Value &nbsp; &nbsp; string &nbsp;`json:&quot;value&quot;`
}
type Response struct {
Message string `json:&quot;message&quot;`
Ok &nbsp; &nbsp; &nbsp;bool &nbsp; `json:&quot;ok&quot;`
}
func Handler(request Request) (Response, error) {
return Response{
Message: fmt.Sprintf(&quot;Processed request ID %f&quot;, request.ID),
Ok: &nbsp; &nbsp; &nbsp;true,
}, nil
}
func main() {
lambda.Start(Handler)
}</code> 
<p>For convenience, the <a href="http://github.com/aws/aws-lambda-go">github.com/aws/aws-lambda-go</a>&nbsp;package provides event sources that you can also use in your handler function arguments. It also provides return values for common sources such as S3, Kinesis, Cognito, and the API Gateway event source and response objects that you’re using in the application example.</p> 
<b>Adding unit tests</b> 
<p>To test that the Lambda handler works as expected, create a main_test.go file containing some basic unit tests.</p> 
<code class="lang-go">package main_test
import (
&quot;testing&quot;
main &quot;github.com/aws-samples/lambda-go-samples&quot;
&quot;github.com/aws/aws-lambda-go/events&quot;
&quot;github.com/stretchr/testify/assert&quot;
)
func TestHandler(t *testing.T) {
tests := []struct {
request events.APIGatewayProxyRequest
expect &nbsp;string
err &nbsp; &nbsp; error
}{
{
// Test that the handler responds with the correct response
// when a valid name is provided in the HTTP body
request: events.APIGatewayProxyRequest{Body: &quot;Paul&quot;},
expect: &nbsp;&quot;Hello Paul&quot;,
err: &nbsp; &nbsp; nil,
},
{
// Test that the handler responds ErrNameNotProvided
// when no name is provided in the HTTP body
request: events.APIGatewayProxyRequest{Body: &quot;&quot;},
expect: &nbsp;&quot;&quot;,
err: &nbsp; &nbsp; main.ErrNameNotProvided,
},
}
for _, test := range tests {
response, err := main.Handler(test.request) 
assert.IsType(t, test.err, err)
assert.Equal(t, test.expect, response.Body)
}
}
</code> 
<h3>Run your tests:</h3> 
<code class="lang-base">$ go test
PASS
ok &nbsp; &nbsp; &nbsp;github.com/awslabs/lambda-go-example &nbsp; &nbsp;0.041s</code> 
<p><em>Note:&nbsp;To make the unit tests more readable, this example uses a third-party library (https://github.com/stretchr/testify). This allows you to describe the test cases in a more natural format, making them more maintainable for other people who may be working in the code base.</em></p> 
<b>Build and deploy</b> 
<p>As Go is a compiled language, build the application and create a <a href="https://docs.aws.amazon.com/lambda/latest/dg/lambda-go-how-to-create-deployment-package.html">Lambda deployment package</a>. To do this, build a binary that runs on Linux, and zip it up into a deployment package.</p> 
<p>To do this, we need to build a binary that will run on Linux, and ZIP it up into a deployment package.</p> 
<code class="lang-bash">$ GOOS=linux go build -o main
$ zip deployment.zip main</code> 
<p>The binary doesn’t need to be called main, but the name must match the Handler configuration property of the deployed Lambda function.</p> 
<p>The deployment package is now ready to be deployed to Lambda.&nbsp;One deployment method is to use the <a href="https://aws.amazon.com/cli/">AWS CLI</a>. Provide a valid <a href="https://docs.aws.amazon.com/lambda/latest/dg/intro-permission-model.html#lambda-intro-execution-role">Lambda execution role</a> for&nbsp; <strong>–role</strong>.</p> 
<code class="lang-bash">$&nbsp;aws lambda create-function \
--region us-west-1 \
--function-name HelloFunction&nbsp;\
--zip-file fileb://./deployment.zip \
--runtime go1.x \
--tracing-config Mode=Active \
--role arn:aws:iam::&lt;account-id&gt;:role/&lt;role&gt;&nbsp;\
--handler main</code> 
<p>From here, configure the invoking service for your function, in this example API Gateway, to call this function and provide the HTTPS frontend for your API. For more information about how to do this in the API Gateway console, see <a href="https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-create-api-as-simple-proxy-for-lambda.html#api-gateway-create-api-as-simple-proxy-for-lambda-build">Create an API with Lambda Proxy Integration</a>. You could also do this in the Lambda console by assigning an API Gateway trigger.</p> 
<p><a href="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/15/lambda-console1.png"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/15/lambda-console1.png" /></a></p> 
<p>Then, configure the trigger:</p> 
<li><strong>API name</strong>: lambda-go</li> 
<li><strong>Deployment stage</strong>: prod</li> 
<li><strong>Security</strong>: open</li> 
<p>This results in an API Gateway endpoint that you can test.</p> 
<p><a href="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/15/lambda-console-gateway.png"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/15/lambda-console-gateway.png" /></a></p> 
<p>Now, you can use cURL to test your API:</p> 
<code class="lang-bash">$ curl -XPOST -d &quot;Paul&quot;&nbsp;https://u7fe6p3v64.execute-api.us-east-1.amazonaws.com/prod/main
Hello&nbsp;Paul</code> 
<p>Doing this manually is fine and works for testing and exploration. If you were doing this for real, you’d want to automate this process further. The next section shows how to add a CI/CD pipeline to this process to build, test, and deploy your serverless application as you change your code.</p> 
<b>Automating tests and deployments</b> 
<p>Next, configure <a href="https://aws.amazon.com/codepipeline">AWS CodePipeline</a> and <a href="https://aws.amazon.com/codebuild">AWS CodeBuild</a> to build your application automatically and run all of the tests. If it passes, deploy your application to Lambda.</p> 
<p>The first thing you need to do is create an <a href="https://aws.amazon.com/about-aws/whats-new/2016/11/introducing-the-aws-serverless-application-model/">AWS Serverless Application Model (AWS SAM)</a> template in your source repository. SAM provides an easy way to deploy Serverless resources, such as Lambda functions, APIs, and other event sources, as well as all of the necessary IAM permissions, etc. You can also include any valid <a href="https://aws.amazon.com/cloudformation">AWS CloudFormation</a> resources within your SAM template, such as a Kinesis stream, or an&nbsp;<a href="https://aws.amazon.com/dynamodb">Amazon DynamoDB</a> table. They are deployed alongside your Serverless application.</p> 
<p>Create a file called <strong>template.yml</strong> in your application repository with the following contents:</p> 
<code class="lang-yaml">AWSTemplateFormatVersion: 2010-09-09
Transform: AWS::Serverless-2016-10-31
Resources:
HelloFunction:
Type: AWS::Serverless::Function
Properties:
Handler:&nbsp;main
Runtime: go1.x
Tracing: Active
Events:
GetEvent:
Type: Api
Properties:
Path: /
Method: post</code> 
<p>The above template instructs SAM to deploy a Lambda function (called <strong>HelloFunction</strong> in this case), with the Go runtime (<strong>go1.x</strong>), and also an API configured to pass HTTP POST requests to your Lambda function. The Handler property defines which binary in the deployment package needs to be executed (<strong>main</strong> in this case).</p> 
<p>You’re going to use CodeBuild to run your tests, build your Go application, and package it. You can tell CodeBuild how to do all of this by creating a <strong>buildspec.yml</strong> file in your repository containing the following:</p> 
<code class="lang-yaml">
version: 0.2
env:
variables:
# This S3 bucket is used to store the packaged Lambda deployment bundle.
# Make sure to provide a valid S3 bucket name (it must exist already).
# The CodeBuild IAM role must allow write access to it.
S3_BUCKET: &quot;your-s3-bucket&quot;
PACKAGE: &quot;github.com/aws-samples/lambda-go-samples&quot;
phases:
install:
commands:
# AWS Codebuild Go images use /go for the $GOPATH so copy the
# application source code into that directory structure.
- mkdir -p &quot;/go/src/$(dirname ${PACKAGE})&quot;
- ln -s &quot;${CODEBUILD_SRC_DIR}&quot; &quot;/go/src/${PACKAGE}&quot;
# Print all environment variables (handy for AWS CodeBuild logs)
- env
# Install golint
- go get -u github.com/golang/lint/golint
pre_build:
commands:
# Make sure we're in the project directory within our GOPATH
- cd &quot;/go/src/${PACKAGE}&quot;
# Fetch all dependencies
- go get -t ./...
# Ensure that the code passes all lint tests
- golint -set_exit_status
# Check for common Go problems with 'go vet'
-&nbsp;go vet .
# Run all tests included with the application
- go test .
build:
commands:
# Build the go application
- go build -o main
# Package the application with AWS SAM
- aws cloudformation package --template-file template.yml --s3-bucket ${S3_BUCKET} --output-template-file packaged.yml
artifacts:
files:
- packaged.yml</code> 
<p>This buildspec file does the following:</p> 
<li>Sets up your GOPATH, ready for building</li> 
<li>Runs <a href="https://github.com/golang/lint">golint</a>&nbsp;to make sure that any committed code matches the Go style and formatting specification</li> 
<li>Runs any unit tests present (via <strong>go test</strong>)</li> 
<li>Builds your application binary</li> 
<li>Packages the binary into a&nbsp;<a href="https://docs.aws.amazon.com/lambda/latest/dg/lambda-go-how-to-create-deployment-package.html">Lambda deployment package</a>&nbsp;and uploads it to S3</li> 
<p>For more details about buildspec files, see the <a href="https://docs.aws.amazon.com/codebuild/latest/userguide/build-spec-ref.html">Build Specification Reference</a> for AWS CodeBuild.</p> 
<p>Your project directory should now contain the following files:</p> 
<code>$ tree
.
├── buildspec.yml &nbsp; &nbsp;(AWS CodeBuild&nbsp;configuration file)
├── main.go &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;(Our&nbsp;application)
├── main_test.go&nbsp;&nbsp; &nbsp;&nbsp;(Unit&nbsp;tests)
└── template.yml &nbsp; &nbsp; (AWS SAM template)
0 directories, 4 files</code> 
<p>You’re now ready to set up your automated pipeline with CodePipeline.</p> 
<h3>Create a new pipeline</h3> 
<p>Get started by navigating to the <a href="https://console.aws.amazon.com/codepipeline/">CodePipeline</a> console. You need to give your new pipeline a name, such as HelloService.</p> 
<p>Next, select the source repository in which your application code is located. CodePipeline supports either AWS CodeCommit, GitHub.com, or S3. To use the example GitHub.com repository mentioned earlier in this post, <a href="https://help.github.com/articles/fork-a-repo/">fork</a> it into your own GitHub.com account or create a new CodeCommit repository and <a href="https://docs.aws.amazon.com/codecommit/latest/userguide/how-to-migrate-repository-existing.html">clone</a> it into there. Do this first before selecting a source location.</p> 
<p><a href="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/15/codepipeline1.png"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/15/codepipeline1.png" /></a></p> 
<p>Tell CodePipeline to use CodeBuild to test, build, and package your application using the buildspec.yml file created earlier:</p> 
<p><a href="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/15/codepipeline-build.png"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/15/codepipeline-build.png" /></a></p> 
<p><strong>Important:</strong>&nbsp;CodeBuild needs read/write access to the S3 bucket referenced in the buildspec.yml file that you wrote. It places the packaged Lambda deployment package into S3 after the tests and build are completed. Make sure that the CodeBuild service role created or provided has the correct IAM permissions. For more information, see <a href="https://aws.amazon.com/blogs/security/writing-iam-policies-how-to-grant-access-to-an-amazon-s3-bucket/">Writing IAM Policies: How to grant access to an Amazon S3 bucket</a>. If you don’t do this, CodeBuild fails.</p> 
<p>Finally, set up the deployment stage of your pipeline. Select <strong>AWS CloudFormation</strong> as the deployment method, and the <strong>Create or replace a change set</strong>&nbsp;mode (as required by SAM). To deploy multiple environments (for example, staging, production), add additional deployment stages to your pipeline after it has been created.</p> 
<p><a href="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/15/codepipeline-deploy.png"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/15/codepipeline-deploy.png" /></a></p> 
<p>After being created, your pipeline takes a few minutes to initialize, and then automatically triggers.&nbsp;You can see the latest commit in your version control system make progress through the build and deploy stages of your pipeline.</p> 
<p>You do not need to configure anything further to automatically run your pipeline on new version control commits. It already automatically triggers, builds, and deploys each time.</p> 
<p><a href="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/15/codepipeline-created.png"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/15/codepipeline-created.png" /></a></p> 
<p>Make one final change to the pipeline, to configure the deployment stage to execute the CloudFormation changeset that it creates. To make this change, choose the <strong>Edit</strong> button on your pipeline, choose the pencil icon on the staging deployment stage, and add a new action:</p> 
<p><a href="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/15/codepipeline-addaction.png"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/15/codepipeline-addaction.png" /></a></p> 
<p>After the action is added, save your pipeline. You can test it by making a small change to your Lambda function, and then committing it back to version control. You can see your pipeline trigger, and the changes get deployed to your staging environment.</p> 
<h3>See it in Action</h3> 
<p>After a successful run of the pipeline has completed, you can navigate to the CloudFormation console to see the deployment details.</p> 
<p>In your case, you have a CloudFormation stack deployed. If you look at the <strong>Resources</strong> tab, you see a table of the AWS resources that have been deployed.</p> 
<p><a href="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/15/cloudformation-resources.png"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/15/cloudformation-resources.png" /></a></p> 
<p>Choose the <strong>ServerlessRestApi</strong> item link to navigate to the API Gateway console and view the details of your deployed API, including the URL,</p> 
<p><a href="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/15/api-gw-stage-edit.png"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/15/api-gw-stage-edit.png" /></a></p> 
<p>You can use cURL to test that your Serverless application is functioning as expected:</p> 
<code>$ curl -XPOST -d &quot;Paul&quot;&nbsp;https://y5fjgtq6dj.execute-api.us-west-1.amazonaws.com/Stage
Hello&nbsp;Paul</code> 
<b>One more thing!</b> 
<p>We are also excited to announce that <a href="https://aws.amazon.com/xray/">AWS X-Ray</a>&nbsp;can be enabled in your Lambda runtime to analyze and debug your Go functions written for Lambda. The&nbsp;<a href="https://docs.aws.amazon.com/xray/latest/devguide/xray-sdk-go.html">X-Ray SDK for Go</a>&nbsp;works with the Go context of your Lambda function, providing features such as&nbsp;AWS SDK retry visibility&nbsp;and one-line error capture.<br /> <a href="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/15/xray-go.png"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/15/xray-go.png">annotations and metadata</a>&nbsp;to capture additional information in X-Ray about your function invocations. Moreover, the SDK supports the net/http client package, enabling you to trace requests made to&nbsp;endpoints even if they are not X-Ray enabled.</p> 
<b>Wrapping it up!</b> 
<p>Support for Go has been a much-requested feature in Lambda and we are excited to be able to bring it to you. In this post, you created a basic Go-based API and then went on to create a full continuous integration and delivery pipeline that tests, builds, and deploys your application each time you make a change.</p> 
<p>You can also get started with AWS Lambda Go support through <a href="https://aws.amazon.com/codestar">AWS CodeStar</a>. AWS CodeStar lets you quickly launch development projects that include a sample application, source control and release automation. With this announcement, AWS CodeStar introduced new project templates for Go running on AWS Lambda. Select one of the <a href="https://console.aws.amazon.com/codestar/home?region=us-east-1#/quickstart">CodeStar Go project templates</a> to get started. CodeStar makes it easy to begin editing your Go project code in <a href="https://aws.amazon.com/cloud9">AWS Cloud9</a>, an online IDE, with just a few clicks.</p> 
<p><a href="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/16/Screen-Shot-2018-01-15-at-9.44.14-PM.png"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2018/01/16/Screen-Shot-2018-01-15-at-9.44.14-PM-300x169.png" /></a></p> 
<p>Excited about Go in Lambda or have questions? Let us know in the comments here, in the <a href="https://forums.aws.amazon.com/forum.jspa?forumID=186">AWS Forums for Lambda</a>, or find us on Twitter at <a href="https://twitter.com/awscloud">@awscloud</a>.</p> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-3608');
});
</script> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<meta property="image" content="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2017/12/22/Social_png.png" /> 
<b class="lb-b blog-post-title" property="name headline">Set Up a Continuous Delivery Pipeline for Containers Using AWS CodePipeline and Amazon ECS</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Nathan Taber</span></span> and 
<span property="author" typeof="Person"><span property="name">Abby Fuller</span></span> | on 
<time property="datePublished" datetime="2017-12-22T12:20:19+00:00">22 DEC 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/compute/category/compute/amazon-ec2-container-service/" title="View all posts in Amazon EC2 Container Service*"><span property="articleSection">Amazon EC2 Container Service*</span></a>, <a href="https://aws.amazon.com/blogs/compute/category/amazon-ecs/" title="View all posts in Amazon ECS"><span property="articleSection">Amazon ECS</span></a>, <a href="https://aws.amazon.com/blogs/compute/category/developer-tools/aws-codebuild/" title="View all posts in AWS CodeBuild*"><span property="articleSection">AWS CodeBuild*</span></a>, <a href="https://aws.amazon.com/blogs/compute/category/developer-tools/aws-codepipeline/" title="View all posts in AWS CodePipeline*"><span property="articleSection">AWS CodePipeline*</span></a>, <a href="https://aws.amazon.com/blogs/compute/category/compute/aws-fargate/" title="View all posts in AWS Fargate"><span property="articleSection">AWS Fargate</span></a></span> | 
<a href="https://aws.amazon.com/blogs/compute/set-up-a-continuous-delivery-pipeline-for-containers-using-aws-codepipeline-and-amazon-ecs/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-3534" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-compute&amp;disqus_identifier=3534&amp;disqus_title=Set+Up+a+Continuous+Delivery+Pipeline+for+Containers+Using+AWS+CodePipeline+and+Amazon+ECS&amp;disqus_url=https://aws.amazon.com/blogs/compute/set-up-a-continuous-delivery-pipeline-for-containers-using-aws-codepipeline-and-amazon-ecs/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-3534');
});
</script> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><em>This post contributed by&nbsp;Abby Fuller</em>,&nbsp;<em>AWS Senior Technical Evangelist</em></p> 
<p>Last week, <a href="https://aws.amazon.com/about-aws/whats-new/2017/12/aws-codepipeline-adds-support-for-amazon-ecs-and-aws-fargate/">AWS announced support</a> for Amazon Elastic Container Service (<a href="https://aws.amazon.com/ecs">ECS</a>) targets (including <a href="https://aws.amazon.com/fargate">AWS Fargate</a>) in <a href="https://aws.amazon.com/codepipeline">AWS CodePipeline</a>. This support makes it easier to create a <a href="https://aws.amazon.com/devops/continuous-delivery/">continuous delivery</a> pipeline for container-based applications and <a href="https://aws.amazon.com/microservices">microservices</a>.</p> 
<p>Building and deploying containerized services&nbsp;manually is slow and prone to errors. Continuous delivery with automated build and test mechanisms helps detect errors early, saves time, and reduces failures, making this a popular model for application deployments. Previously, to automate your container workflows with ECS, you had to build your own solution using AWS CloudFormation. Now, you can integrate CodePipeline and CodeBuild with ECS to automate your workflows in just a few steps.</p> 
<p>A typical continuous delivery workflow with CodePipeline, CodeBuild, and ECS might look something like the following:</p> 
<li>Choosing your source</li> 
<li>Building your project</li> 
<li>Deploying your code</li> 
<p>We also have a continuous deployment reference architecture on <a href="https://github.com/awslabs/ecs-refarch-continuous-deployment">GitHub</a>&nbsp;for this workflow.</p> 
<b>Getting Started</b> 
<p>First, create a new project with CodePipeline and give the project a name, such as “demo”.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2017/12/22/1_name_codepipeline-1024x447.png" /></p> 
<p>Next, choose a source location where the code is stored. This could be AWS CodeCommit, GitHub, or Amazon S3. For this example, enter <strong>GitHub</strong> and then give CodePipeline access to the repository.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2017/12/22/2_add_source_location_codepipeline-1024x686.png" /></p> 
<p>Next, add a build step. You can import an existing build, such as a Jenkins server URL or CodeBuild project, or create a new step with CodeBuild. If you don’t have an existing build project in CodeBuild, create one from within CodePipeline:</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2017/12/22/3_provider_codebuild-766x1024.png" /></p> 
<li><strong>Build provider</strong>: AWS CodeBuild</li> 
<li><strong>Configure your project</strong>: Create a new build project</li> 
<li><strong>Environment image</strong>: Use an image managed by AWS CodeBuild</li> 
<li><strong>Operating system</strong>: Ubuntu</li> 
<li><strong>Runtime</strong>: Docker</li> 
<li><strong>Version</strong>: aws/codebuild/docker:1.12.1</li> 
<li><strong>Build specification</strong>: Use the buildspec.yml in the source code root directory</li> 
<p>Now that you’ve created the CodeBuild step, you can use it as an existing project in CodePipeline.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2017/12/22/4_add_codebuild_codepipeline-1024x713.png" /></p> 
<p>Next, add a deployment provider. This is where your built code is placed. It can be a number of different options, such as AWS CodeDeploy, AWS Elastic Beanstalk, AWS CloudFormation, or Amazon ECS. For this example, connect to Amazon ECS.</p> 
<p>For CodeBuild to deploy to ECS, you must create an image definition JSON file. This requires adding some instructions to the pre-build, build, and post-build phases of the CodeBuild build process in your <em>buildspec.yml</em> file. For help with creating the image definition file, see Step 1 of the <a href="http://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-cd-pipeline.html">Tutorial: Continuous Deployment with AWS CodePipeline</a>.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2017/12/22/5_add_deploy_step_codepipeline-1024x914.png" /></p> 
<li><strong>Deployment provider</strong>: Amazon ECS</li> 
<li><strong>Cluster name</strong>: enter your project name from the build step</li> 
<li><strong>Service name</strong>: web</li> 
<li><strong>Image filename</strong>: enter your image definition filename (“web.json”).</li> 
<p>You are almost done!</p> 
<p>You can now choose an existing IAM service role that CodePipeline can use to access resources in your account, or let CodePipeline create one. For this example, use the wizard, and go with the role that it creates (<code class="lang-bash">AWS-CodePipeline-Service</code>).</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2017/12/22/6_add_role_codepipeline-1024x451.png" /></p> 
<p>Finally, review all of your changes, and choose <strong>Create pipeline</strong>.</p> 
<p>After the pipeline is created, you’ll have a model of your entire pipeline where you can view your executions, add different tests, add manual approvals, or release a change.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2017/12/22/7_review_changes_codepipeline-1024x564.png" /></p> 
<p>You can learn more in the&nbsp;<a href="http://docs.aws.amazon.com/codepipeline/latest/userguide/welcome.html">AWS CodePipeline User Guide</a>.</p> 
<p>Happy automating!</p> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-3534');
});
</script> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">Serverless @ re:Invent 2017</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Chris Munns</span></span> | on 
<time property="datePublished" datetime="2017-12-21T12:03:06+00:00">21 DEC 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/compute/category/mobile-services/amazon-api-gateway/" title="View all posts in Amazon API Gateway*"><span property="articleSection">Amazon API Gateway*</span></a>, <a href="https://aws.amazon.com/blogs/compute/category/application-services/amazon-api-gateway-application-services/" title="View all posts in Amazon API Gateway*"><span property="articleSection">Amazon API Gateway*</span></a>, <a href="https://aws.amazon.com/blogs/compute/category/developer-tools/aws-codedeploy/" title="View all posts in AWS CodeDeploy*"><span property="articleSection">AWS CodeDeploy*</span></a>, <a href="https://aws.amazon.com/blogs/compute/category/compute/aws-lambda/" title="View all posts in AWS Lambda*"><span property="articleSection">AWS Lambda*</span></a>, <a href="https://aws.amazon.com/blogs/compute/category/events/reinvent/" title="View all posts in AWS re:Invent*"><span property="articleSection">AWS re:Invent*</span></a>, <a href="https://aws.amazon.com/blogs/compute/category/networking-content-delivery/lambdaedge/" title="View all posts in Lambda@Edge"><span property="articleSection">Lambda@Edge</span></a>, <a href="https://aws.amazon.com/blogs/compute/category/serverless/" title="View all posts in Serverless*"><span property="articleSection">Serverless*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/compute/serverless-reinvent-2017/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-3521" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-compute&amp;disqus_identifier=3521&amp;disqus_title=Serverless+%40+re%3AInvent+2017&amp;disqus_url=https://aws.amazon.com/blogs/compute/serverless-reinvent-2017/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-3521');
});
</script> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p>At re:Invent 2014, we announced AWS Lambda, what is now the center of the serverless platform at AWS, and helped ignite the trend of companies building serverless applications.</p> 
<p>This year, at re:Invent 2017, the topic of serverless was everywhere. We were incredibly excited to see the energy from everyone attending&nbsp;7 workshops, 15 chalk talks, 20 skills sessions and 27 breakout sessions. Many of these sessions were repeated due to high demand, so we are happy to summarize and provide links to the recordings and slides of these sessions.</p> 
<p>Over the course of the week leading up to and then the week of re:Invent, we also had over 15 new features and capabilities across a number of serverless services, including AWS Lambda, Amazon API Gateway, AWS Lambda@Edge, AWS SAM, and the newly announced AWS Serverless Application Repository!</p> 
<b>AWS Lambda</b> 
<li><a href="https://aws.amazon.com/about-aws/whats-new/2017/11/aws-lambda-doubles-maximum-memory-capacity-for-lambda-functions/">AWS Lambda Doubles Maximum Memory Capacity for Lambda Functions</a> – We’ve doubled the maximum memory that you can configure a function to have available, to 3 GB. With this, comes proportional increases to CPU and networking so that your function gets access to two CPU cores!</li> 
<li><a href="https://aws.amazon.com/about-aws/whats-new/2017/11/aws-lambda-supports-traffic-shifting-and-phased-deployments-with-aws-codedeploy/">AWS Lambda Supports Traffic Shifting and Phased Deployments with AWS CodeDeploy</a> – Traffic shifting allows you to deploy your Lambda functions using standard industry best practices such as canaries and blue/green deployments. With CodeDeploy, you get the ability to automate rollbacks and have events fired off by triggers set around the lifecycle of an individual deployment. 
<li>Blog Post: <a href="https://aws.amazon.com/blogs/compute/implementing-canary-deployments-of-aws-lambda-functions-with-alias-traffic-shifting/">Implementing Canary Deployments of AWS Lambda Functions with Alias Traffic Shifting</a></li> 
</ul> </li> 
<li><a href="https://aws.amazon.com/about-aws/whats-new/2017/11/aws-lambda-introduces-enhanced-console-experience/">AWS Lambda Introduces Enhanced Console Experience</a> – We’ve reworked so many parts of the console that it’s hard to cover it in a single post. Go and check it out for yourself!</li> 
<li><a href="https://aws.amazon.com/about-aws/whats-new/2017/11/set-concurrency-limits-on-individual-aws-lambda-functions/">Set Concurrency Limits on Individual AWS Lambda Functions</a> – You can now set a concurrency reservation for a function in your account allowing you to limit functions from using too many backend resources or taking up too much concurrency, or to control costs. 
<li>Blog Post:&nbsp;<a href="https://aws.amazon.com/blogs/compute/managing-aws-lambda-function-concurrency/">Managing AWS Lambda Function Concurrency</a></li> 
</ul> </li> 
<li><a href="https://aws.amazon.com/about-aws/whats-new/2017/11/aws-cloudtrail-adds-logging-of-execution-activity-for-aws-lambda-functions/">AWS CloudTrail Adds Logging of Execution Activity for AWS Lambda Functions </a>– Gain a better understanding of who or what is invoking your Lambda functions via CloudTrail Data Events for Lambda.<br /> Pre-announcement: Golang and .NET Core 2.0 support coming soon!</li> 
<b>Amazon API Gateway</b> 
<li><a href="https://aws.amazon.com/about-aws/whats-new/2017/11/amazon-api-gateway-supports-endpoint-integrations-with-private-vpcs/">Amazon API Gateway Supports Endpoint Integrations with Private VPCs</a> – You can now provide access to HTTP(S) resources within your VPC without exposing them directly to the public internet. This includes resources available over a VPN or Direct Connect connection!</li> 
<li><a href="https://aws.amazon.com/about-aws/whats-new/2017/11/amazon-api-gateway-supports-canary-release-deployments/">Amazon API Gateway Supports Canary Release Deployments</a> – You can now use canary release deployments to gradually roll out new APIs. This helps you more safely roll out API changes and limit the blast radius of new deployments.</li> 
<li><a href="https://aws.amazon.com/about-aws/whats-new/2017/11/amazon-api-gateway-supports-access-logging/">Amazon API Gateway Supports Access Logging</a> – The access logging feature lets you generate access logs in different formats such as CLF (Common Log Format), JSON, XML, and CSV. The access logs can be fed into your existing analytics or log processing tools so you can perform more in-depth analysis or take action in response to the log data.</li> 
<li><a href="https://aws.amazon.com/about-aws/whats-new/2017/11/customize-integration-timeouts-in-amazon-api-gateway/">Amazon API Gateway Customize Integration Timeouts</a> – You can now set a custom timeout for your API calls as low as 50ms and as high as 29 seconds (the default is 30 seconds).</li> 
<li><a href="https://aws.amazon.com/about-aws/whats-new/2017/11/amazon-api-gateway-supports-generating-sdk-in-ruby/">Amazon API Gateway Supports Generating SDK in Ruby</a> – This is in addition to support for SDKs in Java, JavaScript, Android and iOS (Swift and Objective-C). The SDKs that Amazon API Gateway generates save you development time and come with a number of prebuilt capabilities, such as working with API keys, exponential back, and exception handling.</li> 
<b>AWS Serverless Application Repository</b> 
<p>Serverless Application Repository is a new service (currently in preview) that aids in the publication, discovery, and deployment of serverless applications. With it you’ll be able to find shared serverless applications that you can launch in your account, while also sharing ones that you’ve created for others to do the same.</p> 
<li><a href="https://pages.awscloud.com/serverlessrepo-preview.html">Sign up for the preview</a></li> 
<li><a href="https://aws.amazon.com/blogs/aws/aws-serverless-app-repo/">Jeff Barr blog post on Serverless Application Repository</a></li> 
<b>AWS Lambda@Edge</b> 
<p>Lambda@Edge now supports <a href="https://aws.amazon.com/about-aws/whats-new/2017/11/lambda-at-edge-now-supports-content-based-dynamic-origin-selection-network-calls-from-viewer-events-and-advanced-response-generation/">content-based dynamic origin selection, network calls from viewer events, and advanced response generation</a>. This combination of capabilities greatly increases the use cases for Lambda@Edge, such as allowing you to send requests to different origins based on request information, showing selective content based on authentication, and dynamically watermarking images for each viewer.</p> 
<b>AWS SAM</b> 
<li>Globals, Safe Lambda Deployments, Lambda Versions &amp; Aliases, Local Lambda execution (<a href="https://github.com/awslabs/serverless-application-model/releases/tag/1.3.0">GitHub release notes</a>)</li> 
<li>Make your apps more secure – SAM Policy Templates (<a href="https://github.com/awslabs/serverless-application-model/releases/tag/1.3.1">GitHub release notes</a>)</li> 
<b>Twitch Launchpad live announcements</b> 
<li><a href="https://www.twitch.tv/videos/206958123">Lambda traffic shifting, CodeDeploy, and API Gateway canaries</a></li> 
<li><a href="https://www.twitch.tv/videos/206753530">Lambda CloudTrail support, Lambda console update</a></li> 
<li><a href="https://www.twitch.tv/videos/206753480">Discussion on AWS Serverless Application Repository</a></li> 
<b>Other service announcements</b> 
<p>Here are some of the other highlights that you might have missed. We think these could help you make great applications:</p> 
<li><a href="https://aws.amazon.com/blogs/aws/in-the-works-amazon-aurora-serverless/">Amazon Aurora Serverless: On-demand auto-scaling database</a></li> 
<li><a href="https://aws.amazon.com/blogs/aws/aws-cloud9-cloud-developer-environments/">Cloud9: Cloud Developer Environments</a></li> 
<li><a href="https://aws.amazon.com/blogs/aws/deeplens/">DeepLens; An example of hardware that can run Lambda</a></li> 
<li><a href="https://aws.amazon.com/blogs/aws/introducing-amazon-appsync/">AppSync:&nbsp;Build data-driven apps with real-time and off-line capabilities</a></li> 
<b>AWS re:Invent 2017 sessions</b> 
<p>Coming up with the right mix of talks for an event like this can be quite a challenge. The Product, Marketing, and Developer Advocacy teams for Serverless at AWS spent weeks reading through dozens of talk ideas to boil it down to the final list.</p> 
<p>From feedback at other AWS events and webinars, we knew that customers were looking for talks that focused on concrete examples of solving problems with serverless, how to perform common tasks such as deployment, CI/CD, monitoring, and troubleshooting, and to see customer and partner examples solving real world problems. To that extent we tried to settle on a good mix based on attendee experience and provide a track full of rich content.</p> 
<p>Below are the recordings and slides of breakout sessions from re:Invent 2017. We’ve organized them for those getting started, those who are already beginning to build serverless applications, and the experts out there already running them at scale. Some of the videos and slides haven’t been posted yet, and so we will update this list as they become available.</p> 
<p>Find the entire <a href="https://www.youtube.com/playlist?list=PLhr1KZpdzukc-1lMQ8iugc82jaVUt_Nej">Serverless Track playlist</a> on YouTube.</p> 
<h3>Talks for people new to Serverless</h3> 
<li><a href="https://youtu.be/xJcm9V2jagc">Thirty Serverless Architectures in 30 Minutes</a> (SRV213-R)</li> 
<li><a href="https://youtu.be/ZguvcM_wqoo">NEW LAUNCH! AWS Serverless Application Repository</a> (SRV215)</li> 
<li><a href="https://youtu.be/WrPOz2dx8XY">What’s New in Serverless</a> (SRV305)</li> 
<li><a href="https://youtu.be/sMaqd5J69Ns">AWS Step Functions in the Wild!</a> (SRV306)</li> 
<li><a href="https://youtu.be/pMyniSCOJdA">Authoring and Deploying Serverless Applications with AWS SAM</a> (SRV311)</li> 
<li><a href="https://youtu.be/3iknsVpfYr0">Taking Serverless to the Edge</a> (SRV312) (<a href="https://www.slideshare.net/AmazonWebServices/srv312taking-serverless-to-the-edge">slides</a>)</li> 
<li><a href="https://youtu.be/WbHw14hF7lU">Getting Started with Serverless Computing Using AWS Lambda</a> (ENT332)</li> 
<h3>Advanced topics</h3> 
<li><a href="https://youtu.be/Wx0SHRb2xcI">Improving Microservice and Serverless Observability with Monitoring Data</a> (SRV210)</li> 
<li><a href="https://youtu.be/7plkSUN6DAE">Optimizing Serverless Application Data Tiers with Amazon DynamoDB</a> (SRV301) (<a href="https://www.slideshare.net/AmazonWebServices/srv301optimizing-serverless-application-data-tiers-with-amazon-dynamodb">slides</a>)</li> 
<li><a href="https://youtu.be/dCDZ7HR7dms">Building CI/CD Pipelines for Serverless Applications</a> (SRV302)</li> 
<li><a href="https://youtu.be/I2JE-JGHOKw">Monitoring and Troubleshooting in a Serverless Worl</a>d (SRV303)</li> 
<li><a href="https://youtu.be/Ojc4caCRtPU">Building High-Throughput Serverless Data Processing Pipelines</a> (SRV304) (<a href="https://www.slideshare.net/AmazonWebServices/srv304building-highthroughput-serverless-data-processing-pipelines">slides</a>)</li> 
<li><a href="https://youtu.be/QQjJHK2qEOs">Designing Microservices with Serverless</a> (SRV310-R) (<a href="https://www.slideshare.net/AmazonWebServices/srv310designing-microservices-with-serverless">slides</a>)</li> 
<h3>Expert mode</h3> 
<li><a href="https://youtu.be/tIfqpM3o55s">Operating Your Serverless API in Production at Scale</a> (SRV307)</li> 
<li><a href="https://youtu.be/B3j4xql7we0">Securing Serverless Applications Step-by-step</a> (SRV308)</li> 
<li><a href="https://youtu.be/nk81aI70bKc">Building Resilient, Multi-Region Serverless Applications</a> (SRV313)</li> 
<li><a href="https://youtu.be/Gr2TH277EdA">Best Practices for Orchestrating AWS Lambda Workloads </a>(SRV335)</li> 
<li><a href="https://youtu.be/oQFORsso2go">Become a Serverless Black Belt: Optimizing Your Serverless Applications</a> (SRV401)</li> 
<li><a href="https://youtu.be/k5yycEU1tXw">Big Data, Analytics and Machine Learning on AWS Lambda</a> (SRV402)</li> 
<li><a href="https://youtu.be/VZqG7HjT2AQ">Serverless Authentication and Authorization</a> (SRV403-R)</li> 
<h3>Talks for specific use cases</h3> 
<li><a href="https://youtu.be/lleCVR2Mupw">Building a Serverless Pipeline to Transcode a Two-Hour Video in Minutes</a> (SRV314) (<a href="https://www.slideshare.net/AmazonWebServices/srv314building-a-serverless-pipeline-to-transcode-a-twohour-video-in-minutes">slides</a>)</li> 
<li><a href="https://youtu.be/wLEHOTXU3As">Unlocking High Performance Computing for Financial Services with Serverless Compute</a> (SRV317)</li> 
<h3>Talks from AWS customers &amp; partners</h3> 
<li>Wipro – <a href="https://youtu.be/EpC0B85YO2I">Building Smart Applications Leveraging AWS to Drive Customer and Worker Experience</a> (SRV211) (<a href="https://www.slideshare.net/AmazonWebServices/srv211building-smart-applications-leveraging-aws-to-drive-customer-and-worker-experience">slides</a>)</li> 
<li>Dynatrace – <a href="https://youtu.be/_oYC07GPGjE">Keys to Successfully Monitoring and Optimizing Innovative and Sophisticated Cloud Applications </a>(SRV309)</li> 
<li>Homeaway – <a href="https://youtu.be/Hy2n-fC-r98">How We Built a Mission-Critical, Serverless File Processing Pipelines</a> (SRV315)</li> 
<li>Agero – <a href="https://youtu.be/RyrFqd0jeKo">How Agero is Preventing and Detecting Vehicle Accidents in Real-time with Serverless Computing</a> (SRV316)</li> 
<li>PNNL – <a href="https://youtu.be/2-1T-ly1ylE">Research at PNNL: Powered by AWS</a> (SRV318) (<a href="https://www.slideshare.net/AmazonWebServices/srv318research-at-pnnl-powered-by-aws">slides</a>)</li> 
<li>Nextdoor – <a href="https://youtu.be/AaRawf9vcZ4">How Nextdoor Built a Scalable, Serverless Data Pipeline for Billions of Events per Day</a> (SRV319)</li> 
<li>MongoDB – <a href="https://youtu.be/frW28vPfngU">Build a Serverless, Face-Recognizing IoT Security System with Amazon Rekognition and MongoDB Stitch</a> (SRV336)</li> 
<b>Looking to get hands-on with Serverless?</b> 
<p>At re:Invent, we delivered instructor-led skills sessions to help attendees new to serverless applications get started quickly. The content from these sessions is already online and you can do the hands-on labs yourself!<br /> <a href="https://aws.amazon.com/getting-started/serverless-web-app/">Build a Serverless web application</a></p> 
<b>Still looking for more?</b> 
<p>We also recently completely overhauled the main <a href="https://aws.amazon.com/serverless/">Serverless</a> landing page for AWS. This includes a new <a href="https://aws.amazon.com/lambda/resources/">Resources</a> page containing case studies, webinars, whitepapers, customer stories, reference architectures, and even more Getting Started tutorials. Check it out!</p> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-3521');
});
</script> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<meta property="image" content="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2017/12/14/Longer-ID-Console-screenshot-1022x630.png" /> 
<b class="lb-b blog-post-title" property="name headline">Longer Resource IDs in 2018 for Amazon EC2, Amazon EBS, and Amazon VPC</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Nathan Taber</span></span> | on 
<time property="datePublished" datetime="2017-12-14T14:25:22+00:00">14 DEC 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/compute/category/compute/amazon-ec2/" title="View all posts in Amazon EC2*"><span property="articleSection">Amazon EC2*</span></a>, <a href="https://aws.amazon.com/blogs/compute/category/storage/amazon-elastic-block-storage-ebs/" title="View all posts in Amazon Elastic Block Storage (EBS)*"><span property="articleSection">Amazon Elastic Block Storage (EBS)*</span></a>, <a href="https://aws.amazon.com/blogs/compute/category/compute/amazon-vpc/" title="View all posts in Amazon VPC*"><span property="articleSection">Amazon VPC*</span></a>, <a href="https://aws.amazon.com/blogs/compute/category/networking-content-delivery/amazon-vpc-networking-content-delivery/" title="View all posts in Amazon VPC*"><span property="articleSection">Amazon VPC*</span></a>, <a href="https://aws.amazon.com/blogs/compute/category/compute/" title="View all posts in Compute*"><span property="articleSection">Compute*</span></a>, <a href="https://aws.amazon.com/blogs/compute/category/networking-content-delivery/" title="View all posts in Networking &amp; Content Delivery*"><span property="articleSection">Networking &amp; Content Delivery*</span></a>, <a href="https://aws.amazon.com/blogs/compute/category/storage/" title="View all posts in Storage*"><span property="articleSection">Storage*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/compute/longer-resource-ids-in-2018-for-amazon-ec2-amazon-ebs-and-amazon-vpc/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-3513" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-compute&amp;disqus_identifier=3513&amp;disqus_title=Longer+Resource+IDs+in+2018+for+Amazon+EC2%2C+Amazon+EBS%2C+and+Amazon+VPC&amp;disqus_url=https://aws.amazon.com/blogs/compute/longer-resource-ids-in-2018-for-amazon-ec2-amazon-ebs-and-amazon-vpc/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-3513');
});
</script> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><em>This post contributed by Laura Thomson, Senior Product Manager for Amazon EC2.</em></p> 
<p>As you start planning for the new year, I want to give you a heads up that <a href="https://aws.amazon.com/ec2">Amazon EC2</a> is migrating to longer format, 17-character resource IDs. Instances and volumes currently already receive this ID format. Beginning in July 2018, all newly created EC2 resources receive longer IDs as well.</p> 
<p>The switch-over will not impact most customers. However, I wanted to make you aware so that you can schedule time at the beginning of 2018 to test your systems with the longer format. If you have a system that parses or stores resource IDs, you may be affected.</p> 
<p>From January 2018 through the end of June 2018, there will be a transition period, during which you can opt in to receive longer IDs. To make this easy, AWS will provide an option to opt in with one click for all regions, resources, and users. AWS will also provide more granular controls via API operations and console support. More information on the opt-in process will be sent out in January.</p> 
<p>We need to do this given how fast AWS is continuing to grow. We will start to run low on IDs for certain resources within a year or so. In order to enable the long-term, uninterrupted creation of new resources, we need to move to the longer ID format.</p> 
<p>The current format is a resource identifier followed by an eight-character string. The new format is the same resource identifier followed by a 17-character string. For example, your current VPCs have resource identifiers such as “vpc-1234abc0”. Starting July 2018, new VPCs will be assigned an identifier such as “vpc-1234567890abcdef0”. You can continue using the existing eight-character IDs for your existing resources, which won’t change and will continue to be supported. Only new resources will receive the 17-character IDs and only after you opt in to the new format.</p> 
<p>For more information, see <a href="https://aws.amazon.com/ec2/faqs/#longer-ids">Longer EC2, EBS, and Storage Gateway Resource IDs</a>.&nbsp; If you have any questions, contact AWS Support on the community forums and via <a href="https://console.aws.amazon.com/support/">AWS Support</a>.</p> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-3513');
});
</script> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<meta property="image" content="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2017/12/11/concurrency.png" /> 
<b class="lb-b blog-post-title" property="name headline">Managing AWS Lambda Function Concurrency</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Chris Munns</span></span> | on 
<time property="datePublished" datetime="2017-12-11T10:50:02+00:00">11 DEC 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/compute/category/compute/aws-lambda/" title="View all posts in AWS Lambda*"><span property="articleSection">AWS Lambda*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/compute/managing-aws-lambda-function-concurrency/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-3483" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-compute&amp;disqus_identifier=3483&amp;disqus_title=Managing+AWS+Lambda+Function+Concurrency&amp;disqus_url=https://aws.amazon.com/blogs/compute/managing-aws-lambda-function-concurrency/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-3483');
});
</script> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p>One of the key benefits of <a href="https://aws.amazon.com/serverless/">serverless applications</a> is the ease in which they can scale to meet traffic demands or requests, with little to no need for capacity planning. In <a href="https://aws.amazon.com/lambda">AWS Lambda</a>, which is the core of the serverless platform at AWS, the unit of scale is a <a href="https://docs.aws.amazon.com/lambda/latest/dg/concurrent-executions.html">concurrent execution</a>. This refers to the number of executions of your function code that are happening at any given time.</p> 
<p>Thinking about concurrent executions as a unit of scale is a fairly unique concept. In this post, I dive deeper into this and talk about how you can make use of per function concurrency limits in Lambda.<br /> <span id="more-3483"></span></p> 
<b>Understanding concurrency in Lambda</b> 
<p>Instead of diving right into the guts of how Lambda works, here’s an appetizing analogy: <strong>a magical pizza</strong>.<br /> Yes, a magical pizza!</p> 
<p><a href="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2017/12/11/pizza.png"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2017/12/11/pizza-300x300.png" /></a></p> 
<p>This magical pizza has some unique properties:</p> 
<li>It has a fixed maximum number of slices, such as 8.</li> 
<li>Slices automatically re-appear after they are consumed.</li> 
<li>When you take a slice from the pizza, it does not re-appear until it has been completely consumed.</li> 
<li>One person can take multiple slices at a time.</li> 
<li>You can easily ask to have the number of slices increased, but they remain fixed at any point in time otherwise.</li> 
<p>Now that the magical pizza’s properties are defined, here’s a hypothetical situation of some friends sharing this pizza.</p> 
<p>Shawn, Kate, Daniela, Chuck, Ian and Avleen get together every Friday to share a pizza and catch up on their week. As there is just six of them, they can easily all enjoy a slice of pizza at a time. As they finish each slice, it re-appears in the pizza&nbsp;pan&nbsp;and they can take another slice again. Given the magical properties of their pizza, they can continue to eat all they want, but with two very important constraints:</p> 
<li>If any of them take too many slices at once, the others may not get as much as they want.</li> 
<li>If they take too many slices, they might also eat too much and get sick.</li> 
<p>One particular week, some of the friends are hungrier than the rest, taking two slices at a time instead of just one. If more than two of them try to take two pieces at a time, this can cause contention for pizza slices. Some of them would wait hungry for the slices to re-appear. They could ask for a pizza with more slices, but then run the same risk again later if more hungry friends join than planned for.</p> 
<p>What can they do?</p> 
<p>If the friends agreed to accept a limit for the maximum number of slices they each eat concurrently, both of these issues are avoided. Some could have a maximum of 2 of the 8 slices, or other concurrency limits that were more or less. Just so long as they kept it at or under eight total slices to be eaten at one time. This would keep any from going hungry or eating too much. The six friends can happily enjoy their magical pizza without worry!</p> 
<b>Concurrency in Lambda</b> 
<p>Concurrency in Lambda actually works similarly to the magical pizza model. Each AWS Account has an overall <a href="https://docs.aws.amazon.com/lambda/latest/dg/API_GetAccountSettings.html">AccountLimit</a> value that is fixed at any point in time, but can be easily increased as needed, just like the count of slices in the pizza. <a href="https://aws.amazon.com/about-aws/whats-new/2017/05/aws-lambda-raises-default-concurrent-execution-limit/">As of May 2017</a>, the default limit is 1000 “slices” of concurrency per AWS Region.</p> 
<p>Also like the magical pizza, each concurrency “slice” can only be consumed individually one at a time. After consumption, it becomes available to be consumed again. Services invoking Lambda functions can consume multiple slices of concurrency at the same time, just like the group of friends can take multiple slices of the pizza.</p> 
<p>Let’s take our example of the six friends and bring it back to AWS services that commonly invoke Lambda:</p> 
<li>Amazon S3</li> 
<li>Amazon Kinesis</li> 
<li>Amazon DynamoDB</li> 
<li>Amazon Cognito</li> 
<p>In a single account with the default concurrency limit of 1000 concurrent executions, any of these four services could invoke enough functions to consume the entire limit or some part of it. Just like with the pizza example, there is the possibility for two issues to pop up:</p> 
<li>One or more of these services could invoke enough functions to consume a majority of the available concurrency capacity. This could cause others to be starved for it, causing failed invocations.</li> 
<li>A service could consume too much concurrent capacity and cause a downstream service or database to be overwhelmed, which could cause failed executions.</li> 
<p>For Lambda functions that are launched in a VPC, you have the potential to consume the available IP addresses in a subnet or the maximum number of elastic network interfaces to which your account has access. For more information, see <a href="https://docs.aws.amazon.com/lambda/latest/dg/vpc.html">Configuring a Lambda Function to Access Resources in an Amazon VPC</a>. For information about elastic network interface limits, see <a href="https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Appendix_Limits.html#vpc-limits-enis">Network Interfaces</a> section in the Amazon VPC Limits topic.</p> 
<p>One way to solve both of these problems is applying a concurrency limit to the Lambda functions in an account.</p> 
<b>Configuring per function concurrency limits</b> 
<p>You can now set a concurrency limit on individual Lambda functions in an account. The concurrency limit that you set reserves a portion of your account level concurrency for a given function. All of your functions’ concurrent executions count against this account-level limit by default.</p> 
<p>If you set a concurrency limit for a specific function, then that function’s concurrency limit allocation is deducted from the shared pool and assigned to that specific function. AWS also reserves 100 units of concurrency for all functions that don’t have a specified concurrency limit set. This helps to make sure that future functions have capacity to be consumed.</p> 
<p>Going back to the example of the consuming services, you could set throttles for the functions as follows:</p> 
<p>Amazon S3 function = 350<br /> Amazon Kinesis function = 200<br /> Amazon DynamoDB function = 200<br /> Amazon Cognito function = 150<br /> Total = 900</p> 
<p>With the 100 reserved for all non-concurrency reserved functions, this totals the account limit of 1000.</p> 
<p>Here’s how this works. To start, create a basic Lambda function that is invoked via <a href="https://aws.amazon.com/api-gateway">Amazon API Gateway</a>. This Lambda function returns a single “Hello World” statement with an added sleep time between 2 and 5 seconds. The sleep time simulates an API providing some sort of capability that can take a varied amount of time. The goal here is to show how an API that is underloaded can reach its concurrency limit, and what happens when it does.<br /> <strong>To create the example function</strong></p> 
<ol> 
<li>Open the <a href="https://console.aws.amazon.com/lambda/home">Lambda console</a>.</li> 
<li>Choose <strong>Create Function</strong>.</li> 
<li>For <strong>Author from scratch</strong>, enter the following values: 
<ol> 
<li>For <strong>Name</strong>, enter a value (such as concurrencyBlog01).</li> 
<li>For <strong>Runtime</strong>, choose <strong>Python 3.6</strong>.</li> 
<li>For <strong>Role</strong>, choose <strong>Create new role from template</strong> and enter a name aligned with this function, such as concurrencyBlogRole.</li> 
</ol> </li> 
<li>Choose <strong>Create function</strong>.</li> 
<li>The function is created with some basic example code. Replace that code with the following:</li> 
</ol> 
<code class="lang-python">
import time
from random import randint
seconds = randint(2, 5)
def lambda_handler(event, context):
time.sleep(seconds)
return {&quot;statusCode&quot;: 200,
&quot;body&quot;: (&quot;Hello world, slept &quot; + str(seconds) + &quot; seconds&quot;),
&quot;headers&quot;:
{
&quot;Access-Control-Allow-Headers&quot;: &quot;Content-Type,X-Amz-Date,Authorization,X-Api-Key,X-Amz-Security-Token&quot;,
&quot;Access-Control-Allow-Methods&quot;: &quot;GET,OPTIONS&quot;,
}}
<a href="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2017/12/11/code-editor.png"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2017/12/11/code-editor.png" /></a>
</code> 
<ol start="6"> 
<li>Under <strong>Basic settings</strong>, set <strong>Timeout</strong> to 10 seconds. While this function should only ever take up to 5-6 seconds (with the 5-second max sleep), this gives you a little bit of room if it takes longer.</li> 
</ol> 
<p><a href="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2017/12/11/basic-settings.png"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2017/12/11/basic-settings.png" /></a></p> 
<ol start="7"> 
<li>Choose <strong>Save</strong> at the top right.</li> 
</ol> 
<p>At this point, your function is configured for this example. Test it and confirm this in the console:</p> 
<ol> 
<li>Choose <strong>Test</strong>.</li> 
<li>Enter a name (it doesn’t matter for this example).</li> 
<li>Choose <strong>Create</strong>.</li> 
<li>In the console, choose <strong>Test</strong> again.</li> 
<li>You should see output similar to the following:</li> 
</ol> 
<p><a href="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2017/12/11/test-success.png"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2017/12/11/test-success.png" /></a></p> 
<p>Now configure API Gateway so that you have an HTTPS endpoint to test against.</p> 
<ol> 
<li>In the Lambda console, choose <strong>Configuration</strong>.</li> 
<li>Under <strong>Triggers</strong>, choose <strong>API Gateway</strong>.</li> 
<li>Open the API Gateway icon now shown as attached to your Lambda function:</li> 
</ol> 
<p><a href="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2017/12/11/triggers.png"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2017/12/11/triggers.png" /></a></p> 
<ol start="4"> 
<li>Under <strong>Configure triggers</strong>, leave the default values for <strong>API Name</strong> and <strong>Deployment stage</strong>. For <strong>Security</strong>, choose <strong>Open</strong>.</li> 
<li>Choose <strong>Add, Save</strong>.</li> 
</ol> 
<p>API Gateway is now configured to invoke Lambda at the Invoke URL shown under its configuration. You can take this URL and test it in any browser or command line, using tools such as “curl”:</p> 
<code class="lang-bash">
$ curl https://ofixul557l.execute-api.us-east-1.amazonaws.com/prod/concurrencyBlog01
Hello world, slept 2 seconds
</code> 
<h3>Throwing load at the function</h3> 
<p>Now start throwing some load against your API Gateway + Lambda function combo. Right now, your function is only limited by the total amount of concurrency available in an account. For this example account, you might have 850 unreserved concurrency out of a full account limit of 1000 due to having configured a few concurrency limits already (also the 100 concurrency saved for all functions without configured limits). You can find all of this information on the main <strong>Dashboard</strong> page of the Lambda console:</p> 
<p><a href="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2017/12/11/lambda-dash.png"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2017/12/11/lambda-dash.png" /></a></p> 
<p>For generating load in this example, use an open source tool called “hey” (<a href="https://github.com/rakyll/hey">https://github.com/rakyll/hey</a>), which works similarly to ApacheBench (<a href="https://httpd.apache.org/docs/2.4/programs/ab.html">ab</a>). You test from an Amazon EC2 instance running the default Amazon Linux AMI from the EC2 console. For more help with configuring an EC2 instance, follow the steps in the <a href="https://console.aws.amazon.com/ec2/v2/home?region=us-east-1#LaunchInstanceWizard:">Launch Instance Wizard</a>.</p> 
<p>After the EC2 instance is running, SSH into the host and run the following:</p> 
<code class="lang-bash">
sudo yum install go
go get -u github.com/rakyll/hey
</code> 
<p>“hey” is easy to use. For these tests, specify a total number of tests (5,000) and a concurrency of 50 against the API Gateway URL as follows(replace the URL here with your own):</p> 
<code class="lang-bash">
$ ./go/bin/hey -n 5000 -c 50 https://ofixul557l.execute-api.us-east-1.amazonaws.com/prod/concurrencyBlog01
</code> 
<p>The output from “hey” tells you interesting bits of information:</p> 
<code class="lang-bash">
$ ./go/bin/hey -n 5000 -c 50 https://ofixul557l.execute-api.us-east-1.amazonaws.com/prod/concurrencyBlog01
Summary:
Total: 381.9978 secs
Slowest: 9.4765 secs
Fastest: 0.0438 secs
Average: 3.2153 secs
Requests/sec: 13.0891
Total data: 140024 bytes
Size/request: 28 bytes
Response time histogram:
0.044 [1] |
0.987 [2] |
1.930 [0] |
2.874 [1803] |∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎
3.817 [1518] |∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎
4.760 [719] |∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎
5.703 [917] |∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎
6.647 [13] |
7.590 [14] |
8.533 [9] |
9.477 [4] |
Latency distribution:
10% in 2.0224 secs
25% in 2.0267 secs
50% in 3.0251 secs
75% in 4.0269 secs
90% in 5.0279 secs
95% in 5.0414 secs
99% in 5.1871 secs
Details (average, fastest, slowest):
DNS+dialup: 0.0003 secs, 0.0000 secs, 0.0332 secs
DNS-lookup: 0.0000 secs, 0.0000 secs, 0.0046 secs
req write: 0.0000 secs, 0.0000 secs, 0.0005 secs
resp wait: 3.2149 secs, 0.0438 secs, 9.4472 secs
resp read: 0.0000 secs, 0.0000 secs, 0.0004 secs
Status code distribution:
[200] 4997 responses
[502] 3 responses
</code> 
<p>You can see a helpful histogram and latency distribution. Remember that this Lambda function has a random sleep period in it and so isn’t entirely representational of a real-life workload. Those three 502s warrant digging deeper, but could be due to Lambda cold-start timing and the “second” variable being the maximum of 5, causing the Lambda functions to time out. AWS X-Ray and the Amazon CloudWatch logs generated by both API Gateway and Lambda could help you troubleshoot this.</p> 
<h3>Configuring a concurrency reservation</h3> 
<p>Now that you’ve established that you can generate this load against the function, I show you how to limit it and protect a backend resource from being overloaded by all of these requests.</p> 
<ol> 
<li>In the console, choose <strong>Configure</strong>.</li> 
<li>Under <strong>Concurrency</strong>, for <strong>Reserve concurrency</strong>, enter 25.</li> 
</ol> 
<p><a href="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2017/12/11/concurrency.png"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2017/12/11/concurrency.png" /></a></p> 
<ol start="3"> 
<li>Click on <strong>Save</strong> in the top right corner.</li> 
</ol> 
<p>You could also set this with the AWS CLI using the Lambda&nbsp;<a href="https://docs.aws.amazon.com/cli/latest/reference/lambda/put-function-concurrency.html">put-function-concurrency</a> command or see your current concurrency configuration via Lambda get-function. Here’s an example command:</p> 
<code class="lang-bash">
$ aws lambda get-function --function-name concurrencyBlog01 --output json --query Concurrency
{
&quot;ReservedConcurrentExecutions&quot;: 25
}
</code> 
<p>Either way, you’ve set the Concurrency Reservation to 25 for this function. This acts as both a limit and a reservation in terms of making sure that you can execute 25 concurrent functions at all times. Going above this results in the throttling of the Lambda function. Depending on the invoking service, throttling can result in a number of different outcomes, as shown in the documentation on <a href="https://docs.aws.amazon.com/lambda/latest/dg/concurrent-executions.html">Throttling Behavior</a>. This change has also reduced your unreserved account concurrency for other functions by 25.</p> 
<p>Rerun the same load generation as before and see what happens. Previously, you tested at 50 concurrency, which worked just fine. By limiting the Lambda functions to 25 concurrency, you should see rate limiting kick in. Run the same test again:</p> 
<code class="lang-bash">
$ ./go/bin/hey -n 5000 -c 50 https://ofixul557l.execute-api.us-east-1.amazonaws.com/prod/concurrencyBlog01
</code> 
<p>While this test runs, refresh the <strong>Monitoring</strong> tab on your function detail page. You see the following warning message:</p> 
<p><a href="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2017/12/11/warning.png"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2017/12/11/warning.png" /></a></p> 
<p>This is great! It means that your throttle is working as configured and you are now protecting your downstream resources from too much load from your Lambda function.</p> 
<p>Here is the output from a new “hey” command:</p> 
<code class="lang-bash">
$ ./go/bin/hey -n 5000 -c 50 https://ofixul557l.execute-api.us-east-1.amazonaws.com/prod/concurrencyBlog01
Summary:
Total: 379.9922 secs
Slowest: 7.1486 secs
Fastest: 0.0102 secs
Average: 1.1897 secs
Requests/sec: 13.1582
Total data: 164608 bytes
Size/request: 32 bytes
Response time histogram:
0.010 [1] |
0.724 [3075] |∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎
1.438 [0] |
2.152 [811] |∎∎∎∎∎∎∎∎∎∎∎
2.866 [11] |
3.579 [566] |∎∎∎∎∎∎∎
4.293 [214] |∎∎∎
5.007 [1] |
5.721 [315] |∎∎∎∎
6.435 [4] |
7.149 [2] |
Latency distribution:
10% in 0.0130 secs
25% in 0.0147 secs
50% in 0.0205 secs
75% in 2.0344 secs
90% in 4.0229 secs
95% in 5.0248 secs
99% in 5.0629 secs
Details (average, fastest, slowest):
DNS+dialup: 0.0004 secs, 0.0000 secs, 0.0537 secs
DNS-lookup: 0.0002 secs, 0.0000 secs, 0.0184 secs
req write: 0.0000 secs, 0.0000 secs, 0.0016 secs
resp wait: 1.1892 secs, 0.0101 secs, 7.1038 secs
resp read: 0.0000 secs, 0.0000 secs, 0.0005 secs
Status code distribution:
[502] 3076 responses
[200] 1924 responses
</code> 
<p>This looks fairly different from the last load test run. A large percentage of these requests failed fast due to the concurrency throttle failing them (those with the 0.724 seconds line). The timing shown here in the histogram represents the entire time it took to get a response between the EC2 instance and API Gateway calling Lambda and being rejected. It’s also important to note that this example was configured with an <a href="https://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-api-migration.html">edge-optimized endpoint</a> in API Gateway. You see under <strong>Status code distribution</strong> that 3076 of the 5000 requests failed with a 502, showing that the backend service from API Gateway and Lambda failed the request.</p> 
<b>Other uses</b> 
<p>Managing function concurrency can be useful in a few other ways beyond just limiting the impact on downstream services and providing a reservation of concurrency capacity. Here are two other uses:</p> 
<li>Emergency kill switch</li> 
<li>Cost controls</li> 
<h3>Emergency kill switch</h3> 
<p>On occasion, due to issues with applications I’ve managed in the past, I’ve had a need to disable a certain function or capability of an application. By setting the concurrency reservation and limit of a Lambda function to zero, you can do just that.</p> 
<p>With the reservation set to zero every invocation of a Lambda function results in being throttled. You could then work on the related parts of the infrastructure or application that aren’t working, and then reconfigure the concurrency limit to allow invocations again.</p> 
<h3>Cost controls</h3> 
<p>While I mentioned how you might want to use concurrency limits to control the downstream impact to services or databases that your Lambda function might call, another resource that you might be cautious about is money. Setting the concurrency throttle is another way to help control costs during development and testing of your application.</p> 
<p>You might want to prevent against a function performing a recursive action too quickly or a development workload generating too high of a concurrency. You might also want to protect development resources connected to this function from generating too much cost, such as APIs that your Lambda function calls.</p> 
<b>Conclusion</b> 
<p>Concurrent executions as a unit of scale are a fairly unique characteristic about Lambda functions. Placing limits on how many concurrency “slices” that your function can consume can prevent a single function from consuming all of the available concurrency in an account. Limits can also prevent a function from overwhelming a backend resource that isn’t as scalable.</p> 
<p>Unlike monolithic applications or even microservices where there are mixed capabilities in a single service, Lambda functions encourage a sort of “nano-service” of <a href="https://docs.aws.amazon.com/lambda/latest/dg/best-practices.html">small business logic</a> directly related to the integration model connected to the function. I hope you’ve enjoyed this post and configure your concurrency limits today!</p> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-3483');
});
</script> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<meta property="image" content="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2017/12/06/ECS_windows_container-two.png" /> 
<b class="lb-b blog-post-title" property="name headline">Running Windows Containers on Amazon ECS</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Nathan Taber</span></span> | on 
<time property="datePublished" datetime="2017-12-06T10:33:55+00:00">06 DEC 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/compute/category/compute/amazon-ec2-container-registry/" title="View all posts in Amazon EC2 Container Registry*"><span property="articleSection">Amazon EC2 Container Registry*</span></a>, <a href="https://aws.amazon.com/blogs/compute/category/compute/amazon-ec2-container-service/" title="View all posts in Amazon EC2 Container Service*"><span property="articleSection">Amazon EC2 Container Service*</span></a>, <a href="https://aws.amazon.com/blogs/compute/category/amazon-ecs/" title="View all posts in Amazon ECS"><span property="articleSection">Amazon ECS</span></a></span> | 
<a href="https://aws.amazon.com/blogs/compute/running-windows-containers-on-amazon-ecs/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-3464" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-compute&amp;disqus_identifier=3464&amp;disqus_title=Running+Windows+Containers+on+Amazon+ECS&amp;disqus_url=https://aws.amazon.com/blogs/compute/running-windows-containers-on-amazon-ecs/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-3464');
});
</script> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><em>This post was developed and written by Jeremy Cowan, Thomas Fuller, Samuel Karp, and Akram Chetibi.<br /> </em></p> 
<p>—</p> 
<p>Containers have revolutionized the way that developers build, package, deploy, and run applications. Initially, containers only supported code and tooling for Linux applications. With the release of Docker Engine for Windows Server 2016, Windows developers have started to realize the gains that their Linux counterparts have experienced for the last several years.</p> 
<p>This week, <a href="https://aws.amazon.com/about-aws/whats-new/2017/12/amazon-ecs-support-for-windows-server-containers-ga/">we’re adding support</a> for running production workloads in Windows containers using Amazon Elastic Container Service (<a href="https://aws.amazon.com/ecs">Amazon ECS</a>). Now, Amazon ECS provides an ECS-Optimized&nbsp;Windows Server Amazon Machine Image (AMI). This AMI is based on the EC2 Windows Server 2016&nbsp;AMI, and includes Docker 17.06 Enterprise Edition and the ECS Agent 1.16. This AMI provides improved&nbsp;instance and container launch time performance.&nbsp;It’s based on Windows Server&nbsp;2016 Datacenter and includes Docker 17.06.2-ee-5, along with a new version of the ECS agent that now runs as a native Windows service.<span id="more-3464"></span></p> 
<p>In this post, I discuss the benefits of this new support, and walk you through getting started running Windows containers with Amazon ECS.</p> 
<p>When AWS released the Windows Server 2016 Base with Containers AMI, the ECS agent ran as a process that made it difficult to monitor and manage. As a service, the agent can be health-checked, managed, and restarted no differently than other Windows services. The AMI also includes pre-cached images for Windows Server&nbsp;Core 2016 and Windows Server&nbsp;Nano&nbsp;Server 2016. By caching the images in the AMI, launching new Windows containers is significantly faster. When Docker images include a layer that’s already cached on the instance, Docker re-uses that layer instead of pulling it from the Docker registry.</p> 
<p>The ECS agent and an accompanying ECS PowerShell module used to install, configure, and run the agent come pre-installed on the AMI. This guarantees there is a specific platform version available on the container instance at launch. Because the software is included, you don’t have to download it from the internet. This saves startup time.</p> 
<p>The Windows-compatible ECS-optimized AMI also reports CPU and memory utilization and reservation metrics to <a href="https://aws.amazon.com/cloudwatch">Amazon CloudWatch</a>. Using the CloudWatch integration with ECS, you can create alarms that trigger dynamic scaling events to automatically add or remove capacity to your EC2 instances and ECS tasks.</p> 
<b>Getting started</b> 
<p>To help you get started running Windows containers on ECS, I’ve forked the <a href="https://github.com/awslabs/ecs-refarch-cloudformation">ECS reference architecture</a>, to build an ECS cluster comprised of Windows instances instead of Linux instances. You can pull the latest version of the <a href="https://github.com/aws-samples/ecs-refarch-cloudformation-windows">reference architecture for Windows</a>.</p> 
<p>The reference architecture is a layered CloudFormation stack, in that it calls other stacks to create the environment. Within the stack, the ecs-windows-cluster.yaml file contains the instructions for bootstrapping the Windows instances and configuring the ECS cluster. To configure the instances outside of AWS CloudFormation (for example, through the CLI or the console), you can add the following commands to your instance’s user data:</p> 
<code class="lang-yaml">Import-Module ECSTools
Initialize-ECSAgent</code> 
<p>Or</p> 
<code class="lang-yaml">Import-Module ECSTools
Initialize-ECSAgent –Cluster MyCluster -EnableIAMTaskRole</code> 
<p>If you don’t specify a cluster name when you initialize the agent, the instance is joined to the default cluster.</p> 
<p>Adding <code class="lang-bash">-EnableIAMTaskRole</code> when initializing the agent adds support for IAM roles for tasks. Previously, enabling this setting meant running a complex script and setting an environment variable before you could assign roles to your ECS tasks.</p> 
<p>When you enable IAM roles for tasks on Windows, it consumes port 80 on the host. If you have tasks that listen on&nbsp;port 80 on the host, I recommend configuring a service for them that uses load balancing. You can use port 80 on the load balancer, and the traffic can be routed to another host port on your container instances. For more information, see <a href="http://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-load-balancing.html">Service Load Balancing</a>.</p> 
<h3>Create a cluster</h3> 
<p>To create a new ECS cluster, choose Launch stack, or pull the GitHub project to your local machine and run the following command:</p> 
<p><code class="lang-bash">aws cloudformation create-stack –template-body file://&lt;path to master-windows.yaml&gt; --stack-name &lt;name&gt;</code></p> 
<h3>Upload your container image</h3> 
<p>Now that you have a cluster running, step through how to build and push an image into a container repository. You use a repository hosted in Amazon Elastic Container Registry (<a href="https://aws.amazon.com/ecr">Amazon ECR</a>) for this, but you could also use Docker Hub. To build and push an image to a repository, install Docker on your Windows* workstation. You also create a repository and assign the necessary permissions to the account that pushes your image to Amazon ECR. For detailed instructions, see <a href="http://docs.aws.amazon.com/AmazonECR/latest/userguide/docker-push-ecr-image.html">Pushing an Image</a>.</p> 
<p><em>* If you are building an image that is based on Windows layers, then you must use a Windows environment to build and push your image to the registry.</em></p> 
<h3>Write your task definition</h3> 
<p>Now that your image is built and ready, the next step is to run your Windows containers using a task.</p> 
<p>Start by creating a new task definition based on the <a href="https://hub.docker.com/r/microsoft/iis">windows-simple-iis</a> image from Docker Hub.</p> 
<ol> 
<li>Open the <a href="https://console.aws.amazon.com/ecs/home">ECS console</a>.</li> 
<li>Choose <strong>Task Definitions</strong>, <strong>Create new task definition</strong>.</li> 
<li>Scroll to the bottom of the page and choose <strong>Configure via JSON</strong>.</li> 
<li>Copy and paste the following JSON into that field.</li> 
<li>Choose <strong>Save, Create</strong>.</li> 
</ol> 
<code class="lang-json">{
&quot;family&quot;: &quot;windows-simple-iis&quot;,
&quot;containerDefinitions&quot;: [
{
&quot;name&quot;: &quot;windows_sample_app&quot;,
&quot;image&quot;: &quot;microsoft/iis&quot;,
&quot;cpu&quot;: 100,
&quot;entryPoint&quot;:[&quot;powershell&quot;, &quot;-Command&quot;],
&quot;command&quot;:[&quot;New-Item -Path C:\\inetpub\\wwwroot\\index.html -Type file -Value '&lt;html&gt;&lt;head&gt;&lt;title&gt;Amazon ECS Sample App&lt;/title&gt; &lt;style&gt;body {margin-top: 40px; background-color: #333;} &lt;/style&gt; &lt;/head&gt;&lt;body&gt; &lt;div style=color:white;text-align:center&gt;&lt;b&gt;Amazon ECS Sample App&lt;/b&gt; &lt;b&gt;Congratulations!&lt;/b&gt; &lt;p&gt;Your application is now running on a container in Amazon ECS.&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;'; C:\\ServiceMonitor.exe w3svc&quot;],
&quot;portMappings&quot;: [
{
&quot;protocol&quot;: &quot;tcp&quot;,
&quot;containerPort&quot;: 80,
&quot;hostPort&quot;: 8080
}
],
&quot;memory&quot;: 500,
&quot;essential&quot;: true
}
]
}</code> 
<p>You can now go back into the Task Definition page and see <code class="lang-bash">windows-simple-iis</code> as an available task definition.</p> 
<p>There are a&nbsp;few important aspects of the task definition file to note when working with Windows containers. First, the hostPort is configured as 8080, which is necessary because the ECS agent currently uses port 80 to enable IAM roles for tasks required for least-privilege security configurations.</p> 
<p>There are also some fairly standard task parameters that are intentionally not included. For example, network mode is not available with Windows at the time of this release, so keep that setting blank to allow Docker to configure WinNAT, the only option available today.</p> 
<p>Also, some parameters work differently with Windows than they do with Linux. The CPU limits that you define in the task definition are absolute, whereas on Linux they are weights. For information about other task parameters that are supported or possibly different with Windows, see the <a href="http://docs.aws.amazon.com/AmazonECS/latest/developerguide/windows_task_definitions.html#windows_sample_task_defs">documentation</a>.</p> 
<h3>Run your containers</h3> 
<p>At this point, you are ready to run containers. There are two options to run containers with ECS:</p> 
<ol> 
<li>Task</li> 
<li>Service</li> 
</ol> 
<p>A task is typically a short-lived process that ECS creates. It can’t be configured to actively monitor or scale. A service is meant for longer-running containers and can be configured to use a load balancer, minimum/maximum capacity settings, and a number of other knobs and switches to help ensure that your code keeps running. In both cases, you are able to pick a placement strategy and a specific IAM role for your container.</p> 
<ol> 
<li>Select the task definition that you created above and choose Action, Run Task.</li> 
<li>Leave the settings on the next page to the default values.</li> 
<li>Select the ECS cluster created when you ran the CloudFormation template.</li> 
<li>Choose Run Task to start the process of scheduling a Docker container on your ECS cluster.</li> 
</ol> 
<p>You can now go to the cluster and watch the status of your task. It may take 5–10 minutes for the task to go from <strong>PENDING</strong> to <strong>RUNNING</strong>, mostly because it takes time to download all of the layers necessary to run the&nbsp;<em>microsoft/iis</em> image. After the status is <strong>RUNNING</strong>, you should see the following results:</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2017/12/06/17-12-Windows-GA-1.png" /></p> 
<p>You may have noticed that the example task definition is&nbsp;named <em>windows-simple-iis:2</em>. This is because I created a second version of the task definition, which is one of the powerful capabilities of using ECS. You can make the task definitions part of your source code and then version them. You can also roll out new versions and practice blue/green deployment, switching to reduce downtime and improve the velocity of your deployments!</p> 
<p>After the task has moved to <strong>RUNNING</strong>, you can see your website hosted in ECS. Find the public IP or DNS for your ECS host. Remember that you are hosting on port 8080. Make sure that the security group allows ingress from your client IP address to that port and that your VPC has an internet gateway associated with it. You should see a page that looks like the following:</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2017/12/06/17-12-Windows-GA-2.png" /></p> 
<p>This is a nice start to deploying a simple single instance task, but what if you had a Web API to be scaled out and in based on usage? This is where you could look at defining a service and collecting CloudWatch data to add and remove both instances of the task. You could also use CloudWatch alarms to add more ECS container instances and keep up with the demand. The former is built into the configuration of your service.</p> 
<ol> 
<li>Select the task definition and choose&nbsp;<strong>Create Service</strong>.</li> 
<li>Associate a load balancer.</li> 
<li>Set up Auto Scaling.</li> 
</ol> 
<p>The following screenshot shows an example where you would add an additional task instance when the <strong>CPU Utilization</strong> CloudWatch metric is over 60% on average over three consecutive measurements. This may not be aggressive enough for your requirements; it’s meant to show you the option to scale tasks the same way you scale ECS instances with an Auto Scaling group. The difference is that these tasks start much faster because all of the base layers are already on the ECS host.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/1b6453892473a467d07372d45eb05abc2031647a/2017/12/06/17-12-Windows-GA-3.png" /></p> 
<p>Do not confuse task dynamic scaling with ECS instance dynamic scaling. To add additional hosts, see <a href="http://docs.aws.amazon.com/AmazonECS/latest/developerguide/cloudwatch_alarm_autoscaling.html">Tutorial: Scaling Container Instances with CloudWatch Alarms</a>.</p> 
<b>Conclusion</b> 
<p>This is just scratching the surface of the flexibility that you get from using containers and Amazon ECS. For more information, see the <a href="http://docs.aws.amazon.com/AmazonECS/latest/developerguide/Welcome.html">Amazon ECS Developer Guide</a> and <a href="https://aws.amazon.com/ecs/resources">ECS Resources</a>.</p> 
<p>– Jeremy, Thomas, Samuel, Akram</p> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-3464');
});
</script> 
</article> 
<p>
© 2018 Amazon Web Services, Inc. or its affiliates. All rights reserved.
</p>

    </div>
  </div>
</div>


    <div id="footer" class="navigation hidden-print">
      <div class="container">
        <div class="row">
          <div class="col-xs-12">
            <ul class="footer-links nav navbar-nav">
              <li><a href="../aws.html">AWS</a></li>
              <li><a href="../linux.html">Linux</a></li>
              <li><a href="../docker.html">Docker</a></li>
              <li><a href="../ibmpower.html">IBM Power</a></li>
              <li><a href="blogsataws1.html">Blogs@AWS (Kindle Friendly)</a></li>
            </ul>
            <ul class="footer-links nav navbar-nav navbar-right">
              <li><a href="../comments.html">Comments?</a></li>
            </ul>
          </div>
        </div>
      </div>
    </div>
  </body>
</html>
