<!DOCTYPE html>
<html lang="en">
  <head>
<!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-593498H');</script>
<!-- End Google Tag Manager -->

    <meta charset="utf-8">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">

    <meta name="msapplication-config" content="/microsoft-tile.xml" />
    <meta name="theme-color" content="#ffffff">

    <meta property="og:url" content="https://bejoycalias.github.io/blogsataws/mgmtblogs1.html" />
    <meta property="og:site_name" content="Bejoy's TechNotes"/>
    <meta property="og:title" content="Bejoy's TechNotes - Kindle Friendly AWS Management Tools Blogs" />
    <meta property="og:image" content="https://bejoycalias.github.io/assets/images/og-image.png"/>
    <meta property="og:image:width" content="1200"/>
    <meta property="og:image:height" content="1200"/>
    <meta property="og:description" content="" />

    <title>Bejoy's TechNotes - Kindle Friendly AWS Management Tools Blogs</title>
    <link href="../assets/stylesheets/application-832aa42c.css" rel="stylesheet" />

    <!--[if lt IE 9]>
      <script src="../assets/javascripts/ie-compat-c141a02d.js"></script>
    <![endif]-->
    <script src="../assets/javascripts/application-ff53d307.js"></script>

    <!-- Typekit script to import Klavika font -->
    <script src="https://use.typekit.net/wxf7mfi.js"></script>
    <script>try{Typekit.load({ async: true });}catch(e){}</script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-100043608-1', 'auto');
  ga('send', 'pageview');

</script>

    
  </head>

  <body id="uh-oh-" class="layout-inner page-uh-oh-">
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-593498H"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->


    <div id="header" class="navigation navbar-static-top hidden-print">
      <div class="container">
        <div class="row">
          <div class="col-xs-12">
            <div class="navbar-header">
              <div class="navbar-brand">
                <a href="/">
                  <svg version="1.0" xmlns="http://www.w3.org/2000/svg" width="135.000000pt" height="50" viewbox="0 0 135.000000 45.000000" preserveaspectratio="xMidYMid meet" class="logo">

<g transform="translate(0.000000,45.000000) scale(0.100000,-0.100000)" fill="#000000" stroke="none">
<path class="text" fill="#000000" d="M527 384 c-4 -4 -7 -18 -7 -31 0 -21 4 -24 28 -21 21 2 27 8 27 28 0
18 -6 26 -20 28 -12 2 -24 0 -28 -4z"></path>
<path class="text" fill="#000000" d="M1080 335 c0 -48 2 -55 20 -55 18 0 20 7 20 55 0 48 -2 55 -20 55
-18 0 -20 -7 -20 -55z"></path>
<path class="text" fill="#000000" d="M54 357 c-2 -7 -3 -69 -2 -138 l3 -124 65 -3 c90 -3 130 20 130 77 0
29 -6 44 -20 54 -20 14 -20 15 -3 45 14 25 15 34 5 56 -6 15 -23 31 -38 36
-38 15 -134 13 -140 -3z m110 -33 c19 -7 21 -45 4 -62 -7 -7 -22 -12 -35 -12
-20 0 -23 5 -23 40 0 41 13 50 54 34z m20 -130 c19 -18 19 -20 6 -45 -8 -13
-21 -19 -45 -19 -34 0 -35 1 -35 40 0 38 2 40 29 40 16 0 37 -7 45 -16z"></path>
<path class="text" fill="#000000" d="M319 271 c-23 -24 -29 -38 -29 -74 0 -25 3 -53 6 -62 20 -50 164 -64
164 -15 0 15 -7 17 -45 12 -46 -5 -75 8 -75 34 0 11 16 14 65 14 l65 0 0 35
c0 80 -92 114 -151 56z m99 -33 c3 -15 -4 -18 -37 -18 -43 0 -50 7 -29 28 18
18 62 11 66 -10z"></path>
<path class="text" fill="#000000" d="M520 184 c0 -107 -1 -116 -20 -121 -11 -3 -20 -12 -20 -19 0 -21 76
-19 84 2 3 9 6 69 6 135 l0 119 -25 0 -25 0 0 -116z"></path>
<path class="text" fill="#000000" d="M649 271 c-24 -25 -29 -37 -29 -78 1 -70 34 -103 105 -103 55 0 95
44 95 103 0 60 -7 75 -41 92 -47 25 -96 19 -130 -14z m111 -30 c25 -48 2 -111
-40 -111 -45 0 -69 80 -34 114 21 22 61 20 74 -3z"></path>
<path class="text" fill="#000000" d="M850 287 c0 -8 16 -57 36 -110 28 -76 33 -100 25 -116 -16 -28 -14
-31 18 -31 27 0 29 4 70 123 23 67 41 128 41 135 0 6 -11 12 -24 12 -21 0 -26
-8 -41 -65 -10 -36 -21 -68 -25 -70 -3 -2 -16 27 -29 66 -19 60 -25 69 -47 69
-13 0 -24 -6 -24 -13z"></path>
<path class="text" fill="#000000" d="M1192 284 c-17 -12 -22 -24 -20 -47 2 -26 10 -36 45 -52 49 -23 59
-55 17 -55 -14 0 -34 5 -45 10 -16 9 -19 7 -19 -13 0 -17 7 -27 23 -31 69 -18
117 6 117 60 0 32 -4 37 -45 55 -60 26 -62 54 -4 46 37 -5 40 -3 37 16 -2 18
-11 23 -43 25 -25 2 -49 -3 -63 -14z"></path>
</g>
</svg>

                </a>
              </div>
              <button class="navbar-toggle" type="button">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
              </button>
            </div>
            <div class="buttons hidden-xs">
              <nav class="navigation-links" role="navigation">
                <ul class="main-links nav navbar-nav navbar-right">
                  <li><a href="../aws.html">AWS</a></li>
                  <li><a href="../linux.html">Linux</a></li>
                  <li><a href="../docker.html">Docker</a></li>
                  <li><a href="../ibmpower.html">IBM Power</a></li>
                  <li><a href="blogsataws1.html">Blogs@AWS (Kindle Friendly)</a></li>
                </ul>
              </nav>
            </div>
          </div>
        </div>
      </div>
    </div>

    <div class="sidebar-overlay"></div>

<aside class="sidebar" role="navigation">
  <div class="sidebar-header">
    <svg version="1.0" xmlns="http://www.w3.org/2000/svg" width="135.000000pt" height="42" viewbox="0 0 135.000000 45.000000" preserveaspectratio="xMidYMid meet">

<g transform="translate(0.000000,45.000000) scale(0.100000,-0.100000)" fill="#000000" stroke="none">
<path class="text" fill="#000000" d="M527 384 c-4 -4 -7 -18 -7 -31 0 -21 4 -24 28 -21 21 2 27 8 27 28 0
18 -6 26 -20 28 -12 2 -24 0 -28 -4z"></path>
<path class="text" fill="#000000" d="M1080 335 c0 -48 2 -55 20 -55 18 0 20 7 20 55 0 48 -2 55 -20 55
-18 0 -20 -7 -20 -55z"></path>
<path class="text" fill="#000000" d="M54 357 c-2 -7 -3 -69 -2 -138 l3 -124 65 -3 c90 -3 130 20 130 77 0
29 -6 44 -20 54 -20 14 -20 15 -3 45 14 25 15 34 5 56 -6 15 -23 31 -38 36
-38 15 -134 13 -140 -3z m110 -33 c19 -7 21 -45 4 -62 -7 -7 -22 -12 -35 -12
-20 0 -23 5 -23 40 0 41 13 50 54 34z m20 -130 c19 -18 19 -20 6 -45 -8 -13
-21 -19 -45 -19 -34 0 -35 1 -35 40 0 38 2 40 29 40 16 0 37 -7 45 -16z"></path>
<path class="text" fill="#000000" d="M319 271 c-23 -24 -29 -38 -29 -74 0 -25 3 -53 6 -62 20 -50 164 -64
164 -15 0 15 -7 17 -45 12 -46 -5 -75 8 -75 34 0 11 16 14 65 14 l65 0 0 35
c0 80 -92 114 -151 56z m99 -33 c3 -15 -4 -18 -37 -18 -43 0 -50 7 -29 28 18
18 62 11 66 -10z"></path>
<path class="text" fill="#000000" d="M520 184 c0 -107 -1 -116 -20 -121 -11 -3 -20 -12 -20 -19 0 -21 76
-19 84 2 3 9 6 69 6 135 l0 119 -25 0 -25 0 0 -116z"></path>
<path class="text" fill="#000000" d="M649 271 c-24 -25 -29 -37 -29 -78 1 -70 34 -103 105 -103 55 0 95
44 95 103 0 60 -7 75 -41 92 -47 25 -96 19 -130 -14z m111 -30 c25 -48 2 -111
-40 -111 -45 0 -69 80 -34 114 21 22 61 20 74 -3z"></path>
<path class="text" fill="#000000" d="M850 287 c0 -8 16 -57 36 -110 28 -76 33 -100 25 -116 -16 -28 -14
-31 18 -31 27 0 29 4 70 123 23 67 41 128 41 135 0 6 -11 12 -24 12 -21 0 -26
-8 -41 -65 -10 -36 -21 -68 -25 -70 -3 -2 -16 27 -29 66 -19 60 -25 69 -47 69
-13 0 -24 -6 -24 -13z"></path>
<path class="text" fill="#000000" d="M1192 284 c-17 -12 -22 -24 -20 -47 2 -26 10 -36 45 -52 49 -23 59
-55 17 -55 -14 0 -34 5 -45 10 -16 9 -19 7 -19 -13 0 -17 7 -27 23 -31 69 -18
117 6 117 60 0 32 -4 37 -45 55 -60 26 -62 54 -4 46 37 -5 40 -3 37 16 -2 18
-11 23 -43 25 -25 2 -49 -3 -63 -14z"></path>
</g>
</svg>

  </div>

  <ul class="nav sidebar-nav">
    <li><a href="../aws.html">AWS</a></li>
    <li><a href="../linux.html">Linux</a></li>
    <li><a href="../docker.html">Docker</a></li>
    <li><a href="../ibmpower.html">IBM Power</a></li>
    <li><a href="blogsataws1.html">Blogs@AWS (Kindle Friendly)</a></li>
  </ul>
</aside>


    <div class="container">
  <div class="row">
    <div id="docs-sidebar" class="col-sm-3 col-md-3 col-xs-12 hidden-print" role="complementary">
      <ul class="nav docs-sidenav">
      <li><a href="blogsataws1.html">Blogs @ AWS</a></li>
      <li><a href="whatsnew1.html">What's New @ AWS</a></li>
      <li><a href="secblogs1.html">Security Blogs @ AWS</a></li>
      <li><a href="computeblogs1.html">Compute Blogs @ AWS</a></li>
      <li><a href="apnblogs1.html">APN Blogs @ AWS</a></li>
      <li><a href="devopsblogs1.html">DevOps Blogs @ AWS</a></li>
      <li class="active"><a href="mgmtblogs1.html">Management Tools Blogs @ AWS</a></li>

    </ul>
    </div>

    <div id="inner" class="col-sm-9 col-md-9 col-xs-12" role="main">
<p></p>
<p><i>Contents of this page is copied directly from AWS blog sites to make it Kindle friendly. Some styles & sections from these pages are removed to render this properly in 'Article Mode' of Kindle e-Reader browser. All the contents of this page is property of AWS.</i></p>
<p><a href="mgmtblogs1.html">Page 1</a>|<a href="mgmtblogs2.html">Page 2</a>|<a href="mgmtblogs3.html">Page 3</a>|<a href="mgmtblogs4.html">Page 4</a></p>
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">Tracking AWS Service Catalog products provisioned by individual SAML users</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Remek Hetman</span></span> | on 
<time property="datePublished" datetime="2017-12-19T11:48:17+00:00">19 DEC 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/aws-service-catalog/" title="View all posts in AWS Service Catalog*"><span property="articleSection">AWS Service Catalog*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools*"><span property="articleSection">Management Tools*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/tracking-aws-service-catalog-products-provisioned-by-individual-saml-users/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p>By Remek Hetman, AWS Sr. Cloud Infrastructure Architect</p> 
<p>To manage access to the AWS Cloud, many companies prefer <a title="undefined" href="https://aws.amazon.com/iam/details/manage-federation/" target="_blank" rel="noopener noreferrer">Enterprise Federation</a> over AWS Identity and Access Management (IAM) users. Identity federation provides single sign-on (SSO) to access AWS accounts using credentials from the corporate directory. This method of accessing AWS allows companies to utilize their existing identity solutions, such as Active Directory (AD) or Active Directory Federation Services, by mapping users to IAM roles.</p> 
<p>Another option for managing access to AWS is to use <a title="undefined" href="https://aws.amazon.com/servicecatalog/" target="_blank" rel="noopener noreferrer">AWS Service Catalog</a>. In this blog I’ll show you how to set up AWS Service Catalog to grant users IAM roles for launching AWS resources.</p> 
<p>AWS Service Catalog allows an organization to create a portfolio of products that can be provisioned by users. This method mitigates the need to grant user permissions to AWS resources and only grants permissions to the service catalog and specific products.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/12/19/Diagram1-1024x304.png"></span><br /> This diagram shows how users can access products through AWS Service Catalog after they have access to an appropriate IAM role. However, we need a way to distinguish users because multiple users can belong to the same AD group.</p> 
<p>One way to identify each user is to add the user name parameter to the product template. But this method doesn’t guarantee that the value entered by the user will be correct or match the user name in Active Directory.</p> 
<p>A better way to accomplish this is to programmatically add the user name to each product template. Let’s take a look at how to accomplish this using AWS Service Catalog.</p> 
<b>Solution Overview</b> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/12/19/Diagram2-1024x404.png" /></p> 
<p>This Solution Overview diagram shows the architecture of the proposed solution:</p> 
<ol>
1. The user provisions a product after authenticating to AWS Service Catalog. 
</ol> 
<ol>
2. AWS Service Catalog launches an AWS CloudFormation template in response to the user’s request. 
</ol> 
<ol>
3. An AWS Lambda function is invoked based on the Amazon CloudWatch rule triggered by the CloudFormation CreateStack event. 
</ol> 
<ol>
4. The Lambda function reads the Active Directory User Name and CloudFormation stack ID from the event record and stores this information in an Amazon DynamoDB database. 
</ol> 
<ol>
5. The CloudFormation template provisions a custom resource that invokes the AWS Lambda function. 
</ol> 
<ol>
6. The Lambda function reads the user name from the Amazon DynamoDB record associated with the CloudFormation stack ID and returns this information back to the CloudFormation template. 
</ol> 
<b>Prerequisites</b> 
<p>Before you begin implementing this solution, be sure to do the following:</p> 
<ol> 
<li style="list-style-type: none"> 
<ol>
1. Install the AWS CLI: 
</ol> </li> 
</ol> 
<p><a title="undefined" href="https://aws.amazon.com/cli/" target="_blank" rel="noopener noreferrer">https://aws.amazon.com/cli/</a></p> 
<ol>
. 
</ol> 
<ol>
2. Install Python 2.7 (including pip). 
</ol> 
<b>Implementation</b> 
<h3>Step 1: Create an Amazon DynamoDB table</h3> 
<p>An Amazon DynamoDB table will be used as central location to store the user name and CloudFormation stack ID.</p> 
<code>aws dynamodb create-table --table-name sc-track-user --attribute-definitions AttributeName=CFStackid,AttributeType=S --key-schema AttributeName=CFStackid,KeyType=HASH --provisioned-throughput ReadCapacityUnits=5,WriteCapacityUnits=5</code> 
<h3>Step 2: Create an IAM role</h3> 
<p>Create an IAM role that will be associated with both AWS Lambda functions to grant permission to Amazon DynamoDB table.</p> 
<code>aws iam create-role --role-name sc-lambda-role --assume-role-policy-document &quot;{\&quot;Version\&quot;: \&quot;2012-10-17\&quot;,\&quot;Statement\&quot;:[{\&quot;Effect\&quot;: \&quot;Allow\&quot;,\&quot;Principal\&quot;:{\&quot;Service\&quot;: \&quot;lambda.amazonaws.com\&quot;},\&quot;Action\&quot;: \&quot;sts:AssumeRole\&quot;}]}&quot;</code> 
<h3>Step 3: Create an IAM policy</h3> 
<p>1. Create new file name called lambda-access-policy.json and add following context to the file:</p> 
<code class="lang-json">{
&quot;Version&quot;: &quot;2012-10-17&quot;,
&quot;Statement&quot;: [
{
&quot;Sid&quot;: &quot;AccessDynamoDB&quot;,
&quot;Effect&quot;: &quot;Allow&quot;,
&quot;Action&quot;: [
&quot;dynamodb:GetItem&quot;,
&quot;dynamodb:PutItem&quot;
],
&quot;Resource&quot;: [
&quot;arn:aws:dynamodb:us-east-1:{your AWS Account No}:table/sc-track-user&quot;
]
},
{
&quot;Sid&quot;: &quot;CreateCWLogs&quot;,
&quot;Effect&quot;: &quot;Allow&quot;,
&quot;Action&quot;: [
&quot;logs:CreateLogGroup&quot;,
&quot;logs:CreateLogStream&quot;
],
&quot;Resource&quot;: &quot;*&quot;
},
{
&quot;Sid&quot;: &quot;WriteCWLog&quot;,
&quot;Action&quot;: [
&quot;logs:PutLogEvents&quot;
],
&quot;Resource&quot;: [
&quot;arn:aws:logs:us-east-1: {AWS Account No}:log-group:/aws/lambda/sc-add-user-id:*:*&quot;,
&quot;arn:aws:logs:us-east-1: {AWS Account No}:log-group:/aws/lambda/sc-get-user-id:*:*&quot;
],
&quot;Effect&quot;: &quot;Allow&quot;
}
]
}
</code> 
<p>2. Replace {AWS Account No} with your AWS account number.<br /> 3. Execute the following CLI command:</p> 
<code>aws iam put-role-policy --role-name sc-lambda-role --policy-name Lambda-DynamoDB-CloudWatch --policy-document file://lambda-access-policy.json</code> 
<h3>Step 4: Create an AWS Lambda function</h3> 
<p>Create a Lambda function to store the user name and CloudFormation stack ID.<br /> 1. Create a new file name called adduser.py.<br /> 2. Add the following code to the file:</p> 
<code class="lang-python">import boto3
def lambda_handler(event, context):
dynamodb = boto3.resource('dynamodb',region_name='us-east-1')
table = dynamodb.Table('sc-track-user')
stackId = event['detail']['responseElements']['stackId']
Id = (stackId.split('/'))[-1]
UserArn = event['detail']['userIdentity']['arn']
UserAID = (UserArn.split('/'))[-1]
table.put_item(
Item={
'CFStackid' : Id,
'User' : UserAID
})
return ''
</code> 
<p>3. Zip file as adduser.zip.<br /> 4. Run the following command:</p> 
<code>aws lambda create-function --function-name sc-add-user-id --runtime python2.7 --role arn:aws:iam::{AWS Account No}:role/sc-lambda-role --handler adduser.lambda_handler --timeout 30 --zip-file &quot;fileb://adduser.zip&quot;</code> 
<p><strong>Note</strong>: Before running this command change {AWS Account No} to the correct account number.</p> 
<h3>Step 5: Create an Amazon CloudWatch Event</h3> 
<p>An Amazon CloudWatch Event will invoke a Lambda function each time a new CloudFormation stack is created.</p> 
<p>1. Create the CloudWatch Event:</p> 
<code>aws events put-rule --name &quot;sc-add-user&quot; --event-pattern &quot;{\&quot;source\&quot;:[\&quot;aws.cloudformation\&quot;],\&quot;detail-type\&quot;:[\&quot;AWS API Call via CloudTrail\&quot;],\&quot;detail\&quot;:{\&quot;eventSource\&quot;:[\&quot;cloudformation.amazonaws.com\&quot;],\&quot;eventName\&quot;:[\&quot;CreateStack\&quot;]}}&quot;</code> 
<p>2. Add the Lambda function as the target to the event.</p> 
<code>aws events put-targets --rule sc-add-user --targets &quot;Id&quot;=&quot;LambdaFunction&quot;,&quot;Arn&quot;=&quot;arn:aws:lambda:us-east-1:{AWS Account No}:function:sc-add-user-id&quot;</code> 
<p>3. Grant permission for your event to invoke the Lambda function.</p> 
<code>aws lambda add-permission --function-name sc-add-user-id --statement-id LamdaPermission-10 --action lambda:InvokeFunction --principal events.amazonaws.com --source-arn arn:aws:events:us-east-1: {AWS Account No}:rule/sc-add-user</code> 
<p><strong>Note</strong>: Before running commands change {AWS Account No} to the correct account number, where you need to.</p> 
<h3>Step 6: Call the AWS Lambda function</h3> 
<p>This Lambda function will be called by CloudFormation template to retrieve user name from DynamoDB table</p> 
<p>1. Create a new file name: getuser.py<br /> 2. Add the following code to the file:</p> 
<code class="lang-python">import json
import requests
import os
import boto3
from botocore.exceptions import ClientError
import time
from requests.auth import HTTPBasicAuth
from requests.packages.urllib3.exceptions import InsecureRequestWarning
requests.packages.urllib3.disable_warnings(InsecureRequestWarning)
dynamodb = boto3.resource('dynamodb')
###########################################################################
# Lambda Handler
def lambda_handler(event, context):
stackId = event['ResourceProperties']['stackId']
Id = (stackId.split('/'))[-1]
responseStatus = 'SUCCESS'
responseData = {}
responseData[&quot;Id&quot;]  = get_user_aid(Id)
sendResponse(event, context, responseStatus, responseData)
#Send Response back to CF
def sendResponse(event, context, responseStatus, responseData):
responseBody = {'Status': responseStatus,
'Reason': 'See the details in CloudWatch Log Stream: ' + context.log_stream_name,
'PhysicalResourceId': responseData[&quot;Id&quot;],
'StackId': event['StackId'],
'RequestId': event['RequestId'],
'LogicalResourceId': event['LogicalResourceId'],
'Data': responseData}
try:
req = requests.put(event['ResponseURL'], data=json.dumps(responseBody))
if req.status_code != 200:
print(req.text)
raise Exception('Received non 200 response while sending response to CFN.')
return
except requests.exceptions.RequestException as e:
print(e)
raise
###########################################################################
# Get User AID
def get_user_aid(stackId):
IValue = ''
table = dynamodb.Table('sc-track-user')
counter = 0
while not IValue:
try:
response = table.get_item(
Key={
'CFStackid': stackId
}
)
if 'Item' in response:
IValue = response['Item']['User']
else:
time.sleep(5)
except ClientError as e:
print(e.response['Error']['Message'])
return(IValue)
</code> 
<p>3. The code for our Lambda function requires a requests Python module that is not included in the standard Python library. To install the requests module, use the command that follows. Note that $PWD is the location of the getuser.py file..:</p> 
<code>pip install -t &quot;$PWD&quot; requests</code> 
<p>4. Zip getuser.py along with all modules installed in the previous step as getuser.zip.<br /> 5. Execute the following command:</p> 
<code>aws lambda create-function --function-name sc-get-user-id --runtime python2.7 --role arn:aws:iam::{AWS Account No}:role/sc-lambda-role --handler getuser.lambda_handler --timeout 120 --zip-file &quot;fileb://getuser.zip</code> 
<h3>Step 7: Modify the CloudFormation template</h3> 
<p>In the final step, we need to add a custom resource to product CloudFormation templates to retrieve the name of the user who provisions the product.</p> 
<p>Here is an example of a CloudFormation template for a product:</p> 
<code class="lang-json">{
&quot;AWSTemplateFormatVersion&quot;: &quot;2010-09-09&quot;,
&quot;Description&quot;: &quot;test-get-user-aid&quot;,
&quot;Resources&quot;: {
&quot;UserAID&quot;: {
&quot;Type&quot;: &quot;Custom::SCUserAID&quot;,
&quot;Properties&quot;: {
&quot;ServiceToken&quot;: {
&quot;Fn::Join&quot;: [ &quot;&quot;,  
[ &quot;arn:aws:lambda:&quot;, { &quot;Ref&quot;: &quot;AWS::Region&quot; }, &quot;:&quot;, { &quot;Ref&quot;: &quot;AWS::AccountId&quot; }, &quot;:function:sc-get-user-id&quot; ]
] },
&quot;stackId&quot;: {
&quot;Ref&quot;: &quot;AWS::StackId&quot;
}
}
}
},
&quot;Outputs&quot;: {
&quot;Param&quot;: {
&quot;Value&quot;: {
&quot;Fn::GetAtt&quot;: [
&quot;UserAID&quot;,
&quot;Id&quot;
]
}
}
}
}
</code> 
<p>The user name returned by our Lambda function can now be used to tag AWS resources launched through this process.</p> 
<b>Use cases</b> 
<p>Beside proper tagging resource with correct user name there are examples where described solution come handy. Here are couple of examples:</p> 
<h3>Custom DNS</h3> 
<p>In many cases, provisioning products using the AWS Service Catalog requires access over DNS rather than an IP address– for example an HTTPS connection. Since multiple users can launch the same product, the DNS name cannot be hard coded in the CloudFormation template but should be generated dynamically during product provisioning. In such cases, the user ID could be used as a prefix to the DNS name.</p> 
<h3>AWS Service Catalog product access control</h3> 
<p>When users authenticate to AWS through federation, access to AWS Service Catalog is managed through an IAM role. In such cases, an organization might require excluding access to AWS Service Catalog products) for certain users. This can be accomplished by creating an Amazon DynamoDB table with a list of users who have access to products and then modifying the sc-get-user-id Lambda function so the function will query the table and return status FAILED when user doesn’t have permission to provision a given product. The name of the product can be passed to the Lambda function as additional parameter directly from CloudFormation template.</p> 
<b>About the Author</b> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/12/19/remek.jpg" /><br /> Remek Hetman is a Senior Cloud Infrastructure Architect with the Amazon Web Services ProServe team. He works with AWS Enterprise customers providing technical guidance and assistance for Infrastructure, DevOps, and big data to help them make the best use of AWS services. Outside of work he enjoys spending time actively as well as pursing his passion – astronomy.</p> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">Automating IAM Roles For Cross-Account Access Series Overview</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Erin McGill</span></span> | on 
<time property="datePublished" datetime="2017-12-14T13:26:20+00:00">14 DEC 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/aws-cloudformation/" title="View all posts in AWS CloudFormation*"><span property="articleSection">AWS CloudFormation*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools*"><span property="articleSection">Management Tools*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/automating-iam-roles-for-cross-account-access-series-overview/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p>The <a href="https://aws.amazon.com/blogs/apn/">AWS Partner Network Blog</a> has recently published a series describing a method to automate the creation of an <a href="http://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_terms-and-concepts.html">IAM role</a> for <a href="http://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_common-scenarios_third-party.html">cross-account access</a>, and how to collect the information needed for a partner to assume the role after creation. This post gives readers an overview of the series, summarizing each of the individual posts with links back to the original content for further reading.</p> 
<p>As a reminder, cross-account IAM roles <a href="https://aws.amazon.com/blogs/apn/securely-accessing-customer-aws-accounts-with-cross-account-iam-roles/">allow customers to grant access</a> to resources within their account to a partner or other third parties while enabling the customers to maintain their security posture. Cross-account roles allow the customer to delegate access without the need to distribute key material, and without the burden on the third party to safely handle key material after receipt.</p> 
<p>The blog series kicked off with a <a href="https://aws.amazon.com/blogs/apn/easing-the-creation-of-cross-account-roles-for-customers/">post</a> that explained how to create a custom launch stack URL for AWS CloudFormation. The URL will take users directly to the CloudFormation Create Stack wizard, with values for the Amazon S3 template location, stack name, and default parameters already populated. The launch stack URL eliminates the need to exchange template files with the customer, and ensures that the customer is using the proper template with the correct values.</p> 
<p><span id="more-1250"></span></p> 
<p>The <a href="https://aws.amazon.com/blogs/apn/generating-custom-aws-cloudformation-templates-with-lambda-to-create-cross-account-roles/">second post</a> describes how to use an AWS Lambda function to populate a AWS CloudFormation template with uniquely generated values. The series example uses an <a href="http://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_create_for-user_externalid.html">External ID</a>, an ID that is unique for each end user. This value needs to be set within the CloudFormation template. When triggered, the Lambda function pulls down the default template, inserts a generated unique External ID into the template, and uploads the customized template to an S3 bucket. Once the template upload is complete, the end user is presented with a custom launch stack URL containing the unique template Amazon S3 location. Finally, we demonstrated how to use the Launch Stack icon to make the URL more visible to users.</p> 
<p>The <a href="https://aws.amazon.com/blogs/apn/collecting-information-from-aws-cloudformation-resources-created-in-external-accounts-with-custom-resources/">third post</a> details how to reliably return the Amazon Resource Name (ARN) of the cross-account role created by AWS CloudFormation to a third party. As a reminder, the third party must use the ARN, as well as the ExternalID, when assuming the role in the end user’s account. The post demonstrates a CloudFormation <a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/template-custom-resources.html">custom resource</a> designed to send the ARN back to the third-party account, which consumes the ARN and stores it for later use.</p> 
<p>The <a href="https://aws.amazon.com/blogs/apn/wrap-up-cross-account-role-onboarding-workflow/">final post</a> of the series brings the details of the previous three blog posts together into one cohesive solution. It shows how to implement the automation of cross-account role creation for customer onboarding using the techniques described in each post in a completed workflow. The workflow creates a smoother onboarding experience for the customer while creating a secure way for the third party account to create resources within the customer account.</p> 
<p>We hope that the blog series can help you and your company improve your customer on-boarding experience. You can avoid the sharing of sensitive keys and the error-prone approach of requiring your customers to cut and paste information in their account and your on-boarding portal.</p> 
<hr /> 
<p><strong>About the Author</strong></p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/07/headshot-Erin-220x300.png" />Erin McGill is a Solutions Architect in the AWS Partner Program with a focus on DevOps and automation tooling.</p> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">AWS Service Catalog Hub and Spoke Model: How to Automate the Deployment and Management of Service Catalog to Many Accounts</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Jason Norton</span></span> | on 
<time property="datePublished" datetime="2017-12-14T13:05:36+00:00">14 DEC 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/aws-service-catalog/" title="View all posts in AWS Service Catalog*"><span property="articleSection">AWS Service Catalog*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools*"><span property="articleSection">Management Tools*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/aws-service-catalog-hub-and-spoke-model-how-to-automate-the-deployment-and-management-of-service-catalog-to-many-accounts/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p>Many organizations may have tens to hundreds of accounts and thousands of users that require services in AWS. Enforcing organizational governance controls for deploying services requires time and resources to build the necessary guardrails, security controls, and auditing. Using the AWS Service Catalog hub and spoke model and launch constraints, I’ll show you how to centrally manage Service Catalog deployments in a master/child account relationship. I’ll also show you how to enforce service constraints that allow users to self-provision AWS products, often reducing deployment costs, time, and management.</p> 
<p>Before diving into the details, first I’ll discuss the Service Catalog components.<span id="more-1889"></span></p> 
<b>Service Catalog components</b> 
<h3>Product</h3> 
<p>An AWS Service Catalog product is an IT service (VPC, web server, n-tier environment, database, etc.) that you want to make available for deployment on AWS.</p> 
<h3>Portfolio</h3> 
<p>An AWS Service Catalog portfolio is a collection of products and their configuration information, plus launch and access controls.</p> 
<h3>Constraint</h3> 
<p>An AWS Service Catalog constraint is a restriction on the ways that specific AWS resources can be deployed for a product, e.g., template constraints to allow only certain EC2 instance sizes.</p> 
<h3>Provisioned Product</h3> 
<p>An AWS Service Catalog product is launched using an AWS CloudFormation process. The collection of launched services is called a provisioned product. You might also see this collection of launched services referred to as a landscape.</p> 
<b>Implementation overview</b> 
<p>If you need to centrally manage AWS Service Catalog portfolios and products and then deploy across multiple accounts you can use a master Service Catalog account. Use this account to deploy the minimum portfolio, products, and constraints. Then you can share the master portfolios to child accounts where they are imported. Products that form the imported master portfolios are added to local portfolios in the child account. Constraints, tags, and users for these products can be added so that users in the child account can deploy any AWS CloudFormation stack implemented as a product.</p> 
<p>This is called the AWS Service Catalog hub and spoke model.</p> 
<p><strong>Hub and spoke model</strong></p> 
<li>One master account – Creates baseline products and shares the portfolio</li> 
<li>Multiple child accounts – Import portfolios and leverage the products</li> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/01/SC_Master_Child-1024x552.png" /></p> 
<p><strong>AWS Service Catalog administration</strong></p> 
<p>The hub-spoke model allows you to deploy Service Catalog portfolios and products centrally and locally in an account.</p> 
<p><strong>Two methods of leveraging shared portfolios</strong></p> 
<p>Imported portfolio – leverage the imported portfolio</p> 
<li>Launch and template constraints are inherited</li> 
<li>Constraints cannot be modified</li> 
<p>Local Portfolios – Create a local portfolio and import products from the shared portfolio.</p> 
<li>Only template constraints are inherited</li> 
<li>You can create and assign additional template constraints</li> 
<li>You have to assign launch constraints</li> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/01/SC_Process-1024x497.png" /></p> 
<p><strong>Walkthrough</strong><br /> Prerequisites:</p> 
<li>Two AWS Accounts</li> 
<li>Administrator IAM permissions to each account</li> 
<li>Access keys or AWS STS Credentials for CLI access to each account</li> 
<li>Download the python scripts from <a href="https://s3-us-west-2.amazonaws.com/management-tools-blog-cf-template-storage/ServiceCatalogAgileGovernance.zip">here</a>.</li> 
<p><strong>Note:</strong> Before running the following Python scripts, make sure that your AWS_DEFAULT_PROFILE is set to the correct account for deployment and that you have the proper administrative permissions.</p> 
<p>Files included in the repo:</p> 
<p>Master_SC_Single_Portfolio_Deploy_v1.py</p> 
<li>Python script that creates a Service Catalog portfolio, two products for the portfolio from the CloudFormation scripts that follow, template constraints, and tagging to enforce organization governance controls. The script shares the portfolio with selected child accounts.</li> 
<p>Child_SC_Single_Portfolio_Deploy_v1.py</p> 
<li>Python script that creates a local Service Catalog portfolio in a child account and imports the two products created in the master account, discussed previously. Creates launch constraints for each product to limit launching resources to a single IAM role and appropriate tagging.</li> 
<li>LAMP_Single_Instance_v1.template</li> 
<li>LAMP_Launch_Constraint.json</li> 
<li>Linux_Single_Instance_v1.template</li> 
<li>Linux_Instance_Launch_Constraint.json</li> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/01/SC_Implementation-1024x678.png" /></p> 
<p>A link to the python code can be found <a href="https://s3-us-west-2.amazonaws.com/management-tools-blog-cf-template-storage/ServiceCatalogAgileGovernance.zip">here</a>.</p> 
<p><strong>Master Service Catalog deployment</strong></p> 
<p>$ export AWS_DEFAULT_PROFILE=Master_Service_Catalog_Profile</p> 
<p>1. Upload CFTs and constraint files to the Amazon S3 bucket that the Service Catalog master account has access to:</p> 
<li>LAMP_Single_Instance_v1.template</li> 
<li>Linux_Single_Instance_v1.template</li> 
<li>LAMP_Launch_Constraint.json</li> 
<li>Linux_Instance_Launch_Constraint.json</li> 
<p>2. Run the master deployment script with the bucket name from step 1 as a command line argument. Additional command line arguments can be any AWS accounts that you want to share the Master Portfolio and Products with:</p> 
<p>$ python Master_SC_Single_Portfolio_Deploy_v1.py bucketname share_account_1 share_account_2</p> 
<p>3. Copy the portfolio ID provided by this script for deploying Service Catalog in the child account.</p> 
<p>Your Linux Portfolio ID is: port-xxxxxxxxxxxxx</p> 
<p><strong>Child Service Catalog deployment</strong></p> 
<p>4. For each child account that you shared with in the previous master Service catalog section, do the following steps:</p> 
<p>$ export AWS_DEFAULT_PROFILE=Child_Service_Catalog_Profile</p> 
<p>5. Run the child deployment script with the portfolio ID of the master Service Catalog portfolio that you created in step 1:</p> 
<p>$ python Child_SC_Single_Portfolio_Deploy_v1.py port-xxxxxxxxxxxxx</p> 
<p><strong>After deployment</strong></p> 
<p>6. To ensure that everything deployed properly, check your master and child accounts for portfolios, products, and constraints.</p> 
<p>7. Add users in the child account to use the portfolio that you created.</p> 
<p>8. Test launching products in the child account. Users must have an Amazon EC2 key pair to deploy products.</p> 
<p>a. Notice when deploying the LAMP Instance that users are constrained to specific parameter values. When deploying the Linux single instance users are restricted to specific Security Groups (“WebServerSecurityGroup”) that were created by the LAMP instance product.</p> 
<p><strong>Summary</strong><br /> In this blog post I demonstrate the value of deploying the AWS Service Catalog in a hub and spoke model. In addition, I explain the process and have provided code samples. These samples show you how to automate a deployment across many AWS accounts and constrain users to specific AWS resource values to meet organization governance controls.</p> 
<p><strong>About the Author</strong><br /> <img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/21/Norton-Bio-Shot-150x150.jpg" /></p> 
<p>Jason Norton is a Sr. Consultant with Professional Services&nbsp;who loves showing his customers the possibilities.</p> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">Gain Visibility into the Execution of Your AWS Lambda functions with AWS CloudTrail</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Kyle Somers</span></span> | on 
<time property="datePublished" datetime="2017-11-30T11:23:53+00:00">30 NOV 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/aws-cloudtrail/" title="View all posts in AWS CloudTrail*"><span property="articleSection">AWS CloudTrail*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools*"><span property="articleSection">Management Tools*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/gain-visibility-into-the-execution-of-your-aws-lambda-functions-with-aws-cloudtrail/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p>Today, we are happy to announce that AWS CloudTrail now supports the Lambda Invoke API as a new data event type with the launch of CloudTrail Lambda data events. Previously, AWS CloudTrail supported management events for AWS Lambda, which allowed you to capture when and by whom a function was created, modified, or deleted. With this new feature, you can now gain visibility into when and by whom an Invoke API call was made and which Lambda function was executed. CloudTrail can deliver these logs to Amazon S3 or Amazon CloudWatch Logs, and for near real-time processing, you can send them to Amazon CloudWatch Events to build event-driven security pipelines for the Lambda functions within your serverless applications.</p> 
<p><span id="more-2143"></span></p> 
<h4>AWS CloudTrail Lambda data events</h4> 
<p>Serverless computing with AWS Lambda is an increasingly popular business solution. Lambda allows you to run code in the cloud without managing or provisioning servers. You write your code, package it as a Lambda function, and hook it up with one or more event sources that trigger the function in response to events. All Lambda functions are executed using the Lambda Invoke API, whether you manually invoke your Lambda function via the AWS CLI, SDK, or set it up with any of the event source integrations. The AWS CloudTrail Lambda data events feature enables you to capture this invoke activity within your account to see who, when, and how your functions are being executed.</p> 
<h4>How can I use AWS CloudTrail Lambda data events?</h4> 
<p>AWS CloudTrail Lambda data events can be used to detect and automatically act on invocations of Lambda functions across your AWS account. For example, you can now:</p> 
<li>Meet your IT auditing and compliance requirements. With CloudTrail data events, you can validate that your functions were invoked by permitted users, roles, and services. Customers with regulatory audit and compliance requirements can maintain the same level of visibility and auditability of Lambda function invokes as they do for other AWS service API invocations.</li> 
<li>Perform near real-time and ad-hoc security analysis. Lambda data events are delivered to your log delivery destination just like your existing CloudTrail logs, so it is easy to integrate this new log data type into your security analytics pipelines. You can analyze Lambda function invoke activity in near real time with Amazon CloudWatch Events and Amazon CloudWatch Logs.</li> 
<li>Better understand usage patterns across your AWS Lambda functions. You can perform billing analysis to understand the top user, role, or service callers of Lambda functions. You can also tie costs to specific users and groups for internal chargeback purposes or build reports on function usage across different teams.</li> 
<p>Let’s take a look at how this integration works.</p> 
<h4>Setting up Lambda Data Events</h4> 
<p>Setting up AWS CloudTrail Lambda data events is easy. You can add Lambda data events to an existing trail that you have already created, or you can create a new separate trail just for Lambda data events – either option is suitable and will depend on how you plan to organize and manage your CloudTrail logs. In my example, I have created a separate trail called <strong>LambdaEvents</strong> and have configured it to<em><strong> Log all current and future functions</strong></em>. This feature is really handy and allows me to “set and forget” without needing to revisit my CloudTrail configuration each time a new function or version is published.</p> 
<p><em>&nbsp;You might be wondering what that S3 tab is for in the following image. Remember, AWS CloudTrail also supports data events for Amazon S3, which Jeff Barr discusses in his blog post <a href="https://aws.amazon.com/blogs/aws/cloudtrail-update-capture-and-process-amazon-s3-object-level-api-activity/">here</a>.</em></p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/30/trail_setup-1024x550.png" /></p> 
<p>Once I have configured a new trail called LambdaEvents and enabled it across all AWS Regions for all existing and future functions, I now need to setup a storage location for CloudTrail to store the log files that will be generated. I have previously created my trail to deliver logs to a bucket dedicated to my Lambda data events (aws-ksomers-lambda-cloudtrail). I have left the rest of the settings at the default, but I could optionally enable a few additional things such as log file validation, encryption using AWS KMS, and notifications using Amazon SNS.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/30/storage-1024x513.png" /></p> 
<p>Now that CloudTrail Lambda data events is configured, let’s take a look at how data is presented to us with Lambda data events.</p> 
<p>In my example, I invoked my BlogFunction from the AWS CLI with my “kyle” IAM user as a synchronous request with Lambda invoke type of “RequestResponse”. Remember that Lambda can be invoked either synchronously via a RequestResponse invocation type, asynchronously via an “Event” invocation type, or used in test mode with a “DryRun” invocation type. That invocation generated a CloudTrail log file in my Amazon S3 bucket. Let’s have a look at the event:</p> 
<code class="lang-js">{
&quot;eventVersion&quot;: &quot;1.06&quot;,
&quot;userIdentity&quot;: {
&quot;type&quot;: &quot;IAMUser&quot;,
&quot;principalId&quot;: &quot;AIDAIOR74VCJ2M3NB8U4M&quot;,
&quot;arn&quot;: &quot;arn:aws:iam::999999999999:user/kyle&quot;,
&quot;accountId&quot;: &quot;999999999999&quot;,
&quot;accessKeyId&quot;: &quot;AK2IU7DKE7U2KOI8CCBP&quot;,
&quot;userName&quot;: &quot;kyle&quot;
},
&quot;eventTime&quot;: &quot;2017-11-29T08:47:45Z&quot;,
&quot;eventSource&quot;: &quot;lambda.amazonaws.com&quot;,
&quot;eventName&quot;: &quot;Invoke&quot;,
&quot;awsRegion&quot;: &quot;us-west-2&quot;,
&quot;sourceIPAddress&quot;: &quot;192.168.0.1&quot;,
&quot;userAgent&quot;: &quot;aws-cli/1.11.129 Python/2.7.8 Linux/3.1.56-0.6.839hdh3.x86_64 botocore/1.5.92&quot;,
&quot;requestParameters&quot;: {
&quot;invocationType&quot;: &quot;RequestResponse&quot;,
&quot;functionName&quot;: &quot;arn:aws:lambda:us-west-2:999999999999:function:BlogFunction:prod&quot;,
&quot;clientContext&quot;: &quot;ew0KICAiY29udGV4dGtleSIgOiAiY29udGV4dHZhbHVlIg0KfQ==&quot;,
&quot;qualifier&quot;: &quot;prod&quot;
},
&quot;responseElements&quot;: null,
&quot;additionalEventData&quot;: {
&quot;functionVersion&quot;: &quot;arn:aws:lambda:us-west-2:999999999999:function:BlogFunction:4&quot;
},
&quot;requestID&quot;: &quot;eaccb900-8f45-11e7-b60d-179cdf501g92&quot;,
&quot;eventID&quot;: &quot;0e205f1d-3929-4803-b887-0d2aca122148&quot;,
&quot;readOnly&quot;: false,
&quot;resources&quot;: [{
&quot;accountId&quot;: &quot;999999999999&quot;,
&quot;type&quot;: &quot;AWS::Lambda::Function&quot;,
&quot;ARN&quot;: &quot;arn:aws:lambda:us-west-2:999999999999:function:BlogFunction&quot;
}],
&quot;eventType&quot;: &quot;AwsApiCall&quot;,
&quot;managementEvent&quot;: false,
&quot;recipientAccountId&quot;: &quot;999999999999&quot;,
&quot;sharedEventID&quot;: &quot;6159da59-ad2f-4e04-9669-cf0a6b6b4827&quot;</code> 
<p>When a Lambda function is invoked, the function being invoked will show up in three locations within the CloudTrail Lambda data event. Here is a breakdown of what each one represents:</p> 
<ol> 
<li>“<strong>requestParameters:functionName</strong>” – This field will match the input of the function that was called using the API (qualified version or unqualified). In my example, my function is deployed with a Lambda alias of “prod,” so this is displayed in the ARN.</li> 
<li>“<strong>additionalEventData:functionVersion</strong>” – Here you will see the exact qualified function version that was invoked based on the input in the requestParameters of your Lambda invoke. Remember that a Lambda function alias points to an immutable version of a Lambda function. In this case, I invoked my function via the alias, but the ARN that was executed was version 4 of my function. This field will display the version ARN that was invoked.</li> 
<li>“<strong>resources:ARN</strong>” – This will show the unqualified function ARN (some refer to it as the “base” ARN).</li> 
</ol> 
<p>In the previous example, we looked at the contents of a Lambda Invoke API request of RequestResponse invocation type. For details on the contents of other invocation types such as Event Invocation Types, Cross-Account invocations, invocations from AWS services such as stream-based event sources, check out the documentation <a href="http://docs.aws.amazon.com/lambda/latest/dg/API_Invoke.html">here</a>.</p> 
<h4>Lambda data events example</h4> 
<p>One interesting way you can use this new feature is to monitor your Lambda functions for unauthorized invocations. Let’s take a look at an example of how you can use Lambda data events to check for unauthorized invocations with one of our classic Lambda examples, the S3 Event Notification Trigger for PUT Object Requests on a Bucket:\</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/30/diagram-1024x258.png" /></p> 
<p>In this architecture, there is an S3 bucket that is configured to invoke a Lambda function when new objects are created in the bucket (or any other event you would like). This function might update an Amazon DynamoDB table, send an email, or any other use case you may have!</p> 
<p>With CloudTrail Lambda data events, you can validate that your function is only being invoked by Amazon S3. Every invocation of your function generates a CloudTrail log event which can be delivered to an S3 bucket for long-term retention. You can also configure a CloudWatch Events Rule and run real-time business logic on these log events with Lambda. In this case, if the “<em>userIdentity:invokedBy</em>” field in my CloudTrail log event isn’t “<em>s3.amazonaws.com</em>”, then my remediation Lambda can update my Lambda Function Policy to properly restrict invocation access to Amazon S3.</p> 
<p><strong>Pricing and availability</strong></p> 
<p>Once an AWS CloudTrail trail is set up, Amazon S3 charges apply based on your usage, since AWS CloudTrail delivers logs to an S3 bucket. Data events are recorded only for the functions you specify and are charged at $0.10 per 100,000 events, the same as S3 data events. See CloudTrail <a href="https://aws.amazon.com/cloudtrail/pricing/">pricing page</a> for more details. CloudTrail Lambda data events are available in all AWS public Regions and AWS GovCloud (US).</p> 
<h3>What’s coming</h3> 
<p>Several AWS partners such as Sumo Logic, Rapid7, Saviynt, Alert Logic, and Evident.io are working on integrations with CloudTrail Lambda Data Events, so keep an eye out for updates!</p> 
<hr /> 
<p><strong>About the author</strong></p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/30/kyle.jpg" />Kyle Somers is a Solutions Architect at Amazon Web Services. He works with startups and Focused Territory customers to provide architectural guidance for building applications in the cloud. His passion is AWS Lambda and he serves as a Serverless SME within the AWS community. In his spare time, he likes to travel, read up on the latest tech, and cheer on the University of Arizona Wildcats.</p> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">Monitoring Service Limits with Trusted Advisor and Amazon CloudWatch</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Stas Neyman</span></span> | on 
<time property="datePublished" datetime="2017-11-24T13:41:47+00:00">24 NOV 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/aws-trusted-advisor/" title="View all posts in AWS Trusted Advisor*"><span property="articleSection">AWS Trusted Advisor*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools*"><span property="articleSection">Management Tools*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/monitoring-service-limits-with-trusted-advisor-and-amazon-cloudwatch/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p>Understanding your <a href="http://docs.aws.amazon.com/general/latest/gr/aws_service_limits.html">service limits</a> (and how close you are to them) is an important part of managing your AWS deployments – continuous monitoring allows you to request limit increases or shut down resources before the limit is reached.</p> 
<p>One of the easiest ways to do this is via <a href="https://aws.amazon.com/premiumsupport/trustedadvisor/">AWS Trusted Advisor’s</a> Service Limit Dashboard, which currently covers <a href="https://aws.amazon.com/premiumsupport/ta-faqs/#service-limits-check-questions">39 limits across 10 services</a>.</p> 
<p>With the recent launch of Trusted Advisor metrics in Amazon CloudWatch, <a href="https://aws.amazon.com/premiumsupport/business-support/">Business</a> and <a href="https://aws.amazon.com/premiumsupport/enterprise-support/">Enterprise</a> support customers can create customizable alarms for individual service limits. Let’s look at an example of how to do that.</p> 
<p><span id="more-2122"></span></p> 
<h4>Example: Create an alarm for EC2 On-Demand Instance limits</h4> 
<p>Begin by logging into the <a href="https://console.aws.amazon.com/trustedadvisor/home#/dashboard">Trusted Advisor console</a> and clicking the “Service Limits” link on the left side of the page. After doing so, you should see the new service limits dashboard.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/24/Console-1024x444.png" /></p> 
<p>Click the refresh icon in the top-right of the screen to retrieve the most current utilization and limit data for the service limit checks. This can take a while if you have a lot of AWS resources deployed, so be patient! Once complete, a notification will appear at the top of the Trusted Advisor console.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/24/check_complete-1024x76.png" /></p> 
<p>This ensures that CloudWatch has the most up-to-date information available from Trusted Advisor.</p> 
<p>Next, head over to the <a href="https://console.aws.amazon.com/cloudwatch/">CloudWatch console</a>. Trusted Advisor passes a single metric called “ServiceLimitUsage” that represents the percentage of utilization versus the limit. You can filter these limits by region, limit, or service using the available dimensions.</p> 
<p>Make sure you are in the US East (N. Virginia) region, then click the “Alarms” link on the left side of the page and then click the “Create Alarm” button.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/24/create_alarm-1024x461.png" /></p> 
<p>Click “Service Limits by Region” under the “Trusted Advisor” category.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/24/create_alarm2-1024x936.png" /></p> 
<p>In the search bar, type “Overall On-Demand Instances”. This will filter the list of available limits down to the EC2 overall on-demand instance limits that are tracked by Trusted Advisor. Click the checkbox next to the limit for the us-east-1 region and click “Next”.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/24/create_alarm3-1024x940.png" /></p> 
<p>You can now set up your CloudWatch alarm for this limit. In this example, we’ve configured it to alarm when you’ve reached 60% of the EC2 On-Demand instance limit. Trusted Advisor updates these metrics once per week by default, but refreshing <a href="https://aws.amazon.com/premiumsupport/ta-iam/#table2">checks</a> via the Trusted Advisor console or Support API will send updated metrics on demand.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/24/create_alarm4-1024x933.png" /></p> 
<p>You can repeat this process for any or all of the service limits covered by Trusted Advisor. For more information and a guide to creating these for any type of Trusted Advisor check, visit <a href="http://docs.aws.amazon.com/awssupport/latest/user/cloudwatch-metrics-ta.html">Creating Trusted Advisor Alarms Using CloudWatch</a>.</p> 
<hr /> 
<h4>About the Author</h4> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/24/Scott_Allison.jpg" />Scott Allison is the Senior Technical Product Manager for Trusted Advisor – an AWS service designed to keep your deployments secure, fault tolerant, and cost-effective. He enjoys working directly with customers and hearing the creative ways people use Trusted Advisor!</p> 
<p>&nbsp;</p> 
<p>&nbsp;</p> 
<p>&nbsp;</p> 
<p>&nbsp;</p> 
<p>&nbsp;</p> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">Automate IIS and HttpErr Logs to Amazon CloudWatch Using EC2 Systems Manager</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Pawan Puthran</span></span> | on 
<time property="datePublished" datetime="2017-11-22T09:56:52+00:00">22 NOV 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/amazon-ec2-systems-manager/" title="View all posts in Amazon EC2 Systems Manager*"><span property="articleSection">Amazon EC2 Systems Manager*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools*"><span property="articleSection">Management Tools*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/automate-iis-and-httperr-logs-to-amazon-cloudwatch-using-ec2-systems-manager/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p>When you have workloads or applications hosted on IIS Web Server, it’s important to monitor and analyze both <a href="https://www.iis.net/configreference/system.applicationhost/sites/sitedefaults/logfile#003">IIS</a> and <a href="https://support.microsoft.com/en-us/help/820729/error-logging-in-http-apis#Kinds%20of%20errors%20that%20the%20HTTP%20API%20logs">HttpErr</a> logs for abnormalities. IIS logs contain an entry for every request to the site. However, at times, you might not find the requests in IIS logs, even though IIS logging is enabled. There is a good chance that the request was rejected by HTTP.sys (Kernel mode driver for HTTP) before it was handed to the IIS worker process. Some of the common reasons for rejecting a request include the following:</p> 
<li>The service is unavailable because the application pool is offline. (Http 503: Service Unavailable)</li> 
<li>Parse error – Bad request. (Http 400)</li> 
<p>In this blog post, we show you how to configure Windows EC2 instances to send HttpErr and IIS logs to <a href="https://aws.amazon.com/cloudwatch/">Amazon CloudWatch</a> using <a href="https://aws.amazon.com/ec2/systems-manager">Amazon EC2 Systems Manager (SSM)</a>. Then we show you how to set up a CloudWatch alarm to notify you when the IIS application pool stops using <a href="https://aws.amazon.com/sns/" target="_blank" rel="noopener noreferrer">Amazon Simple Notification Service</a> (SNS).</p> 
<p><span id="more-1788"></span></p> 
<p><a href="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/flowdiag.png"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/flowdiag-1024x293.png" /></a></p> 
<p>Amazon EC2 Systems Manager is a management service that helps you automate management tasks such as collecting system inventory, applying operating system (OS) patches, automating the creation of Amazon Machine Images (AMIs), and configuring operating systems and applications at scale. Systems Manager lets you remotely and securely manage the configuration of your managed instances.</p> 
<b>Configuring Windows EC2 for CloudWatch using EC2 Systems Manager</b> 
<p>There are <a href="http://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/send_logs_to_cwl.html">many ways to send instance metrics</a> to CloudWatch. Let’s look at the steps you need to follow to integrate <a href="https://aws.amazon.com/ec2/systems-manager/state-manager/">System Manager State Manager</a> with CloudWatch.</p> 
<ol> 
<li>Set up the configuration file for CloudWatch</li> 
<li>Configure integration with CloudWatch</li> 
<li>Create a CloudWatch metric filter and configure an alarm</li> 
</ol> 
<b>Step 1: Set up the configuration file for CloudWatch</b> 
<ol> 
<li>Download the sample <a href="https://s3.amazonaws.com/ec2-downloads-windows/CloudWatchConfig/AWS.EC2.Windows.CloudWatch.json">JSON file for CloudWatch</a></li> 
<li>Ensure that “isEnabled” is set to true <code class="lang-json">{
&quot;IsEnabled&quot;: true,
&quot;EngineConfiguration&quot;: {
...
}
}</code> </li> 
<li>In the JSON file, add the following configuration information after the IISLogs section. <code class="lang-json">{
&quot;Id&quot;: &quot;HttpErrLogs&quot;,
&quot;FullName&quot;: &quot;AWS.EC2.Windows.CloudWatch.CustomLog.CustomLogInputComponent,AWS.EC2.Windows.CloudWatch&quot;,
&quot;Parameters&quot;: {
&quot;LogDirectoryPath&quot;: &quot;C:\\Windows\\System32\\LogFiles\\HTTPERR&quot;,
&quot;TimestampFormat&quot;: &quot;yyyy-MM-dd HH:mm:ss&quot;,
&quot;Encoding&quot;: &quot;UTF-8&quot;,
&quot;Filter&quot;: &quot;&quot;,
&quot;CultureName&quot;: &quot;en-US&quot;,
&quot;TimeZoneKind&quot;: &quot;UTC&quot;,
&quot;LineCount&quot;: &quot;3&quot;
}
}</code> </li> 
<li>Add the following configuration to ensure that the log data is sent to CloudWatch. Modify or update the Region, LogGroup, and Logstream name. <code class="lang-json">{
&quot;Id&quot;: &quot;HttpErrCloudWatchLogs&quot;,
&quot;FullName&quot;: &quot;AWS.EC2.Windows.CloudWatch.CloudWatchLogsOutput,AWS.EC2.Windows.CloudWatch&quot;,
&quot;Parameters&quot;: {
&quot;AccessKey&quot;: &quot;&quot;,
&quot;SecretKey&quot;: &quot;&quot;,
&quot;Region&quot;: &quot;us-east-2&quot;,
&quot;LogGroup&quot;: &quot;WebServer&quot;,
&quot;LogStream&quot;: &quot;{instance_id}-httpErr&quot;
}
}</code> <p><strong>Region</strong>: The Region where you want to send log data.<br /> <strong>LogGroup</strong>: Name for your log group. This will appear on the Log Groups screen on the CloudWatch console.<br /> <strong>LogStream</strong>: Destination log stream. This will appear on the Log Groups &gt; Streams screen on the CloudWatch console.</p> <p>Note: If you use Systems Manager State Manager, you don’t have to provide credentials in the configuration file.</p></li> 
<li>Flow Control – Each data type must have a corresponding destination in the Flows section. For example, to send log details defined in the HttpErrLogs section to the destination defined in the HttpCloudWatchLog section, add “HttpErrLogs,HttpCloudWatchLog” to the Flows section <code class="lang-json">&quot;Flows&quot;: {
&quot;Flows&quot;: [
&quot;HttpErrLogs,HttpErrCloudWatchLogs&quot;
]
}
</code> <p>Similarly, add the following to configure the IIS logs (for LogDirectoryPath, check the IIS logs directory and SiteID)</p> <code class="lang-json">{
&quot;Id&quot;: &quot;IISLogs&quot;,
&quot;FullName&quot;: &quot;AWS.EC2.Windows.CloudWatch.CustomLog.CustomLogInputComponent,AWS.EC2.Windows.CloudWatch&quot;,
&quot;Parameters&quot;: {
&quot;LogDirectoryPath&quot;: &quot;C:\\inetpub\\logs\\LogFiles\\W3SVC1&quot;,
&quot;TimestampFormat&quot;: &quot;yyyy-MM-dd HH:mm:ss&quot;,
&quot;Encoding&quot;: &quot;UTF-8&quot;,
&quot;Filter&quot;: &quot;&quot;,
&quot;CultureName&quot;: &quot;en-US&quot;,
&quot;TimeZoneKind&quot;: &quot;UTC&quot;,
&quot;LineCount&quot;: &quot;3&quot;
}
},
{
&quot;Id&quot;: &quot;IISCloudWatchLogs&quot;,
&quot;FullName&quot;: &quot;AWS.EC2.Windows.CloudWatch.CloudWatchLogsOutput,AWS.EC2.Windows.CloudWatch&quot;,
&quot;Parameters&quot;: {
&quot;AccessKey&quot;: &quot;&quot;,
&quot;SecretKey&quot;: &quot;&quot;,
&quot;Region&quot;: &quot;us-east-2&quot;,
&quot;LogGroup&quot;: &quot;WebServer&quot;,
&quot;LogStream&quot;: &quot;{instance_id}-iis&quot;
}
}
...
&quot;Flows&quot;: {
&quot;Flows&quot;: [
&quot;IISLogs,IISCloudWatchLogs&quot;,
&quot;HttpErrLogs,HttpCloudWatchLogs&quot;
]
}
}</code> <p>Complete the configuration using this <a href="https://s3-us-west-2.amazonaws.com/management-tools-blog-cf-template-storage/SSM_HttpErr_Cloudwatch.json">SSM_HttpErr_Cloudwatch</a> example file</p></li> 
</ol> 
<b>Step 2: Configure integration with CloudWatch</b> 
<p>You can either choose Run Command or State Manager features of Systems Manager to integrate with CloudWatch. In this blog, we will show you how to use State Manager to integrate with CloudWatch.</p> 
<p>State Manager automates the process of keeping your managed instances in a defined state. You can use State Manager to ensure that your instances are bootstrapped with specific software at start up, joined to a Windows domain (Windows instances only), or patched with specific software updates.</p> 
<p>Note: Amazon EC2 Systems Manager requires an IAM role for EC2 instances that will process commands. Please ensure you have the correct <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/sysman-configuring-access-policies.html">policy</a> attached to the instance.</p> 
<li>Open the AWS Management Console, and go to the EC2 console. In the EC2 console navigation pane, choose <strong>State Manager</strong> in the <strong>Systems Manager Services</strong> section and select <strong>Create an association</strong>.</li> 
<p><a href="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/association.png"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/association-1024x426.png" /></a></p> 
<li>Provide an associate name and select AWS-ConfigureCloudWatch as the <strong>Document</strong>.</li> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/selectdocument-1024x622.png" /></p> 
<li>For <strong>Targets</strong>, choose the instances to integrate with CloudWatch either by tag or manually. We recommend choosing the target by tag. In case you don’t see any instances here, please check the IAM role policy.</li> 
<li>For <strong>Schedule</strong>, choose 30 minutes as the time interval for how often you want Systems Manager to apply this policy. This doesn’t affect the frequency when the SSM Agent sends data to CloudWatch.</li> 
<li>For <strong>Parameters</strong>, ensure <strong>Status</strong> is <strong>Enabled</strong> and copy and paste your <a href="https://s3-us-west-2.amazonaws.com/management-tools-blog-cf-template-storage/SSM_HttpErr_Cloudwatch.json">JSON contents</a> into the properties.</li> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/targets-1024x854.png" /></p> 
<li>(Optional) Select <strong>Advanced, Write to S3</strong> to send command output to an Amazon S3 bucket.</li> 
<li>Choose <strong>Create Association</strong>.</li> 
<li><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/successassociation-1024x367.png" />On the State Manager, select the association that you just created and then choose <strong>Apply Association Now</strong>.</li> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/apply-1024x179.png" /></p> 
<p>For more information, see <a href="http://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/send_logs_to_cwl_instances.html#ec2-configuration-cwl">http://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/send_logs_to_cwl_instances.html#ec2-configuration-cwl</a></p> 
<p>After you configure integration, the SSM Agent sends all the logs you configured in your JSON file to CloudWatch. SSM creates a log file that can be found at: C:/ProgramData/Amazon/SSM/Logs. It contains the following entries if LogGroup and LogStream are created successfully. If you don’t see these entries, check the error log, which can be found in the same path.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/SSM_Logs-1024x112.png" /></p> 
<p>In the CloudWatch Logs console, in the <strong>Log Groups</strong> list, you should see WebServer, and in the <strong>LogStream</strong> list you should see {instance_id}-httpErr.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/cw-1024x359.png" /></p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/logstream-1024x173.png" /></p> 
<b>Step 3: Create a CloudWatch metric filter and configure an alarm</b> 
<p>Next, we create a metric filter and configure an alarm that is triggered when an IIS application pool stops. If an IIS application stops or goes offline, the following entries are logged in HttpErr logs with s-status as 503 and s-reason as AppOffline.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/HTTPErrlogs-1024x152.png" /></p> 
<p>These logs are located at C:/Windows/System32/LogFiles/HTTPERR</p> 
<li>In the CloudWatch console choose <strong>Logs</strong> in the navigation pane.</li> 
<li>Select the <strong>WebServer</strong> log group and then choose the <strong>Create Metric Filter</strong> button.</li> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/createmetric-1-1024x499.png" /></p> 
<li>Type “AppOffline” for the <strong>Filter pattern</strong>.</li> 
<li>You can test your filter pattern by selecting <strong>Log Data to Test</strong>.</li> 
<li>Choose <strong>Assign Metric</strong> and type “IIS AppPool” for the <strong>Filter Name</strong>.</li> 
<li>For <strong>Metric Details</strong>, type “IIS” for <strong>Metrics Namespace</strong> and “AppPoolOffline” for the <strong>Metric Name</strong>. Choose Create Filter.</li> 
<li>Next, let’s create an alarm.</li> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/createalarm.png" /></p> 
<li>Provide the Alarm name and a brief description. In the <strong>Whenever</strong> section, specify a threshold (AppPoolOffline &gt; 0) for 2 consecutive periods (period of 1 minute). For <strong>Statistic</strong>, choose <strong>Standard</strong>. Be sure that <strong>Sample Count</strong> is chosen in the drop-down box. You could choose a higher resolution based on your requirements, but remember that there are cost implications.</li> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/alarmthreshold-1024x535.png" /></p> 
<li>For <strong>Actions</strong>, for <strong>Whenever this alarm</strong> select <strong>State is Alarm</strong>. For <strong>Send notification to</strong> create a New list to send notification to. Make sure to confirm the subscription.</li> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/alarm-1.png" /></p> 
<li>Whenever an alarm threshold is breached (that is, when the App Pool stops), you will receive an email notification.</li> 
<b><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/email_alert-1024x441.png" /></b> 
<b>Conclusion</b> 
<p>Businesses are moving toward automated IT. It’s common for applications to span across environments and locations. They can be in the &nbsp;AWS Cloud and in on-premises data centers. It’s a challenge to ensure that the infrastructure powering your applications is consistent.. To help ensure a consistent approach, you can use State Manager to create policies, reapply these policies to prevent configuration drift, and monitor the status of your intended state.</p> 
<p>In this blog post, you have learned how to configure a Windows EC2 instance to send HttpErr and IIS logs to CloudWatch using Amazon EC2 Systems Manager. These steps can be applied to a fleet of Windows Instances running IIS to consolidate logs from all the instances centrally.</p> 
<p>To learn more about Amazon EC2 Systems Manager and EC2 Systems Manager State Manager, go to – <a href="https://aws.amazon.com/ec2/systems-manager/">https://aws.amazon.com/ec2/systems-manager/</a></p> 
<h3></h3> 
<hr /> 
<h3>About the Author</h3> 
<p>&nbsp;</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/PawanPuthran_AWS_TAM-150x150.jpg" />Pawan Puthran is a Senior Technical Account Manager at Amazon Web Services. He works with Enterprise Support customers, and he provides technical guidance and assistance to help them make the best use of AWS services. He loves to write blogs outlining his solutions on multiple AWS products.</p> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">Take Microsoft VSS-Enabled Snapshots Using Amazon EC2 Systems Manager</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Purvi Goyal</span></span> | on 
<time property="datePublished" datetime="2017-11-20T13:54:47+00:00">20 NOV 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/amazon-ec2-systems-manager/" title="View all posts in Amazon EC2 Systems Manager*"><span property="articleSection">Amazon EC2 Systems Manager*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/compute/amazon-ec2/" title="View all posts in Amazon EC2*"><span property="articleSection">Amazon EC2*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/storage/amazon-elastic-block-storage-ebs/" title="View all posts in Amazon Elastic Block Storage (EBS)*"><span property="articleSection">Amazon Elastic Block Storage (EBS)*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools*"><span property="articleSection">Management Tools*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/take-microsoft-vss-enabled-snapshots-using-amazon-ec2-systems-manager/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p>We are happy to announce the support for Microsoft Volume Shadow Copy Service (VSS) on Amazon EC2 instances running Windows AMIs. VSS is a popular volume backup technology in the Microsoft Windows ecosystem (compatible with most Microsoft applications, including SQL Server and Exchange Server). VSS manages disk operations, such as file writes, when a backup is in progress so that the resulting backups are application-consistent.&nbsp;<em>Application-consistent</em> backups are the backups of volumes attached to a machine or an instance, taken at the same time, along with capturing all data in memory and all transactions in progress.</p> 
<p>VSS-enabled snapshots of Amazon EBS volumes are available through Amazon EC2 Systems Manager Run Command. The command <em>AWSEC2-CreateVssSnapshot</em> allows you to take application-consistent snapshots of all EBS volumes attached to your running EC2 Windows instances, without losing transactional data consistency between your EC2 instances and attached EBS volumes during the backup process.&nbsp;With this capability, you don’t need to use application-specific backup solutions, such as native SQL Backup, or develop and maintain custom scripts. In addition, you don’t need to run third-party tools for taking image-level backups that are application-consistent.</p> 
<p><span id="more-2030"></span></p> 
<h3>How to use&nbsp;AWSEC2-CreateVssSnapshot</h3> 
<p>You can take VSS-enabled EBS snapshots on EC2 instances running Windows by calling the command <em>AWSEC2-CreateVssSnapshot</em> through EC2 Systems Manager Run Command. You can use the AWS Management Console, the AWS CLI, or you can call it through a custom PowerShell script or a Lambda function. In this blog post, we’ll call the command using the EC2 console.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/15/1.png" /></p> 
<p>In the EC2 console, first select the Run command document <em>AWSEC2-CreateVssSnapshot</em> to take a VSS-enabled snapshot of your EBS volumes attached to an instance. Then select the instance, and specify the description and tags that you want to add to your resulting snapshots. You can also choose to exclude the boot volume from the snapshot process.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/22/7.png" /></p> 
<p>When initiated, the Run Command call makes the VSS components (More details to follow) on your instances coordinate all ongoing I/O operations on VSS-aware applications running on the EC2 Windows instances. This way the I/O buffers are flushed to the EBS volumes, and all I/O operations are frozen while snapshots are taken. This results in application consistency. After the snapshot is initiated, the freeze on I/O is lifted and normal operations are resumed.</p> 
<p>The list of snapshots created through the Run Command or the script can be found under EBS snapshots in the left navigation pane in the EC2 console. All VSS-enabled EBS snapshots that are successfully created from this process are tagged as “AppConsistent:True”. To learn more about this capability, go to the <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/integration-vss.html">documentation for&nbsp;<em>AWSEC2-CreateVssSnapshot</em></a>.</p> 
<h3>Setting up your EC2 instances to take VSS-enabled snapshots</h3> 
<li><strong>Snapshot permissions to instances</strong>: You need to open the IAM console, and use Policy generator to create new Policy for AWS service “Amazon EC2” and attach the following actions to this policy. 
<ol> 
<li>DescribeInstances</li> 
<li>CreateTags</li> 
<li>CreateSnapshot</li> 
</ol> </li> 
<p>Now create an Amazon EC2 role in the IAM console and attach the actions we previously listed and <em>AmazonEC2RoleForSSM</em> policies to it. Attach this role directly to your EC2 Windows instances.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/22/8.png" /></p> 
<li><strong>Installing VSS components</strong>: All instances created using Microsoft Windows Server AMIs dated 2017.11.18 or later have the VSS components pre-installed. If your Windows instances are not updated with the latest packages, you need to perform additional steps to take VSS-enabled EBS snapshots. 
<li><strong>Update SSM agent</strong>: If your instances don’t have SSM agent 2.2.58.0 or later, you need to call the <em>AWS-UpdateSSMAgent</em> Run Command to update latest SSM agent. You can use Managed Instances under the Shared Systems Manager Resources in the left navigation pane to see the SSM agent version installed on your instances. <img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/22/managed.png" /></li> 
<li><strong>Configure AWS package</strong>: You need to install the VSS components (<em>AwsVssComponents</em>) on them by calling the <em>AWS-ConfigureAWSPackage</em> command using Systems Manager Run Command.</li> 
</ul> </li> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/15/4.png" /></p> 
<p>For more information on how you can set up your EC2 instances to take VSS-enabled EBS snapshots, go to the <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/integration-vss.html#integration-vss-prereqs">Amazon EC2 documentation</a>.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/15/5.png" /></p> 
<p>Using the command AWSEC2-CreateVssSnapshot requires you to provide IAM permissions to create and tag EBS snapshots to your EC2 instances.&nbsp;Alternatively, if you don’t want to provide additional IAM permissions to your instances for policy or compliance reasons, then you can use a customizable sample script. To read more about this script, refer to the <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/integration-vss.html#integration-vss-AWSEC2-ManageVssIO">documentation for <em>AWSEC2-ManageVssIO</em></a>.</p> 
<p>The process for restoring the VSS-based EBS snapshots is the same process that you use to restore EBS snapshots. In addition, you can use <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/integration-vss.html#integration-vss-restore">a sample restore script</a> that we provide. This restore script allows you to restore from specified EBS Snapshots to a given Windows instance on Amazon EC2.</p> 
<hr /> 
<h4>About the Author</h4> 
<p style="text-align: left"><img width="100%" src="https://internal-cdn.amazon.com/badgephotos.amazon.com/?uid=goyapurv" />Purvi Goyal is a Senior Product Manager with the Amazon EC2 team, where she strives to enhance the cloud experience of AWS Enterprise customers. Outside of work, she enjoys outdoor activities like hiking and kayaking.</p> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">Query for the Latest Windows AMI Using Systems Manager Parameter Store</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Venkat Krish</span></span> | on 
<time property="datePublished" datetime="2017-11-17T13:03:38+00:00">17 NOV 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/amazon-ec2-systems-manager/" title="View all posts in Amazon EC2 Systems Manager*"><span property="articleSection">Amazon EC2 Systems Manager*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools*"><span property="articleSection">Management Tools*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/query-for-the-latest-windows-ami-using-systems-manager-parameter-store/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p>AWS has introduced a simpler way for you to query for the latest Windows Amazon Machine Image (AMI). You can now use Amazon EC2 Systems Manager Parameter Store. Prior to this release, finding the latest regional ImageID for an Amazon-provided AMI involved a three-step process. First, use an API call to search the list of available public AMIs. Second, filter the results by a given partial string name. Third, sort the matches by CreationDate property and select the newest ImageID.</p> 
<p>Now, the latest version of a Windows regional ImageID can be returned from a simple Parameter Store query. Each Windows AMI now has its own Parameter Store namespace that is public and describable. Upon querying, an AMI namespace returns only its regional ImageID value.</p> 
<p><strong>The&nbsp;namespace is made up of two parts:</strong></p> 
<ol> 
<li>Parameter Store Prefix (tree): /aws/service/ami-windows-latest/</li> 
<li>AMI name alias: Windows_Server-2016-English-Full-Base</li> 
</ol> 
<p>You can determine a Windows AMI alias by taking the full AMI name property of a Windows public AMI and removing the date-based version identifier at the end.&nbsp; A list of these AMI name properties can be seen by running one for the following EC2 queries.</p> 
<p><span id="more-1946"></span></p> 
<p>Using PowerShell</p> 
<code class="lang-powershell">- Get-EC2ImageByName -Name Windows_Server* | Sort-Object CreationDate | Select-Object Name
</code> 
<p>Using AWS CLI</p> 
<code class="lang-bash">- aws ec2 describe-images --owners amazon --filters &quot;Name=name,Values=Windows_Server*&quot; --query 'sort_by(Images, &amp;CreationDate)[].Name'</code> 
<p>For example, Windows_Server-2016-English-Full-Base-2017.10.13 without the date-based version becomes Windows_Server-2016-English-Full-Base. When you add the public Parameter Store prefix namespace to the AMI alias you have the Parameter Store name of “/aws/service/ami-windows-latest/Windows_Server-2016-English-Full-Base”</p> 
<p>Each unique AMI namespace always remains the same. You no longer need to pattern match on name filters, and you no longer need to sort through CreationDate AMI properties. As Windows AMIs are patched and new versions are released to the public, AWS will update the Parameter Store value with the latest ImageID for each AMI namespace in all supported Regions.</p> 
<b><strong>Querying for the latest AMI using public Parameters</strong></b> 
<p>Once you have your target namespace, your query can be created to retrieve the latest AWS Windows ImageID. Each region has an exact replica namespace containing its region specific ImageID value.</p> 
<p>Using PowerShell</p> 
<code class="lang-powershell">Get-SSMParameter -Name /aws/service/ami-windows-latest/Windows_Server-2016-English-Full-Base -region us-east-1</code> 
<p>Using AWS CLI</p> 
<code class="lang-bash">aws ssm get-parameters --names /aws/service/ami-windows-latest/Windows_Server-2016-English-Full-Base --region us-east-1</code> 
<b><strong>Always launch new instances with the latest ImageID</strong></b> 
<p>After you have created the query, you can embed the command as a command substitution into your new instance launches.</p> 
<p>Using PowerShell</p> 
<code class="lang-powershell">New-EC2Instance -ImageId ((Get-SSMParameterValue -Name /aws/service/ami-windows-latest/Windows_Server-2016-English-Full-Base).Parameters[0].Value) -InstanceType m4.large -AssociatePublicIp $true -SubnetId subnet-abcd1234</code> 
<p>Using AWS CLI</p> 
<code class="lang-bash">aws ec2 run-instances --image-id $(aws ssm get-parameters --names /aws/service/ami-windows-latest/Windows_Server-2016-English-Full-Base&nbsp; --query 'Parameters[0].[Value]' --output text) --count 1 --instance-type m4.large --subnet-id subnet-abcd1234</code> 
<p>This new instance launch always results in the latest publicly available Windows AMI for Windows_Server-2016-English-Full-Base. Similar embedding can be used in a number of automation process, docs, and coding languages.</p> 
<b>Display a complete list of all available public Parameter Windows AMIs</b> 
<p>You can also query for the complete list of AWS Windows Parameter Store namespaces available.</p> 
<p>Using PowerShell</p> 
<code class="lang-powershell">Get-SSMParametersByPath -Path &quot;/aws/service/ami-windows-latest&quot; –region us-east-1</code> 
<p>Using AWS CLI</p> 
<code class="lang-bash">aws ssm get-parameters-by-path –-path &quot;/aws/service/ami-windows-latest&quot; –-region us-east-1</code> 
<b>Partial list of public Parameter AWS Windows AMIs</b> 
<code class="lang-bash">/aws/service/ami-windows-latest/Windows_Server-2016-Turkish-Full-Base
/aws/service/ami-windows-latest/Windows_Server-2016-Swedish-Full-Base
/aws/service/ami-windows-latest/Windows_Server-2016-Spanish-Full-Base
/aws/service/ami-windows-latest/Windows_Server-2016-Russian-Full-Base
/aws/service/ami-windows-latest/Windows_Server-2016-Portuguese_Portugal-Full-Base
/aws/service/ami-windows-latest/Windows_Server-2016-Portuguese_Brazil-Full-Base
/aws/service/ami-windows-latest/Windows_Server-2016-Polish-Full-Base
/aws/service/ami-windows-latest/Windows_Server-2016-Korean-Full-SQL_2016_SP1_Standard
/aws/service/ami-windows-latest/Windows_Server-2016-Korean-Full-Base
/aws/service/ami-windows-latest/Windows_Server-2016-Japanese-Full-SQL_2016_SP1_Web
/aws/service/ami-windows-latest/Windows_Server-2016-Japanese-Full-SQL_2016_SP1_Standard
/aws/service/ami-windows-latest/Windows_Server-2016-Japanese-Full-SQL_2016_SP1_Express
/aws/service/ami-windows-latest/Windows_Server-2016-Japanese-Full-SQL_2016_SP1_Enterprise
/aws/service/ami-windows-latest/Windows_Server-2016-Japanese-Full-Base
/aws/service/ami-windows-latest/Windows_Server-2016-Italian-Full-Base
/aws/service/ami-windows-latest/Windows_Server-2016-Hungarian-Full-Base
/aws/service/ami-windows-latest/Windows_Server-2016-German-Full-Base
/aws/service/ami-windows-latest/Windows_Server-2016-French-Full-Base
/aws/service/ami-windows-latest/Windows_Server-2016-English-Nano-Base
/aws/service/ami-windows-latest/Windows_Server-2016-English-Full-SQL_2017_Web
/aws/service/ami-windows-latest/Windows_Server-2016-English-Full-SQL_2017_Standard
/aws/service/ami-windows-latest/Windows_Server-2016-English-Full-SQL_2017_Express
/aws/service/ami-windows-latest/Windows_Server-2016-English-Full-SQL_2017_Enterprise 
</code>… 
<b>About the Author</b> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/16/download.jpg" /></p> 
<p>Steven Armentrout is a Systems Engineer on the Amazon EC2 Windows team and has over a decade of enterprise experience in the public and private sectors as System Administrator, Systems Engineer and Network Engineer.&nbsp;The resident expert on Windows Amazon Machine Images.&nbsp;The seeker of simplicity and ease of use.&nbsp;Living the dream and making a mark on the future of the cloud.</p> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">FINRA Gatekeeper: Amazon EC2 Access Management System Using Amazon EC2 Systems Manager</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Ananth Vaidyanathan</span></span> | on 
<time property="datePublished" datetime="2017-11-14T18:14:22+00:00">14 NOV 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/amazon-ec2-systems-manager/" title="View all posts in Amazon EC2 Systems Manager*"><span property="articleSection">Amazon EC2 Systems Manager*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools*"><span property="articleSection">Management Tools*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/finra-gatekeeper-amazon-ec2-access-management-system-using-amazon-ec2-systems-manager/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><em><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/13/finra-logo.png" />By Daniel Koo, Senior Director at FINRA, and Stephen Mele, Software Developer at FINRA</em></p> 
<h3>Introduction</h3> 
<p>Moving from a traditional data center to the cloud can impose many questions around compliance and security. FINRA took these concerns very seriously with our cloud migration journey to AWS. As a regulatory organization, overseeing up to 75 billion market transactions every day, it is critical for us to establish proper governance to ensure that compliance is met and that the right level of security is in place. In order for us to achieve this, we looked at building solutions on top of existing AWS services for managing human access. We wanted to make sure we properly control who has access to which resources, allow transparency to look at who is trying to access what resources, and add the necessary approval process when access is requested. The goal was to develop a solution which follows a self-service model, making it very easy for the development and ops community to adopt. The <a href="https://aws.amazon.com/ec2/systems-manager/">Amazon EC2 Systems Manager</a> (SSM) and <a href="https://console.aws.amazon.com/ssm/run-command">Run Command</a> service provided us exactly what we needed to build the right solution.</p> 
<p><span id="more-2011"></span></p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/13/problem.png" /></p> 
<h3>Solution Approach</h3> 
<p>Our solution was to provide temporary access to people using their existing credentials and permissions already being leveraged. We also wanted to make sure that we give the temporary access in a timely and responsive manner. In a traditional data center, it takes a significant amount of time to request access to a particular server and finally be granted the access. This is typically done through a paper process. Given that the majority of the servers are transient in the cloud, this long process did not work so we needed to automate the process and have a fast turnaround time. Ultimately, we wanted to discourage people from accessing the servers so that we could promote cloud-centric approaches such as re-deployment and self-healing. However this solution was necessary to achieve our desired control when access was absolutely needed. Following this approach, while keeping the compliance and security goals in mind, we developed an application called Gatekeeper which leverages <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/execute-remote-commands.html">Run Command</a> as the main technology.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/13/approach.png" /></p> 
<h3>Gatekeeper Application</h3> 
<p>Gatekeeper is designed as a Web application that is built around a request lifecycle management system, where a user performs a search, selects one or more EC2 resources for a specified environment (such as DEV, QA, Production), and makes a request for temporary access. The users have the ability to specify a set of people desiring the temporary access as well as the number of hours needed. Upon submitting the request, depending on the environment they are requesting for, there are two outcomes:</p> 
<ol> 
<li>The temporary access is immediately granted to the user(s).</li> 
<li>The access request requires a review and approval before being granted the temporary access. Upon approval, access is immediately granted to the user(s), otherwise the access is denied.</li> 
</ol> 
<p>Once the request is live, our lifecycle management system keeps track of the time that has elapsed since a request has been fulfilled. As soon as the time allotted to a specific request expires, the system will automatically revoke the user’s access from the resources specified in their request.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/15/schema_ssm.jpg" /></p> 
<h3>Creating the Users</h3> 
<p>Gatekeeper needs to be able to create an account for each user on all of the instances provided with the Access Request. To achieve this goal, Gatekeeper has documents staged in EC2 Systems Manager that perform the creation of users on running instances. The document itself is a simple shell script which will set up the user for the temporary access. Gatekeeper calls these documents by leveraging EC2 Systems Manager with the AWS SDK for Java. By taking this route, we do not have to worry about directly connecting to each instance and creating the users; we can simply make an AWS API call and let Systems Manager do all of the heavy lifting for us. Upon successful creation, the system will distribute the private keys to each user that is specified in the Access Request. Currently we have create/delete documents for Amazon Linux, Ubuntu, and Windows, but we could easily add more documents to support more operating systems should the need arise.</p> 
<h4>Example Create Document</h4> 
<code class="lang-json">{
&quot;schemaVersion&quot;:&quot;1.2&quot;,
&quot;description&quot;:&quot;Script for GateKeeper to create temp user.&quot;,
&quot;parameters&quot;:{
&quot;userName&quot;:{
&quot;type&quot;:&quot;String&quot;,
&quot;description&quot;:&quot;(Required) The username to create.&quot;,
&quot;allowedPattern&quot;:&quot;gk-.*&quot;,
&quot;maxChars&quot;:64
},
&quot;publicKey&quot;:{
&quot;type&quot;:&quot;String&quot;,
&quot;description&quot;:&quot;(Required) The public key string for the user.&quot;,
&quot;maxChars&quot;:4096
},
&quot;executionTimeout&quot;:{
&quot;type&quot;:&quot;String&quot;,
&quot;default&quot;:&quot;300&quot;,
&quot;description&quot;:&quot;(Optional) The time in seconds for a command to be completed before it is considered to have failed. Default is 3600 (1 hour). Maximum is 28800 (8 hours).&quot;,
&quot;allowedPattern&quot;:&quot;([1-9][0-9]{0,3})|(1[0-9]{1,4})|(2[0-7][0-9]{1,3})|(28[0-7][0-9]{1,2})|(28800)&quot;
}
},
&quot;runtimeConfig&quot;:{
&quot;aws:runShellScript&quot;:{
&quot;properties&quot;:[
{
&quot;id&quot;:&quot;0.aws:runShellScript&quot;,
&quot;runCommand&quot;:[
&quot;useradd -e `date -d '+2 days' '+%Y-%m-%d'` {{ userName }} -m&quot;,
&quot;mkdir /home/{{ userName }}/.ssh&quot;,
&quot;echo '{{ publicKey }}' &gt;&gt; /home/{{ userName }}/.ssh/authorized_keys&quot;,
&quot;chown -R {{ userName }}:{{ userName }} /home/{{ userName }}&quot;,
&quot;chmod -R go-rwx /home/{{ userName }}/.ssh&quot;,
&quot;echo '{{ userName }}  ALL=(ALL) NOPASSWD: ALL' &gt; /etc/sudoers.d/{{ userName }}&quot;,
&quot;usermod -p '*' {{ userName }}&quot;
],
&quot;workingDirectory&quot;:&quot;/root&quot;,
&quot;timeoutSeconds&quot;:&quot;{{ executionTimeout }}&quot;
}
]
}
}
}</code> 
<p>At a high level the script takes in 3 parameters and uses these to execute a shell script. The arguments for this script are:</p> 
<ol> 
<li><strong>userName</strong> – the username that the script will set up</li> 
<li><strong>publicKey</strong> – the public key that will be used for this user</li> 
<li><strong>executionTimeout</strong> – how much time to wait for the script to successfully complete</li> 
</ol> 
<p>The Gatekeeper application is responsible for providing the Systems Manager document with the <strong>userName</strong> and the public SSH key associated with that user. Gatekeeper will generate a new public/private SSH key each time so that no key will be re-used.</p> 
<p>The script itself will create the user via the&nbsp;<strong>useradd</strong> command, which will set up the user to expire after 2 days (if the system is unable to successfully remove the user). The user will be able to log into the instance only via their private key.</p> 
<h3>Revoking the User(s) Access</h3> 
<p>The Gatekeeper application keeps track of each Access Request that is active and determines whether it is time to revoke the user’s access. When the access period for a request expires, the system will invoke a different Systems Manager script that will execute a shell script which removes the user from the instance(s) to which they had requested access.</p> 
<h4>Example Remove Document</h4> 
<code class="lang-json">{
&quot;schemaVersion&quot;:&quot;1.2&quot;,
&quot;description&quot;:&quot;Script for GateKeeper to cleanup expired users.&quot;,
&quot;parameters&quot;:{
&quot;userName&quot;:{
&quot;type&quot;:&quot;String&quot;,
&quot;description&quot;:&quot;(Required) The username to delete.&quot;,
&quot;allowedPattern&quot;:&quot;gk-.*&quot;,
&quot;maxChars&quot;:64
},
&quot;executionTimeout&quot;:{
&quot;type&quot;:&quot;String&quot;,
&quot;default&quot;:&quot;300&quot;,
&quot;description&quot;:&quot;(Optional) The time in seconds for a command to be completed before it is considered to have failed. Default is 3600 (1 hour). Maximum is 28800 (8 hours).&quot;,
&quot;allowedPattern&quot;:&quot;([1-9][0-9]{0,3})|(1[0-9]{1,4})|(2[0-7][0-9]{1,3})|(28[0-7][0-9]{1,2})|(28800)&quot;
}
},
&quot;runtimeConfig&quot;:{
&quot;aws:runShellScript&quot;:{
&quot;properties&quot;:[
{
&quot;id&quot;:&quot;0.aws:runShellScript&quot;,
&quot;runCommand&quot;:[ &quot;cut -f1 -d':' /etc/passwd | grep {{ userName }} &gt; /dev/null &amp;&amp; (userdel -rf {{ userName }} ; echo 'user deleted' ) || echo 'no user to delete'&quot;,
&quot;ls /etc/sudoers.d/ | grep {{ userName }} &gt; /dev/null &amp;&amp; (rm -f /etc/sudoers.d/{{ userName }} ; echo 'sudo file deleted' ) || echo 'no sudo file to delete'&quot;    ],
&quot;workingDirectory&quot;:&quot;/root&quot;,
&quot;timeoutSeconds&quot;:&quot;{{ executionTimeout }}&quot;
}
]
}
}
}</code> 
<p>The arguments for this script are:</p> 
<ol> 
<li><strong>userName</strong>&nbsp;– the username that the script will delete</li> 
<li><strong>executionTimeout</strong>&nbsp;– how much time to wait for the script to successfully complete</li> 
</ol> 
<p>The script itself uses the <strong>userName</strong>&nbsp;parameter to delete the user from the instance(s). Should the script for some reason fail to run, it will re-try a set amount of times, and if there was no successful run, then the system will notify the Ops team to investigate and remove the user.</p> 
<h3>Conclusion</h3> 
<p>By leveraging Amazon EC2 Systems Manager and other services such as Amazon EC2 and AWS Identity and Access Management (IAM), FINRA was able to build a solution to manage temporary access to our resources running in AWS across multiple environments. Systems Manager is very easy to adopt, and it is extremely reliable and fast. It is a great tool for performing ad-hoc execution of scripts on running instances.</p> 
<p><em>The content and opinions in this blog are those of the third-party author and AWS is not responsible for the content or accuracy of this post.</em></p> 
<p>&nbsp;</p> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">How to Export EC2 Instance Execution Logs to an S3 Bucket Using CloudWatch Logs, Lambda, and CloudFormation</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Veronika Megler</span></span> | on 
<time property="datePublished" datetime="2017-11-13T11:12:07+00:00">13 NOV 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/amazon-cloudwatch/" title="View all posts in Amazon CloudWatch*"><span property="articleSection">Amazon CloudWatch*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/aws-cloudformation/" title="View all posts in AWS CloudFormation*"><span property="articleSection">AWS CloudFormation*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools*"><span property="articleSection">Management Tools*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/how-to-export-ec2-instance-execution-logs-to-an-s3-bucket-using-cloudwatch-logs-lambda-and-cloudformation/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p>“We want to get execution logs from our EC2 instances into S3,” my customer said. “Then we can store them and process them later, for optimization, audit, and security review, and so on. We’d like to do it in our CloudFormation stacks, as that’s our execution standard. Can you help us?”</p> 
<p>This blog post shows you how to build a solution for this problem. We’ll build it using Amazon CloudWatch Logs, AWS Lambda, and some useful capabilities in AWS CloudFormation for customizing EC2 instances.</p> 
<p><span id="more-1466"></span></p> 
<b>How it works</b> 
<p>To export the logs, we add some components to the CloudFormation stack that builds the EC2 instance. The following diagram and code samples show how this solution works in a stand-alone fashion. Later, we’ll discuss other ways to integrate these components into your production infrastructure.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/13/cwexport-arch.png" /></p> 
<p>We use a CloudFormation stack (1) to create the components shown. When everything is up and running, we have an EC2 instance running a CloudWatch Logs agent (2). The agent routes the configured logs to a CloudWatch Logs log group (3). A Lambda function (4) that’s subscribed to the log group picks up each log and writes it to an existing Amazon S3 bucket (5). Note that there’s some delay from the time a log message is created on the EC2 instance to the time it appears in the S3 bucket.</p> 
<p>To configure the EC2 instance, we use a neat feature in CloudFormation, the <a title="undefined" href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/cfn-helper-scripts-reference.html" target="_blank" rel="noopener noreferrer">CloudFormation helper functions</a>. These helper functions can be combined to install and update a variety of software packages, configure them, start services, and more. We’ll show you how in this blog.</p> 
<p>If you’d like to skip ahead and see the code in action, go to “Running the Solution.”</p> 
<b>The implementation</b> 
<p>The implementation consists of the following four files, which we’ll discuss later:</p> 
<p>1.&nbsp;<code>Cwexport-master-template.yaml</code>: This template creates a security group and IAM role for our EC2 instance, and calls two embedded CloudFormation templates to do the real work.</p> 
<p>2.&nbsp;<code>Cloudwatchlogsexport.yaml</code>: This template creates the CloudWatch log group the logs will be sent to, and defines the Lambda function that will perform the export from the log group to S3. It then creates a CloudWatch Log subscription to automatically send the CloudWatch log streams to the Lambda function.</p> 
<p>3.&nbsp;<code>Cloudwatch-log-lambda.zip</code>: This zip file contains the code for the Lambda function, packaged along with its prerequisites.</p> 
<p>4.&nbsp;<code>Run-ec2-instance.yaml</code>: This template creates the EC2 instance, installs the <a title="undefined" href="http://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/AgentReference.html" target="_blank" rel="noopener noreferrer">CloudWatch Log Agent</a>, &nbsp;configures it to export the desired logs, and performs a specified task on startup (in this case, calculating digits of Pi).</p> 
<p>In practice we first set up the CloudWatch log group and export to Amazon S3, and then set up and configure the EC2 instance.</p> 
<b>Exporting logs from CloudWatch Logs to S3</b> 
<p>In Cloudwatchlogsexport.yaml, we first set up the CloudWatch Logs log group itself (<a title="undefined" href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-logs-loggroup.html" target="_blank" rel="noopener noreferrer"><code>&quot;AWS::Logs::LogGroup&quot;</code></a>).</p> 
<p>Next, we define the Lambda function that will perform the actual export. We’ve packaged our Python code into a Lambda deployment package for uploading and deployment by CloudFormation. The function (cloudwatch-log-lambda.py) requires two environment variables, s3BucketName and s3KeyPrefix, to tell it where the log files should be exported to. We specify these variables as inputs to the master CloudFormation script, which passes them to the Lambda function at execution time.</p> 
<p>The Lambda function receives logs from CloudWatch. For each invocation it unzips the received log file, converts it from JSON into a dictionary, then writes it out to S3 with our naming convention (&lt;s3KeyPrefix&gt;/&lt;logGroup&gt;/&lt;logStream&gt;/&lt;timestamp&gt;). You can see the source code of the Lambda <a title="Lambda code" href="https://management-tools-blog-cf-template-storage.s3.amazonaws.com/cloudwatchlogsexport2s3/cloudwatch-exportlogs2s3-lambda.py" target="_blank" rel="noopener noreferrer">here</a>.</p> 
<p>Then, we associate the Lambda function and the CloudWatch log group via an <a title="undefined" href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-logs-subscriptionfilter.html" target="_blank" rel="noopener noreferrer"><code>“AWS::Logs::SubscriptionFilter”</code></a> tag, specifying the Lambda function and the log group it’s subscribing to. This subscription will trigger the Lambda function when new logs are written to the CloudWatch log group, and pass the new log to it.</p> 
<b>Customizing your EC2 instance</b> 
<p>The last CloudFormation template, Run-ec2-instance.yaml, starts our EC2 instance. We use CloudFormation tags to customize the properties of the EC2 instance: specifying the EC2 instance type, AMI, the IAM role, VPC, and so on.</p> 
<p>In our case, we also want to automatically install some software packages (notably, the CloudWatch Logs agent); configure some files; and then start some services – all before the actual processing specified in our UserData section is triggered. We can do so by using some capabilities that CloudFormation provides.</p> 
<p>First, we use an <a title="undefined" href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-init.html" target="_blank" rel="noopener noreferrer"><code>AWS::CloudFormation::Init</code></a> tag in the metadata section of our EC2 definition to define customizations. Then we call a <a title="undefined" href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/cfn-helper-scripts-reference.html" target="_blank" rel="noopener noreferrer">set of provided CloudFormation helper scripts</a> from our EC2 instances’s UserData to implement the definitions before we move on to doing the work we’ve set up the EC2 instance to do. We describe the tag and definitions next.</p> 
<b>The AWS::CloudFormation::Init tag</b> 
<p>We use the <code>AWS::CloudFormation::Init</code> type to include metadata for our Amazon EC2 instance. The metadata can later be accessed by the helper scripts. When we execute the helper scripts from our EC2 instance’s UserData, the script looks for resource metadata specified in the AWS::CloudFormation::Init metadata key and uses that information to customize the instance. Here’s the beginning of our definition:</p> 
<code class="lang-yaml">&nbsp; EC2Instance:
&nbsp;&nbsp;&nbsp; Type: 'AWS::EC2::Instance'
&nbsp;&nbsp;&nbsp; Metadata:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 'AWS::CloudFormation::Init':
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; configSets:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; default:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [config]
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; config:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; …</code> 
<p>The CloudFormation Init tag supports a wide variety of capabilities, which we encourage you to explore. For this EC2 instance we’ll use three: packages, files, and services.</p> 
<h4>Using CloudFormation::Init to install software</h4> 
<p>We can use the packages tag to download and install pre-packaged applications and components. For this blog post, we want to install one yum package: awslogs, the AWS CloudWatch Logs agent. Because the software is installed by the <a title="undefined" href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/cfn-init.html" target="_blank" rel="noopener noreferrer">cfn-init</a> helper script, we’re limited to the package formats it supports. Currently, on Linux the package formats are apt, msi, python, rpm, rubygems, and yum. We specify the package manager, then each package’s name, and a list of (possibly empty) versions. Because we aren’t sensitive to the version here, we’ll leave the version tag blank. In this case, cfn-init installs the latest version if the package isn’t already installed, or leaves it at the current version if the package is installed.</p> 
<code class="lang-yaml">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; config:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; packages:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; yum:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; awslogs: []
...</code> 
<h4>Configuring files</h4> 
<p>Next, we want to use CloudFormation to <a title="undefined" href="http://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/EC2NewInstanceCWL.html" target="_blank" rel="noopener noreferrer">create or modify the CloudWatch Log agent configuration files on the EC2 instance</a>. We can do this by using the “files” key of our <code>AWS::CloudFormation::Init</code>. There are several options for creating the files. Here, we include the desired content for the files directly in the CloudFormation template. We create two <a title="undefined" href="http://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/AgentReference.html" target="_blank" rel="noopener noreferrer">CloudWatch agent configuration files</a> and two CloudFormation helper configuration files:</p> 
<p><strong>/etc/awslogs/awscli.conf:</strong> This short example shows how an entire file is specified within this tag. The file will contain the default Region, and a plugin setting:</p> 
<code class="lang-yaml">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; files:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; '/etc/awslogs/awscli.conf':
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; content: !Sub |
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [default]
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; region = ${AWS::Region}
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [plugins]
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; cwlogs = cwlogs
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; mode: '000644'
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; owner: root
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; group: root</code> 
<p><strong>/etc/awslogs/awslogs.conf:</strong> We specify the local files we want to send to CloudWatch Logs, along with the log stream name to send them to, and other characteristics. The list being exported includes the CloudFormation execution logs. We encourage you to extend the list to include logs for your application or other logs of interest.</p> 
<p>We’ve configured each selected EC2 instance local log file to go to a log stream that consists of the stack name, followed by the EC2 instance ID, followed by the name of the file. This way, the files associated with one instance are grouped together and are easily findable in CloudWatch. This naming convention can easily be changed.</p> 
<p>The CloudWatch Logs agent lets us specify the size of the batches, the time stamp formats, the encoding, and more. By default, the logs are sent using enable gzip http content encoding to send compressed payloads to CloudWatch Logs. This decreases CPU usage, lowers Network Out, and decreases put latency. Our Lambda function unzips the files before writing them out.</p> 
<p><strong>/etc/cfn/cfn-hup.conf and /etc/cfn/hooks.d/cfn-auto-reloader.conf:</strong> These two configuration files are used to configure the <a title="undefined" href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/cfn-hup.html" target="_blank" rel="noopener noreferrer">cfn-hup daemon</a>. This daemon detects changes in the EC2 resource metadata and runs user-specified actions when a change is detected. This allows you to make configuration updates on your running Amazon EC2 instances through the UpdateStack API action.</p> 
<h4>Starting and restarting services</h4> 
<p>The third section in the metadata that we specify is the <a title="undefined" href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-init.html#aws-resource-init-services" target="_blank" rel="noopener noreferrer">services</a> key. This key defines which services should be enabled or disabled when the instance is launched. The services key also allows you to specify dependencies on sources, packages and files. If a restart is needed after files have been installed, cfn-init will take care of the service restart. In our example, we use this key to restart two services after we’ve created the config files for awslogs and cfn-hup.</p> 
<code class="lang-yaml">          services:
sysvinit:
awslogs:
enabled: true
ensureRunning: true
packages:
yum:
- awslogs
files:
- '/etc/awslogs/awslogs.conf'
- '/etc/awslogs/awscli.conf'
cfn-hup:
enabled: true
ensureRunning: true
files:
- '/etc/cfn/cfn-hup.conf'
- '/etc/cfn/hooks.d/cfn-auto-reloader.conf'</code> 
<h4>Finally: Executing the definitions</h4> 
<p>Having specified the files to install, config files to set up, and services to be started, we need to ensure that the <a title="undefined" href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/cfn-init.html" target="null">cfn-init</a> helper function is run to implement these specifications. In the EC2 instance’s UserData section, we first update the helper scripts and ensure that other yum packages are up-to-date. Then, we execute cfn-init, telling it which resource and CloudFormation stack to use as parameters.</p> 
<p>Lastly, we call the <a title="undefined" href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/cfn-signal.html" target="null">cfn-signal</a> helper function to let CloudFormation know that our EC2 instance is up and ready. We pass it the name of the stack, the Region, and the resource we’re sending a signal for. This signal causes CloudFormation to switch the EC2 instance to “Complete”.</p> 
<code class="lang-yaml">&nbsp; UserData:
&nbsp;&nbsp;&nbsp; 'Fn::Base64': !Sub |
&nbsp;&nbsp;&nbsp; #!/bin/bash -x
&nbsp;&nbsp;&nbsp; # Use the line below to ensure the CloudFormation helper scripts are updated to the latest version
&nbsp;&nbsp;&nbsp; # Per: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/cfn-helper-scripts-reference.html
&nbsp;&nbsp;&nbsp; yum install -y aws-cfn-bootstrap
&nbsp;&nbsp;&nbsp; yum update -y&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; /opt/aws/bin/cfn-init -v --stack ${AWS::StackName} --resource EC2Instance --configsets default --region ${AWS::Region}
&nbsp;&nbsp;&nbsp; /opt/aws/bin/cfn-signal -e $? --stack ${AWS::StackName} --region ${AWS::Region} --resource=EC2Instance</code> 
<p>Now, we’re ready to actually perform the work of this EC2 instance. In our example, it’s a dummy job that calculates digits of Pi. We’re actually more interested in the log files created.</p> 
<h3>Running the solution</h3> 
<p>To see this solution in operation in us-west-2, choose the “Launch Stack” button&nbsp;below.</p> 
<p>&nbsp;</p> 
<p>Choose “Next”, then update the parameters shown below for your environment: TheLogsBucketName, VPCId, VPC Subnet and s3BucketForResults (leave the Template Locations as is).</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/30/Cloudwatchloggroup-stackparms.png" /></p> 
<p>Click “Next” twice, acknowledge that AWS CloudFormation might create IAM resources with custom names, and click “Create”. Then wait for the CloudFormation master stack and its two nested stacks to reach a status of “CREATE_COMPLETE”.</p> 
<p>After our EC2 instance is up and running, the files we specified in our CloudWatch Logs agent configuration are exported to CloudWatch. Here’s an example of our log group, as seen in the CloudWatch Logs console:</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/06/Cloudwatch-loggroup-capprechng.png" /></p> 
<p>The Lambda function receives each log from CloudWatch and unzips it. It then writes the event file out to Amazon S3, giving it an S3 key that consists of the given S3 key prefix, followed by the log group, the log stream name (i.e., the filename), and a timestamp.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/13/cwexport-s3-output.png" /></p> 
<p>If the logs don’t appear in Amazon S3 as expected, check the Lambda function’s CloudWatch Logs log group for execution errors. The CloudWatch logs for the Lambda function can be found in a log group named: <code>/aws/lambda/&lt;mainstackname&gt;-CWExportStack-CWEc2LogsLambdaFunction-&lt;id&gt;</code>.</p> 
<h4>The power of change sets</h4> 
<p>Earlier, we configured a cfn-hup daemon. The cfn-hup helper is a daemon that detects changes in resource metadata and runs user-specified actions when a change is detected. This allows you to make configuration updates on your running Amazon EC2 instances through the UpdateStack API action.</p> 
<p>Let’s demonstrate the power of the cfn-hup configuration that’s in our CloudFormation stack. In our files definition, we provided the following configuration:</p> 
<code class="lang-yaml">'/etc/cfn/hooks.d/cfn-auto-reloader.conf':  
content: !Sub |
[cfn-auto-reloader-hook]
triggers=post.update
path=Resources.EC2Instance.Metadata.AWS::CloudFormation::Init
action=/opt/aws/bin/cfn-init --verbose --stack=${AWS::StackName} --region=${AWS::Region} --resource=EC2Instance
runas=root 
</code> 
<p>This configuration tells cfn-hup to re-run cfn-init after the stack has been updated.</p> 
<p>In our case, we’ll make two changes to our EC2 instance. First, we’ll add an additional software package to install: jq. Imagine that there’s a part of our software stack that’s only invoked rarely, and we’re either missing a package or wish to upgrade a version in our running system. Secondly, we’ll add an additional log file export, cloud to our CloudWatch Logs configuration.</p> 
<p>These changes have been made for you, in another CloudFormation template: &nbsp;run-ec2-instance-changed.yaml. To execute this change through the console, do the following steps.</p> 
<ol> 
<li>In the CloudFormation console, select your nested “EC2InstanceStack”.</li> 
<li>Choose Actions&nbsp;&nbsp;-&gt; Update Stack.</li> 
<li>You’ll receive a warning that “Performing operations directly on a nested stack may result in an unstable state where it is out-of-sync with the root stack to which it belongs.” But we’ll be very careful here, so select the option “Yes, Update.”</li> 
<li>Next, select the revised template. Enter the following URL: <code>https://management-tools-blog-cf-template-storage.s3.amazonaws.com/cloudwatchlogsexport2s3/run-ec2-instance-changed.yaml</code>, and choose Next.</li> 
<li>Click through the next two pages that show the existing template parameters. &nbsp;We won’t be modifying any of them.</li> 
<li>On the next page, CloudFormation shows the results of analyzing the differences between the new CloudFormation template and the currently running one. The following screenshot shows the differences. We are modifying the EC2 instance only. The changes we’ve made result in “Replacement: False”, telling us that the existing EC2 instance will be modified. Other results there are “True,” which causes the resource to be replaced; or, “Conditional,” which means the resource property will be dynamically evaluated at execution time to determine if it requires replacement or not.</li> 
</ol> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/30/cwmod-1.png" /><br /> 7. Choose “Update”.</p> 
<p>Then, in the CloudFormation console, you can see the update actions as they occur, and their results, as in the screenshot below.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/30/Cwconsoleduringupdate-1.png" /></p> 
<p>After waiting a little while for the changes and logs to propagate, you can check the CloudWatch log group. You’ll see a new log stream there, for the cloud-init.log definition we added.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/06/Cloudwatch-loggroup-cappostchng.png" /></p> 
<p>In our CloudWatch log group (or in S3), you can review cfn-hup.log and see the moment it’s notified of the CloudFormation template change, and starts the cfn-auto-reloader-hook action.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/06/cfn-hup-log.png" /></p> 
<p>Then, in cfn-init.log, you can see the installation of the jq software package, and the rewriting of the other files specified in our CloudFormation template.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/30/cfn-init-log-1.png" /></p> 
<p>Now we’ve successfully updated our running EC2 instance, with additional software and changed configurations. All through our CloudFormation stack. And, we know that the CloudFormation template we now have reflects our running environment. Sweet!</p> 
<p>Remember to delete the CloudFormation stack when you’re done, to stop incurring fees. If you delete the stack right way, testing the solution will cost only a few cents.</p> 
<h4>Adapting for production use</h4> 
<p>To implement, copy the files from s3://management-tools-blog-cf-template-storage.s3.amazonaws.com/cwexportlogs2s3/, and modify as needed for your environment.</p> 
<p>This implementation demonstrates useful capabilities. However, you should consider modifying some details for production use.</p> 
<p>In <code>cloudwatchlogsexport.yaml</code>, we’ve created a new log group. Since for demo purposes we’ll be deleting the log group when the CloudFormation stack is removed, we’ve added a commented out line <code>“#DeletionPolicy: Retain”</code> at the end of the definition. Because we’re writing the logs to S3, we don’t need to retain the log group. However, you may also choose to retain the group for some time after the run before expiring it, for additional validation. Also, because there is a delay in writing out the logs created, if you aggressively delete &nbsp;the CloudFormation stack as soon as the EC2 instance is terminated you might remove the Lambda function before the last logs have made it to the S3 bucket. We recommend that you wait a few minutes before deleting the CloudFormation stack.</p> 
<p>You can also choose to use one log group for many CloudFormation stacks and EC2 instance executions. Using that approach, you would create the CloudWatch Log group and Lambda function once (run <code>Cloudwatchlogsexport.yaml</code> alone), and leave them in place for the long term. As each EC2 instance gets created (<code>run-ec2-instance.yaml</code>), pass it the name of the log group to use. Since we are using the instance ID in the log stream ID, the different executions will still be clearly identified in CloudWatch and in Amazon S3.</p> 
<h3>Conclusion</h3> 
<p>By integrating the CloudWatch Logs agent into our CloudFormation stack, your EC2 instance logs can easily be exported to an S3 bucket. After the logs are in S3, you have a myriad of additional options. You can make the EC2 instance logs part of your data lake. You can process them using some analytics tools, such as <a title="undefined" href="https://quicksight.aws/" target="_blank" rel="noopener noreferrer">Amazon QuickSight</a>. You can set up S3 lifecycle rules to automatically archive them for audit purposes, using <a title="undefined" href="https://aws.amazon.com/glacier/" target="_blank" rel="noopener noreferrer">Amazon Glacier</a>. Because all the components are automated using a CloudFormation stack, you can ensure that the logs are being exported and stored consistently. For example, you can integrate this solution into <a title="undefined" href="https://aws.amazon.com/blogs/compute/how-to-provision-complex-on-demand-infrastructures-by-using-amazon-api-gateway-and-aws-lambda/" target="null">requests to provision infrastructure</a>, to ensure that audit trails for all such requests are created in a consistent fashion.</p> 
<p>The same CloudFormation components can be used to install, configure, and customize many other combinations of software.You’re limited only by your imagination. We hope this blog inspires you to extend your use to other use cases beyond the ones we’ve described here.</p> 
<h4>About the Author</h4> 
<p><strong>Veronika Megler, PhD, is a Senior Consultant, Big Data, Analytics &amp; Data Science, for AWS Professional Services.</strong> She enjoys helping customers adopt new technologies to solve new problems and to solve old problems more efficiently and effectively. In her spare time she is passionate about conservation, travel to interesting, beautiful or historic places, expanding her knowledge of arcane subjects, and searching for ultimate expression in Argentine tango.</p> 
</article> 
<p>
© 2017, Amazon Web Services, Inc. or its affiliates. All rights reserved.
</p>

    </div>
  </div>
</div>


    <div id="footer" class="navigation hidden-print">
      <div class="container">
        <div class="row">
          <div class="col-xs-12">
            <ul class="footer-links nav navbar-nav">
              <li><a href="../aws.html">AWS</a></li>
              <li><a href="../linux.html">Linux</a></li>
              <li><a href="../docker.html">Docker</a></li>
              <li><a href="../ibmpower.html">IBM Power</a></li>
              <li><a href="blogsataws1.html">Blogs@AWS (Kindle Friendly)</a></li>
            </ul>
            <ul class="footer-links nav navbar-nav navbar-right">
              <li><a href="../comments.html">Comments?</a></li>
            </ul>
          </div>
        </div>
      </div>
    </div>
  </body>
</html>
