<!DOCTYPE html>
<html lang="en">
  <head>
<!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-593498H');</script>
<!-- End Google Tag Manager -->

    <meta charset="utf-8">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">

    <meta name="msapplication-config" content="/microsoft-tile.xml" />
    <meta name="theme-color" content="#ffffff">

    <meta property="og:url" content="https://bejoycalias.github.io/blogsataws/mgmtblogs1.html" />
    <meta property="og:site_name" content="Bejoy's TechNotes"/>
    <meta property="og:title" content="Bejoy's TechNotes - Kindle Friendly AWS Management Tools Blogs" />
    <meta property="og:image" content="https://bejoycalias.github.io/assets/images/og-image.png"/>
    <meta property="og:image:width" content="1200"/>
    <meta property="og:image:height" content="1200"/>
    <meta property="og:description" content="" />

    <title>Bejoy's TechNotes - Kindle Friendly AWS Management Tools Blogs</title>
    <link href="../assets/stylesheets/application-832aa42c.css" rel="stylesheet" />

    <!--[if lt IE 9]>
      <script src="../assets/javascripts/ie-compat-c141a02d.js"></script>
    <![endif]-->
    <script src="../assets/javascripts/application-ff53d307.js"></script>

    <!-- Typekit script to import Klavika font -->
    <script src="https://use.typekit.net/wxf7mfi.js"></script>
    <script>try{Typekit.load({ async: true });}catch(e){}</script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-100043608-1', 'auto');
  ga('send', 'pageview');

</script>

    
  </head>

  <body id="uh-oh-" class="layout-inner page-uh-oh-">
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-593498H"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->


    <div id="header" class="navigation navbar-static-top hidden-print">
      <div class="container">
        <div class="row">
          <div class="col-xs-12">
            <div class="navbar-header">
              <div class="navbar-brand">
                <a href="/">
                  <svg version="1.0" xmlns="http://www.w3.org/2000/svg" width="135.000000pt" height="50" viewbox="0 0 135.000000 45.000000" preserveaspectratio="xMidYMid meet" class="logo">

<g transform="translate(0.000000,45.000000) scale(0.100000,-0.100000)" fill="#000000" stroke="none">
<path class="text" fill="#000000" d="M527 384 c-4 -4 -7 -18 -7 -31 0 -21 4 -24 28 -21 21 2 27 8 27 28 0
18 -6 26 -20 28 -12 2 -24 0 -28 -4z"></path>
<path class="text" fill="#000000" d="M1080 335 c0 -48 2 -55 20 -55 18 0 20 7 20 55 0 48 -2 55 -20 55
-18 0 -20 -7 -20 -55z"></path>
<path class="text" fill="#000000" d="M54 357 c-2 -7 -3 -69 -2 -138 l3 -124 65 -3 c90 -3 130 20 130 77 0
29 -6 44 -20 54 -20 14 -20 15 -3 45 14 25 15 34 5 56 -6 15 -23 31 -38 36
-38 15 -134 13 -140 -3z m110 -33 c19 -7 21 -45 4 -62 -7 -7 -22 -12 -35 -12
-20 0 -23 5 -23 40 0 41 13 50 54 34z m20 -130 c19 -18 19 -20 6 -45 -8 -13
-21 -19 -45 -19 -34 0 -35 1 -35 40 0 38 2 40 29 40 16 0 37 -7 45 -16z"></path>
<path class="text" fill="#000000" d="M319 271 c-23 -24 -29 -38 -29 -74 0 -25 3 -53 6 -62 20 -50 164 -64
164 -15 0 15 -7 17 -45 12 -46 -5 -75 8 -75 34 0 11 16 14 65 14 l65 0 0 35
c0 80 -92 114 -151 56z m99 -33 c3 -15 -4 -18 -37 -18 -43 0 -50 7 -29 28 18
18 62 11 66 -10z"></path>
<path class="text" fill="#000000" d="M520 184 c0 -107 -1 -116 -20 -121 -11 -3 -20 -12 -20 -19 0 -21 76
-19 84 2 3 9 6 69 6 135 l0 119 -25 0 -25 0 0 -116z"></path>
<path class="text" fill="#000000" d="M649 271 c-24 -25 -29 -37 -29 -78 1 -70 34 -103 105 -103 55 0 95
44 95 103 0 60 -7 75 -41 92 -47 25 -96 19 -130 -14z m111 -30 c25 -48 2 -111
-40 -111 -45 0 -69 80 -34 114 21 22 61 20 74 -3z"></path>
<path class="text" fill="#000000" d="M850 287 c0 -8 16 -57 36 -110 28 -76 33 -100 25 -116 -16 -28 -14
-31 18 -31 27 0 29 4 70 123 23 67 41 128 41 135 0 6 -11 12 -24 12 -21 0 -26
-8 -41 -65 -10 -36 -21 -68 -25 -70 -3 -2 -16 27 -29 66 -19 60 -25 69 -47 69
-13 0 -24 -6 -24 -13z"></path>
<path class="text" fill="#000000" d="M1192 284 c-17 -12 -22 -24 -20 -47 2 -26 10 -36 45 -52 49 -23 59
-55 17 -55 -14 0 -34 5 -45 10 -16 9 -19 7 -19 -13 0 -17 7 -27 23 -31 69 -18
117 6 117 60 0 32 -4 37 -45 55 -60 26 -62 54 -4 46 37 -5 40 -3 37 16 -2 18
-11 23 -43 25 -25 2 -49 -3 -63 -14z"></path>
</g>
</svg>

                </a>
              </div>
              <button class="navbar-toggle" type="button">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
              </button>
            </div>
            <div class="buttons hidden-xs">
              <nav class="navigation-links" role="navigation">
                <ul class="main-links nav navbar-nav navbar-right">
                  <li><a href="../aws.html">AWS</a></li>
                  <li><a href="../linux.html">Linux</a></li>
                  <li><a href="../docker.html">Docker</a></li>
                  <li><a href="../ibmpower.html">IBM Power</a></li>
                  <li><a href="blogsataws1.html">Blogs@AWS (Kindle Friendly)</a></li>
                </ul>
              </nav>
            </div>
          </div>
        </div>
      </div>
    </div>

    <div class="sidebar-overlay"></div>

<aside class="sidebar" role="navigation">
  <div class="sidebar-header">
    <svg version="1.0" xmlns="http://www.w3.org/2000/svg" width="135.000000pt" height="42" viewbox="0 0 135.000000 45.000000" preserveaspectratio="xMidYMid meet">

<g transform="translate(0.000000,45.000000) scale(0.100000,-0.100000)" fill="#000000" stroke="none">
<path class="text" fill="#000000" d="M527 384 c-4 -4 -7 -18 -7 -31 0 -21 4 -24 28 -21 21 2 27 8 27 28 0
18 -6 26 -20 28 -12 2 -24 0 -28 -4z"></path>
<path class="text" fill="#000000" d="M1080 335 c0 -48 2 -55 20 -55 18 0 20 7 20 55 0 48 -2 55 -20 55
-18 0 -20 -7 -20 -55z"></path>
<path class="text" fill="#000000" d="M54 357 c-2 -7 -3 -69 -2 -138 l3 -124 65 -3 c90 -3 130 20 130 77 0
29 -6 44 -20 54 -20 14 -20 15 -3 45 14 25 15 34 5 56 -6 15 -23 31 -38 36
-38 15 -134 13 -140 -3z m110 -33 c19 -7 21 -45 4 -62 -7 -7 -22 -12 -35 -12
-20 0 -23 5 -23 40 0 41 13 50 54 34z m20 -130 c19 -18 19 -20 6 -45 -8 -13
-21 -19 -45 -19 -34 0 -35 1 -35 40 0 38 2 40 29 40 16 0 37 -7 45 -16z"></path>
<path class="text" fill="#000000" d="M319 271 c-23 -24 -29 -38 -29 -74 0 -25 3 -53 6 -62 20 -50 164 -64
164 -15 0 15 -7 17 -45 12 -46 -5 -75 8 -75 34 0 11 16 14 65 14 l65 0 0 35
c0 80 -92 114 -151 56z m99 -33 c3 -15 -4 -18 -37 -18 -43 0 -50 7 -29 28 18
18 62 11 66 -10z"></path>
<path class="text" fill="#000000" d="M520 184 c0 -107 -1 -116 -20 -121 -11 -3 -20 -12 -20 -19 0 -21 76
-19 84 2 3 9 6 69 6 135 l0 119 -25 0 -25 0 0 -116z"></path>
<path class="text" fill="#000000" d="M649 271 c-24 -25 -29 -37 -29 -78 1 -70 34 -103 105 -103 55 0 95
44 95 103 0 60 -7 75 -41 92 -47 25 -96 19 -130 -14z m111 -30 c25 -48 2 -111
-40 -111 -45 0 -69 80 -34 114 21 22 61 20 74 -3z"></path>
<path class="text" fill="#000000" d="M850 287 c0 -8 16 -57 36 -110 28 -76 33 -100 25 -116 -16 -28 -14
-31 18 -31 27 0 29 4 70 123 23 67 41 128 41 135 0 6 -11 12 -24 12 -21 0 -26
-8 -41 -65 -10 -36 -21 -68 -25 -70 -3 -2 -16 27 -29 66 -19 60 -25 69 -47 69
-13 0 -24 -6 -24 -13z"></path>
<path class="text" fill="#000000" d="M1192 284 c-17 -12 -22 -24 -20 -47 2 -26 10 -36 45 -52 49 -23 59
-55 17 -55 -14 0 -34 5 -45 10 -16 9 -19 7 -19 -13 0 -17 7 -27 23 -31 69 -18
117 6 117 60 0 32 -4 37 -45 55 -60 26 -62 54 -4 46 37 -5 40 -3 37 16 -2 18
-11 23 -43 25 -25 2 -49 -3 -63 -14z"></path>
</g>
</svg>

  </div>

  <ul class="nav sidebar-nav">
    <li><a href="../aws.html">AWS</a></li>
    <li><a href="../linux.html">Linux</a></li>
    <li><a href="../docker.html">Docker</a></li>
    <li><a href="../ibmpower.html">IBM Power</a></li>
    <li><a href="blogsataws1.html">Blogs@AWS (Kindle Friendly)</a></li>
  </ul>
</aside>


    <div class="container">
  <div class="row">
    <div id="docs-sidebar" class="col-sm-3 col-md-3 col-xs-12 hidden-print" role="complementary">
      <ul class="nav docs-sidenav">
      <li><a href="blogsataws1.html">Blogs @ AWS</a></li>
      <li><a href="whatsnew1.html">What's New @ AWS</a></li>
      <li><a href="secblogs1.html">Security Blogs @ AWS</a></li>
      <li><a href="computeblogs1.html">Compute Blogs @ AWS</a></li>
      <li><a href="apnblogs1.html">APN Blogs @ AWS</a></li>
      <li><a href="devopsblogs1.html">DevOps Blogs @ AWS</a></li>
      <li class="active"><a href="mgmtblogs1.html">Management Tools Blogs @ AWS</a></li>

    </ul>
    </div>

    <div id="inner" class="col-sm-9 col-md-9 col-xs-12" role="main">
<p></p>
<p><i>Contents of this page is copied directly from AWS blog sites to make it Kindle friendly. Some styles & sections from these pages are removed to render this properly in 'Article Mode' of Kindle e-Reader browser. All the contents of this page is property of AWS.</i></p>
<p><a href="mgmtblogs1.html">Page 1</a>|<a href="mgmtblogs2.html">Page 2</a>|<a href="mgmtblogs3.html">Page 3</a>|<a href="mgmtblogs4.html">Page 4</a</p>
<br>
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">FINRA Gatekeeper: Amazon EC2 Access Management System Using Amazon EC2 Systems Manager</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Ananth Vaidyanathan</span></span> | on 
<time property="datePublished" datetime="2017-11-14T18:14:22+00:00">14 NOV 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/amazon-ec2-systems-manager/" title="View all posts in Amazon EC2 Systems Manager*"><span property="articleSection">Amazon EC2 Systems Manager*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools*"><span property="articleSection">Management Tools*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/finra-gatekeeper-amazon-ec2-access-management-system-using-amazon-ec2-systems-manager/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><em><img class="size-full wp-image-2017 alignright" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/13/finra-logo.png" alt="" width="352" height="107" />By Daniel Koo, Senior Director at FINRA, and Stephen Mele, Software Developer at FINRA</em></p> 
<h3>Introduction</h3> 
<p>Moving from a traditional data center to the cloud can impose many questions around compliance and security. FINRA took these concerns very seriously with our cloud migration journey to AWS. As a regulatory organization, overseeing up to 75 billion market transactions every day, it is critical for us to establish proper governance to ensure that compliance is met and that the right level of security is in place. In order for us to achieve this, we looked at building solutions on top of existing AWS services for managing human access. We wanted to make sure we properly control who has access to which resources, allow transparency to look at who is trying to access what resources, and add the necessary approval process when access is requested. The goal was to develop a solution which follows a self-service model, making it very easy for the development and ops community to adopt. The <a href="https://aws.amazon.com/ec2/systems-manager/">Amazon EC2 Systems Manager</a> (SSM) and <a href="https://console.aws.amazon.com/ssm/run-command">Run Command</a> service provided us exactly what we needed to build the right solution.</p> 
<p><span id="more-2011"></span></p> 
<p><img class="size-full wp-image-2014 alignnone" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/13/problem.png" alt="" width="500" height="303" /></p> 
<h3>Solution Approach</h3> 
<p>Our solution was to provide temporary access to people using their existing credentials and permissions already being leveraged. We also wanted to make sure that we give the temporary access in a timely and responsive manner. In a traditional data center, it takes a significant amount of time to request access to a particular server and finally be granted the access. This is typically done through a paper process. Given that the majority of the servers are transient in the cloud, this long process did not work so we needed to automate the process and have a fast turnaround time. Ultimately, we wanted to discourage people from accessing the servers so that we could promote cloud-centric approaches such as re-deployment and self-healing. However this solution was necessary to achieve our desired control when access was absolutely needed. Following this approach, while keeping the compliance and security goals in mind, we developed an application called Gatekeeper which leverages <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/execute-remote-commands.html">Run Command</a> as the main technology.</p> 
<p><img class="size-full wp-image-2015 alignnone" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/13/approach.png" alt="" width="500" height="273" /></p> 
<h3>Gatekeeper Application</h3> 
<p>Gatekeeper is designed as a Web application that is built around a request lifecycle management system, where a user performs a search, selects one or more EC2 resources for a specified environment (such as DEV, QA, Production), and makes a request for temporary access. The users have the ability to specify a set of people desiring the temporary access as well as the number of hours needed. Upon submitting the request, depending on the environment they are requesting for, there are two outcomes:</p> 
<ol> 
<li>The temporary access is immediately granted to the user(s).</li> 
<li>The access request requires a review and approval before being granted the temporary access. Upon approval, access is immediately granted to the user(s), otherwise the access is denied.</li> 
</ol> 
<p>Once the request is live, our lifecycle management system keeps track of the time that has elapsed since a request has been fulfilled. As soon as the time allotted to a specific request expires, the system will automatically revoke the user’s access from the resources specified in their request.</p> 
<p><img class="alignnone wp-image-2033 size-full" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/15/schema_ssm.jpg" alt="" width="579" height="335" /></p> 
<h3>Creating the Users</h3> 
<p>Gatekeeper needs to be able to create an account for each user on all of the instances provided with the Access Request. To achieve this goal, Gatekeeper has documents staged in EC2 Systems Manager that perform the creation of users on running instances. The document itself is a simple shell script which will set up the user for the temporary access. Gatekeeper calls these documents by leveraging EC2 Systems Manager with the AWS SDK for Java. By taking this route, we do not have to worry about directly connecting to each instance and creating the users; we can simply make an AWS API call and let Systems Manager do all of the heavy lifting for us. Upon successful creation, the system will distribute the private keys to each user that is specified in the Access Request. Currently we have create/delete documents for Amazon Linux, Ubuntu, and Windows, but we could easily add more documents to support more operating systems should the need arise.</p> 
<h4>Example Create Document</h4> 
<pre><code class="lang-json">{
&quot;schemaVersion&quot;:&quot;1.2&quot;,
&quot;description&quot;:&quot;Script for GateKeeper to create temp user.&quot;,
&quot;parameters&quot;:{
&quot;userName&quot;:{
&quot;type&quot;:&quot;String&quot;,
&quot;description&quot;:&quot;(Required) The username to create.&quot;,
&quot;allowedPattern&quot;:&quot;gk-.*&quot;,
&quot;maxChars&quot;:64
},
&quot;publicKey&quot;:{
&quot;type&quot;:&quot;String&quot;,
&quot;description&quot;:&quot;(Required) The public key string for the user.&quot;,
&quot;maxChars&quot;:4096
},
&quot;executionTimeout&quot;:{
&quot;type&quot;:&quot;String&quot;,
&quot;default&quot;:&quot;300&quot;,
&quot;description&quot;:&quot;(Optional) The time in seconds for a command to be completed before it is considered to have failed. Default is 3600 (1 hour). Maximum is 28800 (8 hours).&quot;,
&quot;allowedPattern&quot;:&quot;([1-9][0-9]{0,3})|(1[0-9]{1,4})|(2[0-7][0-9]{1,3})|(28[0-7][0-9]{1,2})|(28800)&quot;
}
},
&quot;runtimeConfig&quot;:{
&quot;aws:runShellScript&quot;:{
&quot;properties&quot;:[
{
&quot;id&quot;:&quot;0.aws:runShellScript&quot;,
&quot;runCommand&quot;:[
&quot;useradd -e `date -d '+2 days' '+%Y-%m-%d'` {{ userName }} -m&quot;,
&quot;mkdir /home/{{ userName }}/.ssh&quot;,
&quot;echo '{{ publicKey }}' &gt;&gt; /home/{{ userName }}/.ssh/authorized_keys&quot;,
&quot;chown -R {{ userName }}:{{ userName }} /home/{{ userName }}&quot;,
&quot;chmod -R go-rwx /home/{{ userName }}/.ssh&quot;,
&quot;echo '{{ userName }}  ALL=(ALL) NOPASSWD: ALL' &gt; /etc/sudoers.d/{{ userName }}&quot;,
&quot;usermod -p '*' {{ userName }}&quot;
],
&quot;workingDirectory&quot;:&quot;/root&quot;,
&quot;timeoutSeconds&quot;:&quot;{{ executionTimeout }}&quot;
}
]
}
}
}</code></pre> 
<p>At a high level the script takes in 3 parameters and uses these to execute a shell script. The arguments for this script are:</p> 
<ol> 
<li><strong>userName</strong> – the username that the script will set up</li> 
<li><strong>publicKey</strong> – the public key that will be used for this user</li> 
<li><strong>executionTimeout</strong> – how much time to wait for the script to successfully complete</li> 
</ol> 
<p>The Gatekeeper application is responsible for providing the Systems Manager document with the <strong>userName</strong> and the public SSH key associated with that user. Gatekeeper will generate a new public/private SSH key each time so that no key will be re-used.</p> 
<p>The script itself will create the user via the&nbsp;<strong>useradd</strong> command, which will set up the user to expire after 2 days (if the system is unable to successfully remove the user). The user will be able to log into the instance only via their private key.</p> 
<h3>Revoking the User(s) Access</h3> 
<p>The Gatekeeper application keeps track of each Access Request that is active and determines whether it is time to revoke the user’s access. When the access period for a request expires, the system will invoke a different Systems Manager script that will execute a shell script which removes the user from the instance(s) to which they had requested access.</p> 
<h4>Example Remove Document</h4> 
<pre><code class="lang-json">{
&quot;schemaVersion&quot;:&quot;1.2&quot;,
&quot;description&quot;:&quot;Script for GateKeeper to cleanup expired users.&quot;,
&quot;parameters&quot;:{
&quot;userName&quot;:{
&quot;type&quot;:&quot;String&quot;,
&quot;description&quot;:&quot;(Required) The username to delete.&quot;,
&quot;allowedPattern&quot;:&quot;gk-.*&quot;,
&quot;maxChars&quot;:64
},
&quot;executionTimeout&quot;:{
&quot;type&quot;:&quot;String&quot;,
&quot;default&quot;:&quot;300&quot;,
&quot;description&quot;:&quot;(Optional) The time in seconds for a command to be completed before it is considered to have failed. Default is 3600 (1 hour). Maximum is 28800 (8 hours).&quot;,
&quot;allowedPattern&quot;:&quot;([1-9][0-9]{0,3})|(1[0-9]{1,4})|(2[0-7][0-9]{1,3})|(28[0-7][0-9]{1,2})|(28800)&quot;
}
},
&quot;runtimeConfig&quot;:{
&quot;aws:runShellScript&quot;:{
&quot;properties&quot;:[
{
&quot;id&quot;:&quot;0.aws:runShellScript&quot;,
&quot;runCommand&quot;:[ &quot;cut -f1 -d':' /etc/passwd | grep {{ userName }} &gt; /dev/null &amp;&amp; (userdel -rf {{ userName }} ; echo 'user deleted' ) || echo 'no user to delete'&quot;,
&quot;ls /etc/sudoers.d/ | grep {{ userName }} &gt; /dev/null &amp;&amp; (rm -f /etc/sudoers.d/{{ userName }} ; echo 'sudo file deleted' ) || echo 'no sudo file to delete'&quot;    ],
&quot;workingDirectory&quot;:&quot;/root&quot;,
&quot;timeoutSeconds&quot;:&quot;{{ executionTimeout }}&quot;
}
]
}
}
}</code></pre> 
<p>The arguments for this script are:</p> 
<ol> 
<li><strong>userName</strong>&nbsp;– the username that the script will delete</li> 
<li><strong>executionTimeout</strong>&nbsp;– how much time to wait for the script to successfully complete</li> 
</ol> 
<p>The script itself uses the <strong>userName</strong>&nbsp;parameter to delete the user from the instance(s). Should the script for some reason fail to run, it will re-try a set amount of times, and if there was no successful run, then the system will notify the Ops team to investigate and remove the user.</p> 
<h3>Conclusion</h3> 
<p>By leveraging Amazon EC2 Systems Manager and other services such as Amazon EC2 and AWS Identity and Access Management (IAM), FINRA was able to build a solution to manage temporary access to our resources running in AWS across multiple environments. Systems Manager is very easy to adopt, and it is extremely reliable and fast. It is a great tool for performing ad-hoc execution of scripts on running instances.</p> 
<p><em>The content and opinions in this blog are those of the third-party author and AWS is not responsible for the content or accuracy of this post.</em></p> 
<p>&nbsp;</p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/mt/tag/aws-systems-manager/" rel="tag">AWS Systems Manager</a>, <a href="https://aws.amazon.com/blogs/mt/tag/run-command/" rel="tag">Run Command</a>, <a href="https://aws.amazon.com/blogs/mt/tag/ssm/" rel="tag">SSM</a></span> 
</footer> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">How to Export EC2 Instance Execution Logs to an S3 Bucket Using CloudWatch Logs, Lambda, and CloudFormation</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Veronika Megler</span></span> | on 
<time property="datePublished" datetime="2017-11-13T11:12:07+00:00">13 NOV 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/amazon-cloudwatch/" title="View all posts in Amazon CloudWatch*"><span property="articleSection">Amazon CloudWatch*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/aws-cloudformation/" title="View all posts in AWS CloudFormation*"><span property="articleSection">AWS CloudFormation*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools*"><span property="articleSection">Management Tools*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/how-to-export-ec2-instance-execution-logs-to-an-s3-bucket-using-cloudwatch-logs-lambda-and-cloudformation/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p>“We want to get execution logs from our EC2 instances into S3,” my customer said. “Then we can store them and process them later, for optimization, audit, and security review, and so on. We’d like to do it in our CloudFormation stacks, as that’s our execution standard. Can you help us?”</p> 
<p>This blog post shows you how to build a solution for this problem. We’ll build it using Amazon CloudWatch Logs, AWS Lambda, and some useful capabilities in AWS CloudFormation for customizing EC2 instances.</p> 
<p><span id="more-1466"></span></p> 
<b>How it works</b> 
<p>To export the logs, we add some components to the CloudFormation stack that builds the EC2 instance. The following diagram and code samples show how this solution works in a stand-alone fashion. Later, we’ll discuss other ways to integrate these components into your production infrastructure.</p> 
<p><img src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/13/cwexport-arch.png" alt="Architecture diagram" /></p> 
<p>We use a CloudFormation stack (1) to create the components shown. When everything is up and running, we have an EC2 instance running a CloudWatch Logs agent (2). The agent routes the configured logs to a CloudWatch Logs log group (3). A Lambda function (4) that’s subscribed to the log group picks up each log and writes it to an existing Amazon S3 bucket (5). Note that there’s some delay from the time a log message is created on the EC2 instance to the time it appears in the S3 bucket.</p> 
<p>To configure the EC2 instance, we use a neat feature in CloudFormation, the <a title="undefined" href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/cfn-helper-scripts-reference.html" target="_blank" rel="noopener noreferrer">CloudFormation helper functions</a>. These helper functions can be combined to install and update a variety of software packages, configure them, start services, and more. We’ll show you how in this blog.</p> 
<p>If you’d like to skip ahead and see the code in action, go to “Running the Solution.”</p> 
<b>The implementation</b> 
<p>The implementation consists of the following four files, which we’ll discuss later:</p> 
<p>1.&nbsp;<code>Cwexport-master-template.yaml</code>: This template creates a security group and IAM role for our EC2 instance, and calls two embedded CloudFormation templates to do the real work.</p> 
<p>2.&nbsp;<code>Cloudwatchlogsexport.yaml</code>: This template creates the CloudWatch log group the logs will be sent to, and defines the Lambda function that will perform the export from the log group to S3. It then creates a CloudWatch Log subscription to automatically send the CloudWatch log streams to the Lambda function.</p> 
<p>3.&nbsp;<code>Cloudwatch-log-lambda.zip</code>: This zip file contains the code for the Lambda function, packaged along with its prerequisites.</p> 
<p>4.&nbsp;<code>Run-ec2-instance.yaml</code>: This template creates the EC2 instance, installs the <a title="undefined" href="http://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/AgentReference.html" target="_blank" rel="noopener noreferrer">CloudWatch Log Agent</a>, &nbsp;configures it to export the desired logs, and performs a specified task on startup (in this case, calculating digits of Pi).</p> 
<p>In practice we first set up the CloudWatch log group and export to Amazon S3, and then set up and configure the EC2 instance.</p> 
<b>Exporting logs from CloudWatch Logs to S3</b> 
<p>In Cloudwatchlogsexport.yaml, we first set up the CloudWatch Logs log group itself (<a title="undefined" href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-logs-loggroup.html" target="_blank" rel="noopener noreferrer"><code>&quot;AWS::Logs::LogGroup&quot;</code></a>).</p> 
<p>Next, we define the Lambda function that will perform the actual export. We’ve packaged our Python code into a Lambda deployment package for uploading and deployment by CloudFormation. The function (cloudwatch-log-lambda.py) requires two environment variables, s3BucketName and s3KeyPrefix, to tell it where the log files should be exported to. We specify these variables as inputs to the master CloudFormation script, which passes them to the Lambda function at execution time.</p> 
<p>The Lambda function receives logs from CloudWatch. For each invocation it unzips the received log file, converts it from JSON into a dictionary, then writes it out to S3 with our naming convention (&lt;s3KeyPrefix&gt;/&lt;logGroup&gt;/&lt;logStream&gt;/&lt;timestamp&gt;). You can see the source code of the Lambda <a title="Lambda code" href="https://management-tools-blog-cf-template-storage.s3.amazonaws.com/cloudwatchlogsexport2s3/cloudwatch-exportlogs2s3-lambda.py" target="_blank" rel="noopener noreferrer">here</a>.</p> 
<p>Then, we associate the Lambda function and the CloudWatch log group via an <a title="undefined" href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-logs-subscriptionfilter.html" target="_blank" rel="noopener noreferrer"><code>“AWS::Logs::SubscriptionFilter”</code></a> tag, specifying the Lambda function and the log group it’s subscribing to. This subscription will trigger the Lambda function when new logs are written to the CloudWatch log group, and pass the new log to it.</p> 
<b>Customizing your EC2 instance</b> 
<p>The last CloudFormation template, Run-ec2-instance.yaml, starts our EC2 instance. We use CloudFormation tags to customize the properties of the EC2 instance: specifying the EC2 instance type, AMI, the IAM role, VPC, and so on.</p> 
<p>In our case, we also want to automatically install some software packages (notably, the CloudWatch Logs agent); configure some files; and then start some services – all before the actual processing specified in our UserData section is triggered. We can do so by using some capabilities that CloudFormation provides.</p> 
<p>First, we use an <a title="undefined" href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-init.html" target="_blank" rel="noopener noreferrer"><code>AWS::CloudFormation::Init</code></a> tag in the metadata section of our EC2 definition to define customizations. Then we call a <a title="undefined" href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/cfn-helper-scripts-reference.html" target="_blank" rel="noopener noreferrer">set of provided CloudFormation helper scripts</a> from our EC2 instances’s UserData to implement the definitions before we move on to doing the work we’ve set up the EC2 instance to do. We describe the tag and definitions next.</p> 
<b>The AWS::CloudFormation::Init tag</b> 
<p>We use the <code>AWS::CloudFormation::Init</code> type to include metadata for our Amazon EC2 instance. The metadata can later be accessed by the helper scripts. When we execute the helper scripts from our EC2 instance’s UserData, the script looks for resource metadata specified in the AWS::CloudFormation::Init metadata key and uses that information to customize the instance. Here’s the beginning of our definition:</p> 
<pre><code class="lang-yaml">&nbsp; EC2Instance:
&nbsp;&nbsp;&nbsp; Type: 'AWS::EC2::Instance'
&nbsp;&nbsp;&nbsp; Metadata:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 'AWS::CloudFormation::Init':
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; configSets:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; default:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [config]
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; config:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; …</code></pre> 
<p>The CloudFormation Init tag supports a wide variety of capabilities, which we encourage you to explore. For this EC2 instance we’ll use three: packages, files, and services.</p> 
<h4>Using CloudFormation::Init to install software</h4> 
<p>We can use the packages tag to download and install pre-packaged applications and components. For this blog post, we want to install one yum package: awslogs, the AWS CloudWatch Logs agent. Because the software is installed by the <a title="undefined" href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/cfn-init.html" target="_blank" rel="noopener noreferrer">cfn-init</a> helper script, we’re limited to the package formats it supports. Currently, on Linux the package formats are apt, msi, python, rpm, rubygems, and yum. We specify the package manager, then each package’s name, and a list of (possibly empty) versions. Because we aren’t sensitive to the version here, we’ll leave the version tag blank. In this case, cfn-init installs the latest version if the package isn’t already installed, or leaves it at the current version if the package is installed.</p> 
<pre><code class="lang-yaml">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; config:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; packages:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; yum:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; awslogs: []
...</code></pre> 
<h4>Configuring files</h4> 
<p>Next, we want to use CloudFormation to <a title="undefined" href="http://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/EC2NewInstanceCWL.html" target="_blank" rel="noopener noreferrer">create or modify the CloudWatch Log agent configuration files on the EC2 instance</a>. We can do this by using the “files” key of our <code>AWS::CloudFormation::Init</code>. There are several options for creating the files. Here, we include the desired content for the files directly in the CloudFormation template. We create two <a title="undefined" href="http://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/AgentReference.html" target="_blank" rel="noopener noreferrer">CloudWatch agent configuration files</a> and two CloudFormation helper configuration files:</p> 
<p><strong>/etc/awslogs/awscli.conf:</strong> This short example shows how an entire file is specified within this tag. The file will contain the default Region, and a plugin setting:</p> 
<pre><code class="lang-yaml">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; files:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; '/etc/awslogs/awscli.conf':
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; content: !Sub |
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [default]
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; region = ${AWS::Region}
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [plugins]
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; cwlogs = cwlogs
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; mode: '000644'
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; owner: root
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; group: root</code></pre> 
<p><strong>/etc/awslogs/awslogs.conf:</strong> We specify the local files we want to send to CloudWatch Logs, along with the log stream name to send them to, and other characteristics. The list being exported includes the CloudFormation execution logs. We encourage you to extend the list to include logs for your application or other logs of interest.</p> 
<p>We’ve configured each selected EC2 instance local log file to go to a log stream that consists of the stack name, followed by the EC2 instance ID, followed by the name of the file. This way, the files associated with one instance are grouped together and are easily findable in CloudWatch. This naming convention can easily be changed.</p> 
<p>The CloudWatch Logs agent lets us specify the size of the batches, the time stamp formats, the encoding, and more. By default, the logs are sent using enable gzip http content encoding to send compressed payloads to CloudWatch Logs. This decreases CPU usage, lowers Network Out, and decreases put latency. Our Lambda function unzips the files before writing them out.</p> 
<p><strong>/etc/cfn/cfn-hup.conf and /etc/cfn/hooks.d/cfn-auto-reloader.conf:</strong> These two configuration files are used to configure the <a title="undefined" href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/cfn-hup.html" target="_blank" rel="noopener noreferrer">cfn-hup daemon</a>. This daemon detects changes in the EC2 resource metadata and runs user-specified actions when a change is detected. This allows you to make configuration updates on your running Amazon EC2 instances through the UpdateStack API action.</p> 
<h4>Starting and restarting services</h4> 
<p>The third section in the metadata that we specify is the <a title="undefined" href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-init.html#aws-resource-init-services" target="_blank" rel="noopener noreferrer">services</a> key. This key defines which services should be enabled or disabled when the instance is launched. The services key also allows you to specify dependencies on sources, packages and files. If a restart is needed after files have been installed, cfn-init will take care of the service restart. In our example, we use this key to restart two services after we’ve created the config files for awslogs and cfn-hup.</p> 
<pre><code class="lang-yaml">          services:
sysvinit:
awslogs:
enabled: true
ensureRunning: true
packages:
yum:
- awslogs
files:
- '/etc/awslogs/awslogs.conf'
- '/etc/awslogs/awscli.conf'
cfn-hup:
enabled: true
ensureRunning: true
files:
- '/etc/cfn/cfn-hup.conf'
- '/etc/cfn/hooks.d/cfn-auto-reloader.conf'</code></pre> 
<h4>Finally: Executing the definitions</h4> 
<p>Having specified the files to install, config files to set up, and services to be started, we need to ensure that the <a title="undefined" href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/cfn-init.html" target="null">cfn-init</a> helper function is run to implement these specifications. In the EC2 instance’s UserData section, we first update the helper scripts and ensure that other yum packages are up-to-date. Then, we execute cfn-init, telling it which resource and CloudFormation stack to use as parameters.</p> 
<p>Lastly, we call the <a title="undefined" href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/cfn-signal.html" target="null">cfn-signal</a> helper function to let CloudFormation know that our EC2 instance is up and ready. We pass it the name of the stack, the Region, and the resource we’re sending a signal for. This signal causes CloudFormation to switch the EC2 instance to “Complete”.</p> 
<pre><code class="lang-yaml">&nbsp; UserData:
&nbsp;&nbsp;&nbsp; 'Fn::Base64': !Sub |
&nbsp;&nbsp;&nbsp; #!/bin/bash -x
&nbsp;&nbsp;&nbsp; # Use the line below to ensure the CloudFormation helper scripts are updated to the latest version
&nbsp;&nbsp;&nbsp; # Per: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/cfn-helper-scripts-reference.html
&nbsp;&nbsp;&nbsp; yum install -y aws-cfn-bootstrap
&nbsp;&nbsp;&nbsp; yum update -y&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp; /opt/aws/bin/cfn-init -v --stack ${AWS::StackName} --resource EC2Instance --configsets default --region ${AWS::Region}
&nbsp;&nbsp;&nbsp; /opt/aws/bin/cfn-signal -e $? --stack ${AWS::StackName} --region ${AWS::Region} --resource=EC2Instance</code></pre> 
<p>Now, we’re ready to actually perform the work of this EC2 instance. In our example, it’s a dummy job that calculates digits of Pi. We’re actually more interested in the log files created.</p> 
<h3>Running the solution</h3> 
<p>To see this solution in operation in us-west-2, choose the “Launch Stack” button&nbsp;below.</p> 
<p>&nbsp;</p> 
<p>Choose “Next”, then update the parameters shown below for your environment: TheLogsBucketName, VPCId, VPC Subnet and s3BucketForResults (leave the Template Locations as is).</p> 
<p><img class="alignnone size-medium" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/30/Cloudwatchloggroup-stackparms.png" width="763" height="559" /></p> 
<p>Click “Next” twice, acknowledge that AWS CloudFormation might create IAM resources with custom names, and click “Create”. Then wait for the CloudFormation master stack and its two nested stacks to reach a status of “CREATE_COMPLETE”.</p> 
<p>After our EC2 instance is up and running, the files we specified in our CloudWatch Logs agent configuration are exported to CloudWatch. Here’s an example of our log group, as seen in the CloudWatch Logs console:</p> 
<p><img src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/06/Cloudwatch-loggroup-capprechng.png" alt="" /></p> 
<p>The Lambda function receives each log from CloudWatch and unzips it. It then writes the event file out to Amazon S3, giving it an S3 key that consists of the given S3 key prefix, followed by the log group, the log stream name (i.e., the filename), and a timestamp.</p> 
<p><img src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/13/cwexport-s3-output.png" alt="" /></p> 
<p>If the logs don’t appear in Amazon S3 as expected, check the Lambda function’s CloudWatch Logs log group for execution errors. The CloudWatch logs for the Lambda function can be found in a log group named: <code>/aws/lambda/&lt;mainstackname&gt;-CWExportStack-CWEc2LogsLambdaFunction-&lt;id&gt;</code>.</p> 
<h4>The power of change sets</h4> 
<p>Earlier, we configured a cfn-hup daemon. The cfn-hup helper is a daemon that detects changes in resource metadata and runs user-specified actions when a change is detected. This allows you to make configuration updates on your running Amazon EC2 instances through the UpdateStack API action.</p> 
<p>Let’s demonstrate the power of the cfn-hup configuration that’s in our CloudFormation stack. In our files definition, we provided the following configuration:</p> 
<pre><code class="lang-yaml">'/etc/cfn/hooks.d/cfn-auto-reloader.conf':  
content: !Sub |
[cfn-auto-reloader-hook]
triggers=post.update
path=Resources.EC2Instance.Metadata.AWS::CloudFormation::Init
action=/opt/aws/bin/cfn-init --verbose --stack=${AWS::StackName} --region=${AWS::Region} --resource=EC2Instance
runas=root 
</code></pre> 
<p>This configuration tells cfn-hup to re-run cfn-init after the stack has been updated.</p> 
<p>In our case, we’ll make two changes to our EC2 instance. First, we’ll add an additional software package to install: jq. Imagine that there’s a part of our software stack that’s only invoked rarely, and we’re either missing a package or wish to upgrade a version in our running system. Secondly, we’ll add an additional log file export, cloud to our CloudWatch Logs configuration.</p> 
<p>These changes have been made for you, in another CloudFormation template: &nbsp;run-ec2-instance-changed.yaml. To execute this change through the console, do the following steps.</p> 
<ol> 
<li>In the CloudFormation console, select your nested “EC2InstanceStack”.</li> 
<li>Choose Actions&nbsp;&nbsp;-&gt; Update Stack.</li> 
<li>You’ll receive a warning that “Performing operations directly on a nested stack may result in an unstable state where it is out-of-sync with the root stack to which it belongs.” But we’ll be very careful here, so select the option “Yes, Update.”</li> 
<li>Next, select the revised template. Enter the following URL: <code>https://management-tools-blog-cf-template-storage.s3.amazonaws.com/cloudwatchlogsexport2s3/run-ec2-instance-changed.yaml</code>, and choose Next.</li> 
<li>Click through the next two pages that show the existing template parameters. &nbsp;We won’t be modifying any of them.</li> 
<li>On the next page, CloudFormation shows the results of analyzing the differences between the new CloudFormation template and the currently running one. The following screenshot shows the differences. We are modifying the EC2 instance only. The changes we’ve made result in “Replacement: False”, telling us that the existing EC2 instance will be modified. Other results there are “True,” which causes the resource to be replaced; or, “Conditional,” which means the resource property will be dynamically evaluated at execution time to determine if it requires replacement or not.</li> 
</ol> 
<p><img class="alignnone size-medium" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/30/cwmod-1.png" width="1036" height="178" /><br /> 7. Choose “Update”.</p> 
<p>Then, in the CloudFormation console, you can see the update actions as they occur, and their results, as in the screenshot below.</p> 
<p><img class="alignnone size-medium" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/30/Cwconsoleduringupdate-1.png" width="1151" height="449" /></p> 
<p>After waiting a little while for the changes and logs to propagate, you can check the CloudWatch log group. You’ll see a new log stream there, for the cloud-init.log definition we added.</p> 
<p><img class="alignnone size-medium" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/06/Cloudwatch-loggroup-cappostchng.png" width="961" height="400" /></p> 
<p>In our CloudWatch log group (or in S3), you can review cfn-hup.log and see the moment it’s notified of the CloudFormation template change, and starts the cfn-auto-reloader-hook action.</p> 
<p><img class="alignnone size-medium" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/06/cfn-hup-log.png" width="894" height="195" /></p> 
<p>Then, in cfn-init.log, you can see the installation of the jq software package, and the rewriting of the other files specified in our CloudFormation template.</p> 
<p><img class="alignnone size-medium" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/30/cfn-init-log-1.png" width="943" height="368" /></p> 
<p>Now we’ve successfully updated our running EC2 instance, with additional software and changed configurations. All through our CloudFormation stack. And, we know that the CloudFormation template we now have reflects our running environment. Sweet!</p> 
<p>Remember to delete the CloudFormation stack when you’re done, to stop incurring fees. If you delete the stack right way, testing the solution will cost only a few cents.</p> 
<h4>Adapting for production use</h4> 
<p>To implement, copy the files from s3://management-tools-blog-cf-template-storage.s3.amazonaws.com/cwexportlogs2s3/, and modify as needed for your environment.</p> 
<p>This implementation demonstrates useful capabilities. However, you should consider modifying some details for production use.</p> 
<p>In <code>cloudwatchlogsexport.yaml</code>, we’ve created a new log group. Since for demo purposes we’ll be deleting the log group when the CloudFormation stack is removed, we’ve added a commented out line <code>“#DeletionPolicy: Retain”</code> at the end of the definition. Because we’re writing the logs to S3, we don’t need to retain the log group. However, you may also choose to retain the group for some time after the run before expiring it, for additional validation. Also, because there is a delay in writing out the logs created, if you aggressively delete &nbsp;the CloudFormation stack as soon as the EC2 instance is terminated you might remove the Lambda function before the last logs have made it to the S3 bucket. We recommend that you wait a few minutes before deleting the CloudFormation stack.</p> 
<p>You can also choose to use one log group for many CloudFormation stacks and EC2 instance executions. Using that approach, you would create the CloudWatch Log group and Lambda function once (run <code>Cloudwatchlogsexport.yaml</code> alone), and leave them in place for the long term. As each EC2 instance gets created (<code>run-ec2-instance.yaml</code>), pass it the name of the log group to use. Since we are using the instance ID in the log stream ID, the different executions will still be clearly identified in CloudWatch and in Amazon S3.</p> 
<h3>Conclusion</h3> 
<p>By integrating the CloudWatch Logs agent into our CloudFormation stack, your EC2 instance logs can easily be exported to an S3 bucket. After the logs are in S3, you have a myriad of additional options. You can make the EC2 instance logs part of your data lake. You can process them using some analytics tools, such as <a title="undefined" href="https://quicksight.aws/" target="_blank" rel="noopener noreferrer">Amazon QuickSight</a>. You can set up S3 lifecycle rules to automatically archive them for audit purposes, using <a title="undefined" href="https://aws.amazon.com/glacier/" target="_blank" rel="noopener noreferrer">Amazon Glacier</a>. Because all the components are automated using a CloudFormation stack, you can ensure that the logs are being exported and stored consistently. For example, you can integrate this solution into <a title="undefined" href="https://aws.amazon.com/blogs/compute/how-to-provision-complex-on-demand-infrastructures-by-using-amazon-api-gateway-and-aws-lambda/" target="null">requests to provision infrastructure</a>, to ensure that audit trails for all such requests are created in a consistent fashion.</p> 
<p>The same CloudFormation components can be used to install, configure, and customize many other combinations of software.You’re limited only by your imagination. We hope this blog inspires you to extend your use to other use cases beyond the ones we’ve described here.</p> 
<h4>About the Author</h4> 
<p><strong>Veronika Megler, PhD, is a Senior Consultant, Big Data, Analytics &amp; Data Science, for AWS Professional Services.</strong> She enjoys helping customers adopt new technologies to solve new problems and to solve old problems more efficiently and effectively. In her spare time she is passionate about conservation, travel to interesting, beautiful or historic places, expanding her knowledge of arcane subjects, and searching for ultimate expression in Argentine tango.</p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/mt/tag/amazon-cloudwatch/" rel="tag">Amazon CloudWatch</a>, <a href="https://aws.amazon.com/blogs/mt/tag/aws-cloudformation/" rel="tag">AWS CloudFormation</a>, <a href="https://aws.amazon.com/blogs/mt/tag/aws-lambda/" rel="tag">AWS Lambda</a></span> 
</footer> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">The Virtues of YAML CloudFormation and Using CloudFormation Designer to Convert JSON to YAML</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Aaron Fagan</span></span> | on 
<time property="datePublished" datetime="2017-11-10T09:19:38+00:00">10 NOV 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/aws-cloudformation/" title="View all posts in AWS CloudFormation*"><span property="articleSection">AWS CloudFormation*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools*"><span property="articleSection">Management Tools*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/the-virtues-of-yaml-cloudformation-and-using-cloudformation-designer-to-convert-json-to-yaml/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><a href="https://aws.amazon.com/cloudformation/">AWS CloudFormation</a> provides the framework to define infrastructure-as-code in AWS and, until last year, this could only be written in JSON. However, in 2016, AWS added <a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/template-formats.html">YAML 1.1</a> support for CloudFormation. Let’s take a look at some of the advantages of using YAML over JSON, as well as how to overcome some of the challenges in getting started writing CloudFormation in YAML.</p> 
<h3>The virtues of YAML</h3> 
<p>YAML CloudFormation fully supports all of the same features and functions as JSON CloudFormation with some additional features to reduce the length of code and increase readability. Say goodbye to the curly braces and most of the quotation marks of JSON when you use YAML.&nbsp;YAML uses parent nodes, child nodes, and indentation to denote hierarchy rather than curly braces and commas as in JSON.</p> 
<p>YAML also supports comments using the # character. CloudFormation templates can get complex. Including key comments in the code can make it easier to understand, especially as teams get started with CloudFormation and develop templates together.</p> 
<p>Let’s look at a code sample. The following YAML and JSON CloudFormation templates perform the same function, they deploy an Amazon Linux EC2 instance serving a webpage via Apache HTTP Server.<span id="more-1918"></span></p> 
<h3>JSON template</h3> 
<pre><code class="lang-json">{
&quot;AWSTemplateFormatVersion&quot;: &quot;2010-09-09&quot;,
&quot;Parameters&quot;: {
&quot;SubnetID&quot;: {
&quot;Type&quot;: &quot;AWS::EC2::Subnet::Id&quot;,
&quot;Description&quot;: &quot;Subnet to deploy EC2 instance into&quot;
},
&quot;SecurityGroupIDs&quot;: {
&quot;Type&quot;: &quot;List&lt;AWS::EC2::SecurityGroup::Id&gt;&quot;,
&quot;Description&quot;: &quot;List of Security Groups to add to EC2 instance&quot;
},
&quot;KeyName&quot;: {
&quot;Type&quot;: &quot;AWS::EC2::KeyPair::KeyName&quot;,
&quot;Description&quot;: &quot;Name of an existing EC2 KeyPair to enable SSH access to the instance&quot;
},
&quot;InstanceType&quot;: {
&quot;Description&quot;: &quot;EC2 instance type&quot;,
&quot;Type&quot;: &quot;String&quot;,
&quot;Default&quot;: &quot;t2.micro&quot;
}
},
&quot;Mappings&quot;: {
&quot;AWSRegionToAMI&quot;: {
&quot;us-east-1&quot;: {
&quot;AMIID&quot;: &quot;ami-0b33d91d&quot;
},
&quot;us-east-2&quot;: {
&quot;AMIID&quot;: &quot;ami-c55673a0&quot;
}
}
},
&quot;Resources&quot;: {
&quot;EC2Instance&quot;: {
&quot;Type&quot;: &quot;AWS::EC2::Instance&quot;,
&quot;Properties&quot;: {
&quot;ImageId&quot;: {
&quot;Fn::FindInMap&quot;: [
&quot;AWSRegionToAMI&quot;,
{
&quot;Ref&quot;: &quot;AWS::Region&quot;
},
&quot;AMIID&quot;
]
},
&quot;InstanceType&quot;: {
&quot;Ref&quot;: &quot;InstanceType&quot;
},
&quot;KeyName&quot;: {
&quot;Ref&quot;: &quot;KeyName&quot;
},
&quot;SecurityGroupIds&quot;: {
&quot;Ref&quot;: &quot;SecurityGroupIDs&quot;
},
&quot;SubnetId&quot;: {
&quot;Ref&quot;: &quot;SubnetID&quot;
},
&quot;UserData&quot;: {
&quot;Fn::Base64&quot;: {
&quot;Fn::Sub&quot;: &quot;#!/bin/bash -ex\nyum install -y httpd;\necho \&quot;&lt;html&gt;I love YAML CloudFormation!!&lt;/html&gt;\&quot; &gt; /var/www/html/index.html;\ncd /var/www/html;\nchmod 755 index.html;\nservice httpd start;\nchkconfig httpd on;\n&quot;
}
},
&quot;Tags&quot;: [
{
&quot;Key&quot;: &quot;Name&quot;,
&quot;Value&quot;: &quot;CloudFormation Test - YAML&quot;
},
{
&quot;Key&quot;: &quot;Environment&quot;,
&quot;Value&quot;: &quot;Development&quot;
}
]
}
}
}
}
</code></pre> 
<img style="border: 0px;width: 32px;height: 32px;margin-right: 5px !important" src="https://aws-support-gm.s3.amazonaws.com/prod/tiny-url-shrinker/TinyURLShortener-icon-64x64.png" /> 
<h3 title="Shrink this URL">YAML template</h3> 
<pre><code class="lang-yaml">AWSTemplateFormatVersion: 2010-09-09
Parameters:
SubnetID:
Type: AWS::EC2::Subnet::Id
Description: Subnet to deploy EC2 instance into
SecurityGroupIDs:
Type: List&lt;AWS::EC2::SecurityGroup::Id&gt;
Description: List of Security Groups to add to EC2 instance
KeyName:
Type: AWS::EC2::KeyPair::KeyName
Description: &gt;-
Name of an existing EC2 KeyPair to enable SSH access to the instance
InstanceType:
Description: EC2 instance type
Type: String
Default: t2.micro
Mappings:
AWSRegionToAMI:
us-east-1:
AMIID: ami-0b33d91d
us-east-2:
AMIID: ami-c55673a0
Resources:
EC2Instance:
Type: AWS::EC2::Instance                     
Properties:
ImageId:
!FindInMap                                 # This is an example of the short form YAML FindInMap function
- AWSRegionToAMI                         # It accepts three parameters each denoted by a hyphen (-)
- !Ref AWS::Region
- AMIID
InstanceType: !Ref InstanceType
KeyName: !Ref KeyName
SecurityGroupIds: !Ref SecurityGroupIDs
SubnetId: !Ref SubnetID
UserData:
Fn::Base64:                                # YAML makes userdata much cleaner
!Sub |
#!/bin/bash -ex
yum install -y httpd;
echo &quot;&lt;html&gt;I love YAML CloudFormation!!&lt;/html&gt;&quot; &gt; /var/www/html/index.html;
cd /var/www/html;
chmod 755 index.html;
service httpd start;
chkconfig httpd on;
Tags:                                      # Tags are an example of a sequence of mappings in YAML,
-                                        # each key/value pair is separated by a hyphen
Key: Name
Value: CloudFormation Test - YAML      
-
Key: Environment
Value: Development
</code></pre> 
<p>From a readability perspective, it’s pretty clear YAML is the winner. The JSON template is 1200 characters with whitespace removed. The YAML template is 972 characters for the exact same functionality with whitespace and comments removed. Shorter templates are not only more readable and make troubleshooting errors easier, but they also allow more resources to be deployed in a single template without hitting <a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/cloudformation-limits.html">CloudFormation limits</a> for template body size.</p> 
<h3>Converting a JSON CloudFormation template to YAML</h3> 
<p>We’ve established there are some advantages to using YAML, but many organizations already have libraries of JSON-formatted CloudFormation templates and employees with expertise writing JSON. Additionally, many publically available code samples are written in JSON along with many <a href="https://aws.amazon.com/quickstart/">AWS QuickStarts</a>. If only there were an easy, secure way to convert JSON CloudFormation to YAML. Old JSON templates could be reused and public samples could be converted to make learning YAML easier.</p> 
<p>Enter <a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/working-with-templates-cfn-designer.html">CloudFormation Designer</a></p> 
<p>CloudFormation Designer is an easy-to-use graphical user interface to create, edit, and view CloudFormation templates. The Designer is free and is part of the AWS Management Console. One fantastic feature is the ability to convert CloudFormation templates from JSON to YAML, and back again, with the click of a button. There are other online converters out there but the Designer is part of your AWS Management Console, so the code never leaves your possession.</p> 
<p>&nbsp;</p> 
<p>Let’s convert our JSON template to YAML:</p> 
<p>1. Open the AWS Management Console and navigate to the <strong>CloudFormation service</strong>.</p> 
<p>2. Choose the <strong>Design template</strong> button to open the Designer.</p> 
<p><img class="aligncenter wp-image-1919 size-full" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/02/step2.png" alt="" width="975" height="215" /></p> 
<p>&nbsp;</p> 
<p>3. Open the JSON CloudFormation template by choosing the File icon, then choosing <strong>Open</strong> from the menu.</p> 
<p><img class="aligncenter wp-image-1920 size-full" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/02/step3.png" alt="" width="721" height="342" /></p> 
<p>&nbsp;</p> 
<p>4. <strong>Select the file</strong>, either a local file on your workstation or a file in an Amazon S3 bucket. This opens the CloudFormation template in Designer. We see the familiar JSON code of our template in the bottom pane. In the upper-right pane, we see a graphical representation of the EC2 instance described in our template. Finally, in the upper-left pane, we can optionally drag and drop a variety of Resource Types onto the canvas to include them in our template.</p> 
<p><img class="aligncenter wp-image-1921 size-full" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/02/step4.png" alt="" width="1112" height="672" /></p> 
<p>&nbsp;</p> 
<p>5. In the upper right-hand corner of the code pane, note the <strong>Choose template language</strong> radio button. Choose the button next to YAML to convert the template to YAML. Just like that our JSON is perfectly formatted YAML. Choosing the JSON button will convert the template back to JSON.</p> 
<p>Caution: <em>Converting a commented YAML template to JSON will remove all comments. Comments will not re-appear if the template is toggled back to YAML</em>.</p> 
<p><img class="aligncenter wp-image-1925 size-full" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/02/step51.png" alt="" width="1919" height="438" /></p> 
<p>&nbsp;</p> 
<p>6. <strong>Save</strong> the template in YAML format by once again choosing the File icon and choosing Save from the menu.</p> 
<p style="text-align: center"><img class="alignnone size-full wp-image-1972" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/03/step61-1.png" alt="" width="403" height="257" /></p> 
<h3>Conclusion</h3> 
<p>In this blog post, we discussed some reasons to convert CloudFormation templates from JSON to YAML format and to code in YAML. We also did a side-by-side comparison of the readability of JSON and YAML using a sample template. Finally, we walked through how to convert existing JSON CloudFormation templates to YAML using CloudFormation Designer. There’s no better time than the present to dive in and get started with CloudFormation YAML. Happy coding!</p> 
<hr /> 
<h3>About the Author</h3> 
<p style="text-align: left"><img class="size-medium wp-image-1930 alignleft" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/02/badgephotobw-200x300.jpg" alt="" width="200" height="300" />Aaron Fagan is a Senior Cloud Infrastructure Architect on the Boston AWS Professional Services team where he works with Enterprises to accelerate and optimize their adoption of the AWS public cloud. When not coding CloudFormation in YAML, he enjoys weightlifting and cooking.</p> 
<img style="border: 0px;width: 32px;height: 32px;margin-right: 5px !important" src="https://aws-support-gm.s3.amazonaws.com/prod/tiny-url-shrinker/TinyURLShortener-icon-64x64.png" /> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/mt/tag/aws-cloudformation/" rel="tag">AWS CloudFormation</a>, <a href="https://aws.amazon.com/blogs/mt/tag/aws-cloudformation-designer/" rel="tag">AWS CloudFormation Designer</a>, <a href="https://aws.amazon.com/blogs/mt/tag/yaml/" rel="tag">YAML</a></span> 
</footer> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">Controlling Projected User Costs Through Monthly Budget Policies</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Adam Westrich</span></span> | on 
<time property="datePublished" datetime="2017-11-06T16:10:43+00:00">06 NOV 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/mt/category/aws-cost-management/" title="View all posts in AWS Cost Management*"><span property="articleSection">AWS Cost Management*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/compute/aws-lambda/" title="View all posts in AWS Lambda*"><span property="articleSection">AWS Lambda*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools*"><span property="articleSection">Management Tools*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/controlling-projected-user-costs-through-monthly-budget-policies/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<h3 style="text-align: left">Introduction</h3> 
<p>With the announcement of our new AWS Price List Query APIs, let’s discuss a use-case that you can deploy directly to your AWS account. Customers often ask for ways to proactively control costs while having the flexibility to experiment with different AWS resource sizes and types. The solution we’ll discuss in this blog post gives you the ability to project monthly <a href="https://aws.amazon.com/ec2/">Amazon EC2</a> costs for individual Identity and Access Management (IAM) users and receive alerts when user projected costs exceed their configured thresholds. You can deploy this solution to your AWS account using <a href="https://aws.amazon.com/cloudformation/">AWS CloudFormation</a>&nbsp;below.</p> 
<p>When a user launches or starts EC2 instances, the solution calculates the projected monthly cost using the Price List Query API, and aggregates those costs for each AWS user. Likewise, when a user stops or terminates instances, the user’s projected cost is reduced. The solution also allows user budget targets to be set, which gives Operational Management the ability to intervene when projected thresholds are exceeded before the actual monthly costs are accrued.</p> 
<p><span id="more-1745"></span></p> 
<h3>Architecture</h3> 
<p><img class="alignnone wp-image-1759 size-full" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/blog_westrich_1-1.png" alt="" width="1109" height="532" /></p> 
<h3>Walkthrough</h3> 
<ol> 
<li>When a user launches an EC2 instance, user and launch details are logged in <a href="https://aws.amazon.com/cloudtrail/">AWS CloudTrail</a>, which triggers an <a href="http://docs.aws.amazon.com/AmazonCloudWatch/latest/events/LogEC2InstanceState.html">Amazon CloudWatch event</a>.</li> 
<li>The CloudWatch event triggers a <a href="https://aws.amazon.com/lambda/">Lambda function</a>, which performs three&nbsp;tasks: 
<li>Calls the AWS Price List Query API to retrieve the price of EC2 instance on which action was taken.</li> 
<li>Based on event type (Launch/Start or Stop/Terminate), edits the <a href="https://aws.amazon.com/dynamodb/">DynamoDB</a> table with new price based upon the continued projection for the month.</li> 
<li>Sends a trigger to another Lambda function which will check for a policy breach.</li> 
</ul> </li> 
<li>The policy breach Lambda function checks if the user in the DynamoDB table has breached the budgeted&nbsp;threshold 
<li style="text-align: left">If the budget threshold is breached, the Lambda function generates an Amazon SNS notification to email alert the IT operations team.</li> 
</ul> </li> 
</ol> 
<p>Here is an example of the notification email sent to stakeholders:</p> 
<p><img class="wp-image-1779 size-full aligncenter" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/blog_westrich_2.png" alt="" width="650" height="236" /></p> 
<p>The AWS Price List API makes this process easy to obtain accurate EC2 price information.</p> 
<p>The following CloudFormation templates below can be deployed in your environment with CloudTrail enabled by simply filling in a few parameters:</p> 
<table align="center"> 
<tbody> 
<tr> 
<td><strong>Region</strong></td> 
<td style="text-align: center"><strong>Launch Template</strong></td> 
</tr> 
<tr> 
<td><strong>N. Virginia&nbsp;</strong>(us-east-1)</td> 
<td><a href="https://console.aws.amazon.com/cloudformation/home?region=us-east-1#/stacks/new?stackName=UserCostControl&amp;templateURL=https://s3.us-east-1.amazonaws.com/cost-control-us-east-1/cost_control_v1.yaml"><strong><img class="wp-image-1770 size-full aligncenter" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/blog_westrich_5.png" alt="" width="107" height="20" /></strong></a></td> 
</tr> 
<tr> 
<td><strong>Ohio&nbsp;</strong>(us-east-2)</td> 
<td><a href="https://console.aws.amazon.com/cloudformation/home?region=us-east-2#/stacks/new?stackName=UserCostControl&amp;templateURL=https://s3.us-east-2.amazonaws.com/cost-control-us-east-2/cost_control_v1.yaml"><img class="wp-image-1770 size-full aligncenter" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/blog_westrich_5.png" alt="" width="107" height="20" /></a></td> 
</tr> 
<tr> 
<td><strong>Oregon&nbsp;</strong>(us-west-2)</td> 
<td><a href="https://console.aws.amazon.com/cloudformation/home?region=us-west-2#/stacks/new?stackName=UserCostControl&amp;templateURL=https://s3.us-west-2.amazonaws.com/cost-control-us-west-2/cost_control_v1.yaml"><img class="wp-image-1770 size-full aligncenter" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/blog_westrich_5.png" alt="" width="107" height="20" /></a></td> 
</tr> 
<tr> 
<td><strong>Asia Pacific – Mumbai</strong> (ap-south-1)</td> 
<td><a href="https://console.aws.amazon.com/cloudformation/home?region=ap-south-1#/stacks/new?stackName=UserCostControl&amp;templateURL=https://s3.ap-south-1.amazonaws.com/cost-control-ap-south-1/cost_control_v1.yaml"><img class="size-full wp-image-1770 aligncenter" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/blog_westrich_5.png" alt="" width="107" height="20" /></a></td> 
</tr> 
<tr> 
<td><strong>Asia Pacific – Sydney</strong> (ap-southeast-2)</td> 
<td><a href="https://console.aws.amazon.com/cloudformation/home?region=ap-southeast-2#/stacks/new?stackName=UserCostControl&amp;templateURL=https://s3.ap-southeast-2.amazonaws.com/cost-control-ap-southeast-2/cost_control_v1.yaml"><img class="size-full wp-image-1770 aligncenter" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/blog_westrich_5.png" alt="" width="107" height="20" /></a></td> 
</tr> 
<tr> 
<td><strong>Asia Pacific – Tokyo</strong> (ap-northeast-1)</td> 
<td><a href="https://console.aws.amazon.com/cloudformation/home?region=ap-northeast-1#/stacks/new?stackName=UserCostControl&amp;templateURL=https://s3.ap-northeast-1.amazonaws.com/cost-control-ap-northeast-1/cost_control_v1.yaml"><img class="size-full wp-image-1770 aligncenter" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/blog_westrich_5.png" alt="" width="107" height="20" /></a></td> 
</tr> 
<tr> 
<td><strong>EU – Ireland</strong> (eu-west-1)</td> 
<td><a href="https://console.aws.amazon.com/cloudformation/home?region=eu-west-1#/stacks/new?stackName=UserCostControl&amp;templateURL=https://s3.eu-west-1.amazonaws.com/cost-control-eu-west-1/cost_control_v1.yaml"><img class="size-full wp-image-1770 aligncenter" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/blog_westrich_5.png" alt="" width="107" height="20" /></a></td> 
</tr> 
<tr> 
<td><strong>EU – London </strong>(eu-west-2)</td> 
<td><a href="https://console.aws.amazon.com/cloudformation/home?region=eu-west-2#/stacks/new?stackName=UserCostControl&amp;templateURL=https://s3.eu-west-2.amazonaws.com/cost-control-eu-west-2/cost_control_v1.yaml"><img class="size-full wp-image-1770 aligncenter" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/blog_westrich_5.png" alt="" width="107" height="20" /></a></td> 
</tr> 
</tbody> 
</table> 
<h4>Notes:</h4> 
<li>This solution should be used as an addition to the AWS Billing and Cost Management tools. The solution calculations are based upon on-demand EC2 costs per second for non-Windows operating systems and per hour for Windows operating systems. They don’t include instances with pre-installed software or AWS Marketplace software licenses.</li> 
<li>The monthly cost of the AWS resources to deploy this cost-control solution&nbsp;is in most scenarios, &lt; $5.</li> 
<li>These projections are only estimates, and monthly charges will be based on your actual usage of AWS services, and may vary from the projections provided.</li> 
<h3>Conclusion</h3> 
<p>As organizations are given freedoms to experiment with computing resources in the AWS cloud, they often need governance controls for an effective solution. The AWS Management Tools and partner ecosystem enable you to deploy or even build the right governance solution for your organization’s needs.</p> 
<h3>About the Author:</h3> 
<table> 
<tbody> 
<tr> 
<td><img class="aligncenter wp-image-1750 size-full" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/blog_westrich_4.png" alt="" width="104" height="144" /></td> 
<td>Adam Westrich is a Solutions Architect based in Southern California. He is passionate about working with customers on their AWS Cloud journey, especially leveraging AWS managed services, including serverless technologies.</td> 
</tr> 
</tbody> 
</table> 
<p><em>Thank you to Shashi Prabhakar for his contributions to this post.</em></p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/mt/tag/budget/" rel="tag">Budget</a>, <a href="https://aws.amazon.com/blogs/mt/tag/cost-control/" rel="tag">Cost Control</a>, <a href="https://aws.amazon.com/blogs/mt/tag/governance/" rel="tag">Governance</a>, <a href="https://aws.amazon.com/blogs/mt/tag/price-list-api/" rel="tag">Price List API</a>, <a href="https://aws.amazon.com/blogs/mt/tag/user-budgeting/" rel="tag">User Budgeting</a></span> 
</footer> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">Run Scripts Stored in Private or Public GitHub Repositories Using Amazon EC2 Systems Manager</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Ananth Vaidyanathan</span></span> | on 
<time property="datePublished" datetime="2017-11-06T09:28:29+00:00">06 NOV 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/amazon-ec2-systems-manager/" title="View all posts in Amazon EC2 Systems Manager*"><span property="articleSection">Amazon EC2 Systems Manager*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools*"><span property="articleSection">Management Tools*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/run-scripts-stored-in-private-or-public-github-repositories-using-amazon-ec2-systems-manager/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><em>By Melonia Mendonca, Software Development Engineer at Amazon Web Services</em></p> 
<p><a href="https://aws.amazon.com/ec2/systems-manager/">Amazon EC2 Systems Manager</a> (SSM) lets you configure, manage and automate your AWS and on-premises resources at scale. You can perform safe and secure operations without SSH access or bastion hosts using Systems Manager Run Command, mitigate configuration drift using Systems Manager State Manager, and create an access-controlled environment with full auditing. With SSM Documents, you can author your configurations as code and enable centralized management across accounts, enforcing best practices. Systems Manger provides a number of public documents for common management scenarios, or you can create your own.</p> 
<p>We recently <a href="https://aws.amazon.com/about-aws/whats-new/2017/10/amazon-ec2-systems-manager-now-integrates-with-github/">announced</a> the ability to run scripts from remote locations such as GitHub or Amazon S3. This simplifies how you automate environments by letting you use existing scripts or toolsets without having to port them over to Systems Manager or create Documents as wrapper around those scripts or tools. For information, please read our partner and product integration documentation <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/systems-manager-integration.html">here</a>. &nbsp;For example, you can:</p> 
<li><span style="text-decoration: underline">Execute various types of scripts</span> written in Python, Ruby or PowerShell. You can also run configurations such as Ansible playbooks. You can pretty much run anything on your instances as long as the software (e.g., Python 2.7 or Ansible) is installed on your instance and recognized by Shell on Linux and PowerShell on Windows</li> 
<li><span style="text-decoration: underline">Download scripts</span> stored in private or public GitHub repositories, or on Amazon S3 onto your instances for execution</li> 
<li><span style="text-decoration: underline">Run multiple files</span> by downloading a complete GitHub directory or an S3 bucket</li> 
<p><span id="more-1905"></span></p> 
<p>Systems Manager now provides a new public Document, <strong>AWS-RunRemoteScript</strong> that runs scripts from GitHub or Amazon S3 on specified instances. It does this using the new plugin from <a href="https://github.com/aws/amazon-ssm-agent">Amazon SSM Agent</a>, <a href="https://docs.aws.amazon.com/systems-manager/latest/userguide/ssm-plugins.html#aws-downloadContent">aws:downloadContent</a>, which downloads content from locations such as public or private GitHub repositories, S3 buckets, and Documents already created on SSM. If you create your own documents, you can use the <strong>aws:downloadContent</strong> plugin, and the existing <a href="https://docs.aws.amazon.com/systems-manager/latest/userguide/ssm-plugins.html#aws-runShellScript"><strong>aws:runShellScript</strong></a> (on Linux) or<a href="https://docs.aws.amazon.com/systems-manager/latest/userguide/ssm-plugins.html#aws-runPowerShellScript"><strong> aws:runPowerShellScript</strong></a> (on Windows) to execute the scripts.</p> 
<p>In this blog post, I’ll show you how to run an Ansible playbook located in a public or private GitHub repository using the AWS-RunRemoteScript Document. This lets you run Ansible from an external location without requiring SSH access on your instances.</p> 
<h3>Walkthrough 1 – Run an Ansible playbook from a public GitHub repository</h3> 
<p><strong>Pre-requisites</strong></p> 
<p>We will run an Ansible playbook that installs and configures NGINX from a GitHub public repository. The playbook is expressed in server.yml and this main playbook calls the nginx role.</p> 
<p><img class="size-full wp-image-1908 alignnone" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/02/playbook.png" alt="" width="374" height="237" /></p> 
<p>Before you get started, ensure you have reviewed the Ansible license and then install it on your instances. You can install Ansible using Run Command with the commands below:</p> 
<p>Amazon Linux:</p> 
<pre><code class="lang-bash">sudo pip install ansible</code></pre> 
<p>Ubuntu:</p> 
<pre><code class="lang-bash">sudo apt-get install ansible –y</code></pre> 
<p><strong>Step 1: Find the AWS-RunRemoteScript document for execution</strong></p> 
<p>On the EC2 console, on the navigation pane at the left, under Systems Manager Services, choose <strong>Run Command</strong>. Choose <strong>Run a Command</strong>, and then select the AWS-RunRemoteScript document and the instances you want to execute this document on (whether a list of instances or tag-queries).</p> 
<p><strong>Step 2: Reference the Ansible playbook located on GitHub</strong></p> 
<p>Enter the parameters for the AWS-RunRemoteScript Document to reference the Ansible playbook.</p> 
<li><span style="text-decoration: underline">Source Type</span>: Location of the script – GitHub, S3. In this case, choose GitHub.</li> 
<li><span style="text-decoration: underline">Source Info</span>: Provides location information for accessing the content. &nbsp;In this example, since the repository is public, you only need to provide the owner, repository and the path to the playbook. The playbook needs to access the nginx directory shown in the structure that follows. So we’ll download the entire directory, which includes server.yml and the nginx directory.</li> 
<p><img class="size-full wp-image-1907 alignnone" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/02/github-structure.png" alt="" width="1072" height="163" /></p> 
<li><span style="text-decoration: underline">Command Line</span>: The command needed to execute the playbook</li> 
<p>When you are done, the console will look like this:</p> 
<p><img class="size-full wp-image-1906 alignnone" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/02/console-string-map.png" alt="" width="672" height="317" /></p> 
<p><strong>Step 3: Run the command</strong></p> 
<p>Because you referenced the top-level directory, Systems Manager downloads all the playbook YAML scripts inside the nginx directory as well as the server.yml and user-data.sh files. The server.yml is then executed based on command line parameters, which then installs and configures NGINX.</p> 
<p>You can then view the output and see that NGINX was installed on the specified instances.</p> 
<p>&nbsp;</p> 
<p><img class="size-full wp-image-1909 alignnone" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/02/public-output.png" alt="" width="1946" height="528" /></p> 
<p><img class="size-full wp-image-1911 alignnone" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/02/public-script-ouput.png" alt="" width="1429" height="338" /></p> 
<p>You can also perform this operation using the AWS CLI by running the following command:</p> 
<pre><code class="lang-bash">aws ssm send-command --document-name &quot;AWS-RunRemoteScript&quot; --parameters '{&quot;sourceType&quot;:[&quot;GitHub&quot;],&quot;sourceInfo&quot;:[&quot;{\&quot;owner\&quot; : \&quot;owner-name\&quot;, \&quot;repository\&quot;:\&quot;repository-name\&quot;, \&quot;path\&quot;:\&quot;path/to/directory\&quot;}&quot;], &quot;commandLine&quot;:[&quot;ansible-playbook -i \&quot;localhost,\&quot; --check -c local server.yml&quot;]}'</code></pre> 
<h3>Walkthrough 2 – Run Ansible playbook from private GitHub repository</h3> 
<p>Now, I’ll show you how to execute scripts from private GitHub repositories. Let’s assume that the playbook in the previous example is stored in a private GitHub repository. To access this playbook, you need to create a private access token on GitHub and store it in Amazon EC2 Systems Manager Parameter Store.</p> 
<p><strong>Step 1: Create your GitHub personal access token</strong></p> 
<p>Create a personal access token for your private GitHub repo to give Systems Manager access to the playbook. <a href="https://github.com/blog/1509-personal-api-tokens">Personal API tokens</a> are a way to provide access to systems to access information from your private GitHub repository. These tokens provide limited access to a subset of repository data as well as the ability to revoke access when needed. You can create a personal access token from information provided <a href="https://help.github.com/articles/creating-a-personal-access-token-for-the-command-line/">here</a> and then save the token value.</p> 
<p><strong>Step 2: Store the tokens in Parameter Store</strong></p> 
<p>After creating the personal access token, go to Parameter Store on the EC2 console. On the Parameter Store page, create a parameter and add the token you created on GitHub here, in the Value text box.</p> 
<p><img class="size-full wp-image-1912 alignnone" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/02/create-parameter.png" alt="" width="1502" height="599" /></p> 
<p>If you have an AWS Key Management Service (KMS) key ID, you can add this key ID in the <strong>KMS Key ID</strong> text box. &nbsp;After this, choose <strong>Create Parameter</strong>. You can also perform this operation using the AWS CLI, as follows:</p> 
<pre><code class="lang-bash">aws ssm put-parameter --name example-token --value xxxxxxx --type SecureString</code></pre> 
<p><strong>Step 3: Reference the Ansible playbook located on GitHub</strong></p> 
<p>Along with owner, repository and path, we will add “tokenInfo” that refers to the example-token secure string parameter that we just created. The reference is made using the <strong>ssm-secure</strong> prefix.</p> 
<p><img class="size-full wp-image-1913 alignnone" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/02/stringmap-private.png" alt="" width="743" height="347" /></p> 
<p><strong>Step 3: Run the command</strong></p> 
<p>This command will use the personal access token to access your private GitHub repository. Everything else is the same as if you were to run the playbook from a public GitHub repository.</p> 
<p>You can also perform this operation using the AWS CLI:</p> 
<pre><code class="lang-bash">aws ssm send-command --document-name &quot;AWS-RunRemoteScript&quot; --parameters '{&quot;sourceType&quot;:[&quot;GitHub&quot;],&quot;sourceInfo&quot;:[&quot;{\&quot;owner\&quot; : \&quot;owner-name\&quot;, \&quot;repository\&quot;:\&quot;repository-name\&quot;,\&quot;path\&quot;:\&quot;path/to/directory\&quot;,\&quot;tokenInfo\&quot; : \&quot;{{ssm-secure:example-token}}\&quot;}&quot;],&quot;commandLine&quot;:[&quot;ansible-playbook -i \&quot;localhost,\&quot; --check -c local server.yml&quot;]}' </code></pre> 
<h3>Conclusion</h3> 
<p>In this blog post, I showed you how EC2 Systems Manager is a management platform that lets you use your existing tools to manage your AWS resources and environments. I showed you how to use Systems Manager to run an Ansible playbook on your EC2 instances from a public and private GitHub repository. Using the AWS-RunRemoteScript public document or the aws:downloadContent and aws:runShellScript plugins, you can run any script such as Python, Ruby, or even PowerShell scripts or modules. In a subsequent blogpost, I’ll show you how to enable modular and reusable configurations using composite Documents.</p> 
<h3>About the Author</h3> 
<p><img class="size-full wp-image-1915 alignleft" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/02/melonia.jpg" alt="" width="119" height="160" />Melonia Mendonca is a Software Development Engineer with the Amazon EC2 Systems Manager team. She is a passionate engineer who enjoys the ability to innovate encouraged by Amazon. Outside of work, Melonia likes traveling, playing board games and trying different restaurants/cuisines.</p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/mt/tag/ansible/" rel="tag">Ansible</a>, <a href="https://aws.amazon.com/blogs/mt/tag/aws-systems-manager/" rel="tag">AWS Systems Manager</a>, <a href="https://aws.amazon.com/blogs/mt/tag/configuration-management/" rel="tag">Configuration Management</a>, <a href="https://aws.amazon.com/blogs/mt/tag/ec2-systems-manager/" rel="tag">EC2 Systems Manager</a>, <a href="https://aws.amazon.com/blogs/mt/tag/github/" rel="tag">GitHub</a>, <a href="https://aws.amazon.com/blogs/mt/tag/run-command/" rel="tag">Run Command</a>, <a href="https://aws.amazon.com/blogs/mt/tag/ssm/" rel="tag">SSM</a>, <a href="https://aws.amazon.com/blogs/mt/tag/state-manager/" rel="tag">State Manager</a></span> 
</footer> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">AWS OpsWorks for Chef Automate Now Supports Compliance</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Rahul Gulati</span></span> | on 
<time property="datePublished" datetime="2017-11-06T08:19:50+00:00">06 NOV 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/aws-ops-works/" title="View all posts in AWS OpsWorks*"><span property="articleSection">AWS OpsWorks*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools*"><span property="articleSection">Management Tools*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/aws-opsworks-for-chef-automate-now-supports-compliance/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p>AWS OpsWorks&nbsp;for Chef Automate gives you a fully managed Chef server with a suite of automation tools. &nbsp;The release of Chef Automate version 1.6 includes the new <a href="https://blog.chef.io/2017/07/05/chef-automate-release-july-2017/">Compliance view</a> for Chef Automate UI. With AWS OpsWorks for Chef Automate integrated with compliance, you can track the compliance of your infrastructure based on a predefined policy. This allows you to frequently audit your applications for vulnerabilities and remediate violations.</p> 
<p><span id="more-1957"></span></p> 
<p><span style="text-decoration: underline">Use cases and benefits</span></p> 
<p>With this update, you can detect and correct security risks and compliance issues across your entire infrastructure.</p> 
<li>Move from manual compliance to <a href="https://learn.chef.io/tracks/compliance-automation#/">continuous compliance</a> by frequently conducting assessments and managing compliance as code. This means that you can bake compliance into your Chef workflow.</li> 
<li>Select from 88 pre-packaged profiles that meet industry benchmarks, available in Profile Store. Further, you can customize these profiles to fulfill your information security needs.</li> 
<li>Use the <strong>Compliance</strong> pane, which offers a unified dashboard for identifying issues, remediating them, and tracking progress. In addition, you can view <strong>Scan Results</strong> for various Nodes and Profiles.</li> 
<li>Describe compliance controls in InSpec, an open-source testing framework, and integrate these automated tests into any stage of your deployment pipeline.</li> 
<p>To get started, go to the AWS Management Console, and open the OpsWorks console. On the AWS OpsWorks Stacks home page, choose <strong>Go to OpsWorks for Chef Automate</strong>. &nbsp;Then choose <strong>Compliance</strong>. In the left navigation pane, choose <strong>Profile Store</strong>. Then, in the <strong>Available</strong> tab, select a profile such as <a href="https://github.com/dev-sec/ssh-baseline/">DevSec SSH Baseline</a>, and choose <strong>Get</strong> to install.</p> 
<p><img class="aligncenter size-full wp-image-1959" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/03/Screen-Shot-2017-10-22-at-7.03.34-PM.png" alt="" width="2880" height="1442" /></p> 
<p>On the profile details page, you can view a brief profile description, set of controls, and their severity. Choose <strong>+</strong> to see the expected outcome of a control and code that it executes.</p> 
<p><img class="aligncenter wp-image-1958 size-full" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/03/Screen-Shot-2017-10-22-at-7.07.34-PM.png" alt="" width="2880" height="1442" /></p> 
<p>After it’s installed, configure the <a href="https://supermarket.chef.io/cookbooks/audit">Audit Cookbook</a> with the compliance profile you selected in the previous step. Add the recipe to your node’s run list.</p> 
<p>After the node’s run list is executed with audit attributes set as expected, you can see the profile status on the <strong>Compliance</strong> page.</p> 
<p><img class="aligncenter size-full wp-image-1960" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/03/Screen-Shot-2017-10-22-at-9.31.17-PM.png" alt="" width="2880" height="1148" /></p> 
<p>Go to the <strong>Profiles</strong> tab, choose <strong>Scan Results</strong>, and select a node to find each failed control with details of what failed within that control. This means you can view the expected and actual outcome of each failed test. With this information, you can reconfigure the nodes to ensure that all test cases pass and a rerun is successful.</p> 
<p><img class="aligncenter size-full wp-image-1961" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/03/Screen-Shot-2017-10-22-at-9.39.26-PM.png" alt="" width="2880" height="1346" /></p> 
<p>This update is now generally available and you can start using it today. With OpsWorks for Chef Automate, you pay for the Amazon EC2 instance used to run your managed Chef server (<a href="https://aws.amazon.com/opsworks/chefautomate/pricing/">pricing details here</a>). You can launch OpsWorks for Chef Automate today in the following AWS Regions: US East (Northern Virginia), US West (Oregon), and EU (Ireland). To learn more, read <a href="http://docs.aws.amazon.com/opsworks/latest/userguide/opscm-starterkit.html">Configure the Chef Server Using the Starter Kit</a> in the OpsWorks User Guide.</p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/mt/tag/aws-opsworks/" rel="tag">AWS OpsWorks</a>, <a href="https://aws.amazon.com/blogs/mt/tag/chef-automate/" rel="tag">Chef Automate</a>, <a href="https://aws.amazon.com/blogs/mt/tag/configuration-management/" rel="tag">Configuration Management</a></span> 
</footer> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">Upgrading SQL Server Using EC2 Systems Manager</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Ananth Vaidyanathan</span></span> | on 
<time property="datePublished" datetime="2017-11-01T12:55:40+00:00">01 NOV 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/amazon-ec2-systems-manager/" title="View all posts in Amazon EC2 Systems Manager*"><span property="articleSection">Amazon EC2 Systems Manager*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools*"><span property="articleSection">Management Tools*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/upgrading-sql-server-using-ec2-systems-manager/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><em>This post was written by Alan Cranfield, Systems Engineer at Amazon Web Services</em></p> 
<p>This is the first in a series of blog posts aimed at the enterprise SQL Server DBA. I’ll demonstrate how to administer your SQL Server workloads on Amazon EC2 using practical examples and best practices.</p> 
<h3>Using Run Command</h3> 
<p>In this post I’ll show you how to use <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/execute-remote-commands.html">Run Command</a> from <a href="https://aws.amazon.com/ec2/systems-manager">Amazon EC2 Systems Manager</a> to update one or many of your SQL Servers to the latest service pack.</p> 
<p>Microsoft SQL Server is a popular workload on Amazon EC2. Keeping your SQL Server instances up to date with the latest service pack is important for the stability and security of your critical data. If you need to support multiple versions and editions of SQL Server keeping track of all the latest service packs can be cumbersome.</p> 
<p>Run Command provides a simple and secure way to remotely execute commands or run scripts against EC2 instances or on-premises servers.&nbsp;With Run Command, you can perform commands that make it easy to accomplish common administrative tasks like upgrading SQL service packs!</p> 
<p><span id="more-1694"></span></p> 
<h3>Pre-requisites</h3> 
<p>When you use EC2 Systems Manager you’ll need to first work through some <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/systems-manager-setting-up.html">prerequisites</a>. The most important prerequisite is that you’ll need the SSM agent installed on your instances. The <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/ssm-agent.html#sysman-install-ssm-win">SSM agent</a> is installed by default on Windows Server 2016 instances and instances created from Windows Server 2003-2012 R2 Amazon Machine Images (AMIs) published in November 2016 or later.</p> 
<p>Another pre-requisite is that your instances need to be assigned an AWS Identity and Access Management (IAM) role. The IAM role is used to secure the permission policies needed to communicate with the Systems Manager API. Instances are usually added to an IAM role on launch, but you can also add existing instances using the <a href="https://aws.amazon.com/blogs/security/new-attach-an-aws-iam-role-to-an-existing-amazon-ec2-instance-by-using-the-aws-cli/?sc_channel=sm&amp;sc_campaign=rolesforrunninginstances&amp;sc_publisher=tw&amp;sc_medium=social&amp;sc_content=read-post&amp;sc_country=global&amp;sc_geo=global&amp;sc_category=ec2&amp;sc_outcome=launch">AWS CLI</a>.</p> 
<h3>Using PowerShell modules</h3> 
<p>For this exercise we’ll use the Run Command native support for PowerShell modules to download and import a PowerShell module from an Amazon S3 bucket. This module will be called to identify the version of SQL that is running and then download and install the latest service pack. I’ll walk you through updating the SQL service pack by using the AWS Management Console and by using AWS Tools for PowerShell.</p> 
<h3>Updating the SQL service pack from the EC2 console</h3> 
<li>Sign In to the AWS Management Console. To confirm that your instances are in a state to be managed, make sure they are listed in the EC2 console under EC2 Dashboard\Managed Instances.</li> 
<li>Navigate to the Run Command and choose Run a command. Then select the AWS-InstallPowershellModule document, and the servers you’d like to upgrade.<img class="size-full wp-image-1696 alignnone" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/27/run-a-command.png" alt="" width="708" height="397" /><img class="size-full wp-image-1697 alignnone" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/27/install-ps-module.png" alt="" width="890" height="316" /></li> 
<li>For Source enter the location of the S3 bucket that holds the PowerShell module: <a href="https://s3.amazonaws.com/sql-service-pack/InstallSqlServicePack.zip">https://s3.amazonaws.com/sql-service-pack/InstallSqlServicePack.zip</a></li> 
<li>Paste the following PowerShell script into the Commands Window 
<pre><code class="lang-powershell">Set-ExecutionPolicy -ExecutionPolicy Unrestricted -Force
Import-Module InstallSqlServicePack
Install-SQLUpdate -Action &quot;Yes&quot;</code></pre> 
<li>Choose the <strong>Run</strong> button and check the <strong>Status</strong> column for the instance progress.<img class="size-full wp-image-1699 alignnone" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/27/command-success.png" alt="" width="971" height="300" /></li> 
<li>Choose a specific Instance ID in the top pane, and then in the bottom pane choose the Output tab and then choose View Output.</li> 
<li>The results of the service pack upgrade are shown in the Output results window.<img class="size-full wp-image-1700 alignnone" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/27/output.png" alt="" width="828" height="471" /></li> 
<h3>Updating the SQL service pack using the AWS Tools for PowerShell</h3> 
<p>For those who prefer a scripted solution you can call Run Command using the <a href="http://docs.aws.amazon.com/powershell/latest/userguide/pstools-getting-set-up.html">AWS Tools for Windows PowerShell</a>.</p> 
<li>Download and install the latest AWS Tools for Windows PowerShell.</li> 
<pre><code class="lang-powershell">$AWSPSURL = &quot;http://sdk-for-net.amazonwebservices.com/latest/AWSToolsAndSDKForNet.msi&quot; 
$AWSPSSetup = &quot;C:\Windows\Temp\AWSPowerShellSetup.msi&quot;
(New-Object System.Net.WebClient).DownloadFile($AWSPSURL, $AWSPSSetup)
Start-Process -FilePath msiexec.exe -Argument List &quot;/i $AWSPSSetup&quot;
Remove-Item $AWSPSSetup -Force</code></pre> 
<li>Set your credentials and AWS Region</li> 
<pre><code class="lang-powershell"># set credentials
Set-AWSCredentials -StoreAs SQL -AccessKey &lt;your access key&gt; -SecretKey &lt;your secret key&gt;
Set-AWSCredentials -ProfileName SQL
Set-DefaultAWSRegion &quot;us-west-2&quot; 
Get-IAMUser</code></pre> 
<li>Confirm that your instances are managed by SSM</li> 
<p><code class="lang-powershell">Get-SSMInstanceInformation -InstanceInformationFilterList @{Key=&quot;PingStatus&quot;;ValueSet=&quot;Online&quot;} | select ComputerName, InstanceId<br /> </code></p> 
<li>Run a Command against your instances to upgrade the SQL service pack. (Tagging can also be used to group servers.)</li> 
<pre><code class="lang-powershell"></code><code class="lang-powershell">$InstanceIds = (Get-SSMInstanceInformation).InstanceId
$InstanceIds.count
$source = 'https://s3.amazonaws.com/sql-service-pack/InstallSqlServicePack.zip'
$commands = @(
'Set-ExecutionPolicy -ExecutionPolicy Unrestricted -Force',
'Import-Module InstallSqlServicePack',
'Install-SQLUpdate -Action &quot;Yes&quot;'
)
$parameter = @{
source = $source;
commands = $commands;
}
$document = 'AWS-InstallPowerShellModule'
$cmd = Send-SSMCommand –InstanceId $InstanceIds –DocumentName $document –Parameter $parameter </code></pre> 
<li>Check the progress.</li> 
<pre><code class="lang-powershell">Get-SSMCommandInvocation -CommandId $cmd.CommandId -Details $true | select InstanceId, status </code></pre> 
<pre><code class="lang-powershell">InstanceId          Status    
----------          ------    
i-0fff59f73e94a0449 InProgress
i-0f1f7afc2b605b4d1 Success   
i-0ee0c157a87ede81f InProgress
i-0daa300d38d9c42b1 InProgress
i-0b861190458f9381f InProgress
i-09dc29e6a093ac14c InProgress
i-09aee29b50203cf3c Success
</code></pre> 
<li>Check the results.</li> 
<p><code class="lang-powershell">Get-SSMCommandInvocation -CommandId $cmd.CommandId -Details $true | select -ExpandProperty CommandPlugins</code></p> 
<p><code class="lang-powershell">== Install SQL Update ==<br /> </code></p> 
<pre><code class="lang-powershell">2017-08-18 23:54:38.760 Test-SQLInstallation
2017-08-18 23:54:38.856 - SQL server service is installed and started
2017-08-18 23:54:38.866 - Importing SQLPS Module
2017-08-18 23:54:41.048 Check if Clustered
2017-08-18 23:54:41.227 - Not Clustered
2017-08-18 23:54:41.232 Get-InstallableUpdate
2017-08-18 23:54:41.245 - Read current installed version...
2017-08-18 23:54:41.254 - Found Microsoft SQL Server 2016 (RTM-CU3-GDR) (KB3194717) - 13.0.2186.6 (RTM)
2017-08-18 23:54:41.275 - Looking for latest Service Pack...
2017-08-18 23:54:41.351 - Found Microsoft SQL Server 2016 - 13.0.4001.0 (SP1)
2017-08-18 23:54:41.359 Test-DownloadDestinationFolder
2017-08-18 23:54:41.377 - Get disk information on C: drive
2017-08-18 23:54:41.400 - Free space is 27 GB
2017-08-18 23:54:41.410 - Destination folder C:\Windows\temp was successfully created.
2017-08-18 23:54:41.415 Downloading Microsoft SQL Server 2016 - 13.0.4001.0 (SP1) from Microsoft...
2017-08-18 23:54:49.100 - Downloading Update bits completed
2017-08-18 23:54:49.106 Installing Microsoft SQL Server 2016 - 13.0.4001.0 (SP1)
2017-08-18 23:59:01.504 - Installing Microsoft SQL Server 2016 - 13.0.4001.0 (SP1) Completed
2017-08-18 23:59:01.510 Verify SQL version after update
2017-08-18 23:59:01.525 - Version after update 13.0.4001.0
2017-08-18 23:59:01.530 Update Successful!</code></pre> 
<h3>Conclusion</h3> 
<p>Amazon EC2 Systems Manager offers a suite of tools to help you manage both your EC2 and on-premises SQL Server instances. In this post, I showed you how to use the Run Command feature of Systems Manager to easily upgrade SQL Server to the latest service pack.</p> 
<p>In a critical production environment, when you upgrade you might have extra steps to perform before and after, such as database backups, failovers, failbacks, etc. So, in the next post I’ll show you how to use the Automation feature of Systems Manager to achieve custom maintenance workflows.</p> 
<h3>About the Author</h3> 
<p><img class="alignleft size-full wp-image-1707" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/28/alan_cranfield.jpg" alt="" width="176" height="233" />Alan Cranfield is a Senior Systems Engineer on the EC2 Windows team where he uses his extensive experience managing critical enterprise environments to help make AWS the best cloud platform for running Windows workloads. He spends his spare time in the garage restoring and customizing old motorcycles.</p> 
<p><code class="lang-powershell"></code><code class="lang-powershell"></code></p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/mt/tag/aws-systems-manager/" rel="tag">AWS Systems Manager</a>, <a href="https://aws.amazon.com/blogs/mt/tag/ec2-systems-manager/" rel="tag">EC2 Systems Manager</a>, <a href="https://aws.amazon.com/blogs/mt/tag/run-command/" rel="tag">Run Command</a>, <a href="https://aws.amazon.com/blogs/mt/tag/ssm/" rel="tag">SSM</a></span> 
</footer> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">AWS CloudFormation Guardrails: Protecting your Stacks and Ensuring Safer Updates</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Luis Colon</span></span> | on 
<time property="datePublished" datetime="2017-10-31T17:03:10+00:00">31 OCT 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/aws-cloudformation/" title="View all posts in AWS CloudFormation*"><span property="articleSection">AWS CloudFormation*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/security-identity-compliance/aws-identity-and-access-management-iam/" title="View all posts in AWS Identity and Access Management (IAM)*"><span property="articleSection">AWS Identity and Access Management (IAM)*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/aws-cloudformation-guardrails-protecting-your-stacks-and-ensuring-safer-updates/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<blockquote> 
<p><em>“I wonder what will happen if I touch these two wires together.” – Unix fortune</em></p> 
</blockquote> 
<p>If you’ve worked with cloud-hosted applications or large distributed architectures for any extended period of time, chances are you’ve heard colleagues&nbsp;invoke&nbsp;<a href="https://en.wikipedia.org/wiki/Murphy's_law">Murphy’s law</a>: “Anything that can go wrong, will go wrong”. All of us have&nbsp;experienced one of those events in the middle of the night where a usually well-intentioned colleague decides to run maintenance or cleanup on some systems…and accidentally deletes or changes a volume, server, endpoint, function, or other critical resource.</p> 
<p>If your applications, functions, servers, and other resources are in AWS, and you’re using AWS CloudFormation to automate the deployment and changes to your stacks, you are well positioned to implement several levels of safety guardrails to reduce the likelihood of many of these unplanned events. In this blog post we cover many of these guardrails. We’ll also present ideas collected from user surveys, support cases, and other sources so you can build a strategy&nbsp;to use these safety provisions and improve them over time.</p> 
<p><span id="more-1560"></span></p> 
<p>There are four primary features that you can use to protect your stacks and resources in CloudFormation:</p> 
<table style="height: 203px" border="1" width="100%" cellpadding="4"> 
<tbody> 
<tr> 
<td width="139"><strong>Guardrail</strong></td> 
<td width="328"><strong>Description</strong></td> 
</tr> 
<tr> 
<td width="139">Termination Protection</td> 
<td width="328">Stack level attribute to prevent deletion; also works with nested stacks</td> 
</tr> 
<tr> 
<td width="139">Deletion Policies</td> 
<td width="328">Resource level attribute; can be Delete (default), Retain&nbsp;or Snapshot</td> 
</tr> 
<tr> 
<td width="139">Stack Policies</td> 
<td width="328">Restrict operations at a stack level to multiple resource groups</td> 
</tr> 
<tr> 
<td width="139">IAM Policies</td> 
<td width="328">Restrict operations by users, groups or roles</td> 
</tr> 
</tbody> 
</table> 
<p>These features&nbsp;vary in scope and the granularity of options. Consider implementing several of these features in a layered way, as opposed to using only one of them.</p> 
<p><strong>Using stack termination protection</strong></p> 
<p>Using <a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-cfn-protect-stacks.html">this</a>&nbsp;stack attribute, you can prevent a new or existing stack from being accidentally deleted. This setting is disabled by default, so you have to explicitly enable it when you create new stacks. For existing, non-nested stacks, you can change termination protection&nbsp;using the AWS Management Console or the AWS CLI. For existing nested stacks, you must enable termination protection on the root stack.&nbsp;After it is enabled on the root stack, the protection is also set for the nested or child stacks. However, keep in mind that if you perform a stack update on the root stack that would delete the nested stack, CloudFormation will delete the nested stack. If you attempt to delete a nested stack when its root stack has termination protection in place, the operation will fail and the nested stack will remain unchanged. Like many other CloudFormation operations,&nbsp;you can control who can enable or disable termination protection by using&nbsp;an IAM policy.</p> 
<pre><code class="lang-json">{
&quot;Version&quot;:&quot;2012-10-17&quot;,
&quot;Statement&quot;:[{
&quot;Effect&quot;:&quot;Allow&quot;,
&quot;Action&quot;:[
&quot;cloudformation:UpdateTerminationProtection&quot;
],
&quot;Resource&quot;:&quot;*&quot;
}]
}
</code></pre> 
<p><strong>Figure 1: Sample IAM policy granting permissions to change stack termination protection </strong></p> 
<p>&nbsp;</p> 
<p>So, now that you know about termination protection, should you enable it on all or most of your stacks? Maybe, but you should consider the lifecycle of all your stacks first. Adding termination protection to seldom-changing network resource stacks makes sense, providing yet another layer that can supplement existing controls without interfering with daily application changes. On the other hand, if the application stack changes often, you’ll end up enabling and disabling termination protection often as well. For those types of ephemeral stacks, other guardrails outlined in this article&nbsp;might be more appropriate.</p> 
<p><strong>Using resource-specific deletion policies</strong></p> 
<p>You can use <a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html">Deletion Policies</a> on a resource-by-resource basis in your template code. By default, when a resource is deleted from a stack template and the stack is updated, the resource is deleted by CloudFormation. (The exceptions are some Amazon RDS database resources, which have a different default behavior.) For more information on resource-specific deletion policies, see the CloudFormation <a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html">DeletionPolicy Attribute</a> documentation.</p> 
<p>Keep in mind the&nbsp;Retain option, which deletes the resource from being managed by CloudFormation via stacks and templates, but doesn’t delete it from your AWS account or region. This can be critical for stateful resources like databases and queues, and semi-durable resources like state machines when using AWS Step Functions. For state machines in particular, it’s advisable to retain them because doing so also retains their execution history. In the interest of utmost safety, you should liberally set Deletion Policies to Retain if and until you can make sure you won’t lose valuable historical data for troubleshooting. You can always delete these resources later using other means.</p> 
<p>For some stateful resources like Amazon EC2 volumes, Amazon ElastiCache, Amazon RDS and Amazon Redshift, you also have the option to have CloudFormation create a snapshot before it deletes those resources. To further protect your more critical stateful resources, you&nbsp;can group them into separate stacks with more strict policies, and/or you can create dependencies between stacks&nbsp;using cross-stack references, which implements further implicit checks.</p> 
<pre><code class="lang-json">{
&quot;AWSTemplateFormatVersion&quot;:&quot;2010-09-09&quot;,
&quot;Resources&quot;: {
&quot;myVolume&quot;: {
&quot;Type&quot;:&quot;AWS::EC2::Volume&quot;,
&quot;DeletionPolicy&quot;:&quot;Snapshot&quot;,
&quot;Properties&quot;: {
&quot;AvailabilityZone&quot;:&quot;us-east-1a&quot;,
&quot;Size&quot;:&quot;200&quot;
}
}
}
}
</code></pre> 
<p><strong>Figure 2: Using Deletion Policy to take a snapshot of an EC2 Volume, if deleted</strong></p> 
<p>&nbsp;</p> 
<p><strong>Using stack-level policies</strong></p> 
<p>A <a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/protect-stack-resources.html#protect-stack-resources-protecting">stack policy</a> is a JSON document that defines the update actions that can be performed on a single resource or a group of resources in a flexible yet compact way (versus Deletion Policies, which are defined on a resource-by-resource basis). Stack policies are evaluated and applied in advance of any update actions, which include cases when resources are modified, recreated, or removed. Resources for a rule can be selected with wildcards or by evaluating a condition expression.</p> 
<pre><code class="lang-json">{
&quot;Statement&quot; : [
{
&quot;Effect&quot; : &quot;Deny&quot;,
&quot;Action&quot; : &quot;Update:*&quot;,
&quot;Principal&quot;: &quot;*&quot;,
&quot;Resource&quot; : &quot;*&quot;,
&quot;Condition&quot; : {
&quot;StringEquals&quot; : {
&quot;ResourceType&quot; : [&quot;AWS::RDS::DBInstance&quot;]
}
}
},
{
&quot;Effect&quot; : &quot;Allow&quot;,
&quot;Action&quot; : &quot;Update:*&quot;,
&quot;Principal&quot;: &quot;*&quot;,
&quot;Resource&quot; : &quot;*&quot;
}
]
}
</code></pre> 
<p><strong>Figure 3: A Stack policy that prevents updates to all RDS DB Instances </strong></p> 
<p>&nbsp;</p> 
<p>Stack policies can be set when you create a stack&nbsp;using the AWS Management Console or&nbsp;by using the AWS CLI. However,&nbsp;to set a stack policy on an existing stack, you must do it&nbsp;using&nbsp;the CLI or API. You also must use the CLI or API to modify an existing policy on a stack. You can also opt to create a strict permanent stack policy, and&nbsp;then update policy-protected resources by creating temporary policies that override the permanent stack policy. Finally, if you use AWS Config, you can also record configuration changes to the attributes of a stack policy, as well as other permissions and rollback settings.</p> 
<p><strong>Using IAM Policies</strong></p> 
<p><a href="http://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies.html">IAM Policies</a> explicitly enforce access controls on users, groups or roles. Beyond restricting updates and deletions to a subset of users, you can also restrict users to use only specific templates, use only specific stack policies, create only a few resource types, or assume specific roles. Gaining expertise with IAM policies can benefit you beyond your CloudFormation usage, such as controlling access to logs, who can execute Lambda functions, and many other use cases across all AWS services.</p> 
<pre><code class="lang-json">{
&quot;Effect&quot;:&quot;Allow&quot;,
&quot;Action&quot;:[&quot;cloudformation:CreateStack&quot;]
},
{
&quot;Effect&quot;:&quot;Deny&quot;,
&quot;Action&quot;:[&quot;cloudformation:CreateStack&quot;]
“Condition”:{
‘ForAnyValue:StringLike”:{
“cloudformation:ResourceType”: [“AWS::IAM::*”]
}
}
}
</code></pre> 
<p><strong>Figure 4: IAM policy allowing users to create resources and stacks except for IAM resources</strong></p> 
<p>&nbsp;</p> 
<p><strong>A few more suggestions</strong></p> 
<p>Beyond understanding how these four guardrails work, here are a few other suggestions and ideas you&nbsp;can study&nbsp;as you look to implement these controls, or improve existing controls you may have inherited:</p> 
<li>By having smaller, multiple policies that affect a smaller set of resources and stacks, you can limit the blast radius of policy changes as you improve them over time, to either make them more restrictive or to add layers of control.</li> 
<li>Stack and IAM policies should be treated as code and, with that in mind, they should be periodically tested and versioned. Consider implementing validation pipelines and creating chaos engineering-like tests where critical resource deletions are attempted.</li> 
<li>For your own custom resources, it’s up to you to add code to determine what happens to your resources when they get deleted. For stateful custom resources, it becomes your responsibility to ensure a given resource is backed up or retained. You can also use a Lambda-backed custom resource to pass a stack’s policy from a root stack to a nested stack using the setStackPolicy API call&nbsp;because nested stacks don’t automatically inherit the root stack’s policy.</li> 
<li>These guardrails are preventive steps that you can execute within CloudFormation. If you go outside of CloudFormation and use a resource’s AWS Management Console to update and delete it, your template code will become out-of-sync with the resource’s state. You should update your template to reflect the new changes, and prevent future changes&nbsp;using additional IAM policies.</li> 
<p>You should plan to use most (if not all) of these options. Let’s say, for example, that you’ve just inherited a group of applications (and, with those, the infrastructure stacks and templates associated with them) and are looking at adding layers of protection using these guardrails. A defensible approach may look like this:</p> 
<li>Review your stacks and templates,&nbsp;and review the resources that are more critical, like stateful or semi-durable resources.&nbsp;Determine which of these critical resources are useful candidates for a DeletionPolicy of Retain or Snapshot.</li> 
<li>Go one level up from resources to stacks, and consider what operations will be allowed for resources (or groups of resources) within that stack. On top of your resource deletion policy layer, add stack policy restrictions that reflect the criticality of those stacks. For the more critical stacks, consider also using stack termination protection. Even if it becomes a nuisance, at least you’ll&nbsp;gain understanding about how frequently stack updates are required for those stacks, which stacks have cross stack references or parent/child relationships, etc. Armed with this information, you can adjust your&nbsp;controls accordingly.</li> 
<li>Finally, once you’ve protected the resources and stacks themselves, you should then restrict which users should have the ability to run updates on those stacks using IAM policies.</li> 
<p><strong>Conclusion</strong></p> 
<p>We just walked through a sequence starting with&nbsp;the most detailed controls at the individual resource level, then to the stacks, and finally to the users, and will likely end up with the most enforced or least privileged controls. Alternatively, you can also opt to start with users, groups, and roles first, and then work your way down through stacks and resources. This can probably be justified if, in looking at the history of your unplanned downtime events, you already suspect that your IAM policies need more urgent attention. In either case, you want to ensure that there are multiple layers of safety in place by having multiple guardrails apply to your most critical resources.</p> 
<p>Overall, the key to success in making the most of these features is to carefully test and adapt your use of these guardrails over time, and ensure that you have multiple guardrail layers in place for the most critical stacks and resources. Many existing CloudFormation best practices still apply; for example, smaller stacks will be easier to test and ultimately protect than large, complex ones. &nbsp;Finally, consider ways to establish automated tests for your template code by implementing processes like validation pipelines.</p> 
<p>&nbsp;</p> 
<p><strong>About the Author</strong></p> 
<table class=" alignleft" style="height: 129px" width="100%" cellpadding="4"> 
<tbody> 
<tr> 
<td width="63"><img class="alignnone wp-image-1533" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/17/PhoneTool1.jpg" alt="" width="80" height="106" /></td> 
<td width="408"> <p><strong>Luis Colon is a Senior Developer Advocate for the AWS CloudFormation team.&nbsp;</strong>He works with customers and internal development teams to focus on and improve the developer experience for CloudFormation users. In his spare time, he mixes progressive trance music.</p> <p>&nbsp;</p></td> 
</tr> 
</tbody> 
</table> 
<p></p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/mt/tag/aws-cloudformation/" rel="tag">AWS CloudFormation</a>, <a href="https://aws.amazon.com/blogs/mt/tag/aws-iam/" rel="tag">AWS IAM</a></span> 
</footer> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<meta property="image" content="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/26/awsreinvent2017banner.png" /> 
<b class="lb-b blog-post-title" property="name headline">Your AWS CloudFormation Guide to re:Invent 2017 &nbsp;</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Chuck Meyer</span></span> | on 
<time property="datePublished" datetime="2017-10-30T14:31:05+00:00">30 OCT 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/aws-cloudformation/" title="View all posts in AWS CloudFormation*"><span property="articleSection">AWS CloudFormation*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/events/reinvent/" title="View all posts in AWS re:Invent*"><span property="articleSection">AWS re:Invent*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/your-aws-cloudformation-guide-to-reinvent-2017/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><img class="alignnone size-full wp-image-1685" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/26/awsreinvent2017banner.png" alt="" width="1040" height="204" /></p> 
<p>There are only five weeks left until <a href="https://reinvent.awsevents.com/">re:Invent 2017</a>. As in years past, AWS CloudFormation will be there, both behind the scenes deploying infrastructure and front-and-center for break-out sessions, workshops, and developer chats.</p> 
<p>Here are a few highlights we’ve pulled from the <a href="https://www.portal.reinvent.awsevents.com/connect/search.ww#loadSearch-searchPhrase=CloudFormation&amp;searchType=session&amp;tc=0&amp;sortBy=abbreviationSort&amp;p=">session catalog</a>, followed by the full list of CloudFormation-focused sessions and workshops to help you plan your week in Las Vegas.</p> 
<p><span id="more-1585"></span></p> 
<b id="breakout-sessions">Breakout Sessions</b> 
<p>Breakout sessions are the traditional, 60 minute, lecture-style content format.</p> 
<li><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=14428">DEV317 – Deep Dive on AWS CloudFormation</a> <em>The AWS CloudFormation team guides you through techniques used for creating modular templates and and considerations for governance.</em></li> 
<li><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=16239">DEV318 – Learn How Intuit Built a Frictionless Infrastructure Management System Using AWS CloudFormation</a> <em>Intuit shows you how they built a standardized serverless solution using AWS CloudFormation to manage infrastructure as code.</em></li> 
<li><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=15142">GPSTEC319 – GPS: Build Once, Deploy Many: Architecting and Building Automated, Reusable Reference Deployments with AWS CloudFormation</a> <em>The AWS Quick Start team shares with you the experience and best practices they’ve gained building over 50 Quick Start reference deployments.</em></li> 
<b id="workshops">Workshops</b> 
<p>Workshops are 2.5 hour, small-scale breakouts where you work in teams to build projects and solve problems on AWS.</p> 
<li><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=14430">DEV336 – Stack Mastery: Create and Optimize Advanced AWS CloudFormationTemplates</a> <em>Take a real-world architecture from a sandbox template to production-ready reusable code.</em></li> 
<li><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=16359">DEV337 – Deploy a Data Lake with AWS CloudFormation</a> <em>You will learn how to build AWS CloudFormation templates using proven methods and best practices to deploy a fully functional data lake architecture.</em></li> 
<li><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=14629">SID312 – DevSecOps Capture the Flag</a> <em>Improve your DevSecOps skills in this Capture the Flag style workshop. Earn points by enforcing policy via CloudFormation static analysis.</em></li> 
<b id="other-relevant-sessions">Other relevant sessions</b> 
<p>While the following sessions aren’t CloudFormation specific, they will show you mature patterns for infrastructure management using CloudFormation alongside other AWS services.</p> 
<li><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=14965">DEV324 – Deep Dive on Advanced Continuous Delivery Techniques Using AWS DevOps Tools</a></li> 
<li><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=15199">DEV340 – How Amazon.com Uses AWS Management Tools</a></li> 
<li><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=14521">MSC201 – Building end-to-end IT Lifecycle Mgmt &amp; Workflows with AWS Service Catalog</a></li> 
<p>You can <a href="https://www.portal.reinvent.awsevents.com/connect/publicDashboard.ww">log in and reserve seats for any of these sessions</a> now.</p> 
<p>In addition, the AWS CloudFormation Developer Advocates will be presenting a series of CloudFormation focused Dev Chats on the Expo floor on Wednesday and Thursday. Stop by the Dev Lounge in the Expo Hall for exact times.</p> 
<p>And finally, you can come chat with any of the Management Tools team at the AWS booth all week long.</p> 
<p>See you at re:Invent!</p> 
<hr /> 
<p><strong><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=14479">AMF301 – Big Data &amp; Analytics for Manufacturing Operations</a></strong><br /> Manufacturing companies collect vast troves of process data for tracking purposes. Using this data with advanced analytics can optimize operations, saving time and money. In this session, we explore the latest analytics capabilities to support your goals for optimizing the manufacturing plant floor. Learn how to build dashboards that connect to prediction models driven by sensors across manufacturing processes. Learn how to build a data lake on AWS, using services and techniques such as AWS CloudFormation, Amazon EC2, Amazon S3, AWS Identity and Access Management, and AWS Lambda. We also review a reference architecture that supports data ingestion, event rules, analytics, and the use of machine learning for manufacturing analytics.</p> 
<p><strong><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=16676">CMP216 – Use Amazon EC2 Spot Instances to Deploy a Deep Learning Framework on Amazon ECS</a></strong><br /> Deep learning, an implementation of machine learning, uses neural networks to solve complex problems like computer vision, natural language processing, and recommendations. Deep learning libraries and frameworks enable developers to enhance the capabilities of their applications and projects. In this workshop, learn how to build and deploy a powerful deep learning framework, Apache MXNet, on containers. The portability and resource management benefit of containers enables developers to focus less on infrastructure and more on building. The lab first demonstrates the automation capabilities of AWS CloudFormation to stand up core infrastructure. We also leverage Spot Fleet for the cost benefit of using Spot Instances, especially important for developer environments. Next we create an MXNet container in Docker and deploy it with Amazon ECS. Finally, we explore image classification with MXNet to validate that everything is working as expected.</p> 
<p><strong><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=16740">CON319 – Interstella 8888: CICD for Containers on AWS</a></strong><br /> Interstella 8888 is an intergalactic trading company that deals in rare resources, but their antiquated monolithic logistics systems are causing the business to lose money. Join this workshop to learn how to set up a CI/CD pipeline for containerized microservices. You’ll get hands-on experience deploying Docker container images using Amazon ECS, AWS CloudFormation, AWS CodeBuild, and AWS CodePipline, automating everything from code check-in to production. AWS credits are provided. Bring your laptop, and have an active AWS account.</p> 
<p><strong><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=14428">DEV317 – Deep Dive on AWS CloudFormation</a></strong></p> 
<p>AWS CloudFormation enables developers and system administrators to harness the power of infrastructure-as-code. As organizations adopt AWS CloudFormation for workload deployments, common patterns emerge and opportunities to streamline deployments become evident. Using AWS CloudFormation support for nested templates, customers can further streamline the creation of new workloads as code through modular reuse. This session guides you through some of the techniques used for creating modular AWS CloudFormation templates, and considerations for design and governance to empower departments and teams to own the architectures.</p> 
<p><strong><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=16239">DEV318 – Learn How Intuit Built a Frictionless Infrastructure Management System Using AWS CloudFormation</a></strong></p> 
<p>Managing Infrastructure as Code (IaC) successfully within an organization is a challenge. Regardless of team size, it can turn into a patchwork of solutions causing difficulties collaborating among individuals and teams. Intuit has faced and learned from these challenges, while coordinating among different teams running workloads that provide solutions for different business units. We developed a system that improved our development process for IaC using AWS CloudFormation. In this session, we demonstrate how to move away from an inconsistent development of infrastructure by complementing common development practices with a solution using the serverless technologies from AWS. We walk through our journey and help you discover an approach to assemble a similar solution for your organization.</p> 
<p><strong><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=14965">DEV324 – Deep Dive on Advanced Continuous Delivery Techniques Using AWS DevOps Tools</a></strong><br /> Continuous delivery (CD) enables teams to be more agile and quickens the pace of innovation. Too often, however, teams adopt CD without putting the right safety mechanisms in place. In this talk, we discuss opportunities for you to transform your software release process into a safer one. We explore various DevOps best practices, showcasing sample applications and code. We discuss how to set up delivery pipelines with nonproduction testing stages, failure cases, rollbacks, machine and Availability Zone redundancy, canary testing and deployments, and monitoring. We’ll use AWS Lambda, AWS CloudFormation, AWS CodePipeline, AWS CodeDeploy, and both Amazon CloudWatch alarms and events.</p> 
<p><strong><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=14778">DEV332 – Using AWS to Achieve Both Autonomy and Governance at 3M</a></strong><br /> There is a constant tension between empowering teams to be agile through autonomy and enforcing governance policies to maintain regulatory compliance. Hear from Nathan Scott, Senior Consultant at AWS and James Martin, Automation Engineering Manager at 3M on how they have achieved both autonomy and governance through self-service automation tools on AWS. Learn how to avoid pitfalls with building the CI/CD team, right sizing and how to address. This session will also feature a demo from Casey Lee, Chief Architect at Stelligent on the tools used to accomplish this for 3M, including AWS Service Catalog, AWS CloudFormation, AWS CodePipeline and Cloud Custodian, an open source tool for managing AWS accounts.</p> 
<p><strong><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=14430">DEV336 – Stack Mastery: Create and Optimize Advanced AWS CloudFormationTemplates</a></strong><br /> AWS CloudFormation gives you an easy way to define your infrastructure as code. But are you using it to its full potential? In this workshop, we take real-world architecture from a sandbox template to production-ready reusable code. We start by reviewing an initial template, which you update throughout the session to incorporate AWS CloudFormation features, like nested stacks and intrinsic functions. By the end of this workshop, expect to have a set of AWS CloudFormation templates that demonstrate the same best practices used in AWS Quick Starts.</p> 
<p><strong><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=16359">DEV337 – Deploy a Data Lake with AWS CloudFormation</a></strong><br /> AWS CloudFormation provides many features to automate the provisioning of infrastructure for all types of complex applications. In this workshop, you will learn how to build AWS CloudFormation templates using proven methods and best practices. You will also deploy a fully functional data lake architecture, which uses AWS services like Amazon RDS and open source components like Apache Zeppelin. The labs will demonstrate the capabilities of AWS CloudFormation to stand up infrastructure in a modular way, walk through the deployment of a complex end-to-end application, and validate that all components of the application are working.</p> 
<p><strong><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=15199">DEV340 – How Amazon.com Uses AWS Management Tools</a></strong><br /> Amazon.com enables all of its developers to be productive on AWS by operating across tens-of-thousands of team-owned AWS accounts, all while raising the bar on security, visibility and operational control. Amazon has been able to achieve these seemingly conflicting ideals by automating setup and management of these accounts at scale using AWS Management Tools such as CloudFormation, Config, CloudTrail, CloudWatch and EC2 Systems Manager. In this session, discover more about how Amazon.com built ASAP using AWS Management tools, and understand some of the decisions they made as their usage of AWS evolved over time. You will learn about the design, architecture and implementation that Amazon.com went through as part of this effort.</p> 
<p><strong><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=14951">ENT326 – Oracle Enterprise Solutions on AWS</a></strong><br /> Oracle enterprise applications and middleware such as E-Business Suite, PeopleSoft, Siebel, and WebLogic are central to many IT departments. They often require complex deployments that can greatly benefit from the flexibility, scalability, and security of the cloud. In this session, we discuss architecture patterns and best practices for migrating these applications to and running these applications on AWS. We cover how to work with Oracle enterprise applications and multiple services including Amazon RDS, AWS Database Migration Service, Amazon Elastic File System, and AWS CloudFormation. As part of this, we show examples of successful customer deployments.</p> 
<p><strong><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=15549">GPSCT308 – GPS: Developing and Deploying at the Speed of Light: Automating Serverless Deployments</a></strong><br /> Planning on going serverless, but want to manage it using DevOps-style processes? In this interactive session, we discuss the art of automating and managing deployments of serverless applications on AWS. We cover a range of AWS tools such as AWS CodePipeline, AWS CloudFormation, and AWS Serverless Application Model (AWS SAM), to name just a few.</p> 
<p><strong><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=15142">GPSTEC319 – GPS: Build Once, Deploy Many: Architecting and Building Automated, Reusable Reference Deployments with AWS CloudFormation</a></strong><br /> This session explains how to build reusable, maintainable AWS CloudFormation–based automation for AWS Cloud deployments. We have built over 50 Quick Start reference deployments with partners and customers, and will share this expertise with you. We explore the anatomy of a typical AWS CloudFormation template, dive deep into best practices for building Quick Start automation across Linux and Windows and explore useful design patterns. This expert-level session is for partners interested in building Quick Starts or other AWS CloudFormation–based automation. It requires familiarity with Git, shell scripting, Windows PowerShell, and AWS services like Amazon EC2, Amazon S3 and AWS CloudFormation.</p> 
<p><strong><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=15749">HLC307 – Building a Secure and Healthcare-Compliant Platform for Adopting a Cloud-First Strategy Using AWS</a></strong><br /> This session provides an overview of how Change Healthcare invested in people, process, and an automation platform to adopt a cloud-first strategy. Starting from building a Cloud Center of Excellence team, they identified the compliance, security, and cost optimization requirements and process required to build a framework. They also embedded healthcare compliance, security, architecture best practices, and customer-specific rules and standards for a managed adoption of the cloud. Change Healthcare is leveraging their Cloud 2.0 framework to rapidly deploy their mission applications into AWS. Come learn how Change Healthcare built a serverless architecture using Amazon ECS, AWS Lambda, AWS CodeDeploy, AWS CodeCommit, AWS CloudFormation, AWS Service Catalog, AWS OpsWorks, AWS Elastic Beanstalk, and other managed services.</p> 
<p><strong><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=15746">LFS307 – Becoming a Dynamic Pharma Marketing Organization Using AWS</a></strong><br /> Pharmaceutical company processes tend to be slow when dealing with customer-facing applications that contain FDA-validated messages, all while maintaining infrastructure and security standards. In this session, discover how Mylan, a US–based global generic and specialty pharmaceutical company, overcame these obstacles and provided scalable solutions by leveraging AWS DevOps methods that lower time to market, while maintaining robust security and release management practices. During the presentation, learn how Mylan redefined process models such as infrastructure change management to define new security and process models. Additionally, learn how Mylan used services like Amazon S3, Elastic Load Balancing (ELB), and AWS CloudFormation to define these new models.</p> 
<p><strong><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=15681">LFS308 – Building Data Lakes for Life Sciences Organizations</a></strong><br /> In this chalk talk, we cover the implementation of data lakes for life sciences organizations, such as Amgen and Merck, that are looking to glean new insights from their existing and new clinical data. AWS life sciences solution architects show how to build a data lake on AWS using services and techniques such as AWS CloudFormation, Amazon EC2, Amazon S3, IAM, and AWS Lambda.</p> 
<p><strong><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=15250">MBL308 – Integrating Video in Mobile Apps and Websites</a></strong><br /> In this session, we will build a highly scalable mobile app, website, and serverless mobile backend architecture that demonstrates on-demand video streaming, adaptive multi-bitrate transcoding, and video content ingestion. We use AWS Lambda and Amazon Elastic Transcoder to automatically convert high resolution videos upon upload, Amazon CloudFront to stream video content to devices using network-aware adaptive multi-bitrate protocols (such as HLS), Amazon Cognito to authenticate users, and AWS Mobile Hub and AWS CloudFormation to automate setting up the required resources.</p> 
<p><strong><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=15878">MCL318 – Deep Dive on Amazon Rekognition Architectures for Image Analysis</a></strong><br /> Join us for a deep dive on how to use Amazon Rekognition for real world image analysis. Learn how to integrate Amazon Rekognition with other AWS services to make your image libraries searchable. Also learn how to verify user identities by comparing their live image with a reference image, and estimate the satisfaction and sentiment of your customers. We also share best practices around fine-tuning and optimizing your Amazon Rekognition usage and refer to AWS CloudFormation templates.</p> 
<p><strong><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=14521">MSC201 – Building end-to-end IT Lifecycle Mgmt &amp; Workflows with AWS Service Catalog</a></strong><br /> In this session, you’ll learn how to leverage AWS Service Catalog, AWS Lambda, AWS Config and AWS CloudFormation to create a robust, agile environment while maintaining enterprise standards, controls and workflows. Fannie Mae demonstrates how they are leveraging this solution to integrate with their existing workflows and CMDB/ITSM systems to create an end-to-end automated and agile IT lifecycle and workflow.</p> 
<p><strong><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=14962">SID206 – Best Practices for Managing Security Operation on AWS</a></strong><br /> To help prevent unexpected access to your AWS resources, it is critical to maintain strong identity and access policies and track, effectively detect, and react to changes. In this session you will learn how to use AWS Identity and Access Management (IAM) to control access to AWS resources and integrate your existing authentication system with IAM. We will cover how to deploy and control AWS infrastructure using code templates, including change management policies with AWS CloudFormation. Further, effectively detecting and reacting to changes in posture or adverse actions requires the ability to monitor and process events. There are several services within AWS that enable this kind of monitoring such as CloudTrail, CloudWatch Events, and the AWS service APIs. We learn how Netflix utilizes a combination of these services to operationalize monitoring of their deployments at scale, and discuss changes made as Netflix’s deployment has grown over the years.</p> 
<p><strong><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=14629">SID312 – DevSecOps Capture the Flag</a></strong><br /> In this Capture the Flag workshop, we divide groups into teams and work on AWS CloudFormation DevSecOps. The AWS Red Team supplies an AWS DevSecOps Policy that needs to be enforced via CloudFormation static analysis. Participant Blue Teams are provided with an AWS Lambda-based reference architecture to be used to inspect CloudFormation templates against that policy. Interesting items need to be logged, and made visible via ChatOps. Dangerous items need to be logged, and recorded accurately as a template fail. The secondary challenge is building a CloudFormation template to thwart the controls being created by the other Blue teams. Throughout the session your DevSecOps static analysis will be tested by increasingly difficult CloudFormation templates from the AWS Red Team, with accurate detection being rewarded with points. Finally, we test all teams’ protection against every other team’s malicious template to see which Blue team’s static analysis was most effective.</p> 
<p><strong><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=14785">SID317 – Automating Security and Compliance Testing of Infrastructure-as-Code for DevSecOps</a></strong><br /> Infrastructure-as-Code (IaC) has emerged as an essential element of organizational DevOps practices. Tools such as AWS CloudFormation and Terraform allow software-defined infrastructure to be deployed quickly and repeatably to AWS. But the agility of CI/CD pipelines also creates new challenges in infrastructure security hardening. How do you ensure that your CloudFormation templates meet your organization’s security, compliance, and governance needs before you deploy them? How do you deploy infrastructure securely to production environments, and monitor the security posture on a continuous basis? And how do you do this repeatedly without hitting a speed bump? This session provides a foundation for how to bring proven software hardening practices into the world of infrastructure deployment. We discuss how to build security and compliance tests for infrastructure analogous to unit tests for application code, and showcase how security, compliance and governance testing fit in a modern CI/CD pipeline. Session Sponsored by: Dome9</p> 
<p><strong><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=16300">SID327 – How Zocdoc Achieved Security and Compliance at Scale With Infrastructure as Code</a></strong><br /> In less than 12 months, Zocdoc became a cloud-first organization, diversifying their tech stack and liberating data to help drive rapid product innovation. Brian Lozada, CISO at Zocdoc, and Zhen Wang, Director of Engineering, provide an overview on how their teams recognized that infrastructure as code was the most effective approach for their security policies to scale across their AWS infrastructure. They leveraged tools such as AWS CloudFormation, hardened AMIs, and hardened containers. The use of DevSecOps within Zocdoc has enhanced data protection with the use of AWS services such as AWS KMS and AWS CloudHSM and auditing capabilities, and event-based policy enforcement with Amazon Elasticsearch Service and Amazon CloudWatch, all built on top of AWS.</p> 
<p><strong><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=15779">SID347 – Securely Automating DevOps on AWS</a></strong><br /> In some organizations, the theme of “can’t we all just get along” accurately describes the relationship between DevOps and network security. DevOps operates at a rapid and dynamic pace, taking advantage of the cloud to create and deploy. Security teams exercise industry best practices of policy change control to eliminate potential security holes. Inevitably, deployment challenges arise. In this session, you learn how to automate the deployment of next-generation security to protect DevOps environments on AWS. Topics covered include “touchless” deployment of a fully-configured firewall using AWS CloudFormation templates and AWS Lambda, consuming AWS tags to execute commitless policy updates, using Amazon CloudWatch and Elastic Load Balancing to deliver scalability and resiliency. Come and learn about the next generation of security, operating at the speed of the cloud. Session sponsored by Palo Alto Networks</p> 
<p><strong><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=17593">SPL09 – Launching and Managing a Web Application with AWS CloudFormation</a></strong><br /> In this lab, you will learn how to use AWS CloudFormation to provision and update a web application with a number of supporting AWS products and services, including Auto Scaling groups, Amazon Elastic Compute Cloud (EC2) instances, and Elastic Load Balancing.</p> 
<p><strong><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=16411">WIN309 – How to Optimize AWS Architectures for SharePoint Deployments</a></strong><br /> AWS can help you rapidly deploy and scale your Microsoft SharePoint environment to help you collaborate more efficiently and cost-effectively. This session reviews architectural considerations for building a SharePoint deployment on AWS, best practices to ensure optimal performance, how to leverage multiple Availability Zones for high availability and disaster recovery, and how to integrate with Active Directory. We also look at new Quick Start guides, AWS CloudFormation templates, and other tools that dramatically reduce the time to deployment. Our Windows experts discuss the best ways to deploy and run SharePoint on AWS.</p> 
<p><strong><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=16410">WIN312 – Deploying .NET Application CI/CD Pipelines on AWS</a></strong> In this session, we look at the AWS services that customers are using to build and deploy Microsoft-based solutions that use technologies like Windows, .NET, SQL Server, and PowerShell. We start by showing you how to build a Windows-based CI/CD pipeline on AWS using AWS CodeDeploy, AWS CodePipeline, AWS CloudFormation, and PowerShell using an AWS Quick Start. With new integrations, such as the AWS Tools for VSTS, you have more options than ever. We also cover best practices for creating templates that let you automatically deploy ready-to-use Windows products by using services and tools like AWS CloudFormation, PowerShell, and Git. Our .NET experts discuss the best practices for implementing a .NET CI/CD pipeline with AWS services.</p> 
<hr /> 
<h3><img class="size-full wp-image-1591 alignleft" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/23/BadgePhoto-blog.jpg" alt="" width="128" height="160" />About the Author</h3> 
<p>Chuck Meyer&nbsp;is a Senior Developer Advocate for AWS CloudFormation based in New York.&nbsp; He&nbsp;spends his time&nbsp;working with&nbsp;both&nbsp;external and internal development teams to constantly improve the developer experience for CloudFormation users.&nbsp; He’s a live music true believer and spends as much time as possible playing bass and watching bands.</p> 
<p>&nbsp;</p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/mt/tag/aws-cloudformation/" rel="tag">AWS CloudFormation</a>, <a href="https://aws.amazon.com/blogs/mt/tag/reinvent/" rel="tag">re:Invent</a></span> 
</footer> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">Amazon EC2 Systems Manager Parameter Store adds support for Parameter versions</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Venkat Krish</span></span> | on 
<time property="datePublished" datetime="2017-10-26T12:45:28+00:00">26 OCT 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/amazon-ec2-systems-manager/" title="View all posts in Amazon EC2 Systems Manager*"><span property="articleSection">Amazon EC2 Systems Manager*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools*"><span property="articleSection">Management Tools*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/amazon-ec2-systems-manager-parameter-store-adds-support-for-parameter-versions/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><em>By Lou de la Torre, AWS Partner Solutions Architect and </em><em>Venkat Krishnamachari, Principal Product Manager, Amazon EC2 Systems Manager</em></p> 
<p>Today we are excited to announce versioning support for Amazon EC2 Systems Manager Parameter Store. With Parameter Store versioning support, each iteration of a parameter is assigned a unique version number at creation time. These individual version numbers can be easily referenced in API actions and Systems Manager Documents. By default, the latest value of the parameter will be returned when no version is specified.</p> 
<h3>Parameter Store</h3> 
<p><a href="https://aws.amazon.com/ec2/systems-manager/parameter-store/">Parameter Store</a> is part of <a href="https://aws.amazon.com/ec2/systems-manager/parameter-store/">Amazon EC2 Systems Manager</a>.&nbsp;It provides a centralized, encrypted store to manage your configuration data, whether it is plain text data (database strings) or secure strings and secrets (such as passwords, and API keys). Because Parameter Store is available through the AWS CLI, APIs, and SDKs, you can easily reference parameters across AWS services such as AWS Lambda and Amazon EC2 Container Service (ECS).</p> 
<p>For additional posts on Parameter Store, see:</p> 
<p><a href="https://aws.amazon.com/blogs/mt/the-right-way-to-store-secrets-using-parameter-store/">The Right Way to Store Secrets using Parameter Store</a></p> 
<p><a href="https://aws.amazon.com/blogs/compute/managing-secrets-for-amazon-ecs-applications-using-parameter-store-and-iam-roles-for-tasks/">Managing Secrets for Amazon ECS Applications Using Parameter Store and IAM Roles for Tasks</a></p> 
<p><a href="https://aws.amazon.com/blogs/mt/organize-parameters-by-hierarchy-tags-or-amazon-cloudwatch-events-with-amazon-ec2-systems-manager-parameter-store/">Organize Parameters by Hierarchy, Tags, or Amazon CloudWatch Events with Amazon EC2 Systems Manager Parameter Store</a></p> 
<p><span id="more-1531"></span></p> 
<h3>Parameter Store Versioning</h3> 
<p>Versioning provides an additional layer of protection for your Parameter Store values. For example, if code deployment fails you can easily roll back and reference older versions of config data saved as parameters in the Parameter Store. You can recover from unintended user errors that caused an overwrite in your parameter value. You can also use versioning to keep track of the number of times your stored values changed over the parameter’s lifetime for auditing purposes (see Figure 1).</p> 
<p><img class="alignnone wp-image-1599 size-large" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/23/Figure1-1-1024x546.png" alt="" width="640" height="341" /></p> 
<p>By default, the initially created parameters’ version is 1. Versions are incremented automatically by increments of 1 whenever a value is updated in the Parameter Store. To demonstrate the value of Parameter Store versioning, consider the following scenario.</p> 
<p>In an effort to minimize management overhead you decide to migrate your .NET application back-end SQL database from SQL on EC2 to RDS SQL. This will require that you deploy new code to your .NET application to update the database connection string. As with any migration, you want to ensure you can quickly rollback in case of failure.</p> 
<p>With Parameter Store versioning you can quickly rollback by performing the following steps:</p> 
<ol> 
<li>Create a new Parameter pointing to the existing database string (SQL on EC2)</li> 
<li>Create a new version of the Parameter pointing to the new database string (RDS SQL)</li> 
<li>Update your code with a reference to the latest or Default version of the parameter</li> 
<li>Migrate your database from SQL on EC2 to RDS SQL</li> 
<li>Deploy your code updating the .NET application to point to the new SQL database running on RDS via the latest or Default version of the parameter</li> 
<li>If any issues arise, simply update your code with the original version of the Parameter pointing your .NET application back to the original SQL on EC2 instance and re-deploy</li> 
</ol> 
<p>Let’s take a look at how easily you can make that happen by first creating a Parameter, then updating the parameter, viewing all existing versions of the Parameter, retrieving a Parameter by specific version number and finally rolling back to the original version of the Parameter. To do this you can use either the AWS CLI or the AWS Tools for Windows PowerShell. We will walk you through using both.</p> 
<p><strong>Step 1. Create a Parameter</strong></p> 
<p>Execute the following command to create a Parameter using the AWS CLI:</p> 
<pre><code class="lang-bash">aws ssm put-parameter --name &quot;/Prod/dotnet&quot; --type String --value &quot;ec2-13-57-12-38.us-west-1.compute.amazonaws.com:1433&quot;</code></pre> 
<p>or you can use&nbsp;the AWS Tools for Windows PowerShell:</p> 
<pre><code class="lang-powershell">Write-SSMParameter -Name &quot;/Prod/dotnet&quot; -Value &quot;ec2-13-57-12-38.us-west-1.compute.amazonaws.com:1433&quot; -Type &quot;String&quot;</code></pre> 
<p><strong>Step 2. Update the Parameter</strong></p> 
<p>Execute the following command to update the parameter using the AWS CLI (note the change in value and the overwrite option):</p> 
<pre><code class="lang-bash">aws ssm put-parameter --name &quot;/Prod/dotnet&quot; --type String --value &quot;dotnet.ctvzltftaz4x.us-west-1.rds.amazonaws.com:1433&quot; --overwrite</code></pre> 
<p>Or you can use the AWS Tools for Windows PowerShell (note the change in value and the overwrite option):</p> 
<pre><code class="lang-powershell">Write-SSMParameter -Name &quot;/Prod/dotnet&quot; -Value &quot;dotnet.ctvzltftaz4x.us-west-1.rds.amazonaws.com:1433&quot; -Type &quot;String&quot; -Overwrite $true</code></pre> 
<p><strong>Step 3. View all existing Versions of the Parameter</strong></p> 
<p>Execute the following command to view all existing versions of the Parameter using the CLI:</p> 
<pre><code class="lang-bash">aws ssm get-parameter-history --name “/Prod/dotnet”</code></pre> 
<p>The System returns information similar to the following:</p> 
<pre><code class="lang-bash">PS C:\&gt; aws ssm get-parameter-history --name “/Prod/dotnet”
{
&quot;Parameters&quot;: [
{
&quot;LastModifiedUser&quot;: &quot;arn:aws:iam&quot;, 
&quot;LastModifiedDate&quot;: 1507742527.826, 
&quot;Type&quot;: &quot;String&quot;, 
&quot;Name&quot;: &quot;/Prod/dotnet&quot;, 
&quot;Value&quot;: &quot;ec2-13-57-12-38.us-west-1.compute.amazonaws.com:1433&quot;
&quot;Version&quot;: 1
}, 
{
&quot;LastModifiedUser&quot;: &quot;arn:aws:iam&quot;, 
&quot;LastModifiedDate&quot;: 1507743165.366, 
&quot;Type&quot;: &quot;String&quot;, 
&quot;Name&quot;: &quot;/Prod/dotnet&quot;, 
&quot;Value&quot;: &quot;dotnet.ctvzltftaz4x.us-west-1.rds.amazonaws.com:1433&quot;
&quot;Version&quot;: 2
}
]
}</code></pre> 
<p>or you can execute the following command to view all existing versions of the Parameter using the AWS Tools for Windows PowerShell:</p> 
<p><code class="lang-powershell"></code></p> 
<pre><code class="lang-powershell">Get-SSMParameterHistory -Name &quot;/Prod/dotnet&quot;</code></pre> 
<p>The System returns information similar to the following:</p> 
<p>&nbsp;</p> 
<pre><code class="lang-bash">PS C:\&gt; Get-SSMParameterHistory -Name &quot;/Prod/dotnet&quot;
Description&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; :
KeyId&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; :
LastModifiedDate : 10/11/2017 5:22:07 PM
LastModifiedUser: arn:aws:iam
Name&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; : /Prod/dotnet
Type&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; : String
Value&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; : ec2-13-57-12-38.us-west-1.compute.amazonaws.com:1433
Version&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  : 1
Description&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; : 
KeyId&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; :
LastModifiedDate : 10/11/2017 5:32:45 PM
LastModifiedUser : arn:aws:iam
Name&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; : /Prod/dotnet
Type&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; : String
Value&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; : dotnet.ctvzltftaz4x.us-west-1.rds.amazonaws.com:1433
Version&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  : 2</code></pre> 
<p><strong>Step 4. Retrieve the Parameter</strong></p> 
<p>Use the following AWS CLI to retrieve parameters:</p> 
<p>Execute the following command to retrieve the latest version of the Parameter (default):</p> 
<pre><code class="lang-bash">aws ssm get-parameters --names “/Prod/dotnet”</code></pre> 
<p>The System returns information similar to the following:</p> 
<pre><code class="lang-bash">PS C:\&gt; aws ssm get-parameters --name “/Prod/dotnet”
{
&nbsp;&nbsp;&nbsp; &quot;InvalidParameters&quot;: [],
&nbsp;&nbsp;&nbsp; &quot;Parameters&quot;: [
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; {
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;Type&quot;: &quot;String&quot;,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;Name&quot;: &quot;/Prod/dotnet&quot;,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;Value&quot;: &quot;dotnet.ctvzltftaz4x.us-west-1.rds.amazonaws.com:1433&quot;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;Version&quot;: 2
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }
&nbsp;&nbsp;&nbsp; ]
}</code></pre> 
<p><code class="lang-bash"></code></p> 
Execute the following command to retrieve a specific version of the Parameter (by version number): 
<pre><code class="lang-bash">aws ssm get-parameters --names “/Prod/dotnet:1&quot;</code></pre> 
<p>The System returns information similar to the following:</p> 
<pre>PS C:\&gt; aws ssm get-parameters --region us-west-1 --name “/Prod/dotnet”</pre> 
<pre><code class="lang-bash">
{
&nbsp;&nbsp;&nbsp; &quot;InvalidParameters&quot;: [],
&nbsp;&nbsp;&nbsp; &quot;Parameters&quot;: [
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; {
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;Type&quot;: &quot;String&quot;,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;Name&quot;: &quot;/Prod/dotnet&quot;,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;Value&quot;: &quot;ec2-13-57-12-38.us-west-1.compute.amazonaws.com:1433&quot;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;Version&quot;: 1
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }
&nbsp;&nbsp;&nbsp; ]
}</code></pre> 
<p><code class="lang-bash"></code></p> 
Note the difference in values. 
<p>or using the&nbsp;the AWS Tools for Windows PowerShell, you can execute the following command to retrieve the latest version of the Parameter (default):</p> 
<p><code class="lang-powershell">(Get-SSMParameterValue -Names &quot;/Prod/dotnet&quot;).Parameters | fl</code></p> 
<p>The System returns information&nbsp;similar to the following:</p> 
<pre><code class="lang-bash">PS C:\&gt; (Get-SSMParameterValue -Name &quot;/Prod/dotnet&quot;).Parameters | fl
Name&nbsp; &nbsp;&nbsp;&nbsp;: /Prod/dotnet
Type&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;: String
Value &nbsp;&nbsp;&nbsp;&nbsp;: dotnet.ctvzltftaz4x.us-west-1.rds.amazonaws.com:1433
Version&nbsp; : 2
</code></pre> 
<p>Execute the following command to retrieve a specific version of the Parameter (by version number):</p> 
<pre><code class="lang-powershell">(Get-SSMParameterValue -Names &quot;/Prod/dotnet:1&quot;).Parameters | fl</code></pre> 
<p>The system returns information similar to the following:</p> 
<pre><code class="lang-bash">PS C:\&gt; (Get-SSMParameterValue -Name &quot;/Prod/dotnet:1&quot;).Parameters | fl
Name&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;: /Prod/dotnet
Type&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;: String
Value &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;: ec2-13-57-12-38.us-west-1.compute.amazonaws.com:1433
Version&nbsp;&nbsp; : 1
</code></pre> 
<p>Note the difference in values.</p> 
<p>To roll back your .NET application to point to the original SQL on EC2 instance, simply update your code to reference the previous version of the Parameter and re-deploy.</p> 
<p>You can reference Parameter Store versioning in Systems Manager Documents as well, as show in the following example:</p> 
<p><strong>Systems Manager AWS-RunShellScript example</strong></p> 
<p>The default value for commands is referenced with version 2 of SSM parameter ‘runcommand’.</p> 
<pre><code class="lang-bash">{
&quot;schemaVersion&quot;:&quot;1.2&quot;,
&quot;description&quot;:&quot;Run a shell script or specify the commands to run.&quot;,
&quot;parameters&quot;:{
&quot;commands&quot;:{
&quot;type&quot;:&quot;StringList&quot;,
&quot;description&quot;:&quot;(Required) Specify a shell script or a command to run.&quot;,
&quot;minItems&quot;:1,
&quot;displayType&quot;:&quot;textarea&quot;
&quot;default&quot;:&quot;{{ssm:runcommand:2}}&quot;
},
&quot;executionTimeout&quot;:{
&quot;type&quot;:&quot;String&quot;,
&quot;default&quot;:&quot;3600&quot;,
&quot;description&quot;:&quot;(Optional) The time in seconds for a command to complete before it is considered to have failed. Default is 3600 (1 hour). Maximum is 28800 (8 hours).&quot;,
&quot;allowedPattern&quot;:&quot;([1-9][0-9]{0,3})|(1[0-9]{1,4})|(2[0-7][0-9]{1,3})|(28[0-7][0-9]{1,2})|(28800)&quot;
}
},
&quot;runtimeConfig&quot;:{
&quot;aws:runShellScript&quot;:{
&quot;properties&quot;:[
{
&quot;id&quot;:&quot;0.aws:runShellScript&quot;,
&quot;runCommand&quot;:&quot;{{ commands }}&quot;,
&quot;timeoutSeconds&quot;:&quot;{{ executionTimeout }}&quot;
}
]
}
}
}</code></pre> 
<p><strong>Summary</strong><br /> Parameter Store provides a centralized, encrypted store to manage your configuration data, whether it is plain text data (database strings) or secure strings and secrets (such as passwords, and API keys). Use versioning to add an extra layer of protection for your Parameter Store values.&nbsp;This new feature is available now and you can start using it today!</p> 
<p><strong>About the author</strong></p> 
<p><img class="wp-image-1600 size-thumbnail alignleft" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/23/LouDelat-150x150.jpg" alt="" width="150" height="150" />Lou De La Torre is a Partner Solutions Architect with Amazon Web Services. Lou is responsible for assisting Partners and Customers alike with their AWS for Windows architectures and migration strategies. With a career in information technology that spans more than two decades, Lou brings a significant amount of expertise in cloud and systems architecture, systems management, disaster recovery, process improvement and compliance management. Lou consistently strives to ensure that he is delivering solutions that align with the needs and requirements of his customer’s business objectives, while alleviating any pain points they may be experiencing in their IT operations.</p> 
<p>&nbsp;</p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/mt/tag/aws-systems-manager/" rel="tag">AWS Systems Manager</a>, <a href="https://aws.amazon.com/blogs/mt/tag/configuration-secrets/" rel="tag">Configuration Secrets</a>, <a href="https://aws.amazon.com/blogs/mt/tag/ec2-systems-manager/" rel="tag">EC2 Systems Manager</a>, <a href="https://aws.amazon.com/blogs/mt/tag/ec2-windows/" rel="tag">EC2 Windows</a>, <a href="https://aws.amazon.com/blogs/mt/tag/parameter-store/" rel="tag">Parameter Store</a></span> 
</footer> 
</article> 
<p>
© 2017, Amazon Web Services, Inc. or its affiliates. All rights reserved.
</p>

    </div>
  </div>
</div>


    <div id="footer" class="navigation hidden-print">
      <div class="container">
        <div class="row">
          <div class="col-xs-12">
            <ul class="footer-links nav navbar-nav">
              <li><a href="../aws.html">AWS</a></li>
              <li><a href="../linux.html">Linux</a></li>
              <li><a href="../docker.html">Docker</a></li>
              <li><a href="../ibmpower.html">IBM Power</a></li>
              <li><a href="blogsataws1.html">Blogs@AWS (Kindle Friendly)</a></li>
            </ul>
            <ul class="footer-links nav navbar-nav navbar-right">
              <li><a href="../comments.html">Comments?</a></li>
            </ul>
          </div>
        </div>
      </div>
    </div>
  </body>
</html>
