<!DOCTYPE html>
<html lang="en">
  <head>
<!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-593498H');</script>
<!-- End Google Tag Manager -->

    <meta charset="utf-8">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">

    <meta name="msapplication-config" content="/microsoft-tile.xml" />
    <meta name="theme-color" content="#ffffff">

    <meta property="og:url" content="https://bejoycalias.github.io/blogsataws/apnblogs1.html" />
    <meta property="og:site_name" content="Bejoy's TechNotes"/>
    <meta property="og:title" content="Bejoy's TechNotes - Kindle Friendly AWS APN Blogs" />
    <meta property="og:image" content="https://bejoycalias.github.io/assets/images/og-image.png"/>
    <meta property="og:image:width" content="1200"/>
    <meta property="og:image:height" content="1200"/>
    <meta property="og:description" content="" />

    <title>Bejoy's TechNotes - Kindle Friendly AWS APN Blogs</title>
    <link href="../assets/stylesheets/application-832aa42c.css" rel="stylesheet" />

    <!--[if lt IE 9]>
      <script src="../assets/javascripts/ie-compat-c141a02d.js"></script>
    <![endif]-->
    <script src="../assets/javascripts/application-ff53d307.js"></script>

    <!-- Typekit script to import Klavika font -->
    <script src="https://use.typekit.net/wxf7mfi.js"></script>
    <script>try{Typekit.load({ async: true });}catch(e){}</script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-100043608-1', 'auto');
  ga('send', 'pageview');

</script>

    
  </head>

  <body id="uh-oh-" class="layout-inner page-uh-oh-">
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-593498H"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->


    <div id="header" class="navigation navbar-static-top hidden-print">
      <div class="container">
        <div class="row">
          <div class="col-xs-12">
            <div class="navbar-header">
              <div class="navbar-brand">
                <a href="/">
                  <svg version="1.0" xmlns="http://www.w3.org/2000/svg" width="135.000000pt" height="50" viewbox="0 0 135.000000 45.000000" preserveaspectratio="xMidYMid meet" class="logo">

<g transform="translate(0.000000,45.000000) scale(0.100000,-0.100000)" fill="#000000" stroke="none">
<path class="text" fill="#000000" d="M527 384 c-4 -4 -7 -18 -7 -31 0 -21 4 -24 28 -21 21 2 27 8 27 28 0
18 -6 26 -20 28 -12 2 -24 0 -28 -4z"></path>
<path class="text" fill="#000000" d="M1080 335 c0 -48 2 -55 20 -55 18 0 20 7 20 55 0 48 -2 55 -20 55
-18 0 -20 -7 -20 -55z"></path>
<path class="text" fill="#000000" d="M54 357 c-2 -7 -3 -69 -2 -138 l3 -124 65 -3 c90 -3 130 20 130 77 0
29 -6 44 -20 54 -20 14 -20 15 -3 45 14 25 15 34 5 56 -6 15 -23 31 -38 36
-38 15 -134 13 -140 -3z m110 -33 c19 -7 21 -45 4 -62 -7 -7 -22 -12 -35 -12
-20 0 -23 5 -23 40 0 41 13 50 54 34z m20 -130 c19 -18 19 -20 6 -45 -8 -13
-21 -19 -45 -19 -34 0 -35 1 -35 40 0 38 2 40 29 40 16 0 37 -7 45 -16z"></path>
<path class="text" fill="#000000" d="M319 271 c-23 -24 -29 -38 -29 -74 0 -25 3 -53 6 -62 20 -50 164 -64
164 -15 0 15 -7 17 -45 12 -46 -5 -75 8 -75 34 0 11 16 14 65 14 l65 0 0 35
c0 80 -92 114 -151 56z m99 -33 c3 -15 -4 -18 -37 -18 -43 0 -50 7 -29 28 18
18 62 11 66 -10z"></path>
<path class="text" fill="#000000" d="M520 184 c0 -107 -1 -116 -20 -121 -11 -3 -20 -12 -20 -19 0 -21 76
-19 84 2 3 9 6 69 6 135 l0 119 -25 0 -25 0 0 -116z"></path>
<path class="text" fill="#000000" d="M649 271 c-24 -25 -29 -37 -29 -78 1 -70 34 -103 105 -103 55 0 95
44 95 103 0 60 -7 75 -41 92 -47 25 -96 19 -130 -14z m111 -30 c25 -48 2 -111
-40 -111 -45 0 -69 80 -34 114 21 22 61 20 74 -3z"></path>
<path class="text" fill="#000000" d="M850 287 c0 -8 16 -57 36 -110 28 -76 33 -100 25 -116 -16 -28 -14
-31 18 -31 27 0 29 4 70 123 23 67 41 128 41 135 0 6 -11 12 -24 12 -21 0 -26
-8 -41 -65 -10 -36 -21 -68 -25 -70 -3 -2 -16 27 -29 66 -19 60 -25 69 -47 69
-13 0 -24 -6 -24 -13z"></path>
<path class="text" fill="#000000" d="M1192 284 c-17 -12 -22 -24 -20 -47 2 -26 10 -36 45 -52 49 -23 59
-55 17 -55 -14 0 -34 5 -45 10 -16 9 -19 7 -19 -13 0 -17 7 -27 23 -31 69 -18
117 6 117 60 0 32 -4 37 -45 55 -60 26 -62 54 -4 46 37 -5 40 -3 37 16 -2 18
-11 23 -43 25 -25 2 -49 -3 -63 -14z"></path>
</g>
</svg>

                </a>
              </div>
              <button class="navbar-toggle" type="button">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
              </button>
            </div>
            <div class="buttons hidden-xs">
              <nav class="navigation-links" role="navigation">
                <ul class="main-links nav navbar-nav navbar-right">
                  <li><a href="../aws.html">AWS</a></li>
                  <li><a href="../linux.html">Linux</a></li>
                  <li><a href="../docker.html">Docker</a></li>
                  <li><a href="../ibmpower.html">IBM Power</a></li>
                  <li><a href="blogsataws1.html">Blogs@AWS (Kindle Friendly)</a></li>
                </ul>
              </nav>
            </div>
          </div>
        </div>
      </div>
    </div>

    <div class="sidebar-overlay"></div>

<aside class="sidebar" role="navigation">
  <div class="sidebar-header">
    <svg version="1.0" xmlns="http://www.w3.org/2000/svg" width="135.000000pt" height="42" viewbox="0 0 135.000000 45.000000" preserveaspectratio="xMidYMid meet">

<g transform="translate(0.000000,45.000000) scale(0.100000,-0.100000)" fill="#000000" stroke="none">
<path class="text" fill="#000000" d="M527 384 c-4 -4 -7 -18 -7 -31 0 -21 4 -24 28 -21 21 2 27 8 27 28 0
18 -6 26 -20 28 -12 2 -24 0 -28 -4z"></path>
<path class="text" fill="#000000" d="M1080 335 c0 -48 2 -55 20 -55 18 0 20 7 20 55 0 48 -2 55 -20 55
-18 0 -20 -7 -20 -55z"></path>
<path class="text" fill="#000000" d="M54 357 c-2 -7 -3 -69 -2 -138 l3 -124 65 -3 c90 -3 130 20 130 77 0
29 -6 44 -20 54 -20 14 -20 15 -3 45 14 25 15 34 5 56 -6 15 -23 31 -38 36
-38 15 -134 13 -140 -3z m110 -33 c19 -7 21 -45 4 -62 -7 -7 -22 -12 -35 -12
-20 0 -23 5 -23 40 0 41 13 50 54 34z m20 -130 c19 -18 19 -20 6 -45 -8 -13
-21 -19 -45 -19 -34 0 -35 1 -35 40 0 38 2 40 29 40 16 0 37 -7 45 -16z"></path>
<path class="text" fill="#000000" d="M319 271 c-23 -24 -29 -38 -29 -74 0 -25 3 -53 6 -62 20 -50 164 -64
164 -15 0 15 -7 17 -45 12 -46 -5 -75 8 -75 34 0 11 16 14 65 14 l65 0 0 35
c0 80 -92 114 -151 56z m99 -33 c3 -15 -4 -18 -37 -18 -43 0 -50 7 -29 28 18
18 62 11 66 -10z"></path>
<path class="text" fill="#000000" d="M520 184 c0 -107 -1 -116 -20 -121 -11 -3 -20 -12 -20 -19 0 -21 76
-19 84 2 3 9 6 69 6 135 l0 119 -25 0 -25 0 0 -116z"></path>
<path class="text" fill="#000000" d="M649 271 c-24 -25 -29 -37 -29 -78 1 -70 34 -103 105 -103 55 0 95
44 95 103 0 60 -7 75 -41 92 -47 25 -96 19 -130 -14z m111 -30 c25 -48 2 -111
-40 -111 -45 0 -69 80 -34 114 21 22 61 20 74 -3z"></path>
<path class="text" fill="#000000" d="M850 287 c0 -8 16 -57 36 -110 28 -76 33 -100 25 -116 -16 -28 -14
-31 18 -31 27 0 29 4 70 123 23 67 41 128 41 135 0 6 -11 12 -24 12 -21 0 -26
-8 -41 -65 -10 -36 -21 -68 -25 -70 -3 -2 -16 27 -29 66 -19 60 -25 69 -47 69
-13 0 -24 -6 -24 -13z"></path>
<path class="text" fill="#000000" d="M1192 284 c-17 -12 -22 -24 -20 -47 2 -26 10 -36 45 -52 49 -23 59
-55 17 -55 -14 0 -34 5 -45 10 -16 9 -19 7 -19 -13 0 -17 7 -27 23 -31 69 -18
117 6 117 60 0 32 -4 37 -45 55 -60 26 -62 54 -4 46 37 -5 40 -3 37 16 -2 18
-11 23 -43 25 -25 2 -49 -3 -63 -14z"></path>
</g>
</svg>

  </div>

  <ul class="nav sidebar-nav">
    <li><a href="../aws.html">AWS</a></li>
    <li><a href="../linux.html">Linux</a></li>
    <li><a href="../docker.html">Docker</a></li>
    <li><a href="../ibmpower.html">IBM Power</a></li>
    <li><a href="blogsataws1.html">Blogs@AWS (Kindle Friendly)</a></li>
  </ul>
</aside>


    <div class="container">
  <div class="row">
    <div id="docs-sidebar" class="col-sm-3 col-md-3 col-xs-12 hidden-print" role="complementary">
      <ul class="nav docs-sidenav">
      <li><a href="blogsataws1.html">Blogs @ AWS</a></li>
      <li><a href="whatsnew1.html">What's New @ AWS</a></li>
      <li><a href="secblogs1.html">Security Blogs @ AWS</a></li>
      <li><a href="computeblogs1.html">Compute Blogs @ AWS</a></li>
      <li class="active"><a href="apnblogs1.html">APN Blogs @ AWS</a></li>
      <li><a href="devopsblogs1.html">DevOps Blogs @ AWS</a></li>
      <li><a href="mgmtblogs1.html">Management Tools Blogs @ AWS</a></li>

    </ul>
    </div>

    <div id="inner" class="col-sm-9 col-md-9 col-xs-12" role="main">
<p></p>
<p><i>Contents of this page is copied directly from AWS blog sites to make it Kindle friendly. Some styles & sections from these pages are removed to render this properly in 'Article Mode' of Kindle e-Reader browser. All the contents of this page is property of AWS.</i></p>
<p><a href="apnblogs1.html">Page 1</a>|<a href="apnblogs2.html">Page 2</a>|<a href="apnblogs3.html">Page 3</a>|<a href="apnblogs4.html">Page 4</a</p>
<br>
<article class="post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b><a href="https://aws.amazon.com/blogs/apn/how-an-investment-firm-collaborated-with-hashicorp-and-aws-to-enhance-their-secrets-management/" property="url" rel="bookmark"><span property="name headline">How an investment firm collaborated with HashiCorp and AWS to enhance their secrets management</span></a></b> 
<footer class="meta">
by 
<span property="author" typeof="Person"><span property="name">Peter Sideris</span></span> | on 
<time property="datePublished" datetime="2017-09-18T15:42:26+00:00">18 SEP 2017</time> | in 
<span class="categories"><a href="https://aws.amazon.com/blogs/apn/category/compute/amazon-ec2/" title="View all posts in Amazon EC2*"><span property="articleSection">Amazon EC2*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/apn-partner-highlight/" title="View all posts in APN Partner Highlight"><span property="articleSection">APN Partner Highlight</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/security-identity-compliance/aws-identity-and-access-management-iam/" title="View all posts in AWS Identity and Access Management (IAM)*"><span property="articleSection">AWS Identity and Access Management (IAM)*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/compute/aws-lambda/" title="View all posts in AWS Lambda*"><span property="articleSection">AWS Lambda*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/financial-services/" title="View all posts in Financial Services"><span property="articleSection">Financial Services</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/iam/" title="View all posts in IAM"><span property="articleSection">IAM</span></a></span> | 
<a href="https://aws.amazon.com/blogs/apn/how-an-investment-firm-collaborated-with-hashicorp-and-aws-to-enhance-their-secrets-management/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-4962" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-apn-blog&amp;disqus_identifier=4962&amp;disqus_title=How+an+investment+firm+collaborated+with+HashiCorp+and+AWS+to+enhance+their+secrets+management&amp;disqus_url=https://aws.amazon.com/blogs/apn/how-an-investment-firm-collaborated-with-hashicorp-and-aws-to-enhance-their-secrets-management/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-4962');
});
</script> | 
<a href="#" role="button" data-share-dialog=""><span class="span icon-share"></span>&nbsp;Share</a> 
<ul> 
</ul> 
</footer> 
<h5></h5> 
<p>Bridgewater Associates, based in Westport, CT, is a major investment management firm with more than $150 billion in assets that it manages for a global customer base of pension funds, endowments, foundations, central banks, and national governments. It is also an Amazon Web Services (AWS) customer that we’ve worked closely with over the past year and half, developing a partnership that helps Bridgewater leverage the tools—and benefits—of the AWS Cloud.</p> 
<p>Last December, Bridgewater Systems Engineer Joel Thompson approached us with questions around the features and future roadmap of the GetCallerIdentity API call. He also mentioned work that he was doing with APN Technology Partner HashiCorp to solve the challenge of <a href="https://www.vaultproject.io/" target="_blank" rel="noopener noreferrer">HashiCorp Vault</a> authentication in scalable and serverless environments.</p> 
<p>In their own words, here’s how Joel and HashiCorp Product Manager Andy Manoske describe what happened next.</p> 
<h3>Joel Thompson, Bridgewater Systems Engineer</h3> 
<blockquote> 
<p>Our business requires us to be highly focused on security. For that reason, we’ve been big fans of HashiCorp’s Vault since it was first released. However, we faced the challenge of how to securely authenticate to Vault from various AWS services, such as from Amazon Elastic Compute Cloud (Amazon EC2) instances in an autoscaling group, code running in AWS Lambda (Lambda), and other environments. We were not alone in this either. Many in the financial services industry have long been asking for a solution to this problem.</p> 
<p>&nbsp;</p> 
<p>One of my coworkers proposed a&nbsp;<a href="https://github.com/hashicorp/vault/issues/948" target="_blank" rel="noopener noreferrer">solution</a>&nbsp;that, to work properly, required AWS to add a new API method – the WhoAmI method that is a feature we requested from our AWS Enterprise Support team. Last year, AWS added what was needed — <a href="http://docs.aws.amazon.com/STS/latest/APIReference/API_GetCallerIdentity.html" target="_blank" rel="noopener noreferrer">sts:GetCallerIdentity</a>. So, collaborating with the Vault engineering team and consulting with AWS support, the&nbsp;<a href="https://www.vaultproject.io/docs/auth/aws.html" target="_blank" rel="noopener noreferrer">AWS authentication backend</a>&nbsp;in Vault was born, making it easier for AWS customers to secure their cloud-native applications.</p> 
</blockquote> 
<h3>Andy Manoske, HashiCorp Product Manager</h3> 
<blockquote> 
<p>HashiCorp&nbsp;has created six open-source projects to enable organizations to provision, secure, connect, and run any infrastructure for any application. This is particularly important for organizations that are migrating their workloads to cloud services such as AWS. HashiCorp Vault is one of those projects, providing a focus on securing any infrastructure for any application. Vault provides secrets management, encryption as a service, and a way to enforce privilege and access management.</p> 
<p>Vault is an open-source project, with a growing community of contributors, users, and HashiCorp employees collaborating on the features that go into Vault. One example of this was a major enhancement in Vault 0.7.1 to the AWS-Amazon EC2 authentication backend. The enhancement now makes it easy for many different AWS resource types to securely authenticate with Vault.&nbsp; Given the broadened scope of what this backend can now do it has been &nbsp;renamed to the AWS authentication backend. &nbsp;This backend solved a series of challenges we were seeing within the open-source community and our customer base around securely enabling access to secrets from an AWS-based infrastructure. AWS resources can then access and use the secrets managed by Vault. This includes resources such as Lambda functions, Amazon EC2 Container Services jobs, Amazon EC2 instances, or any other client with access to AWS Identity and Access Management credentials can use those credentials to securely authenticate to Vault to retrieve their secrets.</p> 
<p>&nbsp;</p> 
<p>The AWS authentication backend is an enhancement that was contributed and collaborated on by Joel Thompson at Bridgewater. Through Bridgewater’s use of Vault, Joel recognized a more specific enhancement to the authentication backend and then worked with the HashiCorp Vault engineers to make it a reality.</p> 
<p>&nbsp;</p> 
</blockquote> 
<p>Through this engagement, which included assistance from AWS Enterprise Support to help them plan and build the solution using best practices and guidance from the AWS Identity service team, Bridgewater and HashiCorp were able to quickly and confidently collaborate on an important Vault feature.</p> 
<p><em>To learn more about the collaboration, read Joel’s post on the <a href="https://www.hashicorp.com/blog/bridgewater-securing-their-aws-infrastructure-with-vault/" target="_blank" rel="noopener noreferrer">HashiCorp blog</a>. And <a href="https://aws.amazon.com/premiumsupport/enterprise-support/" target="_blank" rel="noopener noreferrer">go here to learn more about how AWS Enterprise Support can help your organization</a>.</em></p> 
</article> 
<article class="post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b><a href="https://aws.amazon.com/blogs/apn/enabling-amazon-connect-with-salesforce-service-and-sales-cloud/" property="url" rel="bookmark"><span property="name headline">Enabling Amazon Connect with Salesforce Service Cloud and Sales Cloud</span></a></b> 
<footer class="meta">
by 
<span property="author" typeof="Person"><span property="name">Marc Rudkowski</span></span> | on 
<time property="datePublished" datetime="2017-09-12T09:23:35+00:00">12 SEP 2017</time> | in 
<span class="categories"><a href="https://aws.amazon.com/blogs/apn/category/apn-partner-highlight/" title="View all posts in APN Partner Highlight"><span property="articleSection">APN Partner Highlight</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/aws-product-launch/" title="View all posts in AWS Product Launch"><span property="articleSection">AWS Product Launch</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/contact-center/" title="View all posts in Contact Center*"><span property="articleSection">Contact Center*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/apn/enabling-amazon-connect-with-salesforce-service-and-sales-cloud/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-5004" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-apn-blog&amp;disqus_identifier=5004&amp;disqus_title=Enabling+Amazon+Connect+with+Salesforce+Service+Cloud+and+Sales+Cloud&amp;disqus_url=https://aws.amazon.com/blogs/apn/enabling-amazon-connect-with-salesforce-service-and-sales-cloud/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-5004');
});
</script> | 
<a href="#" role="button" data-share-dialog=""><span class="span icon-share"></span>&nbsp;Share</a> 
<ul> 
</ul> 
</footer> 
<p>Building on the strategic alliance between Amazon Web Services and Salesforce, we are excited to announce the first release of the <strong>Amazon Connect Computer Telephony Integration (CTI) Adapter for Salesforce</strong>.</p> 
<p>Amazon Connect is designed as a highly scalable, self-service, cloud-based contact center service that makes it easy for any business to deliver better customer service at lower cost. Salesforce Service Cloud empowers agents on the path to customer success with smarter and faster service tools. Now, the Amazon Connect contact center service and Salesforce’s customer relationship management (CRM) work together to provide the essential foundation for your organization’s customer service experience. This helps support integrated customer workflows between interactive voice response (IVR), automatic call distributor (ACD), and CRM – all critical to contact center strategies.</p> 
<p>The Amazon Connect CTI Adapter is the first release of the package that is designed to provide complete cloud-based integration and workflow capabilities between Amazon Connect, Salesforce Service Cloud and Sales Cloud.</p> 
<p>The Amazon Connect CTI Adapter provides a WebRTC browser-based contact control panel (CCP) within the Salesforce Lightning, Console, and Classic CRM experience. This CTI integration gives your agents the ability to leverage both inbound caller ID screen pop-ups and outbound click to call/transfer/conferencing.<br /> <img class="size-full wp-image-5005 aligncenter" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/09/06/Connect1.png" alt="" width="890" height="468" /></p> 
<h5 style="text-align: center"></h5> 
<h5 style="text-align: center">Agent logging a screen pop call from the Amazon Connect Contact Control Panel (CCP) within the Salesforce Service Cloud Lightning experience</h5> 
<h5></h5> 
<b>Getting Started</b> 
<p>If you have not spun up an Amazon Connect instance, take a look at our <a href="http://docs.aws.amazon.com/connect/latest/adminguide/gettingstarted.html" target="_blank" rel="noopener noreferrer">Getting Started Guide</a>. The Amazon Connect CTI Adapter integration leverages both the <a href="https://github.com/aws/amazon-connect-streams" target="_blank" rel="noopener noreferrer">Amazon Connect Streams API</a> and the <a href="https://developer.salesforce.com/docs/atlas.en-us.api_cti.meta/api_cti/sforce_api_cti_intro.htm" target="_blank" rel="noopener noreferrer">Salesforce Open CTI API</a>. In this blog post, we’re going to focus on setting up the Amazon Connect CTI Adapter for Lightning experience. You can follow the <a href="http://docs.aws.amazon.com/connect/latest/adminguide/salesforce-integration.html" target="_blank" rel="noopener noreferrer">setup instructions</a> for enabling the CTI Adapter for the Salesforce Classic and Console experience.</p> 
<h3>Step 1: Install the Amazon Connect CTI Adapter</h3> 
<p>Once you have your Amazon Connect and Salesforce CRM instances running, the first step will be to install the <strong>Amazon Connect CTI Adapter</strong> from the <a href="https://appexchange.salesforce.com/listingDetail?listingId=a0N3A00000EJH4yUAH" target="_blank" rel="noopener noreferrer">Salesforce AppExchange</a>:</p> 
<p>&nbsp;</p> 
<p><img class="size-full wp-image-5006 aligncenter" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/09/06/Connect2.png" alt="" width="975" height="513" /></p> 
<p>&nbsp;</p> 
<p>We recommend you initially install the package into your Salesforce sandbox.</p> 
<h3>Step 2: Configure your Salesforce Call Center</h3> 
<p>After the package has been installed, the next step is to set up your Salesforce call center configuration. This configuration is a XML file you import into your call center, which provides all the details required to enable the Amazon Connect CTI Adapter. First, <a href="http://amazonconnect-sfdc-installation.s3-website-us-east-1.amazonaws.com/resources/24AC4F3F034E447BE9CEAEE5CA37BFC3.xml" target="_blank" rel="noopener noreferrer">download</a> the call center XML configuration and import it into your Lightning call center configuration:</p> 
<p>&nbsp;</p> 
<p><img class="size-full wp-image-5007 aligncenter" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/09/06/Connect3.png" alt="" width="975" height="313" /></p> 
<p>&nbsp;</p> 
<p>Edit the call center configuration and verify the following:</p> 
<p>&nbsp;</p> 
<p><img class="size-full wp-image-5008 aligncenter" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/09/06/Connect4.png" alt="" width="975" height="677" /></p> 
<p>&nbsp;</p> 
<ol> 
<li>The suffix for the Amazon Connect CTI Adapter URL is set to Lightning. If you were configuring the Amazon Connect CTI Adapter for Classic or Console, those suffixes would be used instead.</li> 
<li>Salesforce Compatibility Mode is set for Lightning. This would be set to Classic if you were configuring for Classic or Console.</li> 
<li>The Amazon Connect CCP URL is set to your Amazon Connect instance name. (replace YOURINSTANCENAME with your Amazon Connect instance name).</li> 
<li>If you are using this in another country (i.e. Great Britain), set the appropriate two digit ISO country code.</li> 
<li>Provide access to users (i.e. admins, supervisors, agents) who will be using the CCP.</li> 
</ol> 
<h3>Step 3: Whitelist Your Salesforce’s Visualforce Domain</h3> 
<p>At this point, you have properly configured your Salesforce instance. The next step is to whitelist your Salesforce Visualforce domain within your Amazon Connect’s Application integration. This is required from a security perspective to ensure you are allowing cross-domain access to your Amazon Connect instance. More information about whitelisting can be found on the <a href="https://github.com/aws/amazon-connect-streams" target="_blank" rel="noopener noreferrer">Amazon Connect Streams documentation</a>.</p> 
<p>&nbsp;</p> 
<p><img class="size-full wp-image-5009 aligncenter" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/09/06/Connect5.png" alt="" width="975" height="278" /></p> 
<p>&nbsp;</p> 
<p>If you’re unsure of the Salesforce Visualforce domain, or if it is getting blocked by Amazon Connect, you can find it by previewing the URL of the Amazon Connect Visualforce page within your Salesforce instance.</p> 
<p>&nbsp;</p> 
<p><img class="size-full wp-image-5010 aligncenter" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/09/06/Connect6.png" alt="" width="975" height="394" /></p> 
<p>&nbsp;</p> 
<b>Testing the Amazon Connect CTI Adapter</b> 
<p>Now that you have everything configured, let’s give this a go. Open your Chrome or Firefox browser and login to your Amazon Connect instance (https://YOURINSTANCENAME.awsapps.com/connect/login). Open another tab and log into your Salesforce CRM instance and go to your Sales or Service Console Lightning application.</p> 
<p>&nbsp;</p> 
<p><img class="size-full wp-image-5011 aligncenter" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/09/06/Connect7.png" alt="" width="927" height="490" /></p> 
<p>&nbsp;</p> 
<p>If you are not seeing the phone icon or an empty pop-up, take a look at our troubleshooting guide in the <a href="http://docs.aws.amazon.com/connect/latest/adminguide/salesforce-integration.html" target="_blank" rel="noopener noreferrer">setup instructions</a>. You should notice that all numbers have a phone icon next to them. At this point, you can leverage the click-to-call capability when you press the icon or number.</p> 
<p>&nbsp;</p> 
<p><img class="size-full wp-image-5012 aligncenter" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/09/06/Connect8.png" alt="" width="878" height="465" /></p> 
<p>&nbsp;</p> 
<p>It will make an outbound call via the Amazon Connect CCP and connect to the customer when they answer the call.</p> 
<p>&nbsp;</p> 
<p><img class="size-full wp-image-5013 aligncenter" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/09/06/Connect9.png" alt="" width="945" height="497" /></p> 
<p>&nbsp;</p> 
<p>Once you complete the call, the Amazon Connect CCP will go into AfterCallWork status where the agent can perform any follow up activities (e.g. logging a call). After these activities are completed, they can make themselves available to take more calls.</p> 
<p>&nbsp;</p> 
<p><img class="size-full wp-image-5014 aligncenter" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/09/06/Connect10.png" alt="" width="909" height="484" /></p> 
<p>&nbsp;</p> 
<p>If the agent is in an available state and they receive a call, the inbound call will screen pop the Amazon Connect CCP and any matching records for the caller ID.</p> 
<p>&nbsp;</p> 
<p><img class="size-full wp-image-5015 aligncenter" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/09/06/Connect11.png" alt="" width="975" height="518" /></p> 
<p>&nbsp;</p> 
<p>You can also configure the screen pop behavior in the Softphone layouts under your Salesforce call center configuration.</p> 
<p>&nbsp;</p> 
<p><img class="size-full wp-image-5016 aligncenter" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/09/06/Connect12.png" alt="" width="975" height="834" /></p> 
<p>&nbsp;</p> 
<b>What’s next</b> 
<p>This is the first release of the Amazon Connect CTI Adapter for Salesforce. More features are coming soon as AWS determines how to best provide more integrated capabilities with Salesforce Service and Sales Cloud. Please try out the Amazon Connect CTI Adapter and open a case with your feedback. We value your input because it will help us define our next set of features.</p> 
<p>For more information also refer to last March <a href="https://www.salesforce.com/company/news-press/press-releases/2017/03/170328-3.jsp" target="_blank" rel="noopener noreferrer">press release</a>.</p> 
</article> 
<article class="post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b><a href="https://aws.amazon.com/blogs/apn/aws-partner-network-apn-partner-sa-roundup-september-2017/" property="url" rel="bookmark"><span property="name headline">AWS Partner Network (APN) Partner SA Roundup – September 2017</span></a></b> 
<footer class="meta">
by 
<span property="author" typeof="Person"><span property="name">Ian Scofield</span></span> | on 
<time property="datePublished" datetime="2017-09-11T17:00:19+00:00">11 SEP 2017</time> | in 
<span class="categories"><a href="https://aws.amazon.com/blogs/apn/category/amazon-ecs/" title="View all posts in Amazon ECS"><span property="articleSection">Amazon ECS</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/aws-partner-solutions-architect-sa-guest-post/" title="View all posts in AWS Partner Solutions Architect (SA) Guest Post"><span property="articleSection">AWS Partner Solutions Architect (SA) Guest Post</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/devops/" title="View all posts in DevOps*"><span property="articleSection">DevOps*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/networking-content-delivery/elastic-load-balancing/" title="View all posts in Elastic Load Balancing*"><span property="articleSection">Elastic Load Balancing*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/partner-guest-post/" title="View all posts in Partner Guest Post"><span property="articleSection">Partner Guest Post</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/saas-on-aws/" title="View all posts in SaaS on AWS"><span property="articleSection">SaaS on AWS</span></a></span> | 
<a href="https://aws.amazon.com/blogs/apn/aws-partner-network-apn-partner-sa-roundup-september-2017/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-5024" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-apn-blog&amp;disqus_identifier=5024&amp;disqus_title=AWS+Partner+Network+%28APN%29+Partner+SA+Roundup+%E2%80%93+September+2017&amp;disqus_url=https://aws.amazon.com/blogs/apn/aws-partner-network-apn-partner-sa-roundup-september-2017/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-5024');
});
</script> | 
<a href="#" role="button" data-share-dialog=""><span class="span icon-share"></span>&nbsp;Share</a> 
<ul> 
</ul> 
</footer> 
<p>This month, we have three Partner Solutions Architects who will be highlighting four APN Partners they’ve been working with.&nbsp; We will hear from David Potes, Chris Hein, and Pratap Ramamurthy, who will dive deeper into offerings from JFrog, Linkerd, Solodev, and Sparkpost!</p> 
<h3>JFrog, by David Potes</h3> 
<p>&nbsp;</p> 
<p class="alignnone"><img class="size-full wp-image-5025 alignleft" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/09/11/SeptRoundup1.png" alt="" width="242" height="212" />&nbsp;A few months ago, I had the opportunity to attend the <a href="https://swampup.jfrog.com/" target="_blank" rel="noopener noreferrer">JFrog Swampup</a> conference in Napa, California. Not only do they have an impressive list of customers, including Amazon, but they also have a few interesting products. The energy and enthusiasm that I felt from the community there really piqued my interest, so I took some time to dive into one of their key offerings. JFrog is all about open source, and the product I’m focusing on today, <a href="https://www.jfrog.com/confluence/display/RTF/Welcome+to+Artifactory" target="_blank" rel="noopener noreferrer">JFrog Artifactory</a>, has a free open source version. They also offer enhanced versions with enterprise features and a SaaS-delivered version, for customers that would rather leave operations to someone else.</p> 
<p>As companies of all sizes have embraced open source technology, their development processes have evolved from primarily using proprietary in-house coding to an amalgamation of free open source libraries, commercial libraries, as well as their own code. Just as in modern manufacturing, code is often assembled from components rather than developed from scratch. The benefits of this approach are well-documented, but using open source or commercial libraries introduces a few new challenges, too.</p> 
<p>The biggest challenge is managing complexity. Often companies have a polyglot of languages they support, packages of various types and system artifacts such as Docker and Vagrant images. Each of these can have its own upstream and downstream dependencies, versions, licenses, and traceability data. The aim of a universal package manager, such as JFrog Artifactory, is to standardize the way that organizations manage all package types used in the software development process.</p> 
<p>Just as teams adopted version control systems for source control, many companies are now adopting package management systems for binary artifacts. Below are a few key things to look for as you are evaluating an artifact repository.</p> 
<p><strong>Highly available access to remote artifacts</strong>. A package control system can act as an intermediate cache for remote repositories. This is known as a remote repository, though the parlance is a bit confusing. By acting as a proxy and a caching system, the tool is designed to provide faster access to binaries, as well as limit the blast radius, when an external repository is temporarily unavailable (or even permanently).</p> 
<p><strong>Full integration with your DevOps toolchain</strong>. Just as with source control, an artifact repository is at the center of your toolchain processes, so it’s critical for it to integrate with the tools that you use (or ones that you may use in the future). JFrog has a staggering number of integrations; everything from CI servers like Jenkins and Bamboo, remote repositories like Nuget and Github, to provisioning tools like Chef and Puppet and familiar names like Maven, Gradle, and Ivy.</p> 
<p><strong>Security and Access Control</strong>. Controlling access to entire repositories down to individual artifacts is a key feature, but also look for the ability to integrate existing access controls via LDAP or SAML. JFrog supports this functionality, as well limiting what can be downloaded to the virtual repository via blacklisting/whitelisting.</p> 
<p><strong>License governance</strong>. With a tool like JFrog Artifactory, you can scan the licensing requirements for any packages you download to the repository and provide immediate feedback on the package and its dependencies. This allows you to make sure you’re compliant early on in the development cycle, and prevent unnecessary delays when it’s time to go to production.</p> 
<p>I’ve only scratched the surface on what you can do with JFrog Artifactory, and I plan to revisit this for a deeper dive in the future. In the meantime, if you’d like to give it a try yourself, JFrog offers a free trial for the <a href="https://www.jfrog.com/artifactory/free-trial/#Pro" target="_blank" rel="noopener noreferrer">Pro</a> and <a href="https://www.jfrog.com/artifactory/free-trial/#Cloud" target="_blank" rel="noopener noreferrer">SaaS</a> versions, or you can just <a href="https://www.jfrog.com/open-source/" target="_blank" rel="noopener noreferrer">grab the open source version</a> and see for yourself.</p> 
<p>&nbsp;</p> 
<h3>Linkerd, by Chris Hein</h3> 
<p>&nbsp;</p> 
<p><img class="alignleft wp-image-5026 size-medium" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/09/11/SeptRoundup2-300x112.png" alt="" width="300" height="112" />When building a distributed system, you have to deal with the challenges of making reliable/resilient requests from one service to another. While the underlying Transmission Control Protocol (TCP) layer can take care of packet-level reliability, request-level reliability–retries, timeouts, load balancing, circuit breaking, discovery, and so on–is relegated to application code. The advent of containers and automated container orchestration has only amplified these issues by making microservices easier to adopt than ever.</p> 
<p>In the past, large scale companies developed OSS toolchains like <a href="https://medium.com/airbnb-engineering/smartstack-service-discovery-in-the-cloud-4b8a080de619" target="_blank" rel="noopener noreferrer">SmartStack</a> and <a href="https://medium.com/netflix-techblog/prana-a-sidecar-for-your-netflix-paas-based-applications-and-services-258a5790a015" target="_blank" rel="noopener noreferrer">Prana</a> to offload this logic from the application and into a dedicated network proxy which handles requests going from one service to another. Although these solutions work, they’re tied to specific technology choices such as <a href="https://zookeeper.apache.org/" target="_blank" rel="noopener noreferrer">ZooKeeper</a> or <a href="https://github.com/Netflix/eureka" target="_blank" rel="noopener noreferrer">Eureka</a>.</p> 
<p>Enter <a href="https://linkerd.io/" target="_blank" rel="noopener noreferrer">Linkerd</a> by APN Partner <a href="https://buoyant.io/" target="_blank" rel="noopener noreferrer">Buoyant</a>. Linkerd is an open source,&nbsp;transparent layer 5/7 network proxy that is deployed as a “service mesh” to automatically add reliability and instrumentation to service requests. Linkerd integrates with a wide variety of environments including Consul, Kubernetes, and DC/OS. In Amazon EC2 Container Service (Amazon ECS), Linkerd only requires you to run a service discovery framework to be effective.</p> 
<p>&nbsp;</p> 
<p><img class="size-full wp-image-5027 aligncenter" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/09/11/SeptRoundup3.png" alt="" width="927" height="576" /></p> 
<p>&nbsp;</p> 
<p>Buoyant has recently been working with various ECS customers to document the best practices from the field. With these best practices, ECS customers can deploy Linkerd as a service mesh using <a href="https://www.consul.io/" target="_blank" rel="noopener noreferrer">Consul</a> by <a href="https://www.hashicorp.com/" target="_blank" rel="noopener noreferrer">Hashicorp</a> for service discovery, allowing you to monitor all internal request traffic (including top-line service metrics such as success rates and latency distributions), automatically retry requests when a service fails, or even dynamically route requests. For more information check out their blog post: <a href="https://buoyant.io/2017/08/08/a-service-mesh-for-ecs/" target="_blank" rel="noopener noreferrer">A Service Mesh for ECS</a></p> 
<p>&nbsp;</p> 
<h3>Solodev Web Experience Platform, by Pratap Ramamurthy</h3> 
<p>&nbsp;</p> 
<p><img class="alignleft wp-image-5028 size-medium" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/09/11/SeptRoundup4-300x67.png" alt="" width="300" height="67" /></p> 
<p>When <a href="https://www.oneblood.org/" target="_blank" rel="noopener noreferrer">OneBlood</a>, a non-profit organization that provides blood donation services, experienced a sudden 2700% increase in traffic on their website in one hour, the website did not go down. This is because they run on the <a href="https://www.solodev.com/product/" target="_blank" rel="noopener noreferrer">Web Experience Platform</a>, which was created and is managed by <a href="https://www.solodev.com/" target="_blank" rel="noopener noreferrer">Solodev</a>, an APN Advanced Technology Partner.</p> 
<p>The Solodev Web Experience Platform is an advanced Web Content Management System (CMS) that helps customers deploy, host and manage enterprise-level websites as well as integrate their web content. It is architected based on best practices for security, high availability, and scalability as defined by the <a href="https://d0.awsstatic.com/whitepapers/architecture/AWS_Well-Architected_Framework.pdf" target="_blank" rel="noopener noreferrer">AWS Well-Architected Framework</a>. Solodev uses the <a href="https://aws.amazon.com/elasticloadbalancing/" target="_blank" rel="noopener noreferrer">Elastic Load Balancing</a> service to distribute traffic to application servers that reside in multiple Availability Zones, to provide high availability. When there are spikes in traffic, Solodev scales horizontally by using <a href="https://aws.amazon.com/opsworks/" target="_blank" rel="noopener noreferrer">AWS OpsWorks</a> to provision more instances.</p> 
<p>The platform comes with several features that set it apart from a simple CMS. When you create new web content, A/B testing is arguably the most important tool you can use to find out what is working and what is not, especially before you release changes to production. With the Solodev platform, users can conduct A/B testing using <a href="https://www.solodev.com/blog/digital-marketing/introducing-a-b-testing-with-solodev-experiments.stml" target="_blank" rel="noopener noreferrer">Solodev Experiments</a>, rapidly iterate through changes in their web content, and make informed decisions based on experimentation and testing.</p> 
<p>Web content is a key part of an enterprise’s marketing effort. When web content, mobile content, CRM, and other marketing campaigns come together, the user gets a seamless experience. Solodev integrates with popular CRM software like <a href="https://www.salesforce.com/" target="_blank" rel="noopener noreferrer">Salesforce</a> and <a href="https://www.sugarcrm.com/" target="_blank" rel="noopener noreferrer">SugarCRM</a>, so you can import new leads from web forms into your CRM system. When you run an email campaign, having a web content manager that is aware of the campaign helps increase its success by making it seamless for the recipients. With this goal, Solodev has integrated with popular marketing automation tools like <a href="http://www.pardot.com/" target="_blank" rel="noopener noreferrer">Pardot</a>, <a href="https://www.marketo.com/" target="_blank" rel="noopener noreferrer">Marketo</a>, <a href="https://www.oracle.com/marketingcloud/products/marketing-automation/index.html" target="_blank" rel="noopener noreferrer">Eloqua</a> and <a href="https://www.solodev.com/product/api-integration.stml" target="_blank" rel="noopener noreferrer">many more</a>. These features and integration points turn the platform into a truly advanced Web Content Management System.</p> 
<p>About the Solodev solution running on the AWS platform, OneBlood states, “While we were happy to have an uptime of 95% previously, we now see an uptime of 99.97%.” You can <a href="https://www.solodev.com/resources/case-studies/oneblood-website-case-study.stml" target="_blank" rel="noopener noreferrer">read about the OneBlood customer case study</a> and try out the platform, which is available as a SaaS subscription.</p> 
<p>&nbsp;</p> 
<h3>SparkPost, by Pratap Ramamurthy</h3> 
<p>&nbsp;</p> 
<p><img class="alignleft wp-image-5034 size-medium" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/09/11/sparkpostlogo-300x78.png" alt="" width="300" height="78" />&nbsp;In my first job, I was tasked to send out a newsletter to around 10,000 recipients. I wrote a quick test program using open source libraries, and successfully tested by sending a few emails. Later, when I started sending all 10,000 emails, everything started to fall apart. In hindsight, I should have used an email delivery service like <a href="https://www.sparkpost.com/" target="_blank" rel="noopener noreferrer">SparkPost</a>. Sending email at scale is a very specialized function that requires domain expertise. SparkPost abstracts this complexity by providing a managed service that customers can integrate with.</p> 
<p>There are two kinds of emails that enterprises usually send. The first is called “bulk email”, this usually includes announcements about new product launches, newsletters, and other similar items. Sending bulk email is an inherently “bursty” workload that could lead to scaling problems if self-managed. This need for elastic scalability is one of the problems that SparkPost solves by running on AWS.</p> 
<p>The second kind of email is called “triggered email,” and it’s the kind that app developers most often want to send. Emails of this kind usually are API-driven and include common service and app use cases such as password changes and other security notifications, new registration and onboarding emails, and transactional receipts.</p> 
<p>Relying on an email delivery service to send both bulk and triggered email is an effective way to reduce operational overhead and increase the success of email delivery. As a SparkPost customer you can leverage the SparkPost libraries to trigger emails from your application. See the figure below for a code sample in Python:</p> 
<p>&nbsp;</p> 
<h6 style="text-align: center"><img class="size-full wp-image-5029 aligncenter" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/09/11/SeptRoundup5.png" alt="" width="975" height="376" />Image used with permission</h6> 
<p>&nbsp;</p> 
<p>An email delivery system cannot be a fire-and-forget system because the senders will not be able to measure success. SparkPost provides a near real time monitoring dashboard for the emails that were sent. This helps the sender measure the success, as well as fine tune the email strategy in future. The way email works today, the sender has no control or visibility beyond the first hop, so how does SparkPost measure success? SparkPost includes tracking info in the email that is triggered when the user opens a message or clicks on a link. This is combined with other relevant data and shown to the sender in a dashboard. Additionally, SparkPost takes it further by optionally enabling Webhooks to call your own endpoints for further analysis.</p> 
<p>When you start measuring your email marketing campaigns, one of the first challenges you will notice is the delivery to success ratio. You may be sending emails, but your Internet Service Provider (ISP) might not be delivering them because of low email sender reputation. The email sender reputation is a score assigned by the ISP, and if it’s low, the ISP might be sending your emails to a Junk folder or even reject the emails outright. Several factors determine the score, like the number of emails sent by the organization, how often emails hit the spam trap, number of email bounces and so on. SparkPost helps you improve your email reputation by <a href="https://www.sparkpost.com/docs/deliverability/ip-warm-up-overview/" target="_blank" rel="noopener noreferrer">warming the IP address</a>, <a href="https://www.sparkpost.com/blog/what-are-feedback-loops/" target="_blank" rel="noopener noreferrer">managing feedback loops</a>, and by following to <a href="https://www.m3aawg.org/sites/default/files/document/M3AAWG_Senders_BCP_Ver3-2015-02.pdf" target="_blank" rel="noopener noreferrer">best practices</a> listed here.</p> 
<p>Inbox delivery success criteria, security and many more aspects of email delivery are detailed in <a href="https://www.sparkpost.com/resources/white-papers-guides/" target="_blank" rel="noopener noreferrer">SparkPost documentation</a>. Once you are ready, you can get started with a range of cost-effective plans. SparkPost also offers a free developer account that provides access to all SparkPost features and up to 15,000 free emails per month.</p> 
</article> 
<article class="post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b><a href="https://aws.amazon.com/blogs/apn/new-apn-partner-training-courses-available/" property="url" rel="bookmark"><span property="name headline">New APN Partner Training Courses Available</span></a></b> 
<footer class="meta">
by 
<span property="author" typeof="Person"><span property="name">Sara Snedeker</span></span> | on 
<time property="datePublished" datetime="2017-09-06T17:02:04+00:00">06 SEP 2017</time> | in 
<span class="categories"><a href="https://aws.amazon.com/blogs/apn/category/aws-training-and-certification/" title="View all posts in AWS Training and Certification"><span property="articleSection">AWS Training and Certification</span></a></span> | 
<a href="https://aws.amazon.com/blogs/apn/new-apn-partner-training-courses-available/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-4986" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-apn-blog&amp;disqus_identifier=4986&amp;disqus_title=New+APN+Partner+Training+Courses+Available&amp;disqus_url=https://aws.amazon.com/blogs/apn/new-apn-partner-training-courses-available/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-4986');
});
</script> | 
<a href="#" role="button" data-share-dialog=""><span class="span icon-share"></span>&nbsp;Share</a> 
<ul> 
</ul> 
</footer> 
<p>Amazon Web Services (AWS) offers training resources at no cost designed for AWS Partner Network (APN) Partners so you can more effectively help customers leverage the AWS cloud. We regularly update and release new Solutions Training for Partners content so you can be sure you are learning the latest about AWS. We are expanding our online training availability to give you more flexibility for completing training.</p> 
<p><img class="aligncenter wp-image-5000 size-full" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/09/06/Unknown.png" alt="" width="600" height="200" /></p> 
<h3>Solutions Training for Partners: Foundations: New Web-Based Training and Updated Instructor-Led Training</h3> 
<p>We now have a web-based training version of our popular&nbsp;<a href="https://aws.amazon.com/partners/training/solutions/" target="_blank" rel="noopener noreferrer">Solutions Training for Partners: Foundations</a>&nbsp;course. We’ve also updated the instructor-led training version of the course to include interactive role play sessions and information about recently released and updated AWS services. This training is recommended for APN Consulting Partner business professionals who want to learn more about AWS best practices to build their business and better meet customer business challenges.</p> 
<h3>Solutions Training for Partners: Windows Technical: New Instructor-Led and Web-Based Training</h3> 
<p>Our newest course,<a href="https://aws.amazon.com/partners/training/windows-technical/" target="_blank" rel="noopener noreferrer">&nbsp;Solutions Training for Partners: AWS for Windows Technical</a>, is available in both instructor-led and web-based training modalities. This course trains APN Consulting Partners on the technical foundations for running Windows-based workloads on AWS. You will learn about the technical advantages and positioning for Windows on AWS, and learn how to provide guidance to customers on architecting common Microsoft workloads for AWS. We recommend you achieve the&nbsp;<a href="https://aws.amazon.com/partners/training/accreditation/" target="_blank" rel="noopener noreferrer">AWS Technical Professional</a>&nbsp;accreditation before registering for this class.</p> 
<p>You can explore more training resources for APN Partners&nbsp;<a href="https://aws.amazon.com/partners/training/" target="_blank" rel="noopener noreferrer">here</a>, and you can search for classes near you by logging into the AWS Training and Certification Portal with your&nbsp;<a href="https://partnercentral.awspartner.com/SiteLogin" target="_blank" rel="noopener noreferrer">APN Portal credentials</a>. APN Partners have access to partner-specific training at no cost and are eligible for a 20% discount on customer-facing public AWS training delivered by AWS. You can also request a private onsite training for your team by&nbsp;<a href="https://aws.amazon.com/contact-us/aws-training/" target="_blank" rel="noopener noreferrer">contacting us</a>.</p> 
</article> 
<article class="post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b><a href="https://aws.amazon.com/blogs/apn/building-serverless-saas-applications-on-aws/" property="url" rel="bookmark"><span property="name headline">Building Serverless SaaS Applications on AWS</span></a></b> 
<footer class="meta">
by 
<span property="author" typeof="Person"><span property="name">Tod Golding</span></span> | on 
<time property="datePublished" datetime="2017-09-06T10:26:28+00:00">06 SEP 2017</time> | in 
<span class="categories"><a href="https://aws.amazon.com/blogs/apn/category/compute/aws-lambda/" title="View all posts in AWS Lambda*"><span property="articleSection">AWS Lambda*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/aws-partner-solutions-architect-sa-guest-post/" title="View all posts in AWS Partner Solutions Architect (SA) Guest Post"><span property="articleSection">AWS Partner Solutions Architect (SA) Guest Post</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/saas-on-aws/" title="View all posts in SaaS on AWS"><span property="articleSection">SaaS on AWS</span></a></span> | 
<a href="https://aws.amazon.com/blogs/apn/building-serverless-saas-applications-on-aws/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-4979" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-apn-blog&amp;disqus_identifier=4979&amp;disqus_title=Building+Serverless+SaaS+Applications+on+AWS&amp;disqus_url=https://aws.amazon.com/blogs/apn/building-serverless-saas-applications-on-aws/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-4979');
});
</script> | 
<a href="#" role="button" data-share-dialog=""><span class="span icon-share"></span>&nbsp;Share</a> 
<ul> 
</ul> 
</footer> 
<p>Software as a service (SaaS) solutions often present architects with a diverse mix of scaling and optimization requirements. With SaaS, your application’s architecture must accommodate a continually shifting landscape of customers and load profiles. The number of customers in the system and their usage patterns can change dramatically on a daily—or even hourly—basis. These dynamics make it challenging for SaaS architects to identify a model that can efficiently anticipate and respond to these variations.</p> 
<p>Dynamically scaling servers and containers have certainly given SaaS architects a range of tools to accommodate these scaling patterns. And now, with the advent of serverless computing and AWS Lamba functions, architects have a computing and consumption model that aligns more precisely with the demands of SaaS environments.</p> 
<p>In this blog post, we’ll discuss how serverless computing and AWS Lambda influence the compute, deployment, management, and operational profiles of your SaaS solution.</p> 
<h3>It’s All About Managed Functions</h3> 
<p>Adopting a serverless model requires developers to adopt a new mindset. Serverless touches nearly every dimension of how developers decompose application domains, build and package code, deploy services, version releases, and manage environments. The key contributor to this shift is the notion that serverless computing relies on a much more granular decomposition of your system, requiring each function of a service to be built, deployed, and managed independently. In many respects, serverless takes the spirit of microservices to the extreme.</p> 
<p>While making this move make requires a paradigm shift, the payoff is significant—especially for SaaS solutions. This more granular model provides us with a much richer set of opportunities to align tenant activity with resource consumption. It is at the core of enabling your ability to tackle many of the challenges associated with SaaS cost and performance optimization.</p> 
<p>The impact of serverless reaches beyond your code and services. It completely removes the notion of servers from your view. Gone is the need to provision, configure, patch, and manage instances or containers. In fact, as a developer of serverless applications, you are intentionally shielded from the details of how and where your application’s functions are executed. Instead, you must rely on the managed service—AWS Lambda—to control and scale the execution of your functions.</p> 
<p>This notion of moving away from the awareness of any specific instance or container sets the stage for all the goodness we are looking for in our SaaS environments. It also frees you up to &nbsp;focus more of your attention on the functionality of your system.</p> 
<h3>Escaping the Policy Challenge</h3> 
<p>The ability to dynamically scale environments is essential to SaaS. Being able to respond quickly to changes in tenant load is key to maximizing a customer experience while still optimizing the cost footprint of your solution. Achieving these scaling goals with server-based environments can be challenging. With instances and containers, the responsibility for defining effective and efficient scaling policies lands squarely on your shoulders. The diagram below illustrates the complexity that is often associated with configuring the policies in traditional server-based SaaS environments.</p> 
<p><img class="wp-image-4980 size-full aligncenter" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/08/28/serverlesssaas1.png" alt="" width="680" height="620" /><br /> In this example, we have decomposed an e-commerce application into a set of services. This decomposition was partly motivated by the desire to have each service scale independently. This is illustrated by the specific policies that are attached to each service. Here, for example, the search service might be scaling on memory, while the checkout service might be scaling on CPU.</p> 
<p>This is a perfectly valid model. However, it puts significant pressure on the SaaS architect to continually refine and tune these policies to align them with the evolving usage patterns of your multi-tenant environment. The policies that are valid today might not be valid tomorrow. As new tenants come on board, the profile and behavior of the system can change. Ultimately, you might end up over-allocating resources to accommodate these variations in load. The end result is often higher per-tenant costs.</p> 
<p>Now, as you move beyond thinking about instances and start implementing your solutions as a series of serverless methods, you can imagine how this influences your approach to managing scale. With AWS Lambda, you can mostly remove yourself from the policy management equation. Instead, scaling and responding effectively to load becomes the job of the managed service.</p> 
<h3>The Power of Granularity</h3> 
<p>The sections above outlined the value and impact of decomposing your system into a series of independent functions. Let’s dig a bit deeper into a real world example that provides a more detailed view of how a serverless model influences the profile of an application service that is implemented with Lambda.</p> 
<p>The image below provides and example of an order management service that might be deployed as a REST service hosted on an instance or container. This service supports a collection of methods that encapsulate the basic operations needed to store, retrieve, and control the state of orders in an e-commerce system.</p> 
<p><img class="aligncenter wp-image-4981 size-full" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/08/28/serverlesssaas2.png" alt="" width="731" height="399" /></p> 
<p>This service includes a range of straightforward capabilities. In a typical scenario, the service would likely support a more detailed set of operations. Still, as you look at the scope of this service, it seems to meet most of the reasonable criteria. It’s relatively focused and is likely loosely coupled to other services.</p> 
<p>While the service seems fine, it could present problems when it comes to scaling in a SaaS environment. Suppose, for example, that the DELETE operation of this service is very CPU-intensive while the PUT operation tends to be more memory-intensive. &nbsp;And, from our profiling, we see that some tenants are pushing the GET operation hard while others are using PUT operations more heavily. This creates a challenge when figuring out how to scale this service effectively without over-allocating resources. Essentially, with this more coarse-grained surface, your options for scaling the service can be somewhat limited. Without more control over your scaling granularity, you’ll be unable to match usage of the service to potential variations in tenant activity. Instead, you’re left with a best guess approach to picking a scaling model with the hope that it might represent an efficient consumption of resources.</p> 
<p>Now, let’s see what it would mean to deliver this order management service in a serverless model. The following diagram illustrates how scale would be achieved in an environment where each of the service’s operations (functions) is implemented as a separate Lambda function.</p> 
<p><img class="aligncenter wp-image-4982 size-full" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/08/28/serverlessaas3.png" alt="" width="975" height="277" /></p> 
<p>As load is placed on an operation, that operation can scale out independently of the others. More calls to GetOrders(), for example, force the scale out of that function. Meanwhile, DeleteOrder() consumes almost no resources. The beauty of this model is that you no longer need to think about how best to decompose your services to find the right balance of consumption and scale. Instead, by representing your service as a series of separately deployed functions, you directly align the consumption of each function with the real-time activity of tenants. If there’s tremendous demand for order searches right now, the system will scale that specific method to meet the demands of that load. Meanwhile, if other functions are going untouched, these functions will not generate any compute costs.</p> 
<p>You can imagine the value this model brings to SaaS environments where the activity of existing and new tenants is constantly changing. With traditional SaaS implementations, it would not be uncommon to have idle services that are rarely exercised or only pushed during specific windows of the day. Now, with a serverless architecture, this is no longer an issue. You can simply deploy your functions and let them to respond actual tenant load. If a group of functions are not called for a day they will incur no costs for remaining idle. Then, if a new tenant suddenly pushes these same functions, Lambda will be responsible for providing the required scale.</p> 
<h3>Serverless Management and Monitoring</h3> 
<p>The more granular nature of serverless applications also adds value to the SaaS management and monitoring experience. With SaaS applications, it’s essential to proactively detect—with precision—any anomalies that may exist in your system. Imagine the dashboard and operational view that could show you the health of your system at the function level. The following image provides a conceptual view of how a serverless system could help you analyze your system’s health and activity more effectively:<img class="aligncenter wp-image-4983 size-full" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/08/28/serverlesssaas4.png" alt="" width="975" height="415" /></p> 
<p>The heat map on the left provides a coarse-grained representation of the services. The health of each service is represented by a range of colors that convey the current status of a service. In this example, you’ll notice that the order management service is red, indicating that there is some kind of issue with the health of that service. However, we won’t know which aspect of this service is actually failing without drilling into logs and other metrics.</p> 
<p>The view on the right represents the health of the system in a serverless model. Here, each square in the grid corresponds to a Lambda function. Now, when the health of any aspect of the system starts to diminish, you get a more granular view of what may be failing. This makes it easier to develop proactive policies and streamlines the troubleshooting process, both of which are essential in SaaS environments where an outage could impact all your customers.</p> 
<h3>More Chances to Impact Availability</h3> 
<p>With SaaS applications, you’re always looking for opportunities to improve the availability profile of your application. Most SaaS solutions lean heavily on building in fault tolerance mechanisms that allow an application to continue to function, even when some portions of the system could be failing.</p> 
<p>Imagine, for example, that your e-commerce application has a ratings service that provides customer reviews about products. Although this feature is valuable to customers, the system could continue to function when this service is down. In this scenario, your system could either temporarily remove the display of the ratings or use a cached copy of the latest ratings data during the failure.</p> 
<p>This approach to fault tolerance is a common technique that is used in many SaaS architectures. However, more coarse-grained services often undermine your ability to introduce effective fault tolerance strategies. The outage of an entire service can be more difficult to overcome. This is an area where the serverless model shines. The decomposition of your system into independently executable functions now gives you a much more diverse set of options for introducing fault tolerant policies.</p> 
<h3>Supporting Siloed Tenants</h3> 
<p>SaaS providers are often required to deliver some or all of their system in a siloed model where each tenant has its own unique set of infrastructure resources. This may be driven by any number of factors, including compliance, regulatory, or legacy architecture requirements. There are a number of downsides to operating a SaaS product in this model. Cost often rises to the top of this list, because the overhead associated with provisioning, operating, and managing separate tenant infrastructure can be substantial.</p> 
<p>Serverless computing often represents a compelling alternative for these siloed solutions. With this model, the execution of each tenant’s functions can be completely isolated from other tenants. In fact, you can leverage AWS Identity and Access Management (IAM) policies to ensure that a Lambda function is executed in the context of a specific tenant, which helps address any concerns customers may have about cross-tenant access.</p> 
<p>The other key upside of using serverless computing in a siloed SaaS model is its impact on costs. If you’ve used virtual machine or containers as your underlying infrastructure, this will require each tenant to have some idle footprint—even if the tenant isn’t exercising any of the system’s functionality. Meanwhile, with serverless computing, your tenant costs will be directly correlated to their consumption of the functions you’ve deployed. And, if there are areas of the system that tenants aren’t using, there will be no compute costs associated with these unused features. This can amount to a significant savings in a siloed environment.</p> 
<h3>The API Gateway and SaaS Agility</h3> 
<p>The Amazon API Gateway is a key piece of the AWS serverless model. It provides a managed REST entry point to the functions of your application. It also offloads issues like metering, DDoS, and throttling, allowing your services to focus more on their implementation and less on managing and routing requests.</p> 
<p>In addition to providing API fundamentals, API Gateway also includes mechanisms to manage the deployment of functions to one or more environments. API Gateway includes support for stage variables that allow you to associate functions with a specific environment. So, for example, you could define separate DEV and PROD stages in the gateway and point these stage at specific versions of your functions. This can simplify both deployment and rollback of releases. It can also simplify the tooling you’ll need to build for your deployment pipeline.</p> 
<p>As you move into a serverless model, you’ll also find that the function-based model aligns nicely with your SaaS agility goals. The following diagram illustrates how the move to more granular functions impacts your continuous delivery pipeline. Since each function is executed in isolation, they can also be deployed separately.</p> 
<p><img class="wp-image-4984 size-full aligncenter" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/08/28/serverlesssaas5.png" alt="" width="904" height="294" /></p> 
<p>This smaller unit of deployment is especially helpful in SaaS environments where there is an even higher premium on maximizing up time. It also narrows the scope of potential impact for each item you deploy, promoting more frequent releases of product features and fixes.</p> 
<h3>Focus on What Matters</h3> 
<p>While there are a number of technical, agility, and economic advantages to building a SaaS solution with a serverless architecture, the biggest advantage of serverless is that frees you up to focus more of your energy on your application’s features and functionality. Serverless computing takes the entire notion of managing servers off your plate, allowing you to create applications that can continually change their scaling profile based on the real-time activity of your tenants.</p> 
<p>For many teams, the real challenge of serverless computing is making the shift to a function-based application decomposition. This transition represents a fairly fundamental change in the mental model for building solutions. It may also have you reconsidering your choice of languages and tooling.</p> 
<p>Challenges aside, the natural alignment between the values of SaaS and the principles of the serverless model are very compelling. The upsides of cost, fault tolerance, deployment agility, and managed scale make serverless computing an attractive model for SaaS providers</p> 
</article> 
<article class="post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b><a href="https://aws.amazon.com/blogs/apn/calculating-tenant-costs-in-saas-environments/" property="url" rel="bookmark"><span property="name headline">Calculating Tenant Costs in SaaS Environments</span></a></b> 
<footer class="meta">
by 
<span property="author" typeof="Person"><span property="name">Tod Golding</span></span> | on 
<time property="datePublished" datetime="2017-08-25T15:08:40+00:00">25 AUG 2017</time> | in 
<span class="categories"><a href="https://aws.amazon.com/blogs/apn/category/aws-partner-solutions-architect-sa-guest-post/" title="View all posts in AWS Partner Solutions Architect (SA) Guest Post"><span property="articleSection">AWS Partner Solutions Architect (SA) Guest Post</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/saas-on-aws/" title="View all posts in SaaS on AWS"><span property="articleSection">SaaS on AWS</span></a></span> | 
<a href="https://aws.amazon.com/blogs/apn/calculating-tenant-costs-in-saas-environments/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-4955" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-apn-blog&amp;disqus_identifier=4955&amp;disqus_title=Calculating+Tenant+Costs+in+SaaS+Environments&amp;disqus_url=https://aws.amazon.com/blogs/apn/calculating-tenant-costs-in-saas-environments/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-4955');
});
</script> | 
<a href="#" role="button" data-share-dialog=""><span class="span icon-share"></span>&nbsp;Share</a> 
<ul> 
</ul> 
</footer> 
<p>In traditional single-tenant environments, calculating and aggregating infrastructure costs is a pretty straightforward exercise. Typically, each application or customer has its own collection of dedicated resources and tallying the costs is simply a matter of categorizing and summing those costs. However, in multi-tenant software as a service (SaaS) environments, this becomes a much more challenging problem.</p> 
<p>With SaaS, tenants often share some or all of a system’s infrastructure resources. A database, for example, may hold all the data for all tenants. How, then, do you apportion costs to each tenant? This gets even more complicated with other forms of tenant consumption like compute or bandwidth. Generally, with the varying flavors of system partitioning that are used to build SaaS systems, it becomes increasingly difficult to associate tenants with specific infrastructure costs.</p> 
<p>While the challenges of calculating tenant costs continue to get more complex, the need for tenant cost data is still essential for many SaaS businesses. SaaS organizations often rely on some understanding of the cost per tenant as a key element of their broader economic and business model. This cost data can directly influence the pricing dimensions and tiering strategies that are adopted by a SaaS provider.</p> 
<p>This blog post examines some of the strategies that you can use to capture and analyze tenant consumption data in multi-tenant environments. It highlights some of the challenges associated with instrumenting your services and architecture to enable a more granular view of consumption that you can use to inform your price modeling.</p> 
<h3>Do I Really Need Cost Per Tenant?</h3> 
<p>For some SaaS teams, the calculation of per-tenant costs can seem like overkill. It’s easy to assume that the energy expended to gather and analyze this data may not be worthy of the investment. Even when technical teams might be advocating this direction, the business may resist moving this requirement ahead of other features and functions that are essential to customers. These factors generally conspire to push cost-per-tenant calculations to the back burner.</p> 
<p>The challenge here is that—without this data—you may be missing key insights into your system’s profile that may directly impact both the technical and business dimensions of your offering. Imagine, for example, that you have a tiered product offering with basic, advanced, and professional tiers. Let’s presume that the basic tier is somewhat inexpensive, while the professional tier is more on the pricey end of the spectrum. Without a clear picture of your system’s underlying cost metrics, the business might pick some consumption dimension to define the boundary between each tier.</p> 
<p>Let’s say, for example, we’re an e-commerce product and we’ve used catalog size as the defining metric that separates the tiers of our system. In this scenario, the business would simply begin acquiring customers and pouring them into the system without any concern for how this might impact the bottom line. Now, if we take this system and begin to collect cost per tenant data, the infrastructure consumption breakdown might end up looking like the bar chart shown below. Here, you’ll notice that most of the tenants have signed up for the basic tier. However, the infrastructure costs associated with the basic tier far exceed that of the other two tiers.</p> 
<p><img class="aligncenter wp-image-4956 size-full" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/08/24/Screen-Shot-2017-08-24-at-1.01.11-PM.png" alt="" width="938" height="528" /></p> 
<p>&nbsp;</p> 
<p>Diving deeper, we see that a flaw in the pricing model assumed that infrastructure consumption would correlate directly to catalog size. However, in reality, consumption ended up being driven by the mix of products that were for sale at a store. This created a significant imbalance between revenue and costs where the lowest revenue customers were generating a disproportionate level of expenses.</p> 
<p>This scenario highlights a very common challenge for SaaS organizations where their business model and tiering strategies don’t always align with the overhead associated with each tenant. So, while the business may not always be focused on the cost-per-tenant number, it’s still essential to give it visibility since its impact can often go overlooked.</p> 
<h3>Giving the Business Options</h3> 
<p>The previous example highlights the tight linkage that often exists between the business and technical SaaS teams. The architectural choices that are made by SaaS developers have the potential to shape and influence the menu of pricing and packaging options offered by the business. The more flexibility you are able to provide the business, the more likely it is that you’ll be able to rapidly respond to the diverse requirements of tenants—each of which may have their own scale, performance, and consumption profiles.</p> 
<p>Equipped with cost data, SaaS architects are in a much better position to make tradeoffs that will consider the current and, potentially, future needs of the business. This data becomes a tool that can be used to offer the business options that may have otherwise been outside the view of product managers and strategists who are responsible for defining packaging and pricing options. Teams will often find points of inflection in their cost dynamics that can translate directly into differentiators that separate the tiers of their SaaS system.</p> 
<p>The broader goal here is to make choices in your SaaS architecture that better align a tenant’s expectations with their experience. If a tenant is a $29/month, basic tier tenant, they are likely to understand that their experience will be different than that of the $5000/month, professional tier tenant. Supporting this model often means introducing variations in policies and—in some cases—architectural models that offer distinct tenant experiences for each tier of your solution. Examples of how this can be achieved is outlined in a blog post on <a href="https://aws.amazon.com/blogs/apn/optimizing-saas-tenant-workflows-and-costs/" target="_blank" rel="noopener noreferrer">Optimizing SaaS Tenant Workflows and Costs</a> as well as a presentation on <a href="https://www.youtube.com/watch?v=D-8fTCz8_Yo" target="_blank" rel="noopener noreferrer">Optimizing SaaS Solutions on AWS</a>.</p> 
<p>Ultimately, this is all about giving the business options. If, tomorrow, the business comes to you with some new way they’d like to package your solution to address a new opportunity or market segment, you’d want to be in a position to understand how this new offering might impact costs. The data you provide to this discussion could be fundamental to determining the viability of the new offering.</p> 
<h3>The Hard Part: Instrumenting Your Solution</h3> 
<p>While the value of cost per tenant data is easy to grasp, capturing and aggregating this data can be a bit more involved. The nature of your tenant partitioning model, the compute model you’re using, and any number of other factors could influence your approach to assembling your view of tenant costs. The following sections provide a breakdown of common considerations that might affect how you instrument your solution to capture tenant cost data.</p> 
<h4>Analyzing Costs in a Silo Model</h4> 
<p>Some SaaS providers rely exclusively on a siloed partitioning model where each tenant is housed in a mostly isolated infrastructure. This isolation might be mandatory for some domains that have strict regulations that prohibit shared infrastructure. For these environments, more pronounced boundaries between each tenant can simplify the efforts to aggregate and derive cost analytics.</p> 
<p>Amazon Web Services (AWS) offers architects a few constructs for implementing tenant isolation. Two common strategies involve the usage of AWS accounts and virtual private clouds (VPCs). With the account model, each tenant is provisioned into a completely separate account. This account creates a distinct view of all the resources associated with the tenant. These accounts can also use the AWS linked account model, which associates an account with a master account. This enables all tenant consumption to be rolled up to a single account while giving you a view of consumption at the linked account level so you can easily identify all the costs associated with a single tenant.</p> 
<p>The other common isolation scheme involves creating separate VPCs for each tenant. With this approach, you can isolate tenants without creating separate accounts for each tenant. This often scales better and simplifies the provisioning model. However, it also adds a degree of complexity to the cost instrumentation. Instead of relying on linked accounts to summarize tenant spend, you’ll need to apply AWS tags to your infrastructure to associate it with your tenants. These tags will then be used to aggregate the spend of each tenant.</p> 
<p>In a more siloed model, you may want to consider leveraging partner solutions to simplify the aggregation and analytics of your tenant costs. AWS Partner Network (APN) Partners like CloudHealth and Cloudability, for example, provide cost analytics tools that can streamline your ability to perform tenant analytics.</p> 
<h4>Analyzing Costs in a Pooled Model</h4> 
<p>In a pooled model, where tenant resources are shared, the attribution of tenant costs can be more challenging. Here, you must employ more specialized strategies to properly capture and classify tenant activity. You’ll need to rely on measurements of actual tenant interactions with your systems resources to apportion load and consumption, and derive an approximation of tenant costs. This typically demands more effort to both instrument your solution and to aggregate the resulting metrics.</p> 
<p>Further complicating the pooled model is the reality that each resource type may require a slightly different approach to instrumenting and aggregating cost information for individual tenants. Compute, for example, will likely require a very different approach than storage. The different types of storage (block, object, relational, and NoSQL), for example, might demand separate strategies for measuring consumption.</p> 
<p>Let’s consider how, in a pooled environment, you might derive a tenant’s consumption from their activity. The diagram below depicts a simplified view of an Amazon EC2 Container Service (Amazon ECS) cluster running services in a pooled, multi-tenant environment. This cluster includes two services that are running in containers (Checkout and Catalog), both of which are being invoked by individual tenants.</p> 
<p>&nbsp;</p> 
<p><img class="aligncenter wp-image-4957 size-full" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/08/24/CostTenant2.png" alt="" width="482" height="433" /></p> 
<p>&nbsp;</p> 
<p>As the tenants use these services, they consume compute resources. The question is: How much of these resources are actually being consumed by each tenant? Tenant 1, for example, may be pushing the system very hard and selling lots of items, forcing the scale out of the cluster, or consuming a disproportionate number of the containers in the cluster. Tenant 2, on the other hand, may be imposing minimal load.</p> 
<p>The challenge, then, is to instrument these services to surface metrics data that can be used to infer the level of consumption for each tenant. Ultimately, this comes down to selecting a strategy that best maps activity to consumption for a service. You might decide to track changes in CPU activity, or you might track the frequency of calls to a&nbsp;service—there’s no absolute model that can universally characterize consumption for all your services. However, with some notion of frequency, you should be able to get close to a reasonable approximation of consumption for many of the services that are part of your SaaS solution.</p> 
<p>Fortunately, instrumenting your compute services will likely mesh nicely with other logging and metrics gathering mechanisms you already employ. The general strategy here would be to instrument all the entry points of your services with log events. With this data, you’ll be able to determine which methods are being called and with what frequency. If you add the tenant context to these logging calls, you’ll have the foundational elements that can be used to infer tenant consumption of these services.</p> 
<p>The diagram below provides a conceptual model for how you might aggregate a series of calls to a service and use that data to determine a tenant’s consumption. Here, we’ve simply used the frequency of calls to determine a percentage of activity for a tenant. This gives you a model for apportioning the compute costs associated with this service to each tenant based on these percentages.</p> 
<p>&nbsp;</p> 
<p><img class="aligncenter wp-image-4969 size-full" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/08/25/Screen-Shot-2017-08-25-at-12.55.43-PM.png" alt="" width="788" height="586" /></p> 
<p>&nbsp;</p> 
<p>This represents a highly simplified version of what you might build. Still, it gives you a sense of what might be involved in arriving at a reasonable distribution of tenant compute costs. The good news here is that the mechanisms needed to support the collection of this data overlap heavily with the general analytics tooling that you’ll want to put in place to analyze and evaluate tenant activity. The key is to ensure you’ve collected the data you need with the context that is required to support your cost allocation model.</p> 
<h3>Calculating Storage Costs</h3> 
<p>While the previous example gave us some sense of how we might calculate compute consumption, this same model may not be a good fit for analyzing storage costs. A tenant could, for example, consume significant amounts of compute and still have a minimal impact on storage costs. There is no guaranteed correlation between compute and storage consumption in SaaS environments.</p> 
<p>Storage also adds some new wrinkles to the cost equation. With storage, you may need to consider how both the size of the data and the IOPS impact a given tenant’s costs.&nbsp; This means your cost analytics must apportion all the elements of storage costs that may appear in your AWS bill to the tenants of your system.</p> 
<p>The analysis of a metric like IOPS has parallels to what we’ve discussed for analyzing compute consumption. The goal would be to derive some notion of tenant storage activity from a tenant’s interactions with the data. These metrics could be derived from each tenant’s interactions with a data access layer that is employed by your solution (as depicted in the following diagram). With this approach, each call to acquire or manage data would be processed by a common framework that would capture and aggregate tenant storage activity. This activity would then be used to apportion costs to each tenant.</p> 
<p>&nbsp;</p> 
<p><img class="aligncenter wp-image-4958 size-full" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/08/24/CostTenant3.png" alt="" width="722" height="654" /></p> 
<p>&nbsp;</p> 
<p>Determining a tenant’s impact on the system’s storage footprint is a less dynamic process. Here, you may have data stored in some AWS services (Amazon DynamoDB, Amazon Simple Storage Service (Amazon S3), Amazon Redshift, Amazon Elastic Block Store (Amazon EBS), and so on) and you’ll need to determine what percentage of that storage belongs to each tenant. Assessing this data will typically require a process that can periodically analyze the data distribution to determine a tenant’s storage consumption. The mechanism used for this analysis will vary based on your data partitioning model and the type of storage resource being evaluated. Amazon S3 and DynamoDB, for example, would require very different strategies for analyzing tenant storage consumption.</p> 
<p>As you put these storage metrics into place, you’ll need to determine how best to aggregate these costs. Should there be one flat cost that aggregates all the aspects of storage, or should you provide a more detailed breakdown of the costs that provides access to all the dimensions of storage? There is no one right answer here. However, having the details could help inform some of the choices you might make with your architecture.</p> 
<h3>Being Good Enough</h3> 
<p>Accuracy is certainly important when you’re capturing metric data. At the same time, when working with tenant cost calculations, it’s important to remember that—in most cases—you’re not attempting to achieve a perfect level of accounting that tracks every ounce of consumption. Unless this data is directly driving billing, which it often is not, the goal is to get data that is good enough. The focus should be on building a model that accurately represents the general distribution of tenant consumption. Equipped with this data, you and the business will be in a much better position to assess the effects of the product and architecture changes you’re considering.</p> 
<p>As you start down this path, you may choose to incrementally introduce elements of metrics collection into the different aspects of your system. You may find compromises and tradeoffs along the way that can simplify your approach and still return enough data to give you a manageable level of insight into customer spending profiles.</p> 
<h3>Bonus Operational Value</h3> 
<p>The added effort to instrument your application with these tenant metrics has value beyond the economics of understanding tenant spend. The data captured can also have operational value, providing tenant-centric views into system activity that may be used to detect or troubleshoot issues that might arise.</p> 
<p>The data captured can also be used to help shape your operational policies. Suppose you see that a tenant’s activity is imposing load at a rate that is stretching the scaling policies of your environment. With the tenant view of consumption, you can see how tenant-specific usage patterns are exercising the architecture of your environment and react with more precision.</p> 
<h3>Billing Metering vs. Tenant Consumption</h3> 
<p>Metering is an essential aspect of many SaaS environments. SaaS providers will often develop a billing and tiering strategy around some dimension of consumption. These consumption dimensions cover a wide range of possibilities. Bandwidth, number of users, storage usage—these are all flavors of billing models that are used to correlate tenant activity with some billing construct.</p> 
<p>On the surface, this sounds like the same model of consumption we’ve been discussing, and there can be some conceptual overlap. However, this notion of metering is targeted at capturing just those metrics that are meant to derive a tenant’s bill. They may not map to the notion of tenant infrastructure consumption, which is focused squarely on determining the actual cost associated with each tenant’s activity. It’s essential for SaaS businesses to understand and separate these two concepts as they develop pricing and packaging models.</p> 
<h3>Correlating AWS with Billing Data</h3> 
<p>There are two parts to the tenant consumption equation. So far, we’ve focused on the instrumentation and allocation of tenant consumption. This data tells us the portion of the system’s resources that are being used by a given tenant. What it doesn’t tell you is the actual costs that a tenant is incurring. Getting to this next level of insight could be viewed as optional, but having the full picture of consumption mapped to cost represents the real payoff.</p> 
<p>Acquiring and correlating the data will require you become familiar with the AWS billing data. You’ll need to dig into your AWS bill and consider how best to correlate the detailed billing information with your consumption data. There are a number of options and approaches, ranging from a high-level allocation of overall costs to more granular, detailed mappings of line items in your bill. Generally, in the spirit of being “good enough” as outlined above, you might want to start with a fairly basic model that eliminates the need to dig into the details of AWS billing reports. Again, this is more about having some approximation of the cost—not building an accounting system.</p> 
<h3>The Business May Not Ask—But They’ll care</h3> 
<p>Often, in the rush to address customer and market needs, it’s very easy for SaaS providers to push tenant costs to the background. This might make sense in the fail fast mindset of getting a product out the door. The business is rarely going to make infrastructure costs—especially before they have lots of customers—a central part of their thinking.</p> 
<p>While tenant costs may not be at the forefront of your product strategy, the business often pays closer attention when they begin to see how this data can impact the bottom line. Once organizations see the numbers, they will begin to ask more informed questions about how new features and product strategies might impact the cost per tenant. You’ll also find that technical teams will begin to use this data to find new and creative ways to evolve an application’s architecture without over-inflating the operational costs.</p> 
<h3>Metrics Matter</h3> 
<p>Most SaaS businesses rely heavily on metrics. Having the pulse of your customer’s often-complex usage patterns is essential to understanding how to market, price, position, and build your solution. Infrastructure overhead often represents a significant percentage of a SaaS provider’s costs. So, having a precise view of how tenants are imposing load on your system gives the business and technical teams another variable that can shape the pricing and tiering strategies you choose to offer.</p> 
<p>As you look at strategies for capturing and analyzing cost metrics, you should view this as an iterative process. You can start with some very basic mechanisms to gain insights into tenant footprints that might otherwise go overlooked. Then, with time, you can evolve and mature this model to add depth to your cost analytics.</p> 
<p>The key is to bring visibility to the cost per tenant metric and make it part of the mental math of the business.</p> 
</article> 
<article class="post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b><a href="https://aws.amazon.com/blogs/apn/how-to-create-an-approval-flow-for-an-aws-service-catalog-product-launch-using-aws-lambda/" property="url" rel="bookmark"><span property="name headline">How to create an approval flow for an AWS Service Catalog product launch using AWS Lambda</span></a></b> 
<footer class="meta">
by 
<span property="author" typeof="Person"><span property="name">Karthik Thirugnanasambandam</span></span> | on 
<time property="datePublished" datetime="2017-08-17T09:12:06+00:00">17 AUG 2017</time> | in 
<span class="categories"><a href="https://aws.amazon.com/blogs/apn/category/application-services/amazon-api-gateway-application-services/" title="View all posts in Amazon API Gateway*"><span property="articleSection">Amazon API Gateway*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/messaging/amazon-simple-notification-service-sns/" title="View all posts in Amazon Simple Notification Service (SNS)*"><span property="articleSection">Amazon Simple Notification Service (SNS)*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/apn-launches/" title="View all posts in APN Launches"><span property="articleSection">APN Launches</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/management-tools/aws-cloudformation/" title="View all posts in AWS CloudFormation*"><span property="articleSection">AWS CloudFormation*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/compute/aws-lambda/" title="View all posts in AWS Lambda*"><span property="articleSection">AWS Lambda*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/aws-partner-solutions-architect-sa-guest-post/" title="View all posts in AWS Partner Solutions Architect (SA) Guest Post"><span property="articleSection">AWS Partner Solutions Architect (SA) Guest Post</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/management-tools/aws-service-catalog/" title="View all posts in AWS Service Catalog*"><span property="articleSection">AWS Service Catalog*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/aws-sns/" title="View all posts in AWS SNS"><span property="articleSection">AWS SNS</span></a></span> | 
<a href="https://aws.amazon.com/blogs/apn/how-to-create-an-approval-flow-for-an-aws-service-catalog-product-launch-using-aws-lambda/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-4904" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-apn-blog&amp;disqus_identifier=4904&amp;disqus_title=How+to+create+an+approval+flow+for+an+AWS+Service+Catalog+product+launch+using+AWS+Lambda&amp;disqus_url=https://aws.amazon.com/blogs/apn/how-to-create-an-approval-flow-for-an-aws-service-catalog-product-launch-using-aws-lambda/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-4904');
});
</script> | 
<a href="#" role="button" data-share-dialog=""><span class="span icon-share"></span>&nbsp;Share</a> 
<ul> 
</ul> 
</footer> 
<p><a href="http://docs.aws.amazon.com/servicecatalog/latest/adminguide/introduction.html" target="_blank" rel="noopener noreferrer">AWS Service Catalog</a> allows organizations to centrally manage commonly deployed IT services, achieve consistent governance, and help meet compliance requirements. AWS Service Catalog provides a standardized landscape for product provisioning. Users browse listings of products (services or applications) that they have access to, locate the product that they want to use, and launch it on their own as a provisioned product. The AWS Service Catalog API also provides programmatic control over all user actions.</p> 
<p>Let’s say you need to build an approval workflow for a launch request from a user. Many solutions are available that use AWS Service Catalog APIs to build complex custom workflows are available (for example, <a href="https://www.servicenow.com/" target="_blank" rel="noopener noreferrer">ServiceNow</a>). In this blog post, I will describe how to build a simple workflow approval process using AWS Lambda, Amazon API Gateway, AWS CloudFormation, and Amazon Simple Notification Service (Amazon SNS), &nbsp;from the perspective of an AWS Service Catalog administrator.</p> 
<p>To build this approval process, I’ll be using AWS CloudFormation features like <a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-waitcondition.html" target="_blank" rel="noopener noreferrer">WaitCondition</a> and <a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-waitconditionhandle.html" target="_blank" rel="noopener noreferrer">WaitHandle</a>, along with AWS Lambda as a <a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/template-custom-resources.html" target="_blank" rel="noopener noreferrer">custom resource</a> to create a simple approval workflow. This approach is beneficial if you are looking for an AWS native solution to extend existing AWS Service Catalog features. This will also help retain the AWS Service Catalog user interface for product launch.</p> 
<h3>Architecture Overview:<br /> <a href="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/08/09/servicecatalog1.png"><img class="alignnone size-full wp-image-4905" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/08/09/servicecatalog1.png" alt="" width="740" height="475" /></a></h3> 
<p>&nbsp;</p> 
<p>&nbsp;</p> 
<ol> 
<li>The user launches a product from their available product list and fills in all required data &nbsp;via the AWS Service Catalog interface. You can obtain the user’s email address through this input.</li> 
<li>For products that require administrator approval, there will be three additional CloudFormation resources: a WaitHandle, the WaitCondition, and the custom resource. The Lambda custom resource is called to notify the admin who is responsible for approving the product launch. The stack will be in a waiting state until it receives a response from the admin.</li> 
<li>The admin receives an email notification about the product launch and an approval URL to allow stack creation. The URL contains the WaitHandle pre-signed URL as a parameter for signaling the stack to continue.</li> 
<li>When the admin clicks the URL, a Lambda function behind API Gateway receives the admin approval to proceed.</li> 
<li>If the admin approves the product launch, the Lambda approval function sends the confirmation for the WaitHandle to proceed with stack creation. Otherwise, the stack is rolled back after the maximum wait time of 12 hours.</li> 
<li>The user receives either a completion or rolled back status on the AWS Service Catalog console. Additionally, the admin could reach out to the user to ask for more information on the launch request before proceeding with the approval.</li> 
</ol> 
<h3>Build Steps:</h3> 
<p>Now that we’ve covered the steps, let’s build the required resources for the approval flow. I have attached an <a href="https://s3.amazonaws.com/service-catalog-approval-flow/v1/resources_for_approval_template.yaml" target="_blank" rel="noopener noreferrer">AWS CloudFormation template</a> for your convenience so you can follow along. When you launch the template, you will be prompted to enter an email address for the approval flow. After stack completion, the following resources will be created:</p> 
<p><strong>SNS topic</strong>: An SNS topic along with the provided email subscription. You will be getting an email to confirm your subscription. Subscribe to the topic to receive messages.</p> 
<p><strong>SNS notification function</strong>: A Lambda function to send the approval mail. Whenever a new product launch requires approval, this Lambda function will be called. This function will get the WaitHandle pre-signed URL and user email address as input.</p> 
<p><strong>Approval function</strong>: A Lambda function to notify the CloudFormation stack by sending the status of the WaitHandle pre-signed URL.</p> 
<p>In addition to these resources, an API Gateway API and IAM roles will also be created.</p> 
<p>Note the ARN for the Lambda function from the output. You will need this later to test the setup.</p> 
<h3>Testing:</h3> 
<p>To test the setup, you can use the attached <a href="https://s3.amazonaws.com/service-catalog-approval-flow/v1/sample_wordpress_for_approval_template.yaml" target="_blank" rel="noopener noreferrer">sample CloudFormation template</a>. This is a standard template provided by Amazon that deploys WordPress on AWS, but I’ve modified it to introduce approval flow and added three additional resources: WaitCondition, WaitConditionHandle, and NotificationFunction.</p> 
<p>WaitCondition and WaitConditionHandle are used to pause the creation of a stack and to wait for a signal before continuing to create the stack.&nbsp;All other resources in the template depend on WaitCondition for approval status.</p> 
<pre><code class="lang-python">  WaitHandle:
Type: 'AWS::CloudFormation::WaitConditionHandle'
WaitCondition:
Type: 'AWS::CloudFormation::WaitCondition'
Properties:
Handle:
Ref: 'WaitHandle'
Timeout: '43200'</code></pre> 
<p>NotificationFunction is a custom resource that triggers the Lambda function responsible for sending approval email.</p> 
<pre><code class="lang-python">  NotificationFunction:
Type: Custom::NotificationFunction
Properties:
ServiceToken: '&lt;REPLACE YOUR LAMBDA ARN&gt;'
Region: !Ref &quot;AWS::Region&quot;
WaitUrl: !Ref WaitHandle
EmailID: !Ref UserEmail</code></pre> 
<p>You’ll need to download the template and modify the NotificationFunction resource’s ServiceToken parameter to specify the ARN you obtained in the previous section. Once you have updated the Lambda ARN, you can add this template as a new product to your existing catalog or test the template in the CloudFormation console.</p> 
<p>When the template has launched successfully, you’ll receive email requesting approval to proceed, similar to this:</p> 
<p><a href="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/08/09/servicecatalog2.png"><img class="alignnone size-full wp-image-4907" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/08/09/servicecatalog2.png" alt="" width="975" height="473" /></a></p> 
<p>When you choose the approval link, the Lambda function behind the API will send a confirmation for WaitHandle to proceed with stack creation. Otherwise, the stack will be rolled back after the maximum wait time of 12 hours.</p> 
<h3>Troubleshooting:</h3> 
<p>If you don’t receive the approval mail, check the SNS topic subscription status. Also, verify that you’ve specified the correct Lambda ARN in the template. Check Amazon CloudWatch logs for any exceptions or errors launching the stack. Additionally, you can check the following sources for general troubleshooting help with services such as Amazon SNS, API Gateway, and AWS Lambda:</p> 
<ul> 
<li><a href="http://docs.aws.amazon.com/sns/latest/dg/SubscribeTopic.html" target="_blank" rel="noopener noreferrer">Check your SNS Topic subscription</a></li> 
<li><a href="http://docs.aws.amazon.com/apigateway/latest/developerguide/monitoring_overview.html" target="_blank" rel="noopener noreferrer">Monitoring and Troubleshooting in API Gateway</a></li> 
<li><a href="http://docs.aws.amazon.com/lambda/latest/dg/monitoring-functions-logs.html" target="_blank" rel="noopener noreferrer">Accessing Amazon CloudWatch Logs for AWS Lambda</a></li> 
</ul> 
<h3>Conclusion:</h3> 
<p>You can now add a simple approval workflow to your Service Catalog stack by adding the three resources from the sample test template. For more information about managing portfolios, products, and constraints from an administrator console, check this <a href="http://docs.aws.amazon.com/servicecatalog/latest/adminguide/catalogs.html" target="_blank" rel="noopener noreferrer">documentation</a>.</p> 
<p>I hope this post and sample templates were useful in helping you extend AWS Service Catalog features. Feel free to leave your feedback or suggestions in the comments.</p> 
</article> 
<article class="post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b><a href="https://aws.amazon.com/blogs/apn/testing-aws-gameday-with-the-aws-well-architected-framework/" property="url" rel="bookmark"><span property="name headline">Testing AWS GameDay with the AWS Well-Architected Framework – Review</span></a></b> 
<footer class="meta">
by 
<span property="author" typeof="Person"><span property="name">Ian Scofield</span></span> | on 
<time property="datePublished" datetime="2017-08-15T11:14:23+00:00">15 AUG 2017</time> | in 
<span class="categories"><a href="https://aws.amazon.com/blogs/apn/category/database/amazon-dynamodb/" title="View all posts in Amazon DynamoDB*"><span property="articleSection">Amazon DynamoDB*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/messaging/amazon-simple-notification-service-sns/" title="View all posts in Amazon Simple Notification Service (SNS)*"><span property="articleSection">Amazon Simple Notification Service (SNS)*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/aws-partner-solutions-architect-sa-guest-post/" title="View all posts in AWS Partner Solutions Architect (SA) Guest Post"><span property="articleSection">AWS Partner Solutions Architect (SA) Guest Post</span></a></span> | 
<a href="https://aws.amazon.com/blogs/apn/testing-aws-gameday-with-the-aws-well-architected-framework/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-4922" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-apn-blog&amp;disqus_identifier=4922&amp;disqus_title=Testing+AWS+GameDay+with+the+AWS+Well-Architected+Framework+%E2%80%93+Review&amp;disqus_url=https://aws.amazon.com/blogs/apn/testing-aws-gameday-with-the-aws-well-architected-framework/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-4922');
});
</script> | 
<a href="#" role="button" data-share-dialog=""><span class="span icon-share"></span>&nbsp;Share</a> 
<ul> 
</ul> 
</footer> 
<h5><em>By Ian Scofield, Juan Villa, and Mike Ruiz</em></h5> 
<p>&nbsp;</p> 
<p>GameDay is an immersive, team-based event we’ve hosted at AWS Summits and re:Invent over the past few years. The event has teams of players settling into a challenging—and hopefully entertaining—scenario as DevOps leads at Unicorn.Rentals, a popular startup minutes away from the very public launch of a widely anticipated product. For more information, see the <a href="https://reinvent.awsevents.com/learn/gameday/" target="_blank" rel="noopener noreferrer">GameDay website</a>.</p> 
<p>Of course, we have a lot going on behind the scenes to make GameDay work. Beyond all the enthusiastic acting and silly props, you’ll find a complex AWS infrastructure that includes a live score tracking engine, a single-instance load generator capable of dynamically varying the load over the course of the game, and various command and control functions. Overall, the infrastructure is simplistic in design but complex to operate, with room for improvement by incorporating the same best practices we encourage players to adopt during the course of the game.</p> 
<p>Today, in an attempt to improve the player experience (and our quality of life), we have invited a team of AWS Partner Solutions Architects to review the GameDay architecture against a standard benchmark: the <a href="https://aws.amazon.com/architecture/well-architected/" target="_blank" rel="noopener noreferrer">AWS Well-Architected Framework</a>. The review team will work to understand the details of our architecture, ask detailed questions about our design and intent, and then deliver a document with prioritized findings.</p> 
<p>In this post, we’ll cover the initial architecture review and the findings delivered from the review team. In future posts, we will share the process of making improvements and our plans to refine our architecture through continuous improvement and collaboration with AWS Solutions Architects.</p> 
<p>&nbsp;</p> 
<h3>Architecture Overview</h3> 
<p>We began the review session by providing the review team with an architectural overview of GameDay, using diagrams and other collateral to highlight various components and relationships where appropriate. To help you follow along, here’s a summary of the high-level details we shared regarding the architecture of GameDay:</p> 
<p>The GameDay infrastructure runs in a master AWS account, with each team having their own player AWS account (Figure 1). Various components in the master account serve load to player accounts, and host other services such as the scoreboard and cost calculator.&nbsp; The master account utilizes an <a href="http://docs.aws.amazon.com/IAM/latest/UserGuide/tutorial_cross-account-with-roles.html" target="_blank" rel="noopener noreferrer">IAM Cross-Account Role</a> in each player account that gives it the required permissions to perform administrative tasks throughout the day.</p> 
<p><a href="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/08/11/GameDay1.png"><img class="size-full wp-image-4924 aligncenter" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/08/11/GameDay1.png" alt="" width="453" height="339" /></a></p> 
<p style="text-align: center"><em>Figure 1: Master – player account relationship</em></p> 
<p>The master account has the following components:</p> 
<ol> 
<li><strong>Scoreboard</strong> – This is a static site hosted in an <a href="https://aws.amazon.com/s3/" target="_blank" rel="noopener noreferrer">Amazon Simple Storage Service</a> (Amazon S3) bucket, written in JavaScript and HTML.</li> 
<li><strong>Cost calculator</strong> – In order to encourage players to take cost optimization into account, we charge players for their <a href="https://aws.amazon.com/ec2/" target="_blank" rel="noopener noreferrer">Amazon Elastic Computer Cloud</a> (Amazon EC2) utilization (as in the real world!). The cost calculator includes three AWS Lambda functions that deduct points proportional to their consumption.</li> 
<li><strong>Amazon DynamoDB</strong> – We use several <a href="https://aws.amazon.com/dynamodb/" target="_blank" rel="noopener noreferrer">Amazon DynamoDB</a> tables to hold team information, score information, generic game configuration values, and other supporting information that is used by the master account components.</li> 
<li><strong>Load generator</strong> – This is the heart of the game implementation. It is made up of a single EC2 instance. &nbsp;The load generator controls the game and initiates administrative actions. 
<ol> 
<li>When player accounts are dynamically created, a message is posted to an <a href="https://aws.amazon.com/sns/" target="_blank" rel="noopener noreferrer">Amazon Simple Notification Service</a> (Amazon SNS) topic in the master account with a notification of the account creation.&nbsp; On the load generator, PHP scripts run to do the account registration/provisioning based on the SNS messages.</li> 
<li>The load generator runs one process per team that initiates connections to the infrastructure running in each player’s account.</li> 
<li>The number of messages delivered to player accounts is scaled by creating additional processes per team within this load generator instance.</li> 
</ol> </li> 
</ol> 
<p>Figure 2 shows a high-level overview of the master account architecture:</p> 
<p><a href="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/08/11/GameDay2.png"><img class="size-full wp-image-4925 aligncenter" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/08/11/GameDay2.png" alt="" width="540" height="463" /></a></p> 
<p style="text-align: center"><em>Figure 2: Initial architecture</em></p> 
<p>&nbsp;</p> 
<h3>Deep Dive</h3> 
<p>Once they understood the architecture, the review team began a deep dive and asked clarifying questions on the various components based on the questions in the appendix of the <a href="https://d0.awsstatic.com/whitepapers/architecture/AWS_Well-Architected_Framework.pdf" target="_blank" rel="noopener noreferrer">Well-Architected Framework whitepaper</a>.&nbsp; In particular, they were very interested in manual operations (especially in the operation of the load generator), disaster recovery (specifically the recovery timing for assets lost before an event), and the security of the application as a whole (specifically the security of customer data and credentials). On the whole, the review was comprehensive and took approximately three hours to complete.</p> 
<h3>Review Findings</h3> 
<p>The review team consolidated the data and provided us with a written report that outlined the various findings.&nbsp; In addition, they provided us with notes and prioritized recommendations for each finding, which would serve as a starting point for us to develop our remediation plan.</p> 
<p>Looking at GameDay through the lens of the Well-Architected Framework, it was obvious that there were many opportunities for improvement. The AWS review team prioritized the findings into two sets: critical and recommended. Most of the findings were classified as recommended—these don’t pose an immediate risk and will be incorporated into our roadmap.&nbsp; However, the three elements that were identified as critical needed to be addressed immediately.</p> 
<p>Here’s the text of the findings from the review team:</p> 
<p>&nbsp;</p> 
<hr /> 
<b></b> 
<h3>SEC11. How are you managing keys?</h3> 
<p><strong>Critical finding:</strong></p> 
<p>The legacy administrative scripts for GameDay use AWS access keys and secret access keys and are stored in plain text in an Amazon DynamoDB table.</p> 
<p><strong>Notes:</strong></p> 
<p>The legacy administrative scripts require the use of an AWS access key and secret access key in order to interact with the AWS API on the player’s account, and do not support cross-account roles. Currently, these keys are being stored in plain text in an Amazon DynamoDB table, which the scripts query to retrieve the keys.&nbsp; AWS access keys and secret access keys are long-lived credentials that do not expire until they are explicitly revoked. Storing them in plain text increases the probability of the keys being compromised, and in the current design, any person with read access to the DynamoDB table (though the application or application administrative interface, indirectly via backups or logs, or directly via the AWS DynamoDB API) can read and exploit the keys.</p> 
<p><strong>Recommendation:</strong></p> 
<p>Modify the legacy administrative scripts to support cross-account roles in order to avoid the need to store and use AWS access keys and secret access Keys.</p> 
<h3>REL 7. How are you planning for disaster recovery?</h3> 
<p><strong>Critical finding:</strong></p> 
<p>There is no clearly defined disaster recovery plan, recovery point objectives (RPO), or recovery time objectives (RTO).&nbsp; Additionally due to not having a plan, it cannot be periodically tested against the RPO and RTO objectives.</p> 
<p><strong>Notes:</strong></p> 
<p>GameDay was originally conceived as a set of instructions players would iteratively execute in a minimally configured account. As tooling and additional features were added over time, they have failed to step back and consider the entire stack and how to protect it from accidental, malicious, or environmental faults. Although it’s just a game, GameDay customers invest a whole day to attend and deserve as good an experience as can be delivered; having to scramble to invent a recovery process in the run-up to an event or, worse, in the middle of a live game would be a bad experience for all involved.</p> 
<p><strong>Recommendation:</strong></p> 
<ol> 
<li>Define a disaster recovery plan, including RPO and RTO.</li> 
<li>Periodically test the plan against the defined objectives.</li> 
</ol> 
<h3>REL 2. How does your system withstand component failures?</h3> 
<p><strong>Critical finding:</strong></p> 
<p>Currently the load generator is a single instance in a single <a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html" target="_blank" rel="noopener noreferrer">Availability Zone</a>, and no recovery options have been configured.</p> 
<p><strong>Notes:</strong></p> 
<p>If this load generator instance were to fail or become unavailable either due to a hardware fault or in the (unlikely) event of an Availability Zone failure, the game would no longer be able to continue, because there is no automated process to recover the failed node.&nbsp; The load generator is currently not in an <a href="http://docs.aws.amazon.com/autoscaling/latest/userguide/AutoScalingGroup.html" target="_blank" rel="noopener noreferrer">Auto Scaling group</a>, nor does it have <a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-recover.html" target="_blank" rel="noopener noreferrer">EC2 instance recovery</a> configured.&nbsp; Additionally, the instance has been configured manually and doesn’t contain all the necessary settings and scripts. &nbsp;Lastly, all state is stored locally on the instance and will need to be broken out when implementing a multi-instance architecture.&nbsp; By storing state externally, this will also alleviate the issue of losing state in the event of an instance failure.</p> 
<p><strong>Recommendation:</strong></p> 
<ol> 
<li>Implement an EC2 Auto Scaling group with a launch configuration by creating an Amazon Machine Image (AMI) which self-contains all necessary components.&nbsp; Optionally, you can utilize user data to pull down all necessary components.</li> 
<li>Configure your Auto Scaling group to span multiple Availability Zones to increase the resiliency and fault tolerance of your architecture.</li> 
<li>Make your instances stateless to reduce the chance of losing information in the event of a failure.</li> 
</ol> 
<p>&nbsp;</p> 
<hr /> 
<h3></h3> 
<h3>Next Steps</h3> 
<p>Now that the review team has given us this feedback and the list of critical items that need to be resolved, we need to construct our remediation plan to correct these deficiencies.&nbsp; In our next blog post, we’ll go through this remediation plan and explain in depth how we plan to correct these items to improve the security and reliability of the GameDay application.</p> 
</article> 
<article class="post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b><a href="https://aws.amazon.com/blogs/apn/announcing-the-addition-of-four-aws-management-tools-to-the-aws-service-delivery-program/" property="url" rel="bookmark"><span property="name headline">Announcing the Addition of four AWS Management Tools to the AWS Service Delivery Program</span></a></b> 
<footer class="meta">
by 
<span property="author" typeof="Person"><span property="name">Lauren Small</span></span> | on 
<time property="datePublished" datetime="2017-08-14T13:30:14+00:00">14 AUG 2017</time> | in 
<span class="categories"><a href="https://aws.amazon.com/blogs/apn/category/management-tools/amazon-ec2-systems-manager/" title="View all posts in Amazon EC2 Systems Manager*"><span property="articleSection">Amazon EC2 Systems Manager*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/apn-launches/" title="View all posts in APN Launches"><span property="articleSection">APN Launches</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/management-tools/aws-cloudformation/" title="View all posts in AWS CloudFormation*"><span property="articleSection">AWS CloudFormation*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/management-tools/aws-cloudtrail/" title="View all posts in AWS CloudTrail*"><span property="articleSection">AWS CloudTrail*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/management-tools/aws-config/" title="View all posts in AWS Config*"><span property="articleSection">AWS Config*</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/aws-service-delivery-program/" title="View all posts in AWS Service Delivery Program"><span property="articleSection">AWS Service Delivery Program</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/aws-summits/" title="View all posts in AWS Summits"><span property="articleSection">AWS Summits</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/management-tools/" title="View all posts in Management Tools*"><span property="articleSection">Management Tools*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/apn/announcing-the-addition-of-four-aws-management-tools-to-the-aws-service-delivery-program/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-4928" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-apn-blog&amp;disqus_identifier=4928&amp;disqus_title=Announcing+the+Addition+of+four+AWS+Management+Tools+to+the+AWS+Service+Delivery+Program&amp;disqus_url=https://aws.amazon.com/blogs/apn/announcing-the-addition-of-four-aws-management-tools-to-the-aws-service-delivery-program/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-4928');
});
</script> | 
<a href="#" role="button" data-share-dialog=""><span class="span icon-share"></span>&nbsp;Share</a> 
<ul> 
</ul> 
</footer> 
<h6>By Ben Perak, APN Global Segment Leader</h6> 
<p>&nbsp;</p> 
<p><a href="https://aws.amazon.com/partners/service-delivery/" target="_blank" rel="noopener noreferrer">The Amazon Web Services (AWS) Service Delivery Program</a> launched in November 2016 with one simple goal: to help customers easily identify AWS Partner Network (APN) Partners with a successful track record of delivering specific AWS services and a demonstrated ability to provide expertise in a particular service or skill area.</p> 
<p>Nineteen AWS services are included in the AWS Service Delivery Program, including many database services, compute services, content delivery services, security services, serverless computing services, and analytics services. This program also highlights APN Partners who deliver workloads in the AWS GovCloud (US) Region.</p> 
<p>Today, we’re excited to announce the addition of four AWS Management Tools to the program: AWS CloudFormation, Amazon EC2 Systems Manager, AWS Config and AWS CloudTrail.</p> 
<p><a href="https://aws.amazon.com/partners/service-delivery/" target="_blank" rel="noopener noreferrer"><img class="size-full wp-image-4936 aligncenter" src="https://d2908q01vomqb2.cloudfront.net/77de68daecd823babbb58edb1c8e14d7106e83bb/2017/08/12/800x200_Management-01.png" alt="" width="3334" height="834" /></a></p> 
<h3>Raising the Bar in Cloud Management with AWS Management Tools Service Delivery Partners</h3> 
<p>Cloud operations are quickly shifting from ‘How do I do it’ to ‘How do I do it BETTER.’ That is why AWS has developed an extensive portfolio of <a href="https://aws.amazon.com/products/management/?nc2=h_l3_db" target="_blank" rel="noopener noreferrer">Management Tools</a> that provide APN Partners and customers with leading cloud-management capabilities. These services –whether used individually or combined as an end-to-end solution—provide cloud operations teams with the solutions they need to keep pace with their agile businesses. Whether it is provisioning resources or a group of resources called stacks via AWS CloudFormation, pushing OS patches at scale with Amazon EC2 Systems Manager, tracking configuration changes in a highly regulated environment using AWS Config, or keeping track of user activity with AWS CloudTrail—these services have you covered. Combined with our APN Partners’ deep domain knowledge, customers can be assured they are getting a world class cloud management solution.</p> 
<blockquote> 
<p>“AWS Management Tools solutions let our customers access the big advantage of cloud: the ability to provision, query and compare the current to desired state,” says Flux7 Chief Technology Officer Ali Hussain. “These services allow us to easily move from an early stage proof of concept to an enterprise-ready product, adding in compliance, security, and long-term maintenance controls.”</p> 
</blockquote> 
<h3>Congratulations to our Launch Partners:</h3> 
<p>The following APN Consulting Partners have demonstrated their ability to raise the bar in delivering results with these services and have become Management Tools Service Delivery launch partners:</p> 
<h4><a href="https://aws.amazon.com/cloudformation/partners/" target="_blank" rel="noopener noreferrer">AWS CloudFormation Partners</a></h4> 
<ul> 
<li>2nd Watch</li> 
<li>Cognizant</li> 
<li>Datapipe</li> 
<li>Flux7</li> 
<li>Foghorn Consulting</li> 
<li>Stelligent</li> 
</ul> 
<h4><a href="https://aws.amazon.com/cloudtrail/partners/" target="_blank" rel="noopener noreferrer">AWS CloudTrail Partners</a></h4> 
<ul> 
<li>2nd Watch</li> 
<li>Cloudreach</li> 
<li>Cognizant</li> 
<li>Datapipe</li> 
<li>Flux7</li> 
<li>Foghorn Consulting</li> 
<li>Stelligent</li> 
</ul> 
<h4><a href="https://aws.amazon.com/config/partners/" target="_blank" rel="noopener noreferrer">AWS Config Partners</a></h4> 
<ul> 
<li>2nd Watch</li> 
<li>Cloudreach</li> 
<li>Cognizant</li> 
<li>Flux7</li> 
<li>Stelligent</li> 
</ul> 
<h4><a href="https://aws.amazon.com/ec2/systems-manager/partners/" target="_blank" rel="noopener noreferrer">Amazon EC2 Systems Manager Partners</a></h4> 
<ul> 
<li>Cloudnexa</li> 
<li>Cloudreach</li> 
<li>Cloudticity</li> 
<li>Flux7</li> 
<li>Logicworks</li> 
<li>REAN Cloud</li> 
<li>Stelligent</li> 
</ul> 
<h3>Why should APN Consulting Partners with expertise in Management Tools join?</h3> 
<p>Joining the program enables you to promote your firm as an AWS-validated expert in AWS Management tools. By becoming an AWS Management Tools Delivery Partner, with a focus on one or more of the included services, you can increase your firm’s visibility to customers seeking your type of expertise through a number of channels, such as the AWS Service Delivery website. Additionally, you’ll be distinguished as an expert in the applicable service in the Partner Solutions Finder and will be featured on the services partner page.</p> 
<h3>What are the requirements?</h3> 
<p>In addition to meeting the minimum requirements of the program listed on <a href="https://aws.amazon.com/partners/service-delivery/" target="_blank" rel="noopener noreferrer">this page</a>, your company must pass service-specific verification of customer references and a technical review. This instills confidence in prospective customers that they are working with partners who provide recent and relevant experience.</p> 
<h3>Want to learn more?</h3> 
<p>Learn more about the Service Deliver program and the partners participating in it by visiting the <a href="https://aws.amazon.com/partners/service-delivery/" target="_blank" rel="noopener noreferrer">Service Delivery Program homepage</a>. If you are a partner and would like to join the AWS Service Delivery Program, apply within the <a href="https://partnercentral.awspartner.com/apex/partnerAccount" target="_blank" rel="noopener noreferrer">APN Portal</a>.</p> 
</article> 
<article class="post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b><a href="https://aws.amazon.com/blogs/apn/meet-our-financial-services-competency-partners-at-the-aws-new-york-summit/" property="url" rel="bookmark"><span property="name headline">Meet our Financial Services Competency Partners at the AWS New York Summit</span></a></b> 
<footer class="meta">
by 
<span property="author" typeof="Person"><span property="name">Lauren Small</span></span> | on 
<time property="datePublished" datetime="2017-08-11T13:50:50+00:00">11 AUG 2017</time> | in 
<span class="categories"><a href="https://aws.amazon.com/blogs/apn/category/apn-competency-partner/" title="View all posts in APN Competency Partner"><span property="articleSection">APN Competency Partner</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/aws-summits/" title="View all posts in AWS Summits"><span property="articleSection">AWS Summits</span></a>, <a href="https://aws.amazon.com/blogs/apn/category/financial-services/" title="View all posts in Financial Services"><span property="articleSection">Financial Services</span></a></span> | 
<a href="https://aws.amazon.com/blogs/apn/meet-our-financial-services-competency-partners-at-the-aws-new-york-summit/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog=""><span class="span icon-share"></span>&nbsp;Share</a> 
<ul> 
</ul> 
</footer> 
<h6><em>By Renata Melnyk, AWS Financial Services Competency Program Manager</em></h6> 
<p>&nbsp;</p> 
<p>AWS is enabling scalable, flexible, and cost-effective solutions for banking and payments, capital markets, and insurance organizations of all sizes, from startups to global enterprises. To support the seamless integration and deployment of these solutions, AWS established the <a href="https://aws.amazon.com/financial-services/partner-solutions/" target="_blank" rel="noopener noreferrer">Financial Services Partner Competency Program</a> to identify AWS Partner Network (APN) Consulting and Technology partners with deep industry experience to assist our customers in their migration to the AWS Cloud. AWS Financial Services Competency Partners have demonstrated industry expertise, readily implemented solutions that align with AWS architectural best practices, and have AWS-certified staff.</p> 
<p>This year at the <a href="https://aws.amazon.com/summits/new-york/" target="_blank" rel="noopener noreferrer">AWS NY Summit</a>, some of our AWS Competency Partners are demonstrating the unique and innovative work they’ve done with customers. If you are attending the NY Summit on August 14th, don’t miss these sessions:</p> 
<p>&nbsp;</p> 
<h3>AWS Financial Services Competency Partners and the 2017 AWS New York Summit</h3> 
<p>&nbsp;</p> 
<h4>Summit Keynote – FICO</h4> 
<p>Our AWS Financial Services Competency Partner, FICO will be presenting during the Summit keynote this year. FICO’s CIO Claus Moldt, will speak about how the company uses data, advanced analytics, and mathematical algorithms to help clients transform their business. FICO is a leading analytics software company, helping businesses in more than 90 countries make better decisions that drive higher levels of growth, profitability, and customer satisfaction.</p> 
<p>As an APN Technology Partner, FICO was also one of the first APN Partners to achieve the <a href="https://aws.amazon.com/financial-services/partner-solutions/" target="_blank" rel="noopener noreferrer">AWS Financial Services Competency</a> in the Risk Management category. This category validates solutions that help financial institutions identify, model, and assess risk; ensure monitoring and compliance with industry regulations; or help in surveillance or fraud monitoring.</p> 
<h4></h4> 
<h4>Migration Journey of AIG’s Global Claims Web Application from Mainframe to Public Cloud – Deloitte</h4> 
<p>The New York Summit will also feature AWS Financial Services Competency Partners through sessions, such as <a href="https://awsnyc17.smarteventscloud.com/connect/agenda.ww" target="_blank" rel="noopener noreferrer">Migration Journey of AIG’s Global Claims Web Application from Mainframe to Public Cloud</a>, with speakers from AWS, AIG, and Deloitte.</p> 
<p>This session will detail the successful migration of a critical AIG business application from mainframe to the cloud. Global Insurance companies such as AIG are taking the lead in ensuring that their business applications are agile and cost efficient. AWS provided the necessary services to enable AIG to architect an optimum solution to migrate their application from private data centers to AWS. AIG collaborated with Deloitte, AWS Financial Services Competency and Premier APN Consulting Partner, and AWS teams to enable successful execution of the initiative, which entailed an end-to-end application migration with outcomes that included operational cost optimization, enhanced application performance, and flexibility improvements. AWS offered a variety of architectural choices, allowing the AIG project teams to structure a migration in the most effective way. The migration and right-sizing helped AIG’s application team realize substantial cost savings through the reduction of compute costs and reduction of infrastructure footprint, which has lowered operation costs. Over the course of 12 months, the program team developed and implemented a migration roadmap, a solution architecture leveraging AWS cloud native services, a testing strategy, operationalization for production, and a cutover plan.</p> 
<h4></h4> 
<h4>Machine Learning in Capital Markets – IHS Markit</h4> 
<p>Financial services companies are using machine learning to reduce fraud, streamline processes, and improve their bottom line. AWS provides tools that help them easily use AI tools like MXNet and Tensor Flow to perform predictive analytics, clustering, and more advanced data analyses. If you’re at the New York Summit, <a href="https://awsnyc17.smarteventscloud.com/connect/agenda.ww" target="_blank" rel="noopener noreferrer">stop by this session</a> to learn how IHS Markit, an Advanced APN Technology Partner and AWS Financial Services Competency Partner, has used machine learning on AWS to help global banking institutions manage their commodities portfolios. You will also learn how the Amazon Machine Learning service can take the hassle out of AI.</p> 
<p>To learn more about AWS Financial Services Competency Partners, please visit our <a href="https://aws.amazon.com/financial-services/partner-solutions/" target="_blank" rel="noopener noreferrer">AWS Financial Services Partner Solutions page</a>.</p> 
<h4>About the AWS Competency Program</h4> 
<p>The <a href="https://aws.amazon.com/partners/competencies/" target="_blank" rel="noopener noreferrer">AWS Competency Program</a> is designed to highlight APN Partners who have demonstrated technical proficiency and proven customer success in specialized solution areas. Attaining an AWS Competency allows partners to differentiate themselves to customers by showcasing expertise in a specific solution area.</p> 
</article> 
<p>
© 2017, Amazon Web Services, Inc. or its affiliates. All rights reserved.
</p>

    </div>
  </div>
</div>


    <div id="footer" class="navigation hidden-print">
      <div class="container">
        <div class="row">
          <div class="col-xs-12">
            <ul class="footer-links nav navbar-nav">
              <li><a href="../aws.html">AWS</a></li>
              <li><a href="../linux.html">Linux</a></li>
              <li><a href="../docker.html">Docker</a></li>
              <li><a href="../ibmpower.html">IBM Power</a></li>
              <li><a href="blogsataws1.html">Blogs@AWS (Kindle Friendly)</a></li>
            </ul>
            <ul class="footer-links nav navbar-nav navbar-right">
              <li><a href="../comments.html">Comments?</a></li>
            </ul>
          </div>
        </div>
      </div>
    </div>
  </body>
</html>
