<!DOCTYPE html>
<html lang="en">
  <head>
<!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-593498H');</script>
<!-- End Google Tag Manager -->

    <meta charset="utf-8">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">

    <meta name="msapplication-config" content="/microsoft-tile.xml" />
    <meta name="theme-color" content="#ffffff">

    <meta property="og:url" content="https://bejoycalias.github.io/blogsataws/devopsblogs1.html" />
    <meta property="og:site_name" content="Bejoy's TechNotes"/>
    <meta property="og:title" content="Bejoy's TechNotes - Kindle Friendly AWS DevOps Blogs" />
    <meta property="og:image" content="https://bejoycalias.github.io/assets/images/og-image.png"/>
    <meta property="og:image:width" content="1200"/>
    <meta property="og:image:height" content="1200"/>
    <meta property="og:description" content="" />

    <title>Bejoy's TechNotes - Kindle Friendly AWS DevOps Blogs</title>
    <link href="../assets/stylesheets/application-832aa42c.css" rel="stylesheet" />

    <!--[if lt IE 9]>
      <script src="../assets/javascripts/ie-compat-c141a02d.js"></script>
    <![endif]-->
    <script src="../assets/javascripts/application-ff53d307.js"></script>

    <!-- Typekit script to import Klavika font -->
    <script src="https://use.typekit.net/wxf7mfi.js"></script>
    <script>try{Typekit.load({ async: true });}catch(e){}</script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-100043608-1', 'auto');
  ga('send', 'pageview');

</script>

    
  </head>

  <body id="uh-oh-" class="layout-inner page-uh-oh-">
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-593498H"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->


    <div id="header" class="navigation navbar-static-top hidden-print">
      <div class="container">
        <div class="row">
          <div class="col-xs-12">
            <div class="navbar-header">
              <div class="navbar-brand">
                <a href="/">
                  <svg version="1.0" xmlns="http://www.w3.org/2000/svg" width="135.000000pt" height="50" viewbox="0 0 135.000000 45.000000" preserveaspectratio="xMidYMid meet" class="logo">

<g transform="translate(0.000000,45.000000) scale(0.100000,-0.100000)" fill="#000000" stroke="none">
<path class="text" fill="#000000" d="M527 384 c-4 -4 -7 -18 -7 -31 0 -21 4 -24 28 -21 21 2 27 8 27 28 0
18 -6 26 -20 28 -12 2 -24 0 -28 -4z"></path>
<path class="text" fill="#000000" d="M1080 335 c0 -48 2 -55 20 -55 18 0 20 7 20 55 0 48 -2 55 -20 55
-18 0 -20 -7 -20 -55z"></path>
<path class="text" fill="#000000" d="M54 357 c-2 -7 -3 -69 -2 -138 l3 -124 65 -3 c90 -3 130 20 130 77 0
29 -6 44 -20 54 -20 14 -20 15 -3 45 14 25 15 34 5 56 -6 15 -23 31 -38 36
-38 15 -134 13 -140 -3z m110 -33 c19 -7 21 -45 4 -62 -7 -7 -22 -12 -35 -12
-20 0 -23 5 -23 40 0 41 13 50 54 34z m20 -130 c19 -18 19 -20 6 -45 -8 -13
-21 -19 -45 -19 -34 0 -35 1 -35 40 0 38 2 40 29 40 16 0 37 -7 45 -16z"></path>
<path class="text" fill="#000000" d="M319 271 c-23 -24 -29 -38 -29 -74 0 -25 3 -53 6 -62 20 -50 164 -64
164 -15 0 15 -7 17 -45 12 -46 -5 -75 8 -75 34 0 11 16 14 65 14 l65 0 0 35
c0 80 -92 114 -151 56z m99 -33 c3 -15 -4 -18 -37 -18 -43 0 -50 7 -29 28 18
18 62 11 66 -10z"></path>
<path class="text" fill="#000000" d="M520 184 c0 -107 -1 -116 -20 -121 -11 -3 -20 -12 -20 -19 0 -21 76
-19 84 2 3 9 6 69 6 135 l0 119 -25 0 -25 0 0 -116z"></path>
<path class="text" fill="#000000" d="M649 271 c-24 -25 -29 -37 -29 -78 1 -70 34 -103 105 -103 55 0 95
44 95 103 0 60 -7 75 -41 92 -47 25 -96 19 -130 -14z m111 -30 c25 -48 2 -111
-40 -111 -45 0 -69 80 -34 114 21 22 61 20 74 -3z"></path>
<path class="text" fill="#000000" d="M850 287 c0 -8 16 -57 36 -110 28 -76 33 -100 25 -116 -16 -28 -14
-31 18 -31 27 0 29 4 70 123 23 67 41 128 41 135 0 6 -11 12 -24 12 -21 0 -26
-8 -41 -65 -10 -36 -21 -68 -25 -70 -3 -2 -16 27 -29 66 -19 60 -25 69 -47 69
-13 0 -24 -6 -24 -13z"></path>
<path class="text" fill="#000000" d="M1192 284 c-17 -12 -22 -24 -20 -47 2 -26 10 -36 45 -52 49 -23 59
-55 17 -55 -14 0 -34 5 -45 10 -16 9 -19 7 -19 -13 0 -17 7 -27 23 -31 69 -18
117 6 117 60 0 32 -4 37 -45 55 -60 26 -62 54 -4 46 37 -5 40 -3 37 16 -2 18
-11 23 -43 25 -25 2 -49 -3 -63 -14z"></path>
</g>
</svg>

                </a>
              </div>
              <button class="navbar-toggle" type="button">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
              </button>
            </div>
            <div class="buttons hidden-xs">
              <nav class="navigation-links" role="navigation">
                <ul class="main-links nav navbar-nav navbar-right">
                  <li><a href="../aws.html">AWS</a></li>
                  <li><a href="../linux.html">Linux</a></li>
                  <li><a href="../docker.html">Docker</a></li>
                  <li><a href="../ibmpower.html">IBM Power</a></li>
                  <li><a href="blogsataws1.html">Blogs@AWS (Kindle Friendly)</a></li>
                </ul>
              </nav>
            </div>
          </div>
        </div>
      </div>
    </div>

    <div class="sidebar-overlay"></div>

<aside class="sidebar" role="navigation">
  <div class="sidebar-header">
    <svg version="1.0" xmlns="http://www.w3.org/2000/svg" width="135.000000pt" height="42" viewbox="0 0 135.000000 45.000000" preserveaspectratio="xMidYMid meet">

<g transform="translate(0.000000,45.000000) scale(0.100000,-0.100000)" fill="#000000" stroke="none">
<path class="text" fill="#000000" d="M527 384 c-4 -4 -7 -18 -7 -31 0 -21 4 -24 28 -21 21 2 27 8 27 28 0
18 -6 26 -20 28 -12 2 -24 0 -28 -4z"></path>
<path class="text" fill="#000000" d="M1080 335 c0 -48 2 -55 20 -55 18 0 20 7 20 55 0 48 -2 55 -20 55
-18 0 -20 -7 -20 -55z"></path>
<path class="text" fill="#000000" d="M54 357 c-2 -7 -3 -69 -2 -138 l3 -124 65 -3 c90 -3 130 20 130 77 0
29 -6 44 -20 54 -20 14 -20 15 -3 45 14 25 15 34 5 56 -6 15 -23 31 -38 36
-38 15 -134 13 -140 -3z m110 -33 c19 -7 21 -45 4 -62 -7 -7 -22 -12 -35 -12
-20 0 -23 5 -23 40 0 41 13 50 54 34z m20 -130 c19 -18 19 -20 6 -45 -8 -13
-21 -19 -45 -19 -34 0 -35 1 -35 40 0 38 2 40 29 40 16 0 37 -7 45 -16z"></path>
<path class="text" fill="#000000" d="M319 271 c-23 -24 -29 -38 -29 -74 0 -25 3 -53 6 -62 20 -50 164 -64
164 -15 0 15 -7 17 -45 12 -46 -5 -75 8 -75 34 0 11 16 14 65 14 l65 0 0 35
c0 80 -92 114 -151 56z m99 -33 c3 -15 -4 -18 -37 -18 -43 0 -50 7 -29 28 18
18 62 11 66 -10z"></path>
<path class="text" fill="#000000" d="M520 184 c0 -107 -1 -116 -20 -121 -11 -3 -20 -12 -20 -19 0 -21 76
-19 84 2 3 9 6 69 6 135 l0 119 -25 0 -25 0 0 -116z"></path>
<path class="text" fill="#000000" d="M649 271 c-24 -25 -29 -37 -29 -78 1 -70 34 -103 105 -103 55 0 95
44 95 103 0 60 -7 75 -41 92 -47 25 -96 19 -130 -14z m111 -30 c25 -48 2 -111
-40 -111 -45 0 -69 80 -34 114 21 22 61 20 74 -3z"></path>
<path class="text" fill="#000000" d="M850 287 c0 -8 16 -57 36 -110 28 -76 33 -100 25 -116 -16 -28 -14
-31 18 -31 27 0 29 4 70 123 23 67 41 128 41 135 0 6 -11 12 -24 12 -21 0 -26
-8 -41 -65 -10 -36 -21 -68 -25 -70 -3 -2 -16 27 -29 66 -19 60 -25 69 -47 69
-13 0 -24 -6 -24 -13z"></path>
<path class="text" fill="#000000" d="M1192 284 c-17 -12 -22 -24 -20 -47 2 -26 10 -36 45 -52 49 -23 59
-55 17 -55 -14 0 -34 5 -45 10 -16 9 -19 7 -19 -13 0 -17 7 -27 23 -31 69 -18
117 6 117 60 0 32 -4 37 -45 55 -60 26 -62 54 -4 46 37 -5 40 -3 37 16 -2 18
-11 23 -43 25 -25 2 -49 -3 -63 -14z"></path>
</g>
</svg>

  </div>

  <ul class="nav sidebar-nav">
    <li><a href="../aws.html">AWS</a></li>
    <li><a href="../linux.html">Linux</a></li>
    <li><a href="../docker.html">Docker</a></li>
    <li><a href="../ibmpower.html">IBM Power</a></li>
    <li><a href="blogsataws1.html">Blogs@AWS (Kindle Friendly)</a></li>
  </ul>
</aside>


    <div class="container">
  <div class="row">
    <div id="docs-sidebar" class="col-sm-3 col-md-3 col-xs-12 hidden-print" role="complementary">
      <ul class="nav docs-sidenav">
      <li><a href="blogsataws1.html">Blogs @ AWS</a></li>
      <li><a href="whatsnew1.html">What's New @ AWS</a></li>
      <li><a href="mgmtblogs1.html">Management Tools Blogs @ AWS</a></li>
      <li><a href="computeblogs1.html">Compute Blogs @ AWS</a></li>
      <li class="active"><a href="devopsblogs1.html">DevOps Blogs @ AWS</a></li>
      <li><a href="secblogs1.html">Security Blogs @ AWS</a></li>
      <li><a href="apnblogs1.html">APN Blogs @ AWS</a></li>

    </ul>
    </div>

    <div id="inner" class="col-sm-9 col-md-9 col-xs-12" role="main">
<p></p>
<p><i>Contents of this page is copied directly from AWS blog sites to make it Kindle friendly. Some styles & sections from these pages are removed to render this properly in 'Article Mode' of Kindle e-Reader browser. All the contents of this page is property of AWS.</i></p>
<p><a href="devopsblogs1.html">Page 1</a>|<a href="devopsblogs2.html">Page 2</a>|<a href="devopsblogs3.html">Page 3</a>|<a href="devopsblogs4.html">Page 4</a></p>
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<meta property="image" content="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/12/automate_to_spot.png" /> 
<b class="lb-b blog-post-title" property="name headline">Automatic Deployment to New Amazon EC2 On-Demand and Spot Instances Using AWS CodeDeploy, Amazon CloudWatch Events, and AWS Lambda</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Tapodipta Ghosh</span></span> | on 
<time property="datePublished" datetime="2018-01-12T13:50:30+00:00">12 JAN 2018</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/devops/category/management-tools/amazon-cloudwatch/" title="View all posts in Amazon CloudWatch*"><span property="articleSection">Amazon CloudWatch*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/compute/amazon-ec2/" title="View all posts in Amazon EC2*"><span property="articleSection">Amazon EC2*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/developer-tools/aws-codedeploy/" title="View all posts in AWS CodeDeploy*"><span property="articleSection">AWS CodeDeploy*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/compute/aws-lambda/" title="View all posts in AWS Lambda*"><span property="articleSection">AWS Lambda*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/compute/" title="View all posts in Compute*"><span property="articleSection">Compute*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/developer-tools/" title="View all posts in Developer Tools*"><span property="articleSection">Developer Tools*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/management-tools/" title="View all posts in Management Tools*"><span property="articleSection">Management Tools*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/devops/automatic-deployment-to-new-amazon-ec2-on-demand-and-spot-instances-using-aws-codedeploy-amazon-cloudwatch-events-and-aws-lambda/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><a href="https://aws.amazon.com/codedeploy/">AWS CodeDeploy</a> is a service that automates application deployments to your compute infrastructure, including fleets of <a href="https://aws.amazon.com/ec2/">Amazon EC2</a> instances. AWS CodeDeploy can automatically deploy the latest app version to any new EC2 instance launched due to a scaling event. However, if your servers are not part of the Auto Scaling group, it might be a challenge to automate the code deployment for new EC2 launches. This is especially true if you are running your workload on an <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/spot-fleet.html">EC2 Spot Fleet</a>. In this post, I’ll show you how to use AWS CodeDeploy, an <a href="http://docs.aws.amazon.com/AmazonCloudWatch/latest/events/WhatIsCloudWatchEvents.html">Amazon CloudWatch Events rule</a>, EC2 tags, and <a href="https://aws.amazon.com/lambda/">AWS Lambda</a> to automate your deployments so that all EC2 instances run the same version of your application.</p> 
<p><strong>Solution overview:</strong></p> 
<p>An Amazon CloudWatch rule is triggered when a new Amazon EC2 instance is launched. The rule invokes an AWS Lambda function that extracts three tags:</p> 
<code class="lang-html">&middot;&nbsp;Name
&middot;&nbsp;CodeDeployDeploymentGroup
&middot;&nbsp;CodeDeployApplication</code> 
<p>The Lambda function then uses the instance tags to add the EC2 instance to the deployment group. After the instance has been added, Lambda queries AWS CodeDeploy to retrieve the last successful deployment in that deployment group and synchronizes the EC2 instance with the latest code. The following diagram shows the sequence:</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/11/solution-overview-1024x514.png" /></p> 
<p>&nbsp;</p> 
<p><strong>Note:</strong> For an EC2 Spot Fleet, the tags that you create for your Spot instance are not added automatically by the Spot service to fulfill the request. The Lambda function adds these tags after the Spot instance is launched.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/11/initial-deployment-group-1024x479.png" /></p> 
<p>&nbsp;</p> 
<p><strong>Example:</strong></p> 
<p>Let’s take an example of an AWS CodeDeploy application <code class="lang-html">cd-single-deploy-app</code>, and its deployment group, <code class="lang-html">cd-single-deploy-app-group</code>, which has two instances in it. These instances are not part of an Auto Scaling group.</p> 
<p>For information about the steps in deploying an application to an instance, see <a href="http://docs.aws.amazon.com/codedeploy/latest/userguide/tutorials-windows.html">this tutorial in the AWS CodeDeploy User Guide</a>.</p> 
<p>In the AWS CodeDeploy console, you’ll find the deployment ID, <code class="lang-markup">d-CSBCXR2GP</code>. We will use this ID later in the testing phase. Our workflow ensures that when a new EC2 instance is launched, it joins the deployment group automatically and the latest version of the application is deployed to it.</p> 
<p>You can configure the Lambda function, associated IAM role and policy, and the CloudWatch Events rule by running <a href="https://github.com/awslabs/aws-codedeploy-new-instance-sync-lambda/blob/master/codedeploy-sync-lambda-setup.json">this CloudFormation template</a> included in the code repository.</p> 
<p><a href="https://github.com/awslabs/aws-codedeploy-new-instance-sync-lambda">https://github.com/awslabs/aws-codedeploy-new-instance-sync-lambda</a></p> 
<p>The CloudFormation template does the following:</p> 
<p><strong>Step 1</strong>: Create an IAM role named <code class="lang-html">Auto-Deploy-EC2-Codedeploy</code> and attach the following policies:</p> 
<code class="lang-html">•	arn:aws:iam::aws:policy/AWSLambdaExecute 
•	arn:aws:iam::aws:policy/AmazonEC2ReadOnlyAccess 
•	arn:aws:iam::aws:policy/service-role/AmazonEC2SpotFleetTaggingRole 
</code> 
<p>Use the following JSON document to create another policy named CodeDeploy and attach it to the IAM role.</p> 
<code class="lang-json">{
&quot;Version&quot;: &quot;2012-10-17&quot;,
&quot;Statement&quot;: [
{
&quot;Action&quot;: [
&quot;codedeploy:Get*&quot;,
&quot;codedeploy:UpdateDeploymentGroup&quot;,
&quot;codedeploy:List*&quot;,
&quot;codedeploy:CreateDeployment&quot;
],
&quot;Resource&quot;: [
&quot;*&quot;
],
&quot;Effect&quot;: &quot;Allow&quot;,
&quot;Sid&quot;: &quot;StartContinuousAssessmentLambdaPolicyStmt&quot;
}
]
}
</code> 
<p>Make sure the CodeDeploy role has PassRole permission &nbsp;to the service role defined in the CodeDeploy deployment group.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/11/iam-role-policy-1024x460.png" /></p> 
<p><strong>Step 2:</strong> Follow these steps to create a Lambda function:</p> 
<p><a href="https://github.com/awslabs/aws-codedeploy-new-instance-sync-lambda/blob/master/README.md">https://github.com/awslabs/aws-codedeploy-new-instance-sync-lambda/blob/master/README.md</a></p> 
<p><strong>Step 3:</strong> In Amazon CloudWatch Events, set up a rule for running instances and configure the Lambda function as a target.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/11/create-cloudwatch-events-rule-1024x581.png" /></p> 
<p><strong>Step 4:</strong> In the AWS Lambda console, choose your Lambda function. On the Triggers tab, check that the trigger is enabled.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/11/lambda-trigger-1024x273.png" /></p> 
<p>You can now test to ensure if a new EC2 instance is launched, it gets synchronized automatically with the latest code</p> 
<p><strong>Test:</strong></p> 
<p>A new EC2 instance is launched from the EC2 console, the AWS CloudFormation template, or the EC2 APIs with CodeDeployApplication, CodeDeployDeploymentGroup, and&nbsp;Name tag.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/11/new-instance-launch.png" /></p> 
<p>&nbsp;</p> 
<p>Go to CloudWatch Logs console to check the Lambda execution logs.</p> 
<p>Here is an analysis of sample log:</p> 
<p>&middot;&nbsp; You should see the EC2 instance ID</p> 
<code class="lang-markup">{[
&quot;arn:aws:EC2:us-east-1:XXXXXXXXXXXX:instance/<strong>i-00203362b337dd743</strong>&quot;]
}
</code> 
<p>&middot;&nbsp; You should see the deployment ID of the last successful deployment. It should match the one you noted earlier</p> 
<p><code class="lang-markup"> DepId is <strong>d-CSBCXR2GP</strong></code></p> 
<p>&middot;&nbsp; &nbsp; Finally, you should see the deployment ID of the new deployment created by CodeDeploy</p> 
<code class="lang-markup">&quot;{u'deploymentId': u'<strong>d-W6E1TFFGP</strong>', 'ResponseMetadata': {'RetryAttempts': 0, '	HTTPStatusCode': 200, 'RequestId': '73046797-bb22-11e7-ad7b-25693e030410', 'HTTPHeaders': {'x-amzn-requestid': '73046797-bb22-11e7-ad7b-25693e030410', 'content-length': '30', 'content-type': 'application/x-amz-json-1.1'}}}
&quot;
</code> 
<p>Now, go to CodeDeploy console to confirm that the new deployment was successful.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/11/new-deployment-1024x503.png" /></p> 
<p>In this screenshot, you can see that the new EC2 instance was synched with latest code.</p> 
<p><strong>Summary:</strong></p> 
<p>In this post,&nbsp;I’ve&nbsp;demonstrated how to use AWS CodeDeploy, AWS Lambda, an Amazon CloudWatch Events rule, and EC2 tags to automate deployments to disparate EC2 instances. If you are running your workload on Spot instances or have a fleet of On-Demand EC2 instances as part of your application, you can use the steps in this blog post to solve the automation around the deployment for new instances.</p> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<meta property="image" content="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/12/CD_to_K8-934x630.png" /> 
<b class="lb-b blog-post-title" property="name headline">Continuous Deployment to Kubernetes using AWS CodePipeline, AWS CodeCommit, AWS CodeBuild, Amazon ECR and AWS Lambda</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Chris Barclay</span></span> | on 
<time property="datePublished" datetime="2018-01-11T09:45:58+00:00">11 JAN 2018</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/devops/category/developer-tools/aws-codebuild/" title="View all posts in AWS CodeBuild*"><span property="articleSection">AWS CodeBuild*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/developer-tools/aws-codecommit/" title="View all posts in AWS CodeCommit*"><span property="articleSection">AWS CodeCommit*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/developer-tools/aws-codepipeline/" title="View all posts in AWS CodePipeline*"><span property="articleSection">AWS CodePipeline*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/developer-tools/" title="View all posts in Developer Tools*"><span property="articleSection">Developer Tools*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/devops/continuous-deployment-to-kubernetes-using-aws-codepipeline-aws-codecommit-aws-codebuild-amazon-ecr-and-aws-lambda/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p>Thank you to my colleague Omar Lari for this blog on how to create a continuous deployment pipeline for Kubernetes!</p> 
<hr /> 
<p>You can use Kubernetes and AWS together to create a fully managed, continuous deployment pipeline for container based applications. This approach takes advantage of Kubernetes’ open-source system to manage your containerized applications, and the AWS developer tools to manage your source code, builds, and pipelines.</p> 
<p>This post describes how to create a continuous deployment architecture for containerized applications. It uses AWS CodeCommit, AWS CodePipeline, AWS CodeBuild, and AWS Lambda to deploy containerized applications into a Kubernetes cluster. In this environment, developers can remain focused on developing code without worrying about how it will be deployed, and development managers can be satisfied that the latest changes are always deployed.</p> 
<b>What is Continuous Deployment?</b> 
<p>There are many articles, posts and even conferences dedicated to the practice of continuous deployment. For the purposes of this post, I will summarize continuous delivery into the following points:</p> 
<li>Code is more frequently released into production environments</li> 
<li>More frequent releases allow for smaller, incremental changes reducing risk and enabling simplified roll backs if needed</li> 
<li>Deployment is automated and requires minimal user intervention</li> 
<p>For a more information, see “<a href="https://d1.awsstatic.com/whitepapers/DevOps/practicing-continuous-integration-continuous-delivery-on-AWS.pdf">Practicing Continuous Integration and Continuous Delivery on AWS</a>”.</p> 
<b>How can you use continuous deployment with AWS and Kubernetes?</b> 
<p>You can leverage AWS services that support continuous deployment to automatically take your code from a source code repository to production in a Kubernetes cluster with minimal user intervention. To do this, you can create a pipeline that will build and deploy committed code changes as long as they meet the requirements of each stage of the pipeline.</p> 
<p>To create the pipeline, you will use the following services:</p> 
<li><strong>AWS CodePipeline.</strong> AWS CodePipeline is a continuous delivery service that models, visualizes, and automates the steps required to release software. You define stages in a pipeline to retrieve code from a source code repository, build that source code into a releasable artifact, test the artifact, and deploy it to production. Only code that successfully passes through all these stages will be deployed. In addition, you can optionally add other requirements to your pipeline, such as manual approvals, to help ensure that only approved changes are deployed to production.</li> 
<li><strong>AWS CodeCommit.</strong> AWS CodeCommit is a secure, scalable, and managed source control service that hosts private Git repositories. You can privately store and manage assets such as your source code in the cloud and configure your pipeline to automatically retrieve and process changes committed to your repository.</li> 
<li><strong>AWS CodeBuild.</strong> AWS CodeBuild is a fully managed build service that compiles source code, runs tests, and produces artifacts that are ready to deploy. You can use AWS CodeBuild to both build your artifacts, and to test those artifacts before they are deployed.</li> 
<li><strong>AWS Lambda.</strong> AWS Lambda is a compute service that lets you run code without provisioning or managing servers. You can invoke a Lambda function in your pipeline to prepare the built and tested artifact for deployment by Kubernetes to the Kubernetes cluster.</li> 
<li><strong>Kubernetes.</strong> Kubernetes is an open-source system for automating deployment, scaling, and management of containerized applications. It provides a platform for running, deploying, and managing containers at scale.</li> 
<b>An Example of Continuous Deployment to Kubernetes:</b> 
<p>The following example illustrates leveraging AWS developer tools to continuously deploy to a Kubernetes cluster:</p> 
<p><img src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/11/k8s-code.png" /></p> 
<ol> 
<li>Developers commit code to an AWS CodeCommit repository and create pull requests to review proposed changes to the production code. When the pull request is merged into the master branch in the AWS CodeCommit repository, AWS CodePipeline automatically detects the changes to the branch and starts processing the code changes through the pipeline.</li> 
<li>AWS CodeBuild packages the code changes as well as any dependencies and builds a Docker image. Optionally, another pipeline stage tests the code and the package, also using AWS CodeBuild.</li> 
<li>The Docker image is pushed to Amazon ECR after a successful build and/or test stage.</li> 
<li>AWS CodePipeline invokes an AWS Lambda function that includes the Kubernetes Python client as part of the function’s resources. The Lambda function performs a string replacement on the tag used for the Docker image in the Kubernetes deployment file to match the Docker image tag applied in the build, one that matches the image in Amazon ECR.</li> 
<li>After the deployment manifest update is completed, AWS Lambda invokes the Kubernetes API to update the image in the Kubernetes application deployment.</li> 
<li>Kubernetes performs a rolling update of the pods in the application deployment to match the docker image specified in Amazon ECR.<br /> The pipeline is now live and responds to changes to the master branch of the CodeCommit repository. This pipeline is also fully extensible, you can add steps for performing testing or adding a step to deploy into a staging environment before the code ships into the production cluster.</li> 
</ol> 
<p>An example pipeline in AWS CodePipeline that supports this architecture can be seen below:</p> 
<p><img src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/11/codepipeline-k8s.png" /></p> 
<b>Conclusion</b> 
<p>We are excited to see how you leverage this pipeline to help ease your developer experience as you develop applications in Kubernetes.</p> 
<p>You’ll find an AWS CloudFormation template with everything necessary to spin up your own continuous deployment pipeline at the <a href="https://github.com/aws-samples/aws-kube-codesuite">CodeSuite – Continuous Deployment Reference Architecture for Kubernetes</a> repo on GitHub. The repository details exactly how the pipeline is provisioned and how you can use it to deploy your own applications. If you have any questions, feedback, or suggestions, please let us know!</p> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<meta property="image" content="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/03/HA_X-Ray_SOCIAL.png" /> 
<b class="lb-b blog-post-title" property="name headline">Aspect-Oriented Programming for AWS X-Ray Using Spring</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Bharath Kumar</span></span> | on 
<time property="datePublished" datetime="2017-12-28T14:26:41+00:00">28 DEC 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/devops/category/developer-tools/aws-x-ray/" title="View all posts in AWS X-Ray*"><span property="articleSection">AWS X-Ray*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/developer-tools/" title="View all posts in Developer Tools*"><span property="articleSection">Developer Tools*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/devops/aspect-oriented-programming-for-aws-x-ray-using-spring/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-2002" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-devops-blog&amp;disqus_identifier=2002&amp;disqus_title=Aspect-Oriented+Programming+for+AWS+X-Ray+Using+Spring&amp;disqus_url=https://aws.amazon.com/blogs/devops/aspect-oriented-programming-for-aws-x-ray-using-spring/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-2002');
});
</script> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p>This post was written by Andy Powell, Partner Solutions Architect.</p> 
<p>For developers, tracing and instrumenting code is one of the most valuable tools when debugging code. When you are developing locally, you can use local debugging and profiling tools, but when you deploy an application to the cloud, the task is more challenging. In this blog post, we will look at a new way to instrument your application using AWS X-Ray without adding tracing code to your business logic.</p> 
<b>AWS X-Ray</b> 
<p>Released to the public earlier this year, <a title="undefined" href="https://aws.amazon.com/xray/" target="null">AWS X-Ray</a> provides a mechanism for developers to instrument and trace their code while running on AWS. AWS X-Ray enables developers to analyze and debug distributed applications through the entire AWS stack. Developers and operations personnel can also follow the flow of a request through the entire AWS infrastructure. X-Ray works well in a monolithic or microservices model. Either way, developers can get a complete view of their application’s performance and behavior.</p> 
<p>X-Ray provides two key mechanisms for analyzing an application:</p> 
<li>The service map.</li> 
<li>The trace view.</li> 
<p>The service map, shown here, provides a high-level view of the services consumed by an application and their relative health:</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/12/26/Picture1.png" /></p> 
<p>Application developers often look for a more detailed view of their application to help them answer questions like “Which functions are my bottlenecks?” and “Where is the most latency in the application?” The trace view allows you to see the flow of an application through service calls. &nbsp;It&nbsp;shows you latency between services and the exact execution time of each X-Ray segment.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/12/27/Picture2.png" /></p> 
<p>Similar to other logging and metrics frameworks, X-Ray requires the developer to insert specific code throughout the application. This might cause issues because the logging and metrics code has the potential to increase the complexity of the application code. Increased complexity leads, in turn, to increased maintenance and testing costs. Ideally, developers should add X-Ray tracing to an application in a non-invasive manner, one that does not affect the underlying business logic.</p> 
<b>Aspect-oriented programming and the Spring Framework</b> 
<p>Aspect-oriented programming (AOP) is a mechanism by which code runs either before, after, or around a target function. The code that runs outside the target code is called an aspect. An aspect provides the ability to perform actions like logging, transaction management, and method retries. The goal is for the aspect to provide these capabilities without affecting the target code. Pointcuts define where these aspects should act in the code. AOP allows developers to leverage powerful functionality without affecting their business logic.</p> 
<p>An aspect-oriented approach is a perfect way to implement AWS X-Ray because it keeps the underlying code clean and provides non-invasive, reusable tracing logic.</p> 
<p>Simply creating an aspect to invoke X-Ray is not enough. We also have to create pointcuts that tell the aspect where to act. These pointcuts will define which methods we wrap with tracing logic. After they are defined, the aspect sends the entire call stack to X-Ray for visualization.</p> 
<p>The Spring Framework is a common application framework for the development of Java software. It provides an extensive programming and config method for modern Java applications.</p> 
<p>Spring provides facilities for a range of application functions, including web applications, messaging applications, and streaming data applications. Spring applications are capable of being cloud-native from the onset.</p> 
<p>AOP is one of the core components of the Spring Framework. Spring’s implementation of AOP “weaves” application code at runtime. Load-time weaving is also available, but it requires extra configuration at compile or application runtime to work properly. The Spring runtime weaving does not require any special compilation or agents.</p> 
<b>AWS X-Ray Spring extensions</b> 
<p>Starting with version 1.3.0, the AWS X-Ray SDK lets you use AOP in the Spring Framework to instrument code with no change to the application’s business logic. This means that there is now a non-invasive way to instrument your applications running remotely in AWS.</p> 
<p>To include the extension in the code, first add the dependency to the application. If you are using Maven, you add the dependency this way:</p> 
<code class="lang-xml">&lt;dependency&gt; 
&lt;groupId&gt;com.amazonaws&lt;/groupId&gt; 
&lt;artifactId&gt;aws-xray-recorder-sdk-spring&lt;/artifactId&gt; 
&lt;version&gt;1.3.0&lt;/version&gt; 
&lt;/dependency&gt;
</code> 
<p>If you are using Gradle, use the following syntax:</p> 
<code class="lang-xml">compile 'com.amazonaws:aws-xray-recorder-sdk-spring:1.3.0'</code> 
<p>After you’ve included this in your application, there are a couple of steps that need configuration before tracing is enabled. First, classes must either be annotated with the <em>@XRayEnabled</em> annotation, or implement the <em>XRayTraced</em> interface. This tells the AOP system to wrap the functions of the affected class for X-Ray instrumentation.</p> 
<p>Second, you need an interceptor to actually wrap the code. This involves extending an abstract class, <em>AbstractXRayInterceptor</em>, to activate X-Ray tracing in the application. The <em>AbstractXRayInterceptor</em> contains methods that must be overridden:</p> 
<li><em>generateMetadata</em> – This function allows customization of the metadata attached to the current function’s trace. &nbsp;By default, the class name of the executing function is recorded in the metadata. &nbsp;You can add more data if you need additional insights.</li> 
<li><em>xrayEnabledClasses</em> – This function is empty, and should remain so. &nbsp;It serves as the host for a pointcut instructing the interceptor about which methods to wrap. &nbsp; The developer should define the pointcut. &nbsp;&nbsp;You can specify which classes that are annotated with XRayEnabled you want traced. &nbsp;A pointcut statement of &nbsp;<em>@Pointcut(“@within(com.amazonaws.xray.spring.aop.XRayEnabled) &amp;&amp; bean(*Controller)”)</em>&nbsp;tells the interceptor to wrap all controller beans annotated with the <em>@XRayEnabled</em> annotation.</li> 
<p>Here is a sample implementation of the <em>AbstractXRayInterceptor</em> :</p> 
<code class="lang-java">@Aspect
@Component
public class XRayInspector extends AbstractXRayInterceptor {    
@Override    
protected Map&lt;String, Map&lt;String, Object&gt;&gt; generateMetadata(ProceedingJoinPoint proceedingJoinPoint, Subsegment subsegment) throws Exception {      
return super.generateMetadata(proceedingJoinPoint, subsegment);    
}    
@Override    
@Pointcut(&quot;@within(com.amazonaws.xray.spring.aop.XRayEnabled) &amp;&amp; bean(*Controller)&quot;)    
public void xrayEnabledClasses() {}
}
</code> 
<p>Here is an example of a Service class that will be instrumented by X-Ray:</p> 
<code class="lang-java">@Service
@XRayEnabled
public class MyServiceImpl implements MyService {    
private final MyEntityRepository myEntityRepository;    
@Autowired    
public MyServiceImpl(MyEntityRepository myEntityRepository) {        
this.myEntityRepository = myEntityRepository;    
}    
@Transactional(readOnly = true)    
public List&lt;MyEntity&gt; getMyEntities(){        
try(Stream&lt;MyEntity&gt; entityStream = this.myEntityRepository.streamAll()){            
return entityStream.sorted().collect(Collectors.toList());        
}    
}
}
</code> 
<p>By default, the <em>AbstractXRayInterceptor</em> instruments around all Spring data repository instances.</p> 
<p>After it’s configured, the Spring application runs as normal. The X-Ray interceptor&nbsp; picks up annotated classes automatically and builds a trace of the call stack. You can view this call stack in the Traces section of the X-Ray console.</p> 
<p><code><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/12/27/Picture3.png" /></code></p> 
<p>Looking at the trace, you will see the complete call stack of the application, from the controller down through the service calls. Stack traces are arranged in a hierarchy in the same way as typical X-Ray traces. Any exceptions that occur in the call stack are added to the trace by the interceptor automatically. This gives you a complete view of the application’s functionality, performance, and error states. &nbsp;X-Ray provides the convenience of a managed service of the tracing and reporting engine. &nbsp;Without it, the developer would have to manage the tracing and reporting infrastructure.</p> 
<b>Conclusion</b> 
<p>On its own, X-Ray provides powerful functionality to trace your applications running on AWS. When you combine the service with the ease of use of AOP and the Spring Framework, it is a natural fit.</p> 
<p>The demo app code is available for <a href="https://github.com/aws/aws-xray-sdk-java" title="undefined" target="null">download</a>. Download it today and start integrating deep tracing into your Spring applications.</p> 
<h4>Note</h4> 
<p><a href="https://github.com/aws/aws-xray-sdk-java" title="undefined" target="null">AWS X-Ray SDK for Java</a> v1.3.0 will be available on maven central in the next few days. In the meantime, you can follow the below steps to use the latest version from the GitHub repo:</p> 
<p>1. Clone the AWS X-Ray SDK for Java repo locally.<br /> 2. In the project root, run “mvn clean install -Dgpg.skip=true”.<br /> 3. Reference version 1.3.0 in your maven / gradle files as mentioned in the blog post.</p> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-2002');
});
</script> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">Instrumenting Web Apps Using AWS X-Ray</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Bharath Kumar</span></span> | on 
<time property="datePublished" datetime="2017-12-28T14:25:45+00:00">28 DEC 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/devops/category/developer-tools/aws-x-ray/" title="View all posts in AWS X-Ray*"><span property="articleSection">AWS X-Ray*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/developer-tools/" title="View all posts in Developer Tools*"><span property="articleSection">Developer Tools*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/devops/instrumenting-web-apps-using-aws-x-ray/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p>This post was written by James Bowman, Software Development Engineer, AWS X-Ray</p> 
<p><a title="undefined" href="https://aws.amazon.com/xray/" target="null">AWS X-Ray</a> helps developers analyze and debug distributed applications and underlying services in production. You can identify and analyze root-causes of performance issues and errors, understand customer impact, and extract statistical aggregations (such as histograms) for optimization.</p> 
<p>In this blog post, I will provide a step-by-step walkthrough for enabling X-Ray tracing in the Go programming language. You can use these steps to add X-Ray tracing to any distributed application.</p> 
<b>Revel: A web framework for the Go language</b> 
<p>This section will assist you with designing a guestbook application. Skip to <strong>“Instrumenting with AWS X-Ray”</strong> section below if you already have a Go language application.</p> 
<p><a title="undefined" href="https://revel.github.io/" target="null">Revel</a> is a web framework for the Go language. It facilitates the rapid development of web applications by providing a predefined framework for controllers, views, routes, filters, and more.</p> 
<p>To get started with Revel, run <code>revel new github.com/jamesdbowman/guestbook</code>. A project base is then copied to <code>$GOPATH/src/github.com/jamesdbowman/guestbook</code>.</p> 
<p><code>$ tree -L 2<br /> .<br /> ├── README.md<br /> ├── app<br /> │ ├── controllers<br /> │ ├── init.go<br /> │ ├── routes<br /> │ ├── tmp<br /> │ └── views<br /> ├── conf<br /> │ ├── app.conf<br /> │ └── routes<br /> ├── messages<br /> │ └── sample.en<br /> ├── public<br /> │ ├── css<br /> │ ├── fonts<br /> │ ├── img<br /> │ └── js<br /> └── tests<br /> └── apptest.go<br /> </code></p> 
<h3>Writing a guestbook application</h3> 
<p>A basic guestbook application can consist of just two routes: one to sign the guestbook and another to list all entries.<br /> Let’s set up these routes by adding a Book controller, which can be routed to by modifying <code>./conf/routes.</code></p> 
<code class="lang-go">./app/controllers/book.go:
package controllers
import (
&quot;math/rand&quot;
&quot;time&quot;
&quot;github.com/aws/aws-sdk-go/aws&quot;
&quot;github.com/aws/aws-sdk-go/aws/endpoints&quot;
&quot;github.com/aws/aws-sdk-go/aws/session&quot;
&quot;github.com/aws/aws-sdk-go/service/dynamodb&quot;
&quot;github.com/aws/aws-sdk-go/service/dynamodb/dynamodbattribute&quot;
&quot;github.com/bowmessage/test/xray&quot;
&quot;github.com/revel/revel&quot;
)
const tableName = &quot;guestbook&quot;
const success = &quot;Success.\n&quot;
var letters = []rune(&quot;ABCDEFGHIJKLMNOPQRSTUVWXYZ&quot;)
func init() {
rand.Seed(time.Now().UnixNano())
}
// randString returns a random string of len n, used for DynamoDB Hash key.
func randString(n int) string {
b := make([]rune, n)
for i := range b {
b[i] = letters[rand.Intn(len(letters))]
}
return string(b)
}
// Book controls interactions with the guestbook.
type Book struct {
*revel.Controller
ddbClient *dynamodb.DynamoDB
}
// Signature represents a user's signature.
type Signature struct {
Message string
Epoch   int64
ID      string
}
// ddb returns the controller's DynamoDB client, instatiating a new client if necessary.
func (c Book) ddb() *dynamodb.DynamoDB {
if c.ddbClient == nil {
sess := session.Must(session.NewSession(&amp;aws.Config{
Region:     aws.String(endpoints.UsWest2RegionID),
MaxRetries: aws.Int(3),
}))
c.ddbClient = dynamodb.New(sess)
xray.AWS(c.ddbClient.Client) // add subsegment-generating X-Ray handlers to this client
}
return c.ddbClient
}
// Sign allows users to sign the book.
// The message is to be passed as application/json typed content, listed under the &quot;message&quot; top level key.
func (c Book) Sign() revel.Result {
var s Signature
err := c.Params.BindJSON(&amp;s)
if err != nil {
return c.RenderError(err)
}
now := time.Now()
s.Epoch = now.Unix()
s.ID = randString(20)
item, err := dynamodbattribute.MarshalMap(s)
if err != nil {
return c.RenderError(err)
}
putItemInput := &amp;dynamodb.PutItemInput{
TableName: aws.String(tableName),
Item:      item,
}
goRequest := c.Request.In.(*revel.GoRequest)
_, err = c.ddb().PutItemWithContext(goRequest.Original.Context(), putItemInput)
if err != nil {
return c.RenderError(err)
}
return c.RenderText(success)
}
// List allows users to list all signatures in the book.
func (c Book) List() revel.Result {
scanInput := &amp;dynamodb.ScanInput{
TableName: aws.String(tableName),
Limit:     aws.Int64(100),
}
goRequest := c.Request.In.(*revel.GoRequest)
res, err := c.ddb().ScanWithContext(goRequest.Original.Context(), scanInput)
if err != nil {
return c.RenderError(err)
}
messages := make([]string, 0)
for _, v := range res.Items {
messages = append(messages, *(v[&quot;Message&quot;].S))
}
return c.RenderJSON(messages)
}
</code> 
<p><code>./conf/routes:<br /> POST /sign Book.Sign<br /> GET /list Book.List<br /> </code></p> 
<h3>Creating the resources and testing</h3> 
<p>For the purposes of this blog post, the application will be run and tested locally. We will store and retrieve messages from an <a title="undefined" href="https://aws.amazon.com/dynamodb/" target="null">Amazon DynamoDB</a> table. Use the following AWS CLI command to create the guestbook table:</p> 
<code class="lang-bash">aws dynamodb create-table --region us-west-2 --table-name &quot;guestbook&quot; --attribute-definitions AttributeName=ID,AttributeType=S AttributeName=Epoch,AttributeType=N --key-schema AttributeName=ID,KeyType=HASH AttributeName=Epoch,KeyType=RANGE --provisioned-throughput ReadCapacityUnits=5,WriteCapacityUnits=5</code> 
<p>Now, let’s test our sign and list routes. If everything is working correctly, the following result appears:</p> 
<code class="lang-bash">$ curl -d '{&quot;message&quot;:&quot;Hello from cURL!&quot;}' -H &quot;Content-Type: application/json&quot; http://localhost:9000/book/sign
Success.
$ curl http://localhost:9000/book/list
[
&quot;Hello from cURL!&quot;
]%
</code> 
<b>Integrating with AWS X-Ray</b> 
<h3>Download and run the AWS X-Ray daemon</h3> 
<p>The AWS SDKs emit trace segments over UDP on port 2000. (This port can be configured.) In order for the trace segments to make it to the X-Ray service, the daemon must listen on this port and batch the segments in calls to the PutTraceSegments API.<br /> For information about downloading and running the X-Ray daemon, see the <a title="undefined" href="http://docs.aws.amazon.com/xray/latest/devguide/xray-daemon.html" target="null">AWS X-Ray Developer Guide</a>.</p> 
<h3>Installing the AWS X-Ray SDK for Go</h3> 
<p>To download the SDK from GitHub, run <code>go get -u github.com/aws/aws-xray-sdk-go/...</code> The SDK will appear in the <code>$GOPATH</code>.</p> 
<h3>Enabling the incoming request filter</h3> 
<p>The first step to instrumenting an application with AWS X-Ray is to enable the generation of trace segments on incoming requests. The SDK conveniently provides an implementation of <code>http.Handler</code> which does exactly that. To ensure incoming web requests travel through this handler, we can modify <code>app/init.go</code>, adding a custom function to be run on application start.</p> 
<code class="lang-go">import (
&quot;github.com/aws/aws-xray-sdk-go/xray&quot;
&quot;github.com/revel/revel&quot;
)
...
func init() {
...
revel.OnAppStart(installXRayHandler)
}
func installXRayHandler() {
server := revel.CurrentEngine.Engine().(*http.Server)
server.Handler = xray.Handler(xray.NewFixedSegmentNamer(&quot;GuestbookApp&quot;), server.Handler)
}
</code> 
<p>The application will now emit a segment for each incoming web request. The service graph appears:<br /> <img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/12/28/Screen-Shot-2017-12-21-at-3.00.24-PM-1024x508.png" /></p> 
<p>You can customize the name of the segment to make it more descriptive by providing an alternate implementation of <code>SegmentNamer</code> to <code>xray.Handler</code>. For example, you can use <code>xray.NewDynamicSegmentNamer(fallback, pattern)</code> in place of the fixed namer. This namer will use the host name from the incoming web request (if it matches <code>pattern</code>) as the segment name. This is often useful when you are trying to separate different instances of the same application.</p> 
<p>In addition, HTTP-centric information such as method and URL is collected in the segment’s <code>http</code> subsection:</p> 
<code class="lang-json">&quot;http&quot;: {
&quot;request&quot;: {
&quot;url&quot;: &quot;/book/list&quot;,
&quot;method&quot;: &quot;GET&quot;,
&quot;user_agent&quot;: &quot;curl/7.54.0&quot;,
&quot;client_ip&quot;: &quot;::1&quot;
},
&quot;response&quot;: {
&quot;status&quot;: 200
}
},
</code> 
<h3>Instrumenting outbound calls</h3> 
<p>To provide detailed performance metrics for distributed applications, the AWS X-Ray SDK needs to measure the time it takes to make outbound requests. Trace context is passed to downstream services using the <code>X-Amzn-Trace-Id</code> header. To draw a detailed and accurate representation of a distributed application, outbound call instrumentation is required.</p> 
<h3>AWS SDK calls</h3> 
<p>The AWS X-Ray SDK for Go provides a one-line AWS client wrapper that enables the collection of detailed per-call metrics for any AWS client. We can modify the DynamoDB client instantiation to include this line:</p> 
<code class="lang-go">// ddb returns the controller's DynamoDB client, instatiating a new client if necessary.
func (c Book) ddb() *dynamodb.DynamoDB {
if c.ddbClient == nil {
sess := session.Must(session.NewSession(&amp;aws.Config{
Region: aws.String(endpoints.UsWest2RegionID),
}))
c.ddbClient = dynamodb.New(sess)
xray.AWS(c.ddbClient.Client) // add subsegment-generating X-Ray handlers to this client
}
return c.ddbClient
}
</code> 
<p>We also need to ensure that the segment generated by our <code>xray.Handler</code> is passed to these AWS calls so that the X-Ray SDK knows to which segment these generated subsegments belong. In Go, the <code>context.Context</code> object is passed throughout the call path to achieve this goal. (In most other languages, some variant of <code>ThreadLocal</code> is used.) AWS clients provide a <code>*WithContext</code> method variant for each AWS operation, which we need to switch to:</p> 
<code class="lang-go">_, err = c.ddb().PutItemWithContext(c.Request.Context(), putItemInput)
res, err := c.ddb().ScanWithContext(c.Request.Context(), scanInput)
</code> 
<p>We now see much more detail in the <strong>Timeline</strong> view of the trace for the sign and list operations:<br /> <img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/12/28/Screen-Shot-2017-12-21-at-3.02.51-PM-1024x722.png" /></p> 
<p>We can use this detail to help diagnose throttling on our DynamoDB table. In the following screenshot, the purple in the DynamoDB service graph node indicates that our table is underprovisioned. The red in the GuestbookApp node indicates that the application is throwing faults due to this throttling.<br /> <img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/12/28/Screen-Shot-2017-12-21-at-3.19.16-PM-1024x326.png" /></p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/12/28/Screen-Shot-2017-12-21-at-3.20.17-PM-1024x709.png" /></p> 
<h3>HTTP calls</h3> 
<p>Although the guestbook application does not make any non-AWS outbound HTTP calls in its current state, there is a similar one-liner to wrap HTTP clients that make outbound requests. <code>xray.Client(c *http.Client)</code> wraps an existing <code>http.Client</code> (or <code>nil</code> if you want to use a default HTTP client). For example:</p> 
<code class="lang-go">resp, err := ctxhttp.Get(ctx, xray.Client(nil), &quot;https://aws.amazon.com/&quot;)</code> 
<h3>Instrumenting local operations</h3> 
<p>X-Ray can also assist in measuring the performance of local compute operations. To see this in action, let’s create a custom subsegment inside the <code>randString</code> method:</p> 
<code class="lang-go">
// randString returns a random string of len n, used for DynamoDB Hash key.
func randString(ctx context.Context, n int) string {
xray.Capture(ctx, &quot;randString&quot;, func(innerCtx context.Context) {
b := make([]rune, n)
for i := range b {
b[i] = letters[rand.Intn(len(letters))]
}
s := string(b)
})
return s
}
// we'll also need to change the callsite
s.ID = randString(c.Request.Context(), 20)
</code> 
<b>Summary</b> 
<p>By now, you are an expert on how to instrument X-Ray for your Go applications. Instrumenting X-Ray with your applications is an easy way to analyze and debug performance issues and understand customer impact. Please feel free to give any feedback or comments below.</p> 
<p>For more information about advanced configuration of the AWS X-Ray SDK for Go, see the <a title="undefined" href="http://docs.aws.amazon.com/xray/latest/devguide/xray-sdk-go.html" target="null">AWS X-Ray SDK for Go</a> in the AWS X-Ray Developer Guide and the <a title="undefined" href="https://github.com/aws/aws-xray-sdk-go" target="null">aws/aws-xray-sdk-go GitHub repository</a>.</p> 
<p>For more information about some of the advanced X-Ray features such as histograms, annotations, and filter expressions, see the <a title="undefined" href="https://aws.amazon.com/blogs/compute/analyzing-performance-for-amazon-rekognition-apps-written-on-aws-lambda-using-aws-x-ray/" target="null">Analyzing Performance for Amazon Rekognition Apps Written on AWS Lambda Using AWS X-Ray</a> blog post.</p> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<meta property="image" content="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/03/architecture-1-1120x630.png" /> 
<b class="lb-b blog-post-title" property="name headline">Using Amazon CloudWatch and Amazon SNS to Notify when AWS X-Ray Detects Elevated Levels of Latency, Errors, and Faults in Your Application</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Bharath Kumar</span></span> | on 
<time property="datePublished" datetime="2017-12-20T13:11:00+00:00">20 DEC 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/devops/category/developer-tools/aws-x-ray/" title="View all posts in AWS X-Ray*"><span property="articleSection">AWS X-Ray*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/developer-tools/" title="View all posts in Developer Tools*"><span property="articleSection">Developer Tools*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/devops/using-amazon-cloudwatch-and-amazon-sns-to-notify-when-aws-x-ray-detects-elevated-levels-of-latency-errors-and-faults-in-your-application/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><a href="https://aws.amazon.com/xray/">AWS X-Ray</a> helps developers analyze and debug production applications built using microservices or serverless architectures and quantify customer impact. With X-Ray, you can understand how your application and its underlying services are performing and identify and troubleshoot the root cause of performance issues and errors. You can use these insights to identify issues and opportunities for optimization.</p> 
<p>In this blog post, I will show you how you can use <a href="https://aws.amazon.com/cloudwatch/">Amazon CloudWatch</a> and <a href="https://aws.amazon.com/sns/">Amazon SNS</a> to get notified when X-Ray detects high latency, errors, and faults in your application. Specifically, I will show you how to use this <a href="https://github.com/aws-samples/aws-xray-cloudwatch-event">sample app</a> to get notified through an email or SMS message when your end users observe high latencies or server-side errors when they use your application. You can customize the alarms and events by updating the sample app code.</p> 
<b>Sample App Overview</b> 
<p>The sample app uses the X-Ray GetServiceGraph API to get the following information:</p> 
<li>Aggregated response time.</li> 
<li>Requests that failed with 4xx status code (errors).</li> 
<li>429 status code (throttle).</li> 
<li>5xx status code (faults).</li> 
<img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/12/19/architecture-1024x576.png" /> 
<p class="wp-caption-text">Overview of sample app architecture</p> 
<h3>Getting started</h3> 
<p>The sample app uses AWS CloudFormation to deploy the required resources.<br /> To install the sample app:</p> 
<ol> 
<li>Run git clone to get the sample app.</li> 
<li>Update the JSON file in the Setup folder with threshold limits and notification details.</li> 
<li>Run the install.py script to install the sample app.</li> 
</ol> 
<p>For more information about the installation steps, see the <a title="undefined" href="https://github.com/aws-samples/aws-xray-cloudwatch-event/blob/master/README.md" target="null">readme</a> file on GitHub.</p> 
<p>You can update the app configuration to include your phone number or email to get notified when your application in X-Ray breaches the latency, error, and fault limits you set in the configuration. If you prefer to not provide your phone number and email, then you can use the CloudWatch alarm deployed by the sample app to monitor your application in X-Ray.</p> 
<p>The sample app deploys resources with the sample app namespace you provided during setup. This enables you to have multiple sample apps in the same region.</p> 
<h3>CloudWatch rules</h3> 
<p>The sample app uses two CloudWatch rules:</p> 
<ol> 
<li><em>SCHEDULEDLAMBDAFOR-sample_app_name</em> to trigger at regular intervals the AWS Lambda function that queries the GetServiceGraph API.</li> 
<li><em>XRAYALERTSFOR-sample_app_name</em> to look for published CloudWatch events that match the pattern defined in this rule.</li> 
</ol> 
<img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/12/19/CloudWatch-Rules-1024x255.png" /> 
<p class="wp-caption-text">CloudWatch rules created for the sample app</p> 
<h3>CloudWatch alarms</h3> 
<p>If you did not provide your phone number or email in the JSON file, the sample app uses a CloudWatch alarm named <em>XRayCloudWatchAlarm-sample_app_name</em> in combination with the CloudWatch event that you can use for monitoring.</p> 
<img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/12/19/CloudWatch-Alarm-1024x265.png" /> 
<p class="wp-caption-text">CloudWatch alarm created for the sample app</p> 
<h3>Amazon SNS messages</h3> 
<p>The sample app creates two SNS topics:</p> 
<li><em>sample_app_name-cloudwatcheventsnstopic</em> to send out an SMS message when the CloudWatch event matches a pattern published from the Lambda function.</li> 
<li><em>sample_app_name-cloudwatchalarmsnstopic</em> to send out an email message when the CloudWatch alarm goes into an ALARM state.</li> 
<img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/12/19/Amazon-SNS.png" /> 
<p class="wp-caption-text">Amazon SNS created for the sample app</p> 
<b>Getting notifications</b> 
<p>The CloudWatch event looks for the following matching pattern:<br /> <code></code></p> 
<code class="lang-json">{
&quot;detail-type&quot;: [
&quot;XCW Notification for Alerts&quot;
],
&quot;source&quot;: [
&quot;&lt;sample_app_name&gt;-xcw.alerts&quot;
]
}
</code> 
<p>The event then invokes an SNS topic that sends out an SMS message.</p> 
<img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/12/19/sms-169x300.png" /> 
<p class="wp-caption-text">SMS that is sent when CloudWatch Event invokes Amazon SNS topic</p> 
<p>The CloudWatch alarm looks for the <em><a title="undefined" href="http://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/cwe-metricscollected.html" target="null">TriggeredRules</a></em> metric that is published whenever the CloudWatch event matches the event pattern. It goes into the <em>ALARM</em> state whenever <em>TriggeredRules &gt; 0</em> for the specified evaluation period and invokes an SNS topic that sends an email message.</p> 
<img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/12/19/email-1024x488.png" /> 
<p class="wp-caption-text">Email that is sent when CloudWatch Alarm goes to ALARM state</p> 
<b>Stopping notifications</b> 
<p>If you provided your phone number or email address, but would like to stop getting notified, change the <em>SUBSCRIBE_TO_EMAIL_SMS</em> environment variable in the Lambda function to <strong>No</strong>. Then, go to the Amazon SNS console and delete the subscriptions. You can still monitor your application for elevated levels of latency, errors, and faults by using the CloudWatch console.</p> 
<img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/12/19/lambdaenvironmentvariable-1024x160.png" /> 
<p class="wp-caption-text">Change environment variable in Lambda</p> 
<p>&nbsp;</p> 
<img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/12/19/deletesubscriptions-1024x228.png" /> 
<p class="wp-caption-text">Delete subscriptions to stop getting notified</p> 
<b>Uninstalling the sample app</b> 
<p>To uninstall the sample app, run the <em>uninstall.py</em> script in the Setup folder.</p> 
<b>Extending the sample app</b> 
<p>The sample app notifes you when when X-Ray detects high latency, errors, and faults in your application. You can extend it to provide more value for your use cases (for example, to perform an action on a resource when the state of a CloudWatch alarm changes).</p> 
<p>To summarize, after this set up you will be able to get notified through Amazon SNS when X-Ray detects high latency, errors and faults in your application.</p> 
<p>I hope you found this information about setting up alarms and alerts for your application in AWS X-Ray helpful. Feel free to leave questions or other feedback in the comments. Feel free to learn more about <a href="https://aws.amazon.com/xray/">AWS X-Ray</a>, <a href="https://aws.amazon.com/sns/">Amazon SNS</a> and <a href="https://aws.amazon.com/cloudwatch">Amazon CloudWatch</a></p> 
<h3>About the Author</h3> 
<p><a title="undefined" href="https://www.linkedin.com/in/bharathkumarvenkateshkumar/" target="null">Bharath Kumar</a> is a Sr.Product Manager with AWS X-Ray. He has developed and launched mobile games, web applications on microservices and serverless architecture.</p> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<meta property="image" content="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/03/custom-source-actions.png" /> 
<b class="lb-b blog-post-title" property="name headline">Using Custom Source Actions in AWS CodePipeline for Increased Visibility for Third-Party Source Control</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Tom Schultz</span></span> | on 
<time property="datePublished" datetime="2017-11-27T11:11:57+00:00">27 NOV 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/devops/category/application-services/amazon-api-gateway-application-services/" title="View all posts in Amazon API Gateway*"><span property="articleSection">Amazon API Gateway*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/management-tools/aws-cloudformation/" title="View all posts in AWS CloudFormation*"><span property="articleSection">AWS CloudFormation*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/developer-tools/aws-codecommit/" title="View all posts in AWS CodeCommit*"><span property="articleSection">AWS CodeCommit*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/developer-tools/aws-codepipeline/" title="View all posts in AWS CodePipeline*"><span property="articleSection">AWS CodePipeline*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/compute/aws-lambda/" title="View all posts in AWS Lambda*"><span property="articleSection">AWS Lambda*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/devops/using-custom-source-actions-in-aws-codepipeline-for-increased-visibility-for-third-party-source-control/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p>In our previous post, <a href="https://aws.amazon.com/blogs/devops/integrating-git-with-aws-codepipeline/"><em>Integrating Git with AWS CodePipeline</em></a>, we demonstrated one way to integrate third-party Git repositories with <a href="https://aws.amazon.com/codepipeline/">AWS CodePipeline</a> by using <a href="https://aws.amazon.com/api-gateway/">Amazon API Gateway</a>, <a href="https://aws.amazon.com/lambda/">AWS Lambda</a>, and <a href="https://aws.amazon.com/s3/">Amazon S3</a>. That approach allows you to quickly integrate your Git repository with CodePipeline, but it doesn’t provide CodePipeline with any of the source metadata that many customers use in their CI/CD pipelines.</p> 
<p>In this post, we will describe CodePipeline custom source actions, which offer a different strategy for providing CodePipeline with more metadata from your source repositories. The most common source metadata are commit identifiers and commit messages. Commit identifiers are frequently used to track changes throughout the software lifecycle while commit messages provide a succinct, human-readable description of the change. Custom source actions allow you to integrate CodePipeline with any source repository in the same way that CodePipeline integrates with <a href="https://aws.amazon.com/codecommit/">CodeCommit</a> and GitHub, giving you access to the commit identifier and the commit message.</p> 
<p>This post covers setting up API Gateway and Lambda to trigger your pipeline, configuring your pipeline with a custom source action, and building a worker to handle jobs from your custom source action. This architecture allows you to access your source providers that are either hosted in a <a href="https://aws.amazon.com/vpc/">VPC</a> or are on premise and accessible from a VPC.</p> 
<h3>Architecture overview</h3> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/25/source_action_blog.png" /></p> 
<p>&nbsp;</p> 
<p>A webhook is a user-defined HTTP callback that occurs in response to an event. In our case, webhooks occur in response to a change in a source repository – a new revision. Webhooks have become a standard mechanism for integrating source repositories with continuous integration tools, such as CodePipeline.</p> 
<p>Here, the webhook is a call to API Gateway and AWS Lambda. The Lambda function calls the <a href="http://docs.aws.amazon.com/codepipeline/latest/APIReference/API_StartPipelineExecution.html">StartPipelineExecution </a>API, which triggers a CodePipeline execution. That execution starts with a custom source action that issues a job. That job is picked up by our worker, which pulls the latest source revision, extracts metadata, and publishes a new CodePipeline artifact for the rest of the pipeline to consume.</p> 
<p>Our example targets a Git repository (in this case, GitHub Enterprise). Although there are multiple methods for retrieving the contents of a Git repo, we do a simple git pull authenticated with SSH. Our example assumes your Git repository is accessible from your VPC. If that is not the case, remove the VpcConfig from the GitPullS3 Lambda function to give it access to internet resources.</p> 
<h3>Build the required AWS resources</h3> 
<p>For your convenience, there is an <a href="https://aws.amazon.com/cloudformation/">AWS CloudFormation</a> template that includes the AWS infrastructure and configuration required to build out this integration. It includes API Gateway, Lambda functions, and a simple pipeline. To launch the AWS CloudFormation stack setup wizard, choose the link for your region. The following AWS regions support all of the services required for this integration:</p> 
<table style="height: 159px" width="268"> 
<tbody> 
<tr> 
<td style="text-align: left">N. Virginia:</td> 
<td style="text-align: center"><a href="https://console.aws.amazon.com/cloudformation/home?region=us-east-1#/stacks/new?stackName=CustomSourceActionDemo&amp;templateURL=https://custom-source-action-blog-us-east-1.s3.amazonaws.com/cloudformation.yaml"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/24/launch-stack.png" /></a></td> 
</tr> 
<tr> 
<td style="text-align: left">Oregon:</td> 
<td><a href="https://console.aws.amazon.com/cloudformation/home?region=us-west-2#/stacks/new?stackName=CustomSourceActionDemo&amp;templateURL=https://custom-source-action-blog-us-west-2.s3.amazonaws.com/cloudformation.yaml"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/24/launch-stack.png" /></a></td> 
</tr> 
<tr> 
<td style="text-align: left">Ireland:</td> 
<td><a href="https://console.aws.amazon.com/cloudformation/home?region=eu-west-1#/stacks/new?stackName=CustomSourceActionDemo&amp;templateURL=https://custom-source-action-blog-eu-west-1.s3.amazonaws.com/cloudformation.yaml"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/24/launch-stack.png" /></a></td> 
</tr> 
</tbody> 
</table> 
<p>For a list of AWS services and the regions in which they are available, see <a href="http://docs.aws.amazon.com/general/latest/gr/rande.html">AWS Regions and Endpoints</a>.</p> 
<p>The stack setup wizard prompts you to enter several parameters. Many of these values must be obtained from your GitHub Enterprise service.</p> 
<p>&nbsp;</p> 
<p><strong>OutputBucketName</strong>: The bucket name for CodePipeline artifacts.</p> 
<p><strong>BranchName</strong>: The branch you want to use in the pipeline.</p> 
<p><strong>GitUrl</strong>: The HTTPS URL of the Git repository you want to clone. If your source repository isn’t exposed to the internet, make sure that you use the private IP address of your source repository.</p> 
<p><strong>ApiSecret</strong>: Webhook secrets for use with GitHub Enterprise and GitLab.</p> 
<p><strong>SourceActionVersion</strong>: The version of the custom source action to use. Because a custom action version cannot be deleted, you must increment this version every time you re-create the stack in a single account.</p> 
<p><strong>GitPullLambdaVPC</strong>: The VPC in which your Lambda function exists. This VPC must have access to the source repository and the public internet for access to CodePipeline.</p> 
<p><strong>GitPullLambdaSubnet</strong>: The subnet in which your Lambda function exists. This subnet must have access to your source repository and be private (that is, no internet gateway) with NAT access to the internet.</p> 
<p>After you have entered values for these parameters, you can complete the steps in the wizard and start the stack creation. If your values change, you can use the update stack functionality in CloudFormation to modify your parameters. When the stack creation is complete, make a note of the WebhookEndpoint and PublicSSHKey. You need these values in the following steps.</p> 
<p>&nbsp;</p> 
<h3>Configure the source repository</h3> 
<ol> 
<li>Sign in to GitHub Enterprise and navigate to the source repository.</li> 
<li>Choose the Settings tab, and then choose Webhooks.</li> 
<li>Choose Add Webhook.</li> 
<li>In Payload URL, enter the WebhookEndpoint value. In Secret, enter your webhook secret.</li> 
<li>Choose Add Webhook.</li> 
<li>Go to your user settings and choose SSH and GPG Keys. Add a new SSH key with the PublicSSHKey value from AWS CloudFormation.</li> 
</ol> 
<h3>Test a commit and clean up resources</h3> 
<p>After you have set up the webhook, push a new commit. In a few minutes, you should see a new execution passing through your pipeline with the correct revision ID and commit message.</p> 
<p>To clean up resources used in this solution, delete the AWS CloudFormation stack.</p> 
<h3>Conclusion</h3> 
<p>We hope you find this blog post useful for injecting source control metadata into your CI/CD pipeline. As always, chime in with your thoughts and suggestions in the comments.</p> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">UI Testing at Scale with AWS Lambda</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Stas Neyman</span></span> | on 
<time property="datePublished" datetime="2017-11-24T13:45:14+00:00">24 NOV 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/devops/category/compute/aws-lambda/" title="View all posts in AWS Lambda*"><span property="articleSection">AWS Lambda*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/compute/" title="View all posts in Compute*"><span property="articleSection">Compute*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/devops/" title="View all posts in DevOps*"><span property="articleSection">DevOps*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/devops/ui-testing-at-scale-with-aws-lambda/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><em>This is a guest blog post by Wes Couch and Kurt Waechter from the Blackboard Internal Product Development team about their experience using AWS Lambda.</em></p> 
<p>One year ago, one of our UI test suites took hours to run. Last month, it took 16 minutes. Today, it takes <strong>39 seconds</strong>. Here’s how we did it.</p> 
<h4>The backstory:</h4> 
<p>Blackboard is a global leader in delivering robust and innovative education software and services to clients in higher education, government, K12, and corporate training. We have a large product development team working across the globe in at least 10 different time zones, with an internal tools team providing support for quality and workflows. We have been using Selenium Webdriver to perform automated cross-browser UI testing since 2007. Because we are now practicing continuous delivery, the automated UI testing challenge has grown due to the faster release schedule. On top of that, every commit made to each branch triggers an execution of our automated UI test suite. If you have ever implemented an automated UI testing infrastructure, you know that it can be very challenging to scale and maintain. Although there are services that are useful for testing different browser/OS combinations, they don’t meet our scale needs.</p> 
<p>It used to take three hours to synchronously run our functional UI suite, which revealed the obvious need for parallel execution. Previously, we used Mesos to orchestrate a Selenium Grid Docker container for each test run. This way, we were able to run eight concurrent threads for test execution, which took an average of 16 minutes. Although this setup is fine for a single workflow, the cracks started to show when we reached the scale required for Blackboard’s mature product lines. Going beyond eight concurrent sessions on a single container introduced performance problems that impact the reliability of tests (for example, issues in Webdriver or the browser popping up frequently). We tried Mesos and considered Kubernetes for Selenium Grid orchestration, but the answer to scaling a Selenium Grid was to think smaller, not larger. This led to our breakthrough with AWS Lambda.</p> 
<p><span id="more-1936"></span></p> 
<h4>The solution:</h4> 
<p>We started using AWS Lambda for UI testing because it doesn’t require costly infrastructure or countless man hours to maintain. The steps we outline in this blog post took one work day, from inception to implementation. By simply packaging the UI test suite into a Lambda function, we can execute these tests in parallel on a massive scale. We use a custom JUnit test runner that invokes the Lambda function with a request to run each test from the suite. The runner then aggregates the results returned from each Lambda test execution.</p> 
<p>Selenium is the industry standard for testing UI at scale. Although there are other options to achieve the same thing in Lambda, we chose this mature suite of tools. Selenium is backed by Google, Firefox, and others to help the industry drive their browsers with code. This makes Lambda and Selenium a compelling stack for achieving UI testing at scale.</p> 
<h4>Making Chrome Run in Lambda</h4> 
<p>Currently, Chrome for Linux will not run in Lambda due to an absent mount point. By rebuilding Chrome with a slight modification, as Marco L&uuml;thy originally <a href="https://github.com/adieuadieu/serverless-chrome/tree/master/chrome">demonstrated</a>, you can run it inside Lambda anyway! It took about two hours to build the current master branch of Chromium to build on a c4.4xlarge. Unfortunately, the current version of ChromeDriver, 2.33, does not support any version of Chrome above 62, so we’ll be using Marco’s modified version of version 60 for the near future.</p> 
<h4>Required System Libraries</h4> 
<p>The Lambda runtime environment comes with a subset of common shared libraries. This means we need to include some extra libraries to get Chrome and ChromeDriver to work. Anything that exists in the java resources folder during compile time is included in the base directory of the compiled jar file. When this jar file is deployed to Lambda, it is placed in the /var/task/ directory. This allows us to simply place the libraries in the java resources folder under a folder named lib/ so they are <a href="http://docs.aws.amazon.com/lambda/latest/dg/current-supported-versions.html">right where they need to be</a> when the Lambda function is invoked.</p> 
<p>To get these libraries, create an EC2 instance and choose the Amazon Linux AMI.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/24/Choose_an_AMI.png" /></p> 
<p>Next, use ssh to connect to the server. After you connect to the new instance, search for the libraries to find their locations.</p> 
<code class="lang-markup">sudo find / -name libgconf-2.so.4
sudo find / -name libORBit-2.so.0
</code> 
<p>Now that you have the locations of the libraries, copy these files from the EC2 instance and place them in the java resources folder under lib/.</p> 
<h4>Packaging the Tests</h4> 
<p>To deploy the test suite to Lambda, we used a simple Gradle tool called <a href="https://github.com/johnrengelman/shadow">ShadowJar</a>, which is similar to the <a href="https://maven.apache.org/plugins/maven-shade-plugin/">Maven Shade Plugin</a>. It packages the libraries and dependencies inside the jar that is built. Usually test dependencies and sources aren’t included in a jar, but for this instance we want to include them. To include the test dependencies, add this section to the build.gradle file.</p> 
<code class="lang-markup">shadowJar {
from sourceSets.test.output
configurations = [project.configurations.testRuntime]
}
</code> 
<h4>Deploying the Test Suite</h4> 
<p>Now that our tests are packaged with the dependencies in a jar, we need to get them into a running Lambda function. We use &nbsp;simple SAM &nbsp;templates to upload the packaged jar into S3, and then deploy it to Lambda with our settings.</p> 
<code class="lang-json">{
&quot;AWSTemplateFormatVersion&quot;: &quot;2010-09-09&quot;,
&quot;Transform&quot;: &quot;AWS::Serverless-2016-10-31&quot;,
&quot;Resources&quot;: {
&quot;LambdaTestHandler&quot;: {
&quot;Type&quot;: &quot;AWS::Serverless::Function&quot;,
&quot;Properties&quot;: {
&quot;CodeUri&quot;: &quot;./build/libs/your-test-jar-all.jar&quot;,
&quot;Runtime&quot;: &quot;java8&quot;,
&quot;Handler&quot;: &quot;com.example.LambdaTestHandler::handleRequest&quot;,
&quot;Role&quot;: &quot;&lt;YourLambdaRoleArn&gt;&quot;,
&quot;Timeout&quot;: 300,
&quot;MemorySize&quot;: 1536
}
}
}
}</code> 
<p>We use the maximum timeout available to ensure our tests have plenty of time to run. We also use the maximum memory size because this ensures our Lambda function can support Chrome and other resources required to run a UI test.</p> 
<p>Specifying the handler is important because this class executes the desired test. The test handler should be able to receive a test class and method. With this information it will then execute the test and respond with the results.</p> 
<code class="lang-json">public LambdaTestResult handleRequest(TestRequest testRequest, Context context) {
LoggerContainer.LOGGER = new Logger(context.getLogger());
BlockJUnit4ClassRunner runner = getRunnerForSingleTest(testRequest);
Result result = new JUnitCore().run(runner);
return new LambdaTestResult(result);
}
</code> 
<h4>Creating a Lambda-Compatible ChromeDriver</h4> 
<p>We provide developers with an easily accessible ChromeDriver for local test writing and debugging. When we are running tests on AWS, we have configured ChromeDriver to run them in Lambda.</p> 
<p>To configure ChromeDriver, we first need to tell ChromeDriver where to find the Chrome binary. Because we know that ChromeDriver is going to be unzipped into the root task directory, we should point the ChromeDriver configuration at that location.</p> 
<p>The settings for getting ChromeDriver running are mostly related to Chrome, which must have its working directories pointed at the tmp/ folder.</p> 
<p>Start with the default DesiredCapabilities for ChromeDriver, and then add the following settings to enable your ChromeDriver to start in Lambda.</p> 
<code class="lang-json">public ChromeDriver createLambdaChromeDriver() {
ChromeOptions options = new ChromeOptions();
// Set the location of the chrome binary from the resources folder
options.setBinary(&quot;/var/task/chrome&quot;);
// Include these settings to allow Chrome to run in Lambda
options.addArguments(&quot;--disable-gpu&quot;);
options.addArguments(&quot;--headless&quot;);
options.addArguments(&quot;--window-size=1366,768&quot;);
options.addArguments(&quot;--single-process&quot;);
options.addArguments(&quot;--no-sandbox&quot;);
options.addArguments(&quot;--user-data-dir=/tmp/user-data&quot;);
options.addArguments(&quot;--data-path=/tmp/data-path&quot;);
options.addArguments(&quot;--homedir=/tmp&quot;);
options.addArguments(&quot;--disk-cache-dir=/tmp/cache-dir&quot;);
DesiredCapabilities desiredCapabilities = DesiredCapabilities.chrome();
desiredCapabilities.setCapability(ChromeOptions.CAPABILITY, options);
return new ChromeDriver(desiredCapabilities);
}
</code> 
<h4>Executing Tests in Parallel</h4> 
<p>You can approach parallel test execution in Lambda in many different ways. Your approach depends on the structure and design of your test suite. For our solution, we implemented a custom test runner that uses reflection and JUnit libraries to create a list of test cases we want run. When we have the list, we create a TestRequest object to pass into the Lambda function that we have deployed. In this TestRequest, we place the class name, test method, and the test run identifier. When the Lambda function receives this TestRequest, our LambdaTestHandler generates and runs the JUnit test. After the test is complete, the test result is sent to the test runner. The test runner compiles a result after all of the tests are complete. By executing the same Lambda function multiple times with different test requests, we can effectively run the entire test suite in parallel.</p> 
<p>To get screenshots and other test data, we pipe those files during test execution to an S3 bucket under the test run identifier prefix. When the tests are complete, we link the files to each test execution in the report generated from the test run. This lets us easily investigate test executions.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/24/Parallell_testing.png" /></p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/24/Parallell_testing2.png" /></p> 
<h4>Pro Tip: Dynamically Loading Binaries</h4> 
<p><a href="http://docs.aws.amazon.com/lambda/latest/dg/limits.html">AWS Lambda has a limit of 250 MB of uncompressed space</a> for packaged Lambda functions. Because we have libraries and other dependencies to our test suite, we hit this limit when we tried to upload a function that contained Chrome and ChromeDriver (~140 MB). This test suite was not originally intended to be used with Lambda. Otherwise, we would have scrutinized some of the included libraries. To get around this limit, we used the Lambda functions temporary directory, which allows up to 500 MB of space at runtime. Downloading these binaries at runtime moves some of that space requirement into the temporary directory. This allows more room for libraries and dependencies. You can do this by grabbing Chrome and ChromeDriver from an S3 bucket and marking them as executable using built-in Java libraries. If you take this route, be sure to point to the new location for these executables in order to create a ChromeDriver.</p> 
<code class="lang-json">private static void downloadS3ObjectToExecutableFile(String key) throws IOException {
File file = new File(&quot;/tmp/&quot; + key);
GetObjectRequest request = new GetObjectRequest(&quot;s3-bucket-name&quot;, key);
FileUtils.copyInputStreamToFile(s3client.getObject(request).getObjectContent(), file);
file.setExecutable(true);
}
</code> 
<h4>Lambda-Selenium Project Source</h4> 
<p>We have compiled an open source example that you can grab from the Blackboard Github repository. Grab the code and try it out!</p> 
<p><a href="https://blackboard.github.io/lambda-selenium/">https://blackboard.github.io/lambda-selenium/</a></p> 
<h4>Conclusion</h4> 
<p>One year ago, one of our UI test suites took hours to run. Last month, it took 16 minutes. Today, it takes <strong>39 seconds</strong>. Thanks to AWS Lambda, we can reduce our build times and perform automated UI testing at scale!</p> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<meta property="image" content="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/02/CodeBuild-social.jpg" /> 
<b class="lb-b blog-post-title" property="name headline">How to Enable Caching for AWS CodeBuild</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Karthik Thirugnanasambandam</span></span> | on 
<time property="datePublished" datetime="2017-11-21T11:35:36+00:00">21 NOV 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/devops/category/developer-tools/aws-codebuild/" title="View all posts in AWS CodeBuild*"><span property="articleSection">AWS CodeBuild*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/developer-tools/" title="View all posts in Developer Tools*"><span property="articleSection">Developer Tools*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/devops/" title="View all posts in DevOps*"><span property="articleSection">DevOps*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/how-to/" title="View all posts in How-To*"><span property="articleSection">How-To*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/new-stuff/" title="View all posts in New stuff"><span property="articleSection">New stuff</span></a></span> | 
<a href="https://aws.amazon.com/blogs/devops/how-to-enable-caching-for-aws-codebuild/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><a href="https://aws.amazon.com/codebuild/">AWS CodeBuild</a> is a fully managed build service. There are no servers to provision and scale, or software to install, configure, and operate. You just specify the location of your source code, choose your build settings, and CodeBuild runs build scripts for compiling, testing, and packaging your code.</p> 
<p>A typical application build process includes phases like preparing the environment, updating the configuration, downloading dependencies, running unit tests, and finally, packaging the built artifact.</p> 
<p>Downloading dependencies is a critical phase in the build process.&nbsp;These dependent files can range in size from a few KBs to multiple MBs. Because most of the dependent files do not change frequently between builds, you can noticeably reduce your build time by caching dependencies.</p> 
<p>In this post, I will show you how to enable caching for AWS CodeBuild.</p> 
<b>Requirements</b> 
<li>Create an <a href="http://docs.aws.amazon.com/AmazonS3/latest/gsg/CreatingABucket.html">Amazon S3</a> bucket&nbsp;for storing cache archives (You can use existing s3 bucket as well).</li> 
<li>Create a <a href="https://github.com/">GitHub account</a>&nbsp;(if you don’t have one).</li> 
<b>Create a sample build project:</b> 
<p>1. Open the AWS CodeBuild console at&nbsp;<a href="https://console.aws.amazon.com/codebuild/">https://console.aws.amazon.com/codebuild/</a>.</p> 
<p>2. If a welcome page is displayed, choose&nbsp;<strong>Get started</strong>.</p> 
<p>If a welcome page is not displayed, on the navigation pane, choose&nbsp;<strong>Build projects</strong>, and then choose&nbsp;<strong>Create project</strong>.</p> 
<p>3. On the&nbsp;<strong>Configure your project</strong>&nbsp;page, for&nbsp;<strong>Project name</strong>, type a name for this build project. Build project names must be unique across each AWS account.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/18/project.png" /></p> 
<p>4. <strong>In&nbsp;Source</strong>: <strong>What to build</strong>, for&nbsp;<strong>Source provider</strong>, choose <strong>GitHub</strong>.</p> 
<li><strong>For Repository</strong>,&nbsp;select <strong>Use a public repository</strong></li> 
<li>For&nbsp;<strong>Repository URL</strong>, type <a href="https://github.com/jenkinsci/aws-codebuild-plugin">https://github.com/jenkinsci/aws-codebuild-plugin</a></li> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/18/Screen-Shot-2017-11-18-at-12.12.01-PM.png" /></p> 
<p>5. <strong>In&nbsp;Environment</strong>: <strong>How to build</strong>, for&nbsp;<strong>Environment image</strong>, select <strong>Use an image managed by AWS CodeBuild</strong>.</p> 
<li>For <strong>Operating system</strong>, choose <strong>Ubuntu</strong>.</li> 
<li>For <strong>Runtime</strong>, choose <strong>Java</strong>.</li> 
<li>For <strong>Version</strong>, &nbsp;choose <strong>aws/codebuild/java:openjdk-8</strong>.</li> 
<li>For <strong>Build specification</strong>, select <strong>Insert build commands</strong>.</li> 
<p><strong>Note:</strong> The&nbsp;build specification file (<strong>buildspec.yml</strong>) can be configured in two ways. You can package it along with your source root directory, or you can override it by using a project environment configuration. In this example, I will use the override option and will use the console editor to specify the build specification.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/18/environment.png" /></p> 
<p>6. Under <strong>Build commands</strong>, click <strong>Switch to editor</strong> to enter the build specification.</p> 
<p>Copy the following text.</p> 
<code class="lang-yaml">version: 0.2
phases:
build:
commands:
- mvn install
cache:
paths:
- '/root/.m2/**/*'</code> 
<p><strong>Note:</strong> The cache section in the build specification instructs AWS CodeBuild about the paths to be cached. Like the&nbsp;artifacts section, the cache paths are relative to&nbsp;$CODEBUILD_SRC_DIR and specify the directories to be cached. In this example, Maven stores the downloaded dependencies to the /root/.m2/ folder, but other tools use different folders. For example, pip uses the /root/.cache/pip folder, and Gradle uses the /root/.gradle/caches folder. You might need to configure the cache paths based on your language platform.</p> 
<p>7. <strong>In Artifacts:&nbsp;</strong>Where to put the artifacts from this build project:</p> 
<li>For <strong>Type</strong>, choose <strong>No artifacts</strong>.</li> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/18/Screen-Shot-2017-11-18-at-12.08.08-PM.png" /></p> 
<p>8. In <strong>Cache</strong>:</p> 
<li>For <strong>Type</strong>, choose <strong>Amazon S3</strong>.</li> 
<li>For <strong>Bucket</strong>, choose your S3 bucket.</li> 
<li>For <strong>Path prefix</strong>, type cache/archives/</li> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/18/cache.png" /></p> 
<p>9. In&nbsp;<strong>Service role</strong>, the <strong>Create a service role in your account option</strong> will display a default role name. &nbsp;You can accept the default name or type your own.</p> 
<p>If you already have an AWS CodeBuild service role, choose&nbsp;<strong>Choose an existing service role from your account</strong>.</p> 
<p>10. Choose&nbsp;<strong>Continue</strong>.</p> 
<p>11. On the&nbsp;<strong>Review</strong>&nbsp;page, to run a build, choose&nbsp;<strong>Save and build</strong>.</p> 
<code class="lang-yaml"></code> 
<b>Review build and cache behavior:</b> 
<p>Let us review our first build for the project.</p> 
<p>In the first run, where no cache exists, overall build time would look something like&nbsp;below (notice the time for <strong>DOWNLOAD_SOURCE</strong>, <strong>BUILD</strong> and <strong>POST_BUILD</strong>):</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/18/pre-build-img.png" /></p> 
<p>If you check the build logs, you will see log entries for dependency downloads. The dependencies are downloaded directly from&nbsp;configured&nbsp;external repositories. At the end of the log, you will see an entry for the cache uploaded to your S3 bucket.</p> 
<p>Let’s review the S3 bucket for the cached archive. You’ll see the cache from our first successful build is uploaded to the configured S3 path.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/18/s3-preview.png" /></p> 
<p>Let’s try another build with the same CodeBuild project. This time the build should pick up the dependencies from the cache.</p> 
<p>In the second run, there was a cache hit (cache was generated from the first run):</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/18/post-build-img.png" /></p> 
<p>You’ll notice a few things:</p> 
<ol> 
<li><strong>DOWNLOAD_SOURCE</strong> took slightly longer. Because, in addition to the source code, this time the build also downloaded the cache from user’s s3 bucket.</li> 
<li><strong>BUILD</strong> time was faster. As the dependencies didn’t need to get downloaded, but were reused from cache.</li> 
<li><strong>POST_BUILD</strong> took slightly longer, but was relatively the same.</li> 
</ol> 
<p>Overall, build duration was improved with cache.</p> 
<b>Best practices for cache</b> 
<li style="text-align: left">By default, the cache archive is encrypted on the server side with the customer’s artifact <a href="https://aws.amazon.com/kms/">KMS</a> key.</li> 
<li style="text-align: left">You can expire the cache by manually removing the cache archive from S3. Alternatively, you can expire the cache by using an <a href="http://docs.aws.amazon.com/AmazonS3/latest/user-guide/create-lifecycle.html">S3 lifecycle policy</a>.</li> 
<li style="text-align: left">You can override cache behavior by updating the project. You can use the AWS CodeBuild <a href="https://aws.amazon.com/Users/allysona/AppData/Local/Temp/docs.aws.amazon.com/codebuild/latest/userguide/change-project.html">the AWS CodeBuild console, AWS CLI, or AWS SDKs</a> to update the project. You can also invalidate cache setting by using the new <strong>InvalidateProjectCache</strong> API. This API forces a new InvalidationKey to be generated, ensuring that future builds receive an empty cache. This API does&nbsp;not&nbsp;remove the existing cache, because this could cause inconsistencies with builds currently in flight.</li> 
<li style="text-align: left">The cache can be enabled for any folders in the build environment, but we recommend you only cache dependencies/files that will not change frequently between builds. Also, to avoid unexpected application behavior, don’t cache configuration and sensitive information.</li> 
<b>Conclusion</b> 
<p>In this blog post, I showed you how to enable and configure cache setting for AWS CodeBuild. As you see, this can save considerable build time. It also improves resiliency by avoiding external network connections to an artifact repository.</p> 
<p>I hope you found this post useful. Feel free to leave your feedback or suggestions in the comments.</p> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<meta property="image" content="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/02/CodeBuild-social.jpg" /> 
<b class="lb-b blog-post-title" property="name headline">Access Resources in a VPC from AWS CodeBuild Builds</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">John Pignata</span></span> | on 
<time property="datePublished" datetime="2017-11-21T11:32:09+00:00">21 NOV 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/devops/category/developer-tools/aws-codebuild/" title="View all posts in AWS CodeBuild*"><span property="articleSection">AWS CodeBuild*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/developer-tools/" title="View all posts in Developer Tools*"><span property="articleSection">Developer Tools*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/news/launch/" title="View all posts in Launch*"><span property="articleSection">Launch*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/news/" title="View all posts in News*"><span property="articleSection">News*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/devops/access-resources-in-a-vpc-from-aws-codebuild-builds/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-1886" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-devops-blog&amp;disqus_identifier=1886&amp;disqus_title=Access+Resources+in+a+VPC+from+AWS+CodeBuild+Builds&amp;disqus_url=https://aws.amazon.com/blogs/devops/access-resources-in-a-vpc-from-aws-codebuild-builds/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-1886');
});
</script> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><em>John Pignata, Startup Solutions Architect, Amazon Web Services</em></p> 
<p>In this blog post we’re going to discuss a new <a href="https://aws.amazon.com/codebuild/">AWS CodeBuild</a> feature that is available starting today. CodeBuild&nbsp;builds can now access resources in a VPC&nbsp;directly without these resources being exposed to the public internet. These resources include <a href="https://aws.amazon.com/rds">Amazon Relational Database Service (Amazon RDS)</a>&nbsp;databases, <a href="https://aws.amazon.com/elasticache">Amazon ElastiCache</a> clusters, internal services running on <a href="https://aws.amazon.com/ec2/">Amazon Elastic Compute Cloud (Amazon EC2)</a>, and <a href="https://aws.amazon.com/ecs/">Amazon EC2 Container Service (Amazon ECS)</a>, or any service endpoints that are only reachable from within a specific VPC.</p> 
<p>CodeBuild is a fully managed build service that compiles source code, runs tests, and produces software packages that are ready to deploy. As part of the build process, developers often require access to resources that should be isolated from the public Internet. Now CodeBuild builds can be optionally configured to have VPC connectivity and access these resources directly.</p> 
<p><strong>Accessing Resources in a VPC</strong></p> 
<p>You can configure builds to have access to a VPC when you create a CodeBuild project or you can update an existing CodeBuild project with VPC configuration attributes. Here’s how it looks in the console:</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/16/Picture1.png" /></p> 
<p>&nbsp;</p> 
<p>To configure VPC connectivity: select a VPC, one or more subnets within that VPC, and one or more VPC security groups that CodeBuild should apply when attaching to your VPC. Once configured, commands running as part of your build will be able to access resources in your VPC without transiting across the public Internet.</p> 
<p><strong>Use Cases</strong></p> 
<p>The availability of VPC connectivity from CodeBuild builds unlocks many potential uses. For example, you can:</p> 
<li>Run integration tests from your build against data in an Amazon RDS instance that’s isolated on a private subnet.</li> 
<li>Query data in an ElastiCache cluster directly from tests.</li> 
<li>Interact with internal web services hosted on Amazon EC2, Amazon ECS, or services that use internal Elastic Load Balancing.</li> 
<li>Retrieve dependencies from self-hosted, internal artifact repositories such as PyPI for Python, Maven for Java, npm for Node.js, and so on.</li> 
<li>Access objects in an Amazon S3 bucket configured to allow access only through a VPC endpoint.</li> 
<li>Query external web services that require fixed IP addresses through the Elastic IP address of the NAT gateway associated with your subnet(s).</li> 
<p>… and more! Your builds can now access any resource that’s hosted in your VPC without any compromise on network isolation.</p> 
<p><strong>Internet Connectivity</strong></p> 
<p>CodeBuild requires access to resources on the public Internet to successfully execute builds. At a minimum, it must be able to reach your source repository system (such as <a href="https://aws.amazon.com/codecommit/">AWS CodeCommit</a>, <a href="https://github.com">GitHub</a>, <a href="https://www.bitbucket.org">Bitbucket</a>), <a href="https://aws.amazon.com/s3/">Amazon Simple Storage Service (Amazon S3)</a> to deliver build artifacts, and <a href="http://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/WhatIsCloudWatchLogs.html">Amazon CloudWatch Logs</a> to stream logs from the build process. The interface attached to your VPC will not be assigned a public IP address so to enable Internet access from your builds, you will need to set up a managed <a href="http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/vpc-nat-gateway.html">NAT Gateway</a> or <a href="http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_NAT_Instance.html">NAT instance</a> for the subnets you configure. You must also ensure your security groups allow outbound access to these services.</p> 
<p><strong>IP Address Space</strong></p> 
<p>Each running build will be assigned an IP address from one of the subnets in your VPC that you designate for CodeBuild to use. As CodeBuild scales to meet your build volume, ensure that you select subnets with enough address space to accommodate your expected number of concurrent builds.</p> 
<p><strong>Service Role Permissions</strong></p> 
<p>CodeBuild requires new permissions in order to manage network interfaces on your VPCs. If you create a service role for your new projects, these permissions will be included in that role’s policy automatically. For existing service roles, you can edit the policy document to include the additional actions. For the full policy document to apply to your service role, see <a href="http://docs.aws.amazon.com/codebuild/latest/userguide/setting-up.html#setting-up-service-permissions-group">Advanced Setup</a> in the CodeBuild documentation.</p> 
<p>For more information, see <a href="https://docs.aws.amazon.com/codebuild/latest/userguide/vpc-support.html">VPC Support</a> in the CodeBuild documentation. We hope you find the ability to access internal resources on a VPC useful&nbsp;in your build processes! If you have any questions or feedback, feel free to reach out to us through the <a href="https://forums.aws.amazon.com/forum.jspa?forumID=230">AWS CodeBuild forum</a> or leave a comment!</p> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-1886');
});
</script> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">Using AWS CodeCommit Pull Requests to request code reviews and discuss code</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Chris Barclay</span></span> | on 
<time property="datePublished" datetime="2017-11-20T13:27:15+00:00">20 NOV 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/devops/category/developer-tools/aws-codecommit/" title="View all posts in AWS CodeCommit*"><span property="articleSection">AWS CodeCommit*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/how-to/" title="View all posts in How-To*"><span property="articleSection">How-To*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/devops/using-aws-codecommit-pull-requests-to-request-code-reviews-and-discuss-code/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p>Thank you to Michael Edge, Senior Cloud Architect, for a great blog on CodeCommit pull requests.</p> 
<p>~~~~~~~</p> 
<p><a href="http://aws.amazon.com/codecommit">AWS CodeCommit</a> is a fully managed service for securely hosting private Git repositories. CodeCommit now supports pull requests, which allows repository users to review, comment upon, and interactively iterate on code changes. Used as a collaboration tool between team members, pull requests help you to review potential changes to a CodeCommit repository before merging those changes into the repository. Each pull request goes through a simple lifecycle, as follows:</p> 
<li>The new features to be merged are added as one or more commits to a feature branch. The commits are not merged into the destination branch.</li> 
<li>The pull request is created, usually from the difference between two branches.</li> 
<li>Team members review and comment on the pull request. The pull request might be updated with additional commits that contain changes made in response to comments, or include changes made to the destination branch.</li> 
<li>Once team members are happy with the pull request, it is merged into the destination branch. The commits are applied to the destination branch in the same order they were added to the pull request.</li> 
<p>Commenting is an integral part of the pull request process, and is used to collaborate between the developers and the reviewer. Reviewers add comments and questions to a pull request during the review process, and developers respond to these with explanations. Pull request comments can be added to the overall pull request, a file within the pull request, or a line within a file.</p> 
<p>To make the comments more useful, sign in to the AWS Management Console as an AWS Identity and Access Management (IAM) user. The username will then be associated with the comment, indicating the owner of the comment. Pull request comments are a great quality improvement tool as they allow the entire development team visibility into what reviewers are looking for in the code. They also serve as a record of the discussion between team members at a point in time, and shouldn’t be deleted.</p> 
<p>AWS CodeCommit is also introducing the ability to add comments to a commit, another useful collaboration feature that allows team members to discuss code changed as part of a commit. This helps you discuss changes made in a repository, including why the changes were made, whether further changes are necessary, or whether changes should be merged. As is the case with pull request comments, you can comment on an overall commit, on a file within a commit, or on a specific line or change within a file, and other repository users can respond to your comments. Comments are not restricted to commits, they can also be used to comment on the differences between two branches, or between two tags. Commit comments are separate from pull request comments, i.e. you will not see commit comments when reviewing a pull request – you will only see pull request comments.</p> 
<b>A pull request example</b> 
<p>Let’s get started by running through an example. We’ll take a typical pull request scenario and look at how we’d use CodeCommit and the AWS Management Console for each of the steps.</p> 
<p>To try out this scenario, you’ll need:</p> 
<li>An AWS CodeCommit repository with some sample code in the master branch. We’ve provided sample code below.</li> 
<li>Two AWS Identity and Access Management (IAM) users, both with the <a href="http://docs.aws.amazon.com/codecommit/latest/userguide/auth-and-access-control-iam-identity-based-access-control.html#managed-policies">AWSCodeCommitPowerUser managed policy</a> applied to them.</li> 
<li>Git installed on your local computer, and access configured for AWS CodeCommit.</li> 
<li>A clone of the AWS CodeCommit repository on your local computer.</li> 
<p>In the course of this example, you’ll sign in to the AWS CodeCommit console as one IAM user to create the pull request, and as the other IAM user to review the pull request. To learn more about how to set up your IAM users and how to connect to AWS CodeCommit with Git, see the following topics:</p> 
<li>Information on <a href="http://docs.aws.amazon.com/IAM/latest/UserGuide/id_users_create.html#id_users_create_console">creating an IAM user</a> with AWS Management Console access.</li> 
<li>Instructions on how to <a href="http://docs.aws.amazon.com/codecommit/latest/userguide/setting-up-gc.html">access CodeCommit using Git</a>.</li> 
<li>If you’d like to use the same ‘hello world’ application as used in this article, here is the source code:</li> 
<code class="lang-java">package com.amazon.helloworld;
public class Main {
public static void main(String[] args) {
System.out.println(&quot;Hello, world&quot;);
}
}</code> 
<p>The scenario below uses the us-east-2 region.</p> 
<h3>Creating the branches</h3> 
<p>Before we jump in and create a pull request, we’ll need at least two branches. In this example, we’ll follow a branching strategy similar to the one <a href="https://datasift.github.io/gitflow/IntroducingGitFlow.html">described in GitFlow</a>. We’ll create a new branch for our feature from the main development branch (the default branch). We’ll develop the feature in the feature branch. Once we’ve written and tested the code for the new feature in that branch, we’ll create a pull request that contains the differences between the feature branch and the main development branch. Our team lead (the second IAM user) will review the changes in the pull request. Once the changes have been reviewed, the feature branch will be merged into the development branch.</p> 
<p><img src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/16/pull-request-1a.png" /></p> 
<p style="text-align: center">Figure 1: Pull request link</p> 
<p>Sign in to the AWS CodeCommit console with the IAM user you want to use as the developer. You can use an existing repository or you can go ahead and <a href="http://docs.aws.amazon.com/codecommit/latest/userguide/how-to-create-repository.html#how-to-create-repository-console">create a new one</a>. We won’t be merging any changes to the master branch of your repository, so it’s safe to use an existing repository for this example. You’ll find the Pull requests link has been added just above the Commits link (see Figure 1), and below Commits you’ll find the Branches link. Click <strong>Branches</strong> and create a new branch called ‘develop’, branched from the ‘master’ branch. Then create a new branch called ‘feature1’, branched from the ‘develop’ branch. You’ll end up with three branches, as you can see in Figure 2. (Your repository might contain other branches in addition to the three shown in the figure).</p> 
<p><img src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/16/Picture2.png" /></p> 
<p style="text-align: center">Figure 2: Create a feature branch</p> 
<p>If you haven’t cloned your repo yet, go to the <strong>Code</strong> link in the CodeCommit console and click the <strong>Connect</strong> button. Follow the instructions to clone your repo (<a href="http://docs.aws.amazon.com/codecommit/latest/userguide/how-to-connect.html">detailed instructions are here</a>). Open a terminal or command line and paste the git clone command supplied in the Connect instructions for your repository. The example below shows cloning a repository named codecommit-demo:</p> 
<code class="lang-bash">git clone https://git-codecommit.us-east-2.amazonaws.com/v1/repos/codecommit-demo</code> 
<p>If you’ve previously cloned the repo you’ll need to update your local repo with the branches you created. Open a terminal or command line and make sure you’re in the root directory of your repo, then run the following command:</p> 
<code class="lang-bash">git remote update origin</code> 
<p>You’ll see your new branches pulled down to your local repository.</p> 
<code class="lang-bash">$ git remote update origin
Fetching origin
From https://git-codecommit.us-east-2.amazonaws.com/v1/repos/codecommit-demo
* [new branch]      develop    -&gt; origin/develop
* [new branch]      feature1   -&gt; origin/feature1</code> 
<p>You can also see your new branches by typing:</p> 
<code class="lang-bash">git branch --all
$ git branch --all
* master
remotes/origin/develop
remotes/origin/feature1
remotes/origin/master</code> 
<p>Now we’ll make a change to the ‘feature1’ branch. Open a terminal or command line and check out the feature1 branch by running the following command:</p> 
<code class="lang-bash">git checkout feature1
$ git checkout feature1
Branch feature1 set up to track remote branch feature1 from origin.
Switched to a new branch 'feature1'</code> 
<h3>Make code changes</h3> 
<p>Edit a file in the repo using your favorite editor and save the changes. Commit your changes to the local repository, and push your changes to CodeCommit. For example:</p> 
<code class="lang-bash">git commit -am 'added new feature'
git push origin feature1
$ git commit -am 'added new feature'
[feature1 8f6cb28] added new feature
1 file changed, 1 insertion(+), 1 deletion(-)
$ git push origin feature1
Counting objects: 9, done.
Delta compression using up to 4 threads.
Compressing objects: 100% (4/4), done.
Writing objects: 100% (9/9), 617 bytes | 617.00 KiB/s, done.
Total 9 (delta 2), reused 0 (delta 0)
To https://git-codecommit.us-east-2.amazonaws.com/v1/repos/codecommit-demo
2774a53..8f6cb28  feature1 -&gt; feature1</code> 
<h3>Creating the pull request</h3> 
<p>Now we have a ‘feature1’ branch that differs from the ‘develop’ branch. At this point we want to merge our changes into the ‘develop’ branch. We’ll create a pull request to notify our team members to review our changes and check whether they are ready for a merge.</p> 
<p>In the AWS CodeCommit console, click <strong>Pull requests</strong>. Click <strong>Create pull request</strong>. On the next page select ‘develop’ as the destination branch and ‘feature1’ as the source branch. Click <strong>Compare</strong>. CodeCommit will check for merge conflicts and highlight whether the branches can be automatically merged using the fast-forward option, or whether a manual merge is necessary. A pull request can be created in both situations.</p> 
<p><img src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/16/Picture3.png" /></p> 
<p style="text-align: center">Figure 3: Create a pull request</p> 
<p>After comparing the two branches, the CodeCommit console displays the information you’ll need in order to create the pull request. In the ‘Details’ section, the ‘Title’ for the pull request is mandatory, and you may optionally provide comments to your reviewers to explain the code change you have made and what you’d like them to review. In the ‘Notifications’ section, there is an option to set up notifications to notify subscribers of changes to your pull request. Notifications will be sent on creation of the pull request as well as for any pull request updates or comments. And finally, you can review the changes that make up this pull request. This includes both the individual commits (a pull request can contain one or more commits, available in the Commits tab) as well as the changes made to each file, i.e. the diff between the two branches referenced by the pull request, available in the Changes tab. After you have reviewed this information and added a title for your pull request, click the <strong>Create</strong> button. You will see a confirmation screen, as shown in Figure 4, indicating that your pull request has been successfully created, and can be merged without conflicts into the ‘develop’ branch.</p> 
<p><img src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/16/Picture4.png" /></p> 
<p style="text-align: center">Figure 4: Pull request confirmation page</p> 
<h3>Reviewing the pull request</h3> 
<p>Now let’s view the pull request from the perspective of the team lead. If you set up notifications for this CodeCommit repository, creating the pull request would have sent an email notification to the team lead, and he/she can use the links in the email to navigate directly to the pull request. In this example, sign in to the AWS CodeCommit console as the IAM user you’re using as the team lead, and click <strong>Pull requests</strong>. You will see the same information you did during creation of the pull request, plus a record of activity related to the pull request, as you can see in Figure 5.</p> 
<p><img src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/16/Picture5.png" /></p> 
<p style="text-align: center">Figure 5: Team lead reviewing the pull request</p> 
<h3>Commenting on the pull request</h3> 
<p>You now perform a thorough review of the changes and make a number of comments using the new pull request comment feature. To gain an overall perspective on the pull request, you might first go to the Commits tab and review how many commits are included in this pull request. Next, you might visit the Changes tab to review the changes, which displays the differences between the feature branch code and the develop branch code. At this point, you can add comments to the pull request as you work through each of the changes. Let’s go ahead and review the pull request. During the review, you can add review comments at three levels:</p> 
<li>The overall pull request</li> 
<li>A file within the pull request</li> 
<li>An individual line within a file</li> 
<p><strong>The overall pull request</strong><br /> In the Changes tab near the bottom of the page you’ll see a ‘Comments on changes’ box. We’ll add comments here related to the overall pull request. Add your comments as shown in Figure 6 and click the <strong>Save</strong> button.</p> 
<p><img src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/16/Picture6.png" /></p> 
<p style="text-align: center">Figure 6: Pull request comment</p> 
<p><strong>A specific file in the pull request</strong><br /> Hovering your mouse over a filename in the Changes tab will cause a blue ‘comments’ icon to appear to the left of the filename. Clicking the icon will allow you to enter comments specific to this file, as in the example in Figure 7. Go ahead and add comments for one of the files changed by the developer. Click the <strong>Save</strong> button to save your comment.</p> 
<p><img src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/16/Picture7.png" /></p> 
<p style="text-align: center">Figure 7: File comment</p> 
<p><strong>A specific line in a file in the pull request</strong><br /> A blue ‘comments’ icon will appear as you hover over individual lines within each file in the pull request, allowing you to create comments against lines that have been added, removed or are unchanged. In Figure 8, you add comments against a line that has been added to the source code, encouraging the developer to review the naming standards. Go ahead and add line comments for one of the files changed by the developer. Click the <strong>Save</strong> button to save your comment.</p> 
<p><img src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/16/Picture8.png" /></p> 
<p style="text-align: center">Figure 8: Line comment</p> 
<p>A pull request that has been commented at all three levels will look similar to Figure 9. The pull request comment is shown expanded in the ‘Comments on changes’ section, while the comments at file and line level are shown collapsed. A ‘comment’ icon indicates that comments exist at file and line level. Clicking the icon will expand and show the comment. Since you are expecting the developer to make further changes based on your comments, you won’t merge the pull request at this stage, but will leave it open awaiting feedback. Each comment you made results in a notification being sent to the developer, who can respond to the comments. This is great for remote working, where developers and team lead may be in different time zones.</p> 
<p><img src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/16/Picture9.png" /></p> 
<p style="text-align: center">Figure 9: Fully commented pull request</p> 
<h3>Adding a little complexity</h3> 
<p>A typical development team is going to be creating pull requests on a regular basis. It’s highly likely that the team lead will merge other pull requests into the ‘develop’ branch while pull requests on feature branches are in the review stage. This may result in a change to the ‘Mergable’ status of a pull request. Let’s add this scenario into the mix and check out how a developer will handle this.</p> 
<p>To test this scenario, we could create a new pull request and ask the team lead to merge this to the ‘develop’ branch. But for the sake of simplicity we’ll take a shortcut. Clone your CodeCommit repo to a new folder, switch to the ‘develop’ branch, and make a change to one of the same files that were changed in your pull request. Make sure you change a line of code that was also changed in the pull request. Commit and push this back to CodeCommit. Since you’ve just changed a line of code in the ‘develop’ branch that has also been changed in the ‘feature1’ branch, the ‘feature1’ branch cannot be cleanly merged into the ‘develop’ branch. Your developer will need to resolve this merge conflict.</p> 
<p>A developer reviewing the pull request would see the pull request now looks similar to Figure 10, with a ‘Resolve conflicts’ status rather than the ‘Mergable’ status it had previously (see Figure 5).</p> 
<p><img src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/16/Picture10.png" /></p> 
<p style="text-align: center">Figure 10: Pull request with merge conflicts</p> 
<h3>Reviewing the review comments</h3> 
<p>Once the team lead has completed his review, the developer will review the comments and make the suggested changes. As a developer, you’ll see the list of review comments made by the team lead in the pull request Activity tab, as shown in Figure 11. The Activity tab shows the history of the pull request, including commits and comments. You can reply to the review comments directly from the Activity tab, by clicking the Reply button, or you can do this from the Changes tab. The Changes tab shows the comments for the latest commit, as comments on previous commits may be associated with lines that have changed or been removed in the current commit. Comments for previous commits are available to view and reply to in the Activity tab.</p> 
<p>In the Activity tab, use the shortcut link (which looks like this &lt;/&gt;) to move quickly to the source code associated with the comment. In this example, you will make further changes to the source code to address the pull request review comments, so let’s go ahead and do this now. But first, you will need to resolve the ‘Resolve conflicts’ status.</p> 
<p><img src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/16/Picture11.png" /></p> 
<p style="text-align: center">Figure 11: Pull request activity</p> 
<h3>Resolving the ‘Resolve conflicts’ status</h3> 
<p>The ‘Resolve conflicts’ status indicates there is a merge conflict between the ‘develop’ branch and the ‘feature1’ branch. This will require manual intervention to restore the pull request back to the ‘Mergable’ state. We will resolve this conflict next.</p> 
<p>Open a terminal or command line and check out the develop branch by running the following command:</p> 
<code class="lang-bash">git checkout develop
$ git checkout develop
Switched to branch 'develop'
Your branch is up-to-date with 'origin/develop'.</code> 
<p>To incorporate the changes the team lead made to the ‘develop’ branch, merge the remote ‘develop’ branch with your local copy:</p> 
<code class="lang-bash">git pull
$ git pull
remote: Counting objects: 9, done.
Unpacking objects: 100% (9/9), done.
From https://git-codecommit.us-east-2.amazonaws.com/v1/repos/codecommit-demo
af13c82..7b36f52  develop    -&gt; origin/develop
Updating af13c82..7b36f52
Fast-forward
src/main/java/com/amazon/helloworld/Main.java | 2 +-
1 file changed, 1 insertion(+), 1 deletion(-)</code> 
<p>Then checkout the ‘feature1’ branch:</p> 
<code class="lang-bash">git checkout feature1
$ git checkout feature1
Switched to branch 'feature1'
Your branch is up-to-date with 'origin/feature1'.</code> 
<p>Now merge the changes from the ‘develop’ branch into your ‘feature1’ branch:</p> 
<code class="lang-bash">git merge develop
$ git merge develop
Auto-merging src/main/java/com/amazon/helloworld/Main.java
CONFLICT (content): Merge conflict in src/main/java/com/amazon/helloworld/Main.java
Automatic merge failed; fix conflicts and then commit the result.</code> 
<p>Yes, this fails. The file Main.java has been changed in both branches, resulting in a merge conflict that can’t be resolved automatically. However, Main.java will now contain markers that indicate where the conflicting code is, and you can use these to resolve the issues manually. Edit Main.java using your favorite IDE, and you’ll see it looks something like this:</p> 
<code class="lang-java">package com.amazon.helloworld;
import java.util.*;
/**
* This class prints a hello world message
*/
public class Main {
public static void main(String[] args) {
&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD
Date todaysdate = Calendar.getInstance().getTime();
System.out.println(&quot;Hello, earthling. Today's date is: &quot; + todaysdate);
=======
System.out.println(&quot;Hello, earth&quot;);
&gt;&gt;&gt;&gt;&gt;&gt;&gt; develop
}
}</code> 
<p>The code between HEAD and ‘===’ is the code the developer added in the ‘feature1’ branch (HEAD represents ‘feature1’ because this is the current checked out branch). The code between ‘===’ and ‘&gt;&gt;&gt; develop’ is the code added to the ‘develop’ branch by the team lead. We’ll resolve the conflict by manually merging both changes, resulting in an updated Main.java:</p> 
<code class="lang-java">package com.amazon.helloworld;
import java.util.*;
/**
* This class prints a hello world message
*/
public class Main {
public static void main(String[] args) {
Date todaysdate = Calendar.getInstance().getTime();
System.out.println(&quot;Hello, earth. Today's date is: &quot; + todaysdate);
}
}</code> 
<p>After saving the change you can add and commit it to your local repo:</p> 
<code class="lang-bash">git add src/
git commit -m 'fixed merge conflict by merging changes'</code> 
<h3>Fixing issues raised by the reviewer</h3> 
<p>Now you are ready to address the comments made by the team lead. If you are no longer pointing to the ‘feature1’ branch, check out the ‘feature1’ branch by running the following command:</p> 
<code class="lang-bash">git checkout feature1
$ git checkout feature1
Branch feature1 set up to track remote branch feature1 from origin.
Switched to a new branch 'feature1'</code> 
<p>Edit the source code in your favorite IDE and make the changes to address the comments. In this example, the developer has updated the source code as follows:</p> 
<code class="lang-java">package com.amazon.helloworld;
import java.util.*;
/**
*  This class prints a hello world message
*
* @author Michael Edge
* @see HelloEarth
* @version 1.0
*/
public class Main {
public static void main(String[] args) {
Date todaysDate = Calendar.getInstance().getTime();
System.out.println(&quot;Hello, earth. Today's date is: &quot; + todaysDate);
}
}</code> 
<p>After saving the changes, commit and push to the CodeCommit ‘feature1’ branch as you did previously:</p> 
<code class="lang-bash">git commit -am 'updated based on review comments'
git push origin feature1</code> 
<h3>Responding to the reviewer</h3> 
<p>Now that you’ve fixed the code issues you will want to respond to the review comments. In the AWS CodeCommit console, check that your latest commit appears in the pull request Commits tab. You now have a pull request consisting of more than one commit. The pull request in Figure 12 has four commits, which originated from the following activities:</p> 
<li>8th Nov: the original commit used to initiate this pull request</li> 
<li>10th Nov, 3 hours ago: the commit by the team lead to the ‘develop’ branch, merged into our ‘feature1’ branch</li> 
<li>10th Nov, 24 minutes ago: the commit by the developer that resolved the merge conflict</li> 
<li>10th Nov, 4 minutes ago: the final commit by the developer addressing the review comments</li> 
<p><img src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/16/Picture12.png" /></p> 
<p style="text-align: center">Figure 12: Pull request with multiple commits</p> 
<p>Let’s reply to the review comments provided by the team lead. In the Activity tab, reply to the pull request comment and save it, as shown in Figure 13.</p> 
<p><img src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/16/Picture13.png" /></p> 
<p style="text-align: center">Figure 13: Replying to a pull request comment</p> 
<p>At this stage, your code has been committed and you’ve updated your pull request comments, so you are ready for a final review by the team lead.</p> 
<h3>Final review</h3> 
<p>The team lead reviews the code changes and comments made by the developer. As team lead, you own the ‘develop’ branch and it’s your decision on whether to merge the changes in the pull request into the ‘develop’ branch. You can close the pull request with or without merging using the Merge and Close buttons at the bottom of the pull request page (see Figure 13). Clicking Close will allow you to add comments on why you are closing the pull request without merging. Merging will perform a fast-forward merge, incorporating the commits referenced by the pull request. Let’s go ahead and click the Merge button to merge the pull request into the ‘develop’ branch.</p> 
<p><img class="aligncenter" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/16/Picture14.png" /></p> 
<p style="text-align: center">Figure 14: Merging the pull request</p> 
<p>After merging a pull request, development of that feature is complete and the feature branch is no longer needed. It’s common practice to delete the feature branch after merging. CodeCommit provides a check box during merge to automatically delete the associated feature branch, as seen in Figure 14. Clicking the <strong>Merge</strong> button will merge the pull request into the ‘develop’ branch, as shown in Figure 15. This will update the status of the pull request to ‘Merged’, and will close the pull request.</p> 
<p><img src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/20/Picture16.png" /></p> 
<b>Conclusion</b> 
<p>This blog has demonstrated how pull requests can be used to request a code review, and enable reviewers to get a comprehensive summary of what is changing, provide feedback to the author, and merge the code into production. For more information on pull requests, <a href="http://docs.aws.amazon.com/codecommit/latest/userguide/pull-requests.html">see the documentation</a>.</p> 
</article> 
<p>
© 2018 Amazon Web Services, Inc. or its affiliates. All rights reserved.
</p>

    </div>
  </div>
</div>


    <div id="footer" class="navigation hidden-print">
      <div class="container">
        <div class="row">
          <div class="col-xs-12">
            <ul class="footer-links nav navbar-nav">
              <li><a href="../aws.html">AWS</a></li>
              <li><a href="../linux.html">Linux</a></li>
              <li><a href="../docker.html">Docker</a></li>
              <li><a href="../ibmpower.html">IBM Power</a></li>
              <li><a href="blogsataws1.html">Blogs@AWS (Kindle Friendly)</a></li>
            </ul>
            <ul class="footer-links nav navbar-nav navbar-right">
              <li><a href="../comments.html">Comments?</a></li>
            </ul>
          </div>
        </div>
      </div>
    </div>
  </body>
</html>
