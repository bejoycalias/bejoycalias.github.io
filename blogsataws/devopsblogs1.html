<!DOCTYPE html>
<html lang="en">
  <head>
<!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-593498H');</script>
<!-- End Google Tag Manager -->

    <meta charset="utf-8">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">

    <meta name="msapplication-config" content="/microsoft-tile.xml" />
    <meta name="theme-color" content="#ffffff">

    <meta property="og:url" content="https://bejoycalias.github.io/blogsataws/devopsblogs1.html" />
    <meta property="og:site_name" content="Bejoy's TechNotes"/>
    <meta property="og:title" content="Bejoy's TechNotes - DevOps Blogs Blogs @ AWS" />
    <meta property="og:image" content="https://bejoycalias.github.io/assets/images/og-image.png"/>
    <meta property="og:image:width" content="1200"/>
    <meta property="og:image:height" content="1200"/>
    <meta property="og:description" content="" />

    <title>Bejoy's TechNotes - DevOps Blogs Blogs @ AWS</title>
    <link href="../assets/stylesheets/application-832aa42c.css" rel="stylesheet" />

    <!--[if lt IE 9]>
      <script src="../assets/javascripts/ie-compat-c141a02d.js"></script>
    <![endif]-->
    <script src="../assets/javascripts/application-ff53d307.js"></script>

    <!-- Typekit script to import Klavika font -->
    <script src="https://use.typekit.net/wxf7mfi.js"></script>
    <script>try{Typekit.load({ async: true });}catch(e){}</script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-100043608-1', 'auto');
  ga('send', 'pageview');

</script>

    
  </head>

  <body id="uh-oh-" class="layout-inner page-uh-oh-">
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-593498H"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->


    <div id="header" class="navigation navbar-static-top hidden-print">
      <div class="container">
        <div class="row">
          <div class="col-xs-12">
            <div class="navbar-header">
              <div class="navbar-brand">
                <a href="/">
                  <svg version="1.0" xmlns="http://www.w3.org/2000/svg" width="135.000000pt" height="50" viewbox="0 0 135.000000 45.000000" preserveaspectratio="xMidYMid meet" class="logo">

<g transform="translate(0.000000,45.000000) scale(0.100000,-0.100000)" fill="#000000" stroke="none">
<path class="text" fill="#000000" d="M527 384 c-4 -4 -7 -18 -7 -31 0 -21 4 -24 28 -21 21 2 27 8 27 28 0
18 -6 26 -20 28 -12 2 -24 0 -28 -4z"></path>
<path class="text" fill="#000000" d="M1080 335 c0 -48 2 -55 20 -55 18 0 20 7 20 55 0 48 -2 55 -20 55
-18 0 -20 -7 -20 -55z"></path>
<path class="text" fill="#000000" d="M54 357 c-2 -7 -3 -69 -2 -138 l3 -124 65 -3 c90 -3 130 20 130 77 0
29 -6 44 -20 54 -20 14 -20 15 -3 45 14 25 15 34 5 56 -6 15 -23 31 -38 36
-38 15 -134 13 -140 -3z m110 -33 c19 -7 21 -45 4 -62 -7 -7 -22 -12 -35 -12
-20 0 -23 5 -23 40 0 41 13 50 54 34z m20 -130 c19 -18 19 -20 6 -45 -8 -13
-21 -19 -45 -19 -34 0 -35 1 -35 40 0 38 2 40 29 40 16 0 37 -7 45 -16z"></path>
<path class="text" fill="#000000" d="M319 271 c-23 -24 -29 -38 -29 -74 0 -25 3 -53 6 -62 20 -50 164 -64
164 -15 0 15 -7 17 -45 12 -46 -5 -75 8 -75 34 0 11 16 14 65 14 l65 0 0 35
c0 80 -92 114 -151 56z m99 -33 c3 -15 -4 -18 -37 -18 -43 0 -50 7 -29 28 18
18 62 11 66 -10z"></path>
<path class="text" fill="#000000" d="M520 184 c0 -107 -1 -116 -20 -121 -11 -3 -20 -12 -20 -19 0 -21 76
-19 84 2 3 9 6 69 6 135 l0 119 -25 0 -25 0 0 -116z"></path>
<path class="text" fill="#000000" d="M649 271 c-24 -25 -29 -37 -29 -78 1 -70 34 -103 105 -103 55 0 95
44 95 103 0 60 -7 75 -41 92 -47 25 -96 19 -130 -14z m111 -30 c25 -48 2 -111
-40 -111 -45 0 -69 80 -34 114 21 22 61 20 74 -3z"></path>
<path class="text" fill="#000000" d="M850 287 c0 -8 16 -57 36 -110 28 -76 33 -100 25 -116 -16 -28 -14
-31 18 -31 27 0 29 4 70 123 23 67 41 128 41 135 0 6 -11 12 -24 12 -21 0 -26
-8 -41 -65 -10 -36 -21 -68 -25 -70 -3 -2 -16 27 -29 66 -19 60 -25 69 -47 69
-13 0 -24 -6 -24 -13z"></path>
<path class="text" fill="#000000" d="M1192 284 c-17 -12 -22 -24 -20 -47 2 -26 10 -36 45 -52 49 -23 59
-55 17 -55 -14 0 -34 5 -45 10 -16 9 -19 7 -19 -13 0 -17 7 -27 23 -31 69 -18
117 6 117 60 0 32 -4 37 -45 55 -60 26 -62 54 -4 46 37 -5 40 -3 37 16 -2 18
-11 23 -43 25 -25 2 -49 -3 -63 -14z"></path>
</g>
</svg>

                </a>
              </div>
              <button class="navbar-toggle" type="button">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
              </button>
            </div>
            <div class="buttons hidden-xs">
              <nav class="navigation-links" role="navigation">
                <ul class="main-links nav navbar-nav navbar-right">
                  <li><a href="../aws.html">AWS</a></li>
                  <li><a href="../linux.html">Linux</a></li>
                  <li><a href="../docker.html">Docker</a></li>
                  <li><a href="../ibmpower.html">IBM Power</a></li>
                  <li><a href="blogsataws1.html">Blogs@AWS (Kindle Friendly)</a></li>
                </ul>
              </nav>
            </div>
          </div>
        </div>
      </div>
    </div>

    <div class="sidebar-overlay"></div>

<aside class="sidebar" role="navigation">
  <div class="sidebar-header">
    <svg version="1.0" xmlns="http://www.w3.org/2000/svg" width="135.000000pt" height="42" viewbox="0 0 135.000000 45.000000" preserveaspectratio="xMidYMid meet">

<g transform="translate(0.000000,45.000000) scale(0.100000,-0.100000)" fill="#000000" stroke="none">
<path class="text" fill="#000000" d="M527 384 c-4 -4 -7 -18 -7 -31 0 -21 4 -24 28 -21 21 2 27 8 27 28 0
18 -6 26 -20 28 -12 2 -24 0 -28 -4z"></path>
<path class="text" fill="#000000" d="M1080 335 c0 -48 2 -55 20 -55 18 0 20 7 20 55 0 48 -2 55 -20 55
-18 0 -20 -7 -20 -55z"></path>
<path class="text" fill="#000000" d="M54 357 c-2 -7 -3 -69 -2 -138 l3 -124 65 -3 c90 -3 130 20 130 77 0
29 -6 44 -20 54 -20 14 -20 15 -3 45 14 25 15 34 5 56 -6 15 -23 31 -38 36
-38 15 -134 13 -140 -3z m110 -33 c19 -7 21 -45 4 -62 -7 -7 -22 -12 -35 -12
-20 0 -23 5 -23 40 0 41 13 50 54 34z m20 -130 c19 -18 19 -20 6 -45 -8 -13
-21 -19 -45 -19 -34 0 -35 1 -35 40 0 38 2 40 29 40 16 0 37 -7 45 -16z"></path>
<path class="text" fill="#000000" d="M319 271 c-23 -24 -29 -38 -29 -74 0 -25 3 -53 6 -62 20 -50 164 -64
164 -15 0 15 -7 17 -45 12 -46 -5 -75 8 -75 34 0 11 16 14 65 14 l65 0 0 35
c0 80 -92 114 -151 56z m99 -33 c3 -15 -4 -18 -37 -18 -43 0 -50 7 -29 28 18
18 62 11 66 -10z"></path>
<path class="text" fill="#000000" d="M520 184 c0 -107 -1 -116 -20 -121 -11 -3 -20 -12 -20 -19 0 -21 76
-19 84 2 3 9 6 69 6 135 l0 119 -25 0 -25 0 0 -116z"></path>
<path class="text" fill="#000000" d="M649 271 c-24 -25 -29 -37 -29 -78 1 -70 34 -103 105 -103 55 0 95
44 95 103 0 60 -7 75 -41 92 -47 25 -96 19 -130 -14z m111 -30 c25 -48 2 -111
-40 -111 -45 0 -69 80 -34 114 21 22 61 20 74 -3z"></path>
<path class="text" fill="#000000" d="M850 287 c0 -8 16 -57 36 -110 28 -76 33 -100 25 -116 -16 -28 -14
-31 18 -31 27 0 29 4 70 123 23 67 41 128 41 135 0 6 -11 12 -24 12 -21 0 -26
-8 -41 -65 -10 -36 -21 -68 -25 -70 -3 -2 -16 27 -29 66 -19 60 -25 69 -47 69
-13 0 -24 -6 -24 -13z"></path>
<path class="text" fill="#000000" d="M1192 284 c-17 -12 -22 -24 -20 -47 2 -26 10 -36 45 -52 49 -23 59
-55 17 -55 -14 0 -34 5 -45 10 -16 9 -19 7 -19 -13 0 -17 7 -27 23 -31 69 -18
117 6 117 60 0 32 -4 37 -45 55 -60 26 -62 54 -4 46 37 -5 40 -3 37 16 -2 18
-11 23 -43 25 -25 2 -49 -3 -63 -14z"></path>
</g>
</svg>

  </div>

  <ul class="nav sidebar-nav">
    <li><a href="../aws.html">AWS</a></li>
    <li><a href="../linux.html">Linux</a></li>
    <li><a href="../docker.html">Docker</a></li>
    <li><a href="../ibmpower.html">IBM Power</a></li>
    <li><a href="blogsataws1.html">Blogs@AWS (Kindle Friendly)</a></li>
  </ul>
</aside>


    <div class="container">
  <div class="row">
    <div id="docs-sidebar" class="col-sm-3 col-md-3 col-xs-12 hidden-print" role="complementary">
      <ul class="nav docs-sidenav">
      <li><a href="blogsataws1.html">Blogs @ AWS</a></li>
      <li><a href="whatsnew1.html">What's New @ AWS</a></li>
      <li><a href="secblogs1.html">Security Blogs @ AWS</a></li>
      <li><a href="computeblogs1.html">Compute Blogs @ AWS</a></li>
      <li><a href="apnblogs1.html">APN Blogs @ AWS</a></li>
      <li class="active"><a href="devopsblogs1.html">DevOps Blogs @ AWS</a></li>
      <li><a href="mgmtblogs1.html">Management Tools Blogs @ AWS</a></li>

    </ul>
    </div>

    <div id="inner" class="col-sm-9 col-md-9 col-xs-12" role="main">
<p></p>
<p><i>Contents of this page is copied directly from AWS blog sites to make it Kindle friendly. Some styles & sections from these pages are removed to render this properly in 'Article Mode' of Kindle e-Reader browser. All the contents of this page is property of AWS.</i></p>
<p><a href="devopsblogs1.html">Page 1</a>|<a href="devopsblogs2.html">Page 2</a>|<a href="devopsblogs3.html">Page 3</a>|<a href="devopsblogs4.html">Page 4</a</p>
<br>
<article class="post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<meta property="image" content="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/12/codepipeline_statemachine-1-1260x623.png" /> 
<b><a href="https://aws.amazon.com/blogs/devops/using-aws-step-functions-state-machines-to-handle-workflow-driven-aws-codepipeline-actions/" property="url" rel="bookmark"><span property="name headline">Using AWS Step Functions State Machines to Handle Workflow-Driven AWS CodePipeline Actions</span></a></b> 
<footer class="meta">
by 
<span property="author" typeof="Person"><span property="name">Marcilio Mendonca</span></span> | on 
<time property="datePublished" datetime="2017-10-18T08:40:39+00:00">18 OCT 2017</time> | in 
<span class="categories"><a href="https://aws.amazon.com/blogs/devops/category/developer-tools/aws-codepipeline/" title="View all posts in AWS CodePipeline"><span property="articleSection">AWS CodePipeline</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/application-services/aws-step-functions/" title="View all posts in AWS Step Functions"><span property="articleSection">AWS Step Functions</span></a></span> | 
<a href="https://aws.amazon.com/blogs/devops/using-aws-step-functions-state-machines-to-handle-workflow-driven-aws-codepipeline-actions/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog=""><span class="span icon-share"></span>&nbsp;Share</a> 
<ul> 
</ul> 
</footer> 
<p><a href="https://aws.amazon.com/codepipeline/">AWS&nbsp;CodePipeline</a>&nbsp;is a continuous integration and continuous delivery service for fast and reliable application and infrastructure updates. It offers powerful integration with other AWS services, such as <a href="https://aws.amazon.com/codebuild/">AWS&nbsp;CodeBuild</a>,&nbsp;<a href="https://aws.amazon.com/codedeploy/">AWS&nbsp;CodeDeploy</a>,&nbsp;<a href="https://aws.amazon.com/codecommit/">AWS CodeCommit</a>, <a href="https://aws.amazon.com/cloudformation/">AWS&nbsp;CloudFormation</a>&nbsp;and with third-party tools such as&nbsp;<a href="https://jenkins.io/">Jenkins</a>&nbsp;and&nbsp;<a href="https://github.com/">GitHub</a>.&nbsp;These services make it possible for AWS customers to successfully automate various tasks, including infrastructure provisioning, blue/green deployments,&nbsp;serverless&nbsp;deployments, AMI baking, database provisioning, and release management.</p> 
<p>Developers have been able to use&nbsp;CodePipeline&nbsp;to build sophisticated automation pipelines that often require a single&nbsp;CodePipeline&nbsp;action to perform multiple tasks, fork into different execution paths, and deal with asynchronous behavior. For example, to deploy a Lambda function, a&nbsp;CodePipeline&nbsp;action might first inspect the changes pushed to the code repository. If only the Lambda code has changed, the action can simply update the Lambda code package, create a new version, and point the Lambda alias to the new version. If the changes also affect infrastructure resources managed by AWS CloudFormation, the pipeline action might have to create a stack or update an existing one through the use of a&nbsp;change set. In addition, if an update is required, the pipeline action might enforce a safety policy to infrastructure resources that prevents the deletion and replacement of resources.&nbsp;You can do this by creating a <a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-cfn-updating-stacks-changesets-create.html">change set</a> and having the pipeline action inspect its changes before updating the stack.&nbsp;Change sets that do not conform to the policy are deleted.</p> 
<p>This use case is a good illustration of&nbsp;<em>workflow-driven&nbsp;pipeline actions</em>. These are actions that run multiple tasks, deal with&nbsp;async&nbsp;behavior and loops, need to maintain and propagate state, and fork into different execution paths. Implementing&nbsp;workflow-driven&nbsp;actions directly in&nbsp;CodePipeline&nbsp;can lead to complex pipelines that are hard for developers to understand and maintain. Ideally, a pipeline action should perform a single task and delegate the complexity of dealing with&nbsp;workflow-driven&nbsp;behavior associated with that task to a state machine engine. This would make it possible for developers to build simpler, more intuitive pipelines and allow them to use state machine execution logs to visualize and troubleshoot their pipeline actions.</p> 
<p>In this blog post, we discuss how&nbsp;<a href="https://aws.amazon.com/step-functions/">AWS Step Functions</a>&nbsp;state machines can be used to handle&nbsp;workflow-driven&nbsp;actions. We show how a&nbsp;CodePipeline&nbsp;action can trigger a Step Functions state machine and how the pipeline and the state machine are kept decoupled through a Lambda function. The advantages of using state machines include:</p> 
<ul> 
<li>Simplified logic (complex tasks are broken into multiple smaller tasks).</li> 
<li>Ease of handling asynchronous behavior (through state machine&nbsp;wait&nbsp;states).</li> 
<li>Built-in support for choices and processing different execution paths (through state machine&nbsp;choices).</li> 
<li>Built-in visualization and logging of the state machine execution.</li> 
</ul> 
<p>The source code for the sample pipeline, pipeline actions, and state machine used in this post is available at&nbsp;<a href="https://github.com/awslabs/aws-codepipeline-stepfunctions">https://github.com/awslabs/aws-codepipeline-stepfunctions</a>.</p> 
<b>Overview</b> 
<p>This figure shows the components in the CodePipeline-Step Functions integration that will be described in this post. The pipeline contains two stages: a Source stage represented by a CodeCommit Git repository and a Prod stage with a single Deploy action that represents the workflow-driven action.</p> 
<p><img src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/11/codepipeline_statemachine.png" /></p> 
<p>This action invokes a Lambda function (1) called the&nbsp;State Machine Trigger Lambda, which, in turn, triggers a Step Functions State Machine to process the request (2). The Lambda function sends a continuation token back to the pipeline (3) to continue its execution later and terminates. Seconds later, the pipeline invokes the Lambda function again (4), passing the continuation token received. The Lambda function checks the execution state of the state machine (5,6) and communicates the status to the pipeline. The process is repeated until the state machine execution is complete. Then the Lambda function notifies the pipeline that the corresponding pipeline action is complete (7). If the state machine has failed, the Lambda function will then fail the pipeline action and stop its execution (7). While running, the state machine triggers various Lambda functions to perform different tasks. The state machine and the pipeline are fully decoupled. Their interaction is handled by the Lambda function.</p> 
<b>The&nbsp;Deploy&nbsp;State Machine</b> 
<p>The sample state machine used in this post is a simplified version of the use case, with emphasis on infrastructure deployment. The state machine will follow distinct execution paths and thus have different outcomes, depending on:</p> 
<ul> 
<li>The current state of the AWS&nbsp;CloudFormation&nbsp;stack.</li> 
<li>The nature of the code changes made to the AWS&nbsp;CloudFormation&nbsp;template and pushed into the pipeline.</li> 
</ul> 
<p>If the stack does not exist, it will be created. If the stack exists, a change set will be created and its resources inspected by the state machine. The inspection consists of parsing the change set results and detecting whether any resources will be deleted or replaced. If no resources are being deleted or replaced, the change set is allowed to be executed and the state machine completes successfully. Otherwise, the change set is deleted and the state machine completes execution with a failure as the terminal state.</p> 
<p>Let’s dive into each of these execution paths.</p> 
<h3>Path 1: Create a Stack and Succeed Deployment</h3> 
<p>The Deploy state machine is shown here. It is triggered by the Lambda function using the following input parameters stored in an S3 bucket.</p> 
<p><img class="aligncenter size-full wp-image-1771" style="width: 60%;height: 60%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/12/create_stack_statemachine-1.png" alt="Create New Stack Execution Path" /></p> 
<pre><code class="lang-json">{
&quot;environmentName&quot;: &quot;prod&quot;,
&quot;stackName&quot;: &quot;sample-lambda-app&quot;,
&quot;templatePath&quot;: &quot;infra/Lambda-template.yaml&quot;,
&quot;revisionS3Bucket&quot;: &quot;codepipeline-us-east-1-418586629775&quot;,
&quot;revisionS3Key&quot;: &quot;StepFunctionsDrivenD/CodeCommit/sjcmExZ&quot;
}</code></pre> 
<p>Note that some values used here are for the use case example only. Account-specific parameters like <em>revisionS3Bucket</em>&nbsp;and&nbsp;<em>revisionS3Key</em>&nbsp;will be different when you deploy this use case in your account.</p> 
<p>These input parameters are used by various states in the state machine and passed to the corresponding Lambda functions to perform different tasks. For example,&nbsp;<em>stackName</em>&nbsp;is used to create a stack, check the status of stack creation, and create a change set. The&nbsp;<em>environmentName</em>&nbsp;represents the environment (for example, dev, test, prod) to which the code is being deployed. It is used to prefix the name of stacks and change sets.</p> 
<p>With the exception of built-in states such as&nbsp;<em>wait</em>&nbsp;and&nbsp;<em>choice</em>, each state in the state machine invokes a specific Lambda function.&nbsp;&nbsp;The results received from the Lambda invocations are appended to the state machine’s original input. When the state machine finishes its execution, several parameters will have been added to its original input.</p> 
<p>The first stage in the state machine is “Check Stack Existence”. It checks whether a stack with the input name specified in the&nbsp;<em>stackName</em>&nbsp;input parameter already exists. The output of the state adds a Boolean value called&nbsp;<em>doesStackExist</em>&nbsp;to the original state machine input as follows:</p> 
<pre><code class="lang-json">{
&quot;doesStackExist&quot;: true,
&quot;environmentName&quot;: &quot;prod&quot;,
&quot;stackName&quot;: &quot;sample-lambda-app&quot;,
&quot;templatePath&quot;: &quot;infra/lambda-template.yaml&quot;,
&quot;revisionS3Bucket&quot;: &quot;codepipeline-us-east-1-418586629775&quot;,
&quot;revisionS3Key&quot;: &quot;StepFunctionsDrivenD/CodeCommit/sjcmExZ&quot;,
}</code></pre> 
<p>The following stage, “Does Stack Exist?”, is represented by Step Functions built-in&nbsp;<em>choice</em>&nbsp;state. It checks the value of&nbsp;<em>doesStackExist</em>&nbsp;to determine whether a new stack needs to be created (<em>doesStackExist=true</em>) or a change set needs to be created and inspected (<em>doesStackExist=false</em>).</p> 
<p>If the stack does not exist, the states illustrated in green in the preceding figure are executed. This execution path creates the stack, waits until the stack is created, checks the status of the stack’s creation, and marks the deployment successful after the stack has been created. Except for “Stack Created?” and “Wait Stack Creation,” each of these stages invokes a Lambda function. “Stack Created?” and “Wait Stack Creation” are implemented by using the built-in&nbsp;<em>choice</em>&nbsp;state (to decide which path to follow) and the&nbsp;<em>wait</em> state&nbsp;(to wait a few seconds before proceeding), respectively. Each stage adds the results of their Lambda function executions to the initial input of the state machine, allowing future stages to process them.</p> 
<h3>Path 2: Safely Update a Stack and Mark Deployment as Successful</h3> 
<p><img class="aligncenter size-full wp-image-1772" style="width: 60%;height: 60%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/12/create_changeset_statemachine.png" alt="Safely Update a Stack and Mark Deployment as Successful Execution Path" /></p> 
<p>If the stack indicated by the&nbsp;<em>stackName</em>&nbsp;parameter already exists, a different path is executed. (See the green states in the figure.) This path will create a change set and use&nbsp;<em>wait</em>&nbsp;and&nbsp;<em>choice</em>&nbsp;states to wait until the change set is created. Afterwards, a stage in the execution path will&nbsp;inspect&nbsp; the resources affected before the change set is executed.</p> 
<p>The inspection procedure represented by the “Inspect Change Set Changes” stage consists of parsing the resources affected by the change set and checking whether any of the existing resources are being deleted or replaced. The following is an excerpt of the algorithm, where&nbsp;<em>changeSetChanges.Changes</em>&nbsp;is the object representing the change set changes:</p> 
<pre><code class="lang-js">...
var RESOURCES_BEING_DELETED_OR_REPLACED = &quot;RESOURCES-BEING-DELETED-OR-REPLACED&quot;;
var CAN_SAFELY_UPDATE_EXISTING_STACK = &quot;CAN-SAFELY-UPDATE-EXISTING-STACK&quot;;
for (var i = 0; i &lt; changeSetChanges.Changes.length; i++) {
var change = changeSetChanges.Changes[i];
if (change.Type == &quot;Resource&quot;) {
if (change.ResourceChange.Action == &quot;Delete&quot;) {
return RESOURCES_BEING_DELETED_OR_REPLACED;
}
if (change.ResourceChange.Action == &quot;Modify&quot;) {
if (change.ResourceChange.Replacement == &quot;True&quot;) {
return RESOURCES_BEING_DELETED_OR_REPLACED;
}
}
}
}
return CAN_SAFELY_UPDATE_EXISTING_STACK;</code></pre> 
<p>The algorithm returns different values to indicate whether the change set can be safely executed (<em>CAN_SAFELY_UPDATE_EXISTING_STACK</em>&nbsp;or&nbsp;<em>RESOURCES_BEING_DELETED_OR_REPLACED</em>). This value is used later by the state machine to decide whether to execute the change set and update the stack or interrupt the deployment.</p> 
<p>The output of the “Inspect Change Set” stage is shown here.</p> 
<pre><code class="lang-json">{
&quot;environmentName&quot;: &quot;prod&quot;,
&quot;stackName&quot;: &quot;sample-lambda-app&quot;,
&quot;templatePath&quot;: &quot;infra/lambda-template.yaml&quot;,
&quot;revisionS3Bucket&quot;: &quot;codepipeline-us-east-1-418586629775&quot;,
&quot;revisionS3Key&quot;: &quot;StepFunctionsDrivenD/CodeCommit/sjcmExZ&quot;,
&quot;doesStackExist&quot;: true,
&quot;changeSetName&quot;: &quot;prod-sample-lambda-app-change-set-545&quot;,
&quot;changeSetCreationStatus&quot;: &quot;complete&quot;,
&quot;changeSetAction&quot;: &quot;CAN-SAFELY-UPDATE-EXISTING-STACK&quot;
}</code></pre> 
<p>At this point, these parameters have been added to the state machine’s original input:</p> 
<ul> 
<li><em>changeSetName</em>,&nbsp;which is added by the “Create Change Set” state.</li> 
<li><em>changeSetCreationStatus</em>,&nbsp;which is added by the “Get Change Set Creation Status” state.</li> 
<li><em>changeSetAction</em>,&nbsp;which is added by the “Inspect Change Set Changes” state.</li> 
</ul> 
<p>The “Safe to Update Infra?” step is a&nbsp;choice&nbsp;state (its JSON spec follows) that simply checks the value of the&nbsp;changeSetAction&nbsp;parameter. If the value is equal to&nbsp;“<em>CAN-SAFELY-UPDATE-EXISTING-STACK</em>“, meaning that no resources will be deleted or replaced, the step will execute the change set by proceeding to the “Execute Change Set” state. The deployment is successful (the state machine completes its execution successfully).</p> 
<pre><code class="lang-json">&quot;Safe to Update Infra?&quot;: {
&quot;Type&quot;: &quot;Choice&quot;,
&quot;Choices&quot;: [
{
&quot;Variable&quot;: &quot;$.taskParams.changeSetAction&quot;,
&quot;StringEquals&quot;: &quot;CAN-SAFELY-UPDATE-EXISTING-STACK&quot;,
&quot;Next&quot;: &quot;Execute Change Set&quot;
}
],
&quot;Default&quot;: &quot;Deployment Failed&quot;
}</code></pre> 
<h3>Path 3: Reject Stack Update and Fail Deployment</h3> 
<p><img class="aligncenter size-full wp-image-1772" style="width: 60%;height: 60%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/12/deployment_failed_statemachine-1.png" alt="Reject Stack Update and Fail Deployment Execution Path" /></p> 
<p>If the <em>changeSetAction</em> parameter is different from “<em>CAN-SAFELY-UPDATE-EXISTING-STACK</em>“, the state machine will interrupt the deployment by deleting the change set and proceeding to the “Deployment Fail” step, which is a built-in <em>Fail</em> state. (Its JSON spec follows.) This state causes the state machine to stop in a failed state and serves to indicate to the Lambda function that the pipeline deployment should be interrupted in a fail state as well.</p> 
<pre><code class="lang-json"> &quot;Deployment Failed&quot;: {
&quot;Type&quot;: &quot;Fail&quot;,
&quot;Cause&quot;: &quot;Deployment Failed&quot;,
&quot;Error&quot;: &quot;Deployment Failed&quot;
}</code></pre> 
<p>In all three scenarios, there’s a state machine’s visual representation available in the AWS Step Functions console that makes it very easy for developers to identify what tasks have been executed or why a deployment has failed. Developers can also inspect the inputs and outputs of each state and look at the state machine Lambda function’s logs for details. Meanwhile, the corresponding CodePipeline action remains very simple and intuitive for developers who only need to know whether the deployment was successful or failed.</p> 
<b>The State Machine Trigger Lambda Function</b> 
<p>The <em>Trigger Lambda function</em> is invoked directly by the <em>Deploy</em> action in CodePipeline. The CodePipeline action must pass a JSON structure to the trigger function through the UserParameters attribute, as follows:</p> 
<pre><code class="lang-json">{
&quot;s3Bucket&quot;: &quot;codepipeline-StepFunctions-sample&quot;,
&quot;stateMachineFile&quot;: &quot;state_machine_input.json&quot;
}</code></pre> 
<p>The&nbsp;<em>s3Bucket</em>&nbsp;parameter specifies the S3 bucket location for the state machine input parameters file. The&nbsp;<em>stateMachineFile</em>&nbsp;parameter specifies the file holding the input parameters. By being able to specify different input parameters to the state machine, we make the Trigger Lambda function and the state machine reusable across environments. For example, the same state machine could be called from a&nbsp;<em>test</em>&nbsp;and&nbsp;<em>prod</em>&nbsp;pipeline action by specifying a different S3 bucket or state machine input file for each environment.</p> 
<p>The Trigger Lambda function performs two main tasks: triggering the state machine and checking the execution state of the state machine. Its core logic is shown here:</p> 
<pre><code class="lang-javascript">exports.index = function (event, context, callback) {
try {
console.log(&quot;Event: &quot; + JSON.stringify(event));
console.log(&quot;Context: &quot; + JSON.stringify(context));
console.log(&quot;Environment Variables: &quot; + JSON.stringify(process.env));
if (Util.isContinuingPipelineTask(event)) {
monitorStateMachineExecution(event, context, callback);
}
else {
triggerStateMachine(event, context, callback);
}
}
catch (err) {
failure(Util.jobId(event), callback, context.invokeid, err.message);
}
}</code></pre> 
<p><em>Util.isContinuingPipelineTask(event)</em> is a utility function that checks if the Trigger Lambda function is being called for the first time (that is, no continuation token is passed by CodePipeline) or as a continuation of a previous call. In its first execution, the Lambda function will trigger the state machine and send a continuation token to CodePipeline that contains the state machine execution ARN. The state machine ARN is exposed to the Lambda function through a Lambda environment variable called <em>stateMachineArn</em>. Here is the code that triggers the state machine:</p> 
<pre><code class="lang-javascript">function triggerStateMachine(event, context, callback) {
var stateMachineArn = process.env.stateMachineArn;
var s3Bucket = Util.actionUserParameter(event, &quot;s3Bucket&quot;);
var stateMachineFile = Util.actionUserParameter(event, &quot;stateMachineFile&quot;);
getStateMachineInputData(s3Bucket, stateMachineFile)
.then(function (data) {
var initialParameters = data.Body.toString();
var stateMachineInputJSON = createStateMachineInitialInput(initialParameters, event);
console.log(&quot;State machine input JSON: &quot; + JSON.stringify(stateMachineInputJSON));
return stateMachineInputJSON;
})
.then(function (stateMachineInputJSON) {
return triggerStateMachineExecution(stateMachineArn, stateMachineInputJSON);
})
.then(function (triggerStateMachineOutput) {
var continuationToken = { &quot;stateMachineExecutionArn&quot;: triggerStateMachineOutput.executionArn };
var message = &quot;State machine has been triggered: &quot; + JSON.stringify(triggerStateMachineOutput) + &quot;, continuationToken: &quot; + JSON.stringify(continuationToken);
return continueExecution(Util.jobId(event), continuationToken, callback, message);
})
.catch(function (err) {
console.log(&quot;Error triggering state machine: &quot; + stateMachineArn + &quot;, Error: &quot; + err.message);
failure(Util.jobId(event), callback, context.invokeid, err.message);
})
}</code></pre> 
<p>The Trigger Lambda function fetches the state machine input parameters from an S3 file, triggers the execution of the state machine using the input parameters and the&nbsp;<em>stateMachineArn</em>&nbsp;environment variable, and signals to&nbsp;CodePipeline&nbsp;that the execution should continue later by passing a continuation token that contains the state machine execution ARN. In case any of these operations fail and an exception is thrown, the Trigger Lambda function will fail the pipeline immediately by signaling a pipeline failure through the&nbsp;<em>putJobFailureResult</em>&nbsp;CodePipeline&nbsp;API.</p> 
<p>If the Lambda function is continuing a previous execution, it will extract the state machine execution ARN from the continuation token and check the status of the state machine, as shown here.</p> 
<pre><code class="lang-javascript">function monitorStateMachineExecution(event, context, callback) {
var stateMachineArn = process.env.stateMachineArn;
var continuationToken = JSON.parse(Util.continuationToken(event));
var stateMachineExecutionArn = continuationToken.stateMachineExecutionArn;
getStateMachineExecutionStatus(stateMachineExecutionArn)
.then(function (response) {
if (response.status === &quot;RUNNING&quot;) {
var message = &quot;Execution: &quot; + stateMachineExecutionArn + &quot; of state machine: &quot; + stateMachineArn + &quot; is still &quot; + response.status;
return continueExecution(Util.jobId(event), continuationToken, callback, message);
}
if (response.status === &quot;SUCCEEDED&quot;) {
var message = &quot;Execution: &quot; + stateMachineExecutionArn + &quot; of state machine: &quot; + stateMachineArn + &quot; has: &quot; + response.status;
return success(Util.jobId(event), callback, message);
}
// FAILED, TIMED_OUT, ABORTED
var message = &quot;Execution: &quot; + stateMachineExecutionArn + &quot; of state machine: &quot; + stateMachineArn + &quot; has: &quot; + response.status;
return failure(Util.jobId(event), callback, context.invokeid, message);
})
.catch(function (err) {
var message = &quot;Error monitoring execution: &quot; + stateMachineExecutionArn + &quot; of state machine: &quot; + stateMachineArn + &quot;, Error: &quot; + err.message;
failure(Util.jobId(event), callback, context.invokeid, message);
});
}</code></pre> 
<p>If the state machine is in the&nbsp;<em>RUNNING</em>&nbsp;state, the Lambda function will send the continuation token back to the&nbsp;CodePipeline&nbsp;action. This will cause CodePipeline to call the Lambda function again a few seconds later. If the state machine has&nbsp;<em>SUCCEEDED</em>, then the Lambda function will notify the CodePipeline action that the action has succeeded. In any other case (<em>FAILURE,&nbsp;TIMED-OUT, or&nbsp;ABORT</em>), the Lambda function will fail the pipeline action.</p> 
<p>This behavior is especially useful for developers who are building and debugging a new state machine because a bug in the state machine can potentially leave the pipeline action hanging for long periods of time until it times out. The Trigger Lambda function prevents this.</p> 
<p>Also, by having the Trigger Lambda function as a means to decouple the pipeline and state machine, we make the state machine more reusable. It can be triggered from anywhere, not just from a&nbsp;CodePipeline&nbsp;action.</p> 
<b>The Pipeline in CodePipeline</b> 
<p>Our sample pipeline contains two simple stages: the <em>Source</em> stage represented by a CodeCommit Git repository and the <em>Prod</em> stage, which contains the Deploy action that invokes the Trigger Lambda function. When the state machine decides that the change set created must be rejected (because it replaces or deletes some the existing production resources), it fails the pipeline without performing any updates to the existing infrastructure. (See the failed Deploy action in red.) Otherwise, the pipeline action succeeds, indicating that the existing provisioned infrastructure was either created (first run) or updated without impacting any resources. (See the green Deploy stage in the pipeline on the left.)</p> 
<p><img class="aligncenter size-full wp-image-1768" style="width: 50%;height: 50%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/12/codepipeline_pipeline-1.png" alt="The Pipeline in CodePipeline" /></p> 
<p>The JSON spec for the pipeline’s Prod stage is shown here. We use the <em>UserParameters</em> attribute to pass the S3 bucket and state machine input file to the Lambda function. These parameters are action-specific, which means that we can reuse the state machine in another pipeline action.</p> 
<pre><code class="lang-json">{
&quot;name&quot;: &quot;Prod&quot;,
&quot;actions&quot;: [
{
&quot;inputArtifacts&quot;: [
{
&quot;name&quot;: &quot;CodeCommitOutput&quot;
}
],
&quot;name&quot;: &quot;Deploy&quot;,
&quot;actionTypeId&quot;: {
&quot;category&quot;: &quot;Invoke&quot;,
&quot;owner&quot;: &quot;AWS&quot;,
&quot;version&quot;: &quot;1&quot;,
&quot;provider&quot;: &quot;Lambda&quot;
},
&quot;outputArtifacts&quot;: [],
&quot;configuration&quot;: {
&quot;FunctionName&quot;: &quot;StateMachineTriggerLambda&quot;,
&quot;UserParameters&quot;: &quot;{\&quot;s3Bucket\&quot;: \&quot;codepipeline-StepFunctions-sample\&quot;, \&quot;stateMachineFile\&quot;: \&quot;state_machine_input.json\&quot;}&quot;
},
&quot;runOrder&quot;: 1
}
]
}</code></pre> 
<b>Conclusion</b> 
<p>In this blog post, we discussed how state machines in AWS Step Functions can be used to handle&nbsp;workflow-driven&nbsp;actions. We showed how a Lambda function can be used to fully decouple the pipeline and the state machine and manage their interaction. The use of a state machine greatly simplified the associated CodePipeline action, allowing us to build a much simpler and cleaner pipeline while drilling down into the state machine’s execution for troubleshooting or debugging.</p> 
<p>Here are two exercises you can complete by using the&nbsp;source code.</p> 
<p><strong>Exercise #1</strong>: Do not fail the state machine and pipeline action after inspecting a change set that deletes or replaces resources. Instead, create a stack with a different name (think of blue/green deployments). You can do this by creating a state machine transition between the “Safe to Update Infra?” and “Create Stack” stages and passing a new stack name as input to the “Create Stack” stage.</p> 
<p><strong>Exercise #2</strong>: Add wait logic to the state machine to wait until the change set completes its execution before allowing the state machine to proceed to the “Deployment Succeeded” stage. Use the stack creation case as an example. You’ll have to create a Lambda function (similar to the Lambda function that checks the creation status of a stack) to get the creation status of the change set.</p> 
<p>Have fun and share your thoughts!</p> 
<b>About the Author</b> 
<p><img class="size-full wp-image-1782 alignleft" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/12/marcilio_mendonca.jpg" alt="" width="116" height="160" /></p> 
<p>Marcilio Mendonca is a Sr. Consultant in the Canadian Professional Services Team at Amazon Web Services. He has helped AWS customers design, build, and deploy best-in-class, cloud-native AWS applications using VMs, containers, and&nbsp;serverless&nbsp;architectures. Before he joined AWS, Marcilio was a Software Development Engineer at Amazon. Marcilio also holds a Ph.D. in Computer Science. In his spare time, he enjoys playing drums, riding his motorcycle in the Toronto GTA area, and spending quality time with his family.</p> 
</article> 
<article class="post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b><a href="https://aws.amazon.com/blogs/devops/aws-developer-tools-expands-integration-to-include-github/" property="url" rel="bookmark"><span property="name headline">AWS Developer Tools Expands Integration to Include GitHub</span></a></b> 
<footer class="meta">
by 
<span property="author" typeof="Person"><span property="name">Balaji Iyer</span></span> | on 
<time property="datePublished" datetime="2017-10-11T11:37:09+00:00">11 OCT 2017</time> | in 
<span class="categories"><a href="https://aws.amazon.com/blogs/devops/category/developer-tools/aws-codebuild/" title="View all posts in AWS CodeBuild"><span property="articleSection">AWS CodeBuild</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/developer-tools/aws-codedeploy/" title="View all posts in AWS CodeDeploy"><span property="articleSection">AWS CodeDeploy</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/developer-tools/aws-codepipeline/" title="View all posts in AWS CodePipeline"><span property="articleSection">AWS CodePipeline</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/developer-tools/aws-codestar/" title="View all posts in AWS CodeStar"><span property="articleSection">AWS CodeStar</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/developer-tools/" title="View all posts in Developer Tools"><span property="articleSection">Developer Tools</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/devops/" title="View all posts in DevOps"><span property="articleSection">DevOps</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/how-to/" title="View all posts in How-To"><span property="articleSection">How-To</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/management-tools/" title="View all posts in Management Tools"><span property="articleSection">Management Tools</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/new-stuff/" title="View all posts in New stuff"><span property="articleSection">New stuff</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/partners/" title="View all posts in Partners"><span property="articleSection">Partners</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/web-app/" title="View all posts in Web app"><span property="articleSection">Web app</span></a></span> | 
<a href="https://aws.amazon.com/blogs/devops/aws-developer-tools-expands-integration-to-include-github/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog=""><span class="span icon-share"></span>&nbsp;Share</a> 
<ul> 
</ul> 
</footer> 
<p>AWS Developer Tools is a set of services that include <a href="https://aws.amazon.com/codecommit/">AWS CodeCommit</a>, <a href="https://aws.amazon.com/codepipeline/">AWS CodePipeline</a>, <a href="https://aws.amazon.com/codebuild/">AWS CodeBuild</a>, and <a href="https://aws.amazon.com/codedeploy/">AWS CodeDeploy</a>. Together, these services help you securely store and maintain version control of your application’s source code and automatically build, test, and deploy your application to AWS or your on-premises environment. These services are designed to enable developers and IT professionals to rapidly and safely deliver software.</p> 
<p>As part of our continued commitment to extend the AWS Developer Tools ecosystem to third-party tools and services, we’re pleased to announce <a href="https://aws.amazon.com/codestar/">AWS CodeStar</a> and <a href="https://aws.amazon.com/codebuild/">AWS CodeBuild</a> now integrate with GitHub. This will make it easier for GitHub users to set up a continuous integration and continuous delivery toolchain as part of their release process using AWS Developer Tools.</p> 
<p>In this post, I will walk through the following:</p> 
<ul> 
<li><a href="https://aws.amazon.com/about-aws/whats-new/2017/10/announcing-aws-codestar-integration-with-github/">Integrating GitHub as a source repository for your AWS CodeStar projects</a></li> 
<li><a href="https://aws.amazon.com/about-aws/whats-new/2017/09/aws-codebuild-now-supports-building-github-pull-requests/">Enabling GitHub pull requests to automatically trigger a build in AWS CodeBuild</a></li> 
</ul> 
<p><u><strong>Prerequisites</strong>:</u></p> 
<p>You’ll need an AWS account, a <a href="http://github.com/join">GitHub account</a>, an&nbsp;<a href="https://aws.amazon.com/ec2/">Amazon EC2</a>&nbsp;key pair, and administrator-level permissions for AWS&nbsp;<a href="https://aws.amazon.com/iam/">Identity and Access Management (IAM)</a>, <a href="https://aws.amazon.com/codestar/">AWS CodeStar</a>, <a href="https://aws.amazon.com/codebuild/">AWS CodeBuild</a>, <a href="https://aws.amazon.com/codepipeline/">AWS CodePipeline</a>, <a href="https://aws.amazon.com/ec2/">Amazon EC2</a>, <a href="https://aws.amazon.com/s3/">Amazon S3</a>.</p> 
<p>&nbsp;</p> 
<b>Integrating GitHub with AWS CodeStar</b> 
<p>AWS CodeStar enables you to quickly develop, build, and deploy applications on AWS. Its unified user interface helps you easily manage your software development activities in one place. With AWS CodeStar, you can set up your entire&nbsp;<a href="https://aws.amazon.com/devops/continuous-delivery/">continuous delivery</a>&nbsp;toolchain in minutes, so you can start releasing code faster.</p> 
<p>When AWS CodeStar <a href="https://aws.amazon.com/blogs/aws/new-aws-codestar/">launched</a> in April of this year, it used AWS CodeCommit as the hosted source repository. You can now choose between AWS CodeCommit or GitHub as the source control service for your CodeStar projects. In addition, your CodeStar project dashboard lets you centrally track GitHub activities, including commits, issues, and pull requests. This makes it easy to manage project activity across the components of your CI/CD toolchain. Adding the GitHub dashboard view will simplify development of your AWS applications.</p> 
<p>In this section, I will show you how to use GitHub as the source provider for your CodeStar projects. I’ll also show you how to work with recent commits, issues, and pull requests in the CodeStar dashboard.</p> 
<p>Sign in to the AWS Management Console and from the <strong>Services</strong> menu, choose <strong>CodeStar</strong>. In the CodeStar console, choose <strong>Create a new project</strong>. You should see the <strong>Choose a project template</strong> page.</p> 
<p><img class="alignnone wp-image-1631 size-full" style="margin: 20px 0px 20px 0px" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/10/Picture1.png" alt="CodeStar Project" width="975" height="538" /></p> 
<p>Choose an option by programming language, application category, or AWS service. I am going to choose the Ruby on Rails web application that will be running on Amazon EC2.</p> 
<p>On the <strong>Project details </strong>page, you’ll now see the GitHub option. Type a name for your project, and then choose <strong>Connect to GitHub</strong>.</p> 
<p><img class="alignnone wp-image-1636 size-full" style="margin: 20px 0px 20px 0px" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/10/Picture2.png" alt="Project details" width="975" height="606" /></p> 
<p>You’ll see a message requesting authorization to connect to your GitHub repository. When prompted, choose <strong>Authorize</strong>, and then type your GitHub account password.</p> 
<p><img class="alignnone size-full wp-image-1658" style="margin: 20px 0px 20px 0px" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/10/Picture3-2.png" alt="Authorize" width="395" height="504" /></p> 
<p>This connects your GitHub identity to AWS CodeStar through OAuth. You can always review your settings by navigating to your <a href="https://github.com/settings/applications">GitHub application settings</a>.</p> 
<p><img class="alignnone wp-image-1640 size-full" style="margin: 20px 0px 20px 0px" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/11/Screen-Shot-2017-10-11-at-1.30.54-PM.png" alt="Installed GitHub Apps" /></p> 
<p>You’ll see <strong>AWS CodeStar is now connected to GitHub</strong>:</p> 
<p><img class="alignnone wp-image-1641 size-full" style="margin: 20px 0px 20px 0px" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/10/Picture5.png" alt="Create project" width="975" height="613" /></p> 
<p>You can choose a public or private repository. GitHub offers free accounts for users and organizations working on public and open source projects and paid accounts that offer unlimited private repositories and optional user management and security features.</p> 
<p>In this example, I am going to choose the public repository option. Edit the repository description, if you like, and then choose <strong>Next</strong>.</p> 
<p>Review your CodeStar project details, and then choose <strong>Create Project</strong>. On <strong>Choose an Amazon EC2 Key Pair</strong>, choose <strong>Create Project</strong>.</p> 
<p><img class="alignnone size-full wp-image-1660" style="margin: 20px 0px 20px 0px" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/10/Picture6-1.png" alt="Key Pair" width="576" height="432" /></p> 
<p>On the <strong>Review project details</strong> page, you’ll see <strong>Edit Amazon EC2 configuration.</strong> Choose this link to configure instance type, VPC, and subnet options. AWS CodeStar requires a <a href="http://docs.aws.amazon.com/codestar/latest/userguide/access-permissions.html#access-permissions-service-role">service role</a> to create and manage AWS resources and IAM permissions. This role will be created for you when you select the <strong>AWS CodeStar would like permission to administer AWS resources on your behalf </strong>check box.</p> 
<p>Choose <strong>Create Project</strong>. It might take a few minutes to create your project and resources.</p> 
<p><img class="alignnone wp-image-1645 size-full" style="margin: 20px 0px 20px 0px" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/10/Picture7.png" alt="Review project details" width="975" height="587" /></p> 
<p>When you create a CodeStar project, you’re added to the project team as an owner. If this is the first time you’ve used AWS CodeStar, you’ll be asked to provide the following information, which will be shown to others:</p> 
<ul> 
<li>Your display name.</li> 
<li>Your email address.</li> 
</ul> 
<p>This information is used in your AWS CodeStar user profile. User profiles are not project-specific, but they are limited to a single AWS region. If you are a team member in projects in more than one region, you’ll have to create a user profile in each region.</p> 
<img class="size-full wp-image-1718" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/11/2017-10-04_08-20-52-1.png" alt="User settings" width="425" height="388" /> 
<p class="wp-caption-text">User settings</p> 
<p>Choose <strong>Next</strong>. AWS CodeStar will create a GitHub repository with your configuration settings (for example, <a href="https://github.com/biyer/ruby-on-rails">https://github.com/biyer/ruby-on-rails</a>-service).</p> 
<p>When you integrate your integrated development environment (IDE) with AWS CodeStar, you can continue to write and develop code in your preferred environment. The changes you make will be included in the AWS CodeStar project each time you commit and push your code.</p> 
<p><img class="alignnone wp-image-1648 size-full" style="margin: 20px 0px 20px 0px" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/11/GitHub-Blog2.png" alt="IDE" /></p> 
<p>After setting up your IDE, choose <strong>Next</strong> to go to the CodeStar dashboard. Take a few minutes to familiarize yourself with the dashboard. You can easily track progress across your entire software development process, from your backlog of work items to recent code deployments.</p> 
<p><img class="alignnone wp-image-1649 size-full" style="margin: 20px 0px 20px 0px" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/10/Picture10.png" alt="Dashboard" width="975" height="489" /></p> 
<p>After the application deployment is complete, choose the endpoint that will display the application.</p> 
<p><img class="alignnone size-full wp-image-1681" style="margin: 20px 0px 20px 0px" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/10/Picture11-1.png" alt="Pipeline" width="485" height="691" /></p> 
<p>This is what you’ll see when you open the application endpoint:</p> 
<p><img class="alignnone size-full wp-image-1668" style="margin: 20px 0px 20px 0px" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/10/Picture12.png" alt="" width="975" height="583" /></p> 
<p>The<strong> Commit history </strong>section of the dashboard lists the commits made to the Git repository. If you choose the commit ID or the <strong>Open in GitHub </strong>option, you can use a hotlink to your GitHub repository.</p> 
<p><img class="alignnone size-full wp-image-1670" style="margin: 20px 0px 20px 0px" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/10/Picture13.png" alt="Commit history" width="975" height="317" /></p> 
<p>Your AWS CodeStar project dashboard is where you and your team view the status of your project resources, including the latest commits to your project, the state of your continuous delivery pipeline, and the performance of your instances. This information is displayed on tiles that are dedicated to a particular resource. To see more information about any of these resources, choose the details link on the tile. The console for that AWS service will open on the details page for that resource.</p> 
<p><img class="alignnone size-full wp-image-1671" style="margin: 20px 0px 20px 0px" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/10/Picture14.png" alt="Issues" width="975" height="462" /></p> 
<p>You can also filter issues based on their status and the assigned user.</p> 
<p><img class="alignnone size-full wp-image-1674" style="margin: 20px 0px 20px 0px" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/10/Picture15-1.png" alt="Filter" width="975" height="391" /></p> 
<b id="codebuild">AWS CodeBuild Now Supports Building GitHub Pull Requests</b> 
<p>CodeBuild is a fully managed build service that compiles source code, runs tests, and produces software packages that are ready to deploy. With CodeBuild, you don’t need to provision, manage, and scale your own build servers. CodeBuild scales continuously and processes multiple builds concurrently, so your builds are not left waiting in a queue. You can use prepackaged build environments to get started quickly or you can create custom build environments that use your own build tools.</p> 
<p>We recently <a href="https://aws.amazon.com/about-aws/whats-new/2017/09/aws-codebuild-now-supports-building-github-pull-requests/">announced</a> support for GitHub pull requests in AWS CodeBuild. This functionality makes it easier to collaborate across your team while editing and building your application code with CodeBuild. You can use the AWS CodeBuild or AWS CodePipeline consoles to run AWS CodeBuild. You can also automate the running of AWS CodeBuild by using the AWS Command Line Interface (AWS CLI), the AWS SDKs, or the <a href="https://aws.amazon.com/blogs/devops/simplify-your-jenkins-builds-with-aws-codebuild/">AWS CodeBuild Plugin for Jenkins</a>.</p> 
<p><img class="alignnone size-full wp-image-1675" style="margin: 20px 0px 20px 0px" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/10/Picture16.png" alt="AWS CodeBuild" width="782" height="421" /></p> 
<p>In this section, I will show you how to trigger a build in AWS CodeBuild with a pull request from GitHub through webhooks.</p> 
<p>Open the AWS CodeBuild console at&nbsp;<a href="https://console.aws.amazon.com/codebuild/">https://console.aws.amazon.com/codebuild/</a>. Choose&nbsp;<strong>Create project</strong>. If you already have a CodeBuild project, you can choose <strong>Edit project</strong>, and then follow along. CodeBuild can connect to AWS CodeCommit, S3, BitBucket, and GitHub to pull source code for builds. For <strong>Source provider</strong>, choose <strong>GitHub</strong>, and then choose <strong>Connect to GitHub</strong>.</p> 
<p><img class="alignnone size-full wp-image-1705" style="margin: 20px 0px 20px 0px" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/10/Picture17.png" alt="Configure" width="834" height="597" /></p> 
<p>After you’ve successfully linked GitHub and your CodeBuild project, you can choose a repository in your GitHub account. CodeBuild also supports connections to any public repository. You can review your settings by navigating to your <a href="https://github.com/settings/applications">GitHub application settings</a>.</p> 
<p><img class="alignnone size-full wp-image-1679" style="margin: 20px 0px 20px 0px" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/10/Picture18.png" alt="GitHub Apps" width="975" height="266" /></p> 
<p>On <strong>Source: What to Build</strong>, for&nbsp;<strong>Webhook</strong>, select&nbsp;the <strong>Rebuild every time a code change is pushed to this repository </strong>check box.</p> 
<p><strong>Note</strong>: You can select this option only if, under<strong>&nbsp;Repository</strong>, you chose&nbsp;<strong>Use a repository in my account</strong>.</p> 
<p><img class="alignnone size-full wp-image-1682" style="margin: 20px 0px 20px 0px" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/10/Picture19.png" alt="Source" width="975" height="459" /></p> 
<p>In&nbsp;<strong>Environment: How to build</strong>, for <strong>Environment image</strong>, select <strong>Use an image managed by AWS CodeBuild</strong>. For <strong>Operating system</strong>, choose <strong>Ubuntu</strong>. For <strong>Runtime</strong>, choose <strong>Base</strong>. For <strong>Version</strong>, choose the latest available version. For <strong>Build specification</strong>, you can provide a collection of build commands and related settings, in YAML format (buildspec.yml) or you can override the build spec by inserting build commands directly in the console. AWS CodeBuild uses these commands to run a build. In this example, the output is the string “hello.”</p> 
<p><img class="alignnone size-full wp-image-1685" style="margin: 20px 0px 20px 0px" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/10/Picture20-1.png" alt="Environment" width="975" height="637" /></p> 
<p><strong>On Artifacts: Where to put the artifacts from this build project</strong>, for <strong>Type</strong>, choose <strong>No artifacts</strong>. (This is also the type to choose if you are just running tests or pushing a Docker image to Amazon ECR.) You also need an AWS CodeBuild service role so that AWS CodeBuild can interact with dependent AWS services on your behalf. Unless you already have a role, choose <strong>Create a role</strong>, and for <strong>Role name</strong>, type a name for your role.</p> 
<p><img class="alignnone size-full wp-image-1686" style="margin: 20px 0px 20px 0px" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/10/Picture21.png" alt="Artifacts" width="975" height="328" /></p> 
<p>In this example, leave the advanced settings at their defaults.</p> 
<p>If you expand <strong>Show advanced settings</strong>, you’ll see options for customizing your build, including:</p> 
<ul> 
<li>A build timeout.</li> 
<li>A KMS key to encrypt all the artifacts that the builds for this project will use.</li> 
<li>Options for building a Docker image.</li> 
<li>Elevated permissions during your build action (for example, accessing Docker inside your build container to build a Dockerfile).</li> 
<li>Resource options for the build compute type.</li> 
<li>Environment variables (built-in or custom). For more information, see <a href="http://jburdon.aka.corp.amazon.com/AWSCodeFactoryDocs/src/AWSCodeFactoryDocs/build/server-root/codebuild/latest/userguide/create-project.html">Create a Build Project</a> in the AWS CodeBuild User Guide.</li> 
</ul> 
<p><img class="alignnone size-full wp-image-1688" style="margin: 20px 0px 20px 0px" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/10/Picture22.png" alt="Advanced settings" width="975" height="631" /></p> 
<p>You can use the AWS CodeBuild console to create a parameter in Amazon EC2 Systems Manager. Choose&nbsp;<strong>Create a parameter</strong>, and then follow the instructions in the dialog box. (In that dialog box, for&nbsp;<strong>KMS key</strong>, you can optionally specify the ARN of an AWS KMS key in your account. Amazon EC2 Systems Manager uses this key to encrypt the parameter’s value during storage and decrypt during retrieval.)</p> 
<p><img class="alignnone size-full wp-image-1706" style="margin: 20px 0px 20px 0px" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/10/Picture23-1.png" alt="Create parameter" width="448" height="307" /></p> 
<p>Choose&nbsp;<strong>Continue</strong>. On the&nbsp;<strong>Review</strong>&nbsp;page, either choose&nbsp;<strong>Save and build</strong>&nbsp;or choose&nbsp;<strong>Save</strong>&nbsp;to run the build later.</p> 
<p>Choose <strong>Start build</strong>. When the build is complete, the <strong>Build logs </strong>section should display detailed information about the build.</p> 
<p><img class="alignnone size-full wp-image-1692" style="margin: 20px 0px 20px 0px" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/10/Picture24.png" alt="Logs" width="975" height="512" /></p> 
<p>To demonstrate a pull request, I will fork the repository as a different GitHub user, make commits to the forked repo, check in the changes to a newly created branch, and then open a pull request.</p> 
<p><img class="alignnone size-full wp-image-1694" style="margin: 20px 0px 20px 0px" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/10/Picture25.png" alt="Pull request" width="975" height="690" /></p> 
<p>As soon as the pull request is submitted, you’ll see CodeBuild start executing the build.</p> 
<p><img class="alignnone size-full wp-image-1697" style="margin: 20px 0px 20px 0px" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/10/Picture26.png" alt="Build" width="975" height="194" /></p> 
<p>GitHub sends an HTTP POST payload to the webhook’s configured URL (highlighted here), which CodeBuild uses to download the latest source code and execute the build phases.</p> 
<p><img class="alignnone size-full wp-image-1699" style="margin: 20px 0px 20px 0px" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/10/Picture27.png" alt="Build project" width="975" height="785" /></p> 
<p>If you expand the <strong>Show all checks</strong> option for the GitHub pull request, you’ll see that CodeBuild has completed the build, all checks have passed, and a deep link is provided in <strong>Details</strong>, which opens the build history in the CodeBuild console.</p> 
<p><img class="alignnone size-full wp-image-1701" style="margin: 20px 0px 20px 0px" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/10/Picture28.png" alt="Pull request" width="975" height="587" /></p> 
<b>Summary:</b> 
<p>In this post, I showed you how to use GitHub as the source provider for your CodeStar projects and how to work with recent commits, issues, and pull requests in the CodeStar dashboard. I also showed you how you can use GitHub pull requests to automatically trigger a build in AWS CodeBuild — specifically, how this functionality makes it easier to collaborate across your team while editing and building your application code with CodeBuild.</p> 
<hr /> 
<h3>About the author:</h3> 
<p><img class="alignnone wp-image-1723 size-thumbnail" style="margin: 20px 0px 20px 0px" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/10/11/pic-150x150.jpg" alt="" width="150" height="150" /></p> 
<p><strong>Balaji Iyer is an Enterprise Consultant for the Professional Services Team&nbsp;at Amazon Web Services</strong>. In this role, he has helped several customers successfully navigate their journey to AWS. His specialties include architecting and implementing highly scalable distributed systems, serverless architectures, large scale migrations, operational&nbsp;security, and leading strategic AWS initiatives. Before he joined Amazon, Balaji spent more than&nbsp;a decade building operating systems, big data analytics solutions, mobile services, and web applications. In his spare time, he enjoys experiencing the great outdoors and spending time with his family.</p> 
<p>&nbsp;</p> 
</article> 
<article class="post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="b post-title" property="name headline">Using AWS CodePipeline, AWS CodeBuild, and AWS Lambda for Serverless Automated UI Testing</b> 
<footer class="meta">
by 
<span property="author" typeof="Person"><span property="name">Prakash Palanisamy</span></span> | on 
<time property="datePublished" datetime="2017-09-18T21:23:54+00:00">18 SEP 2017</time> | in 
<span class="categories"><a href="https://aws.amazon.com/blogs/devops/category/developer-tools/aws-codebuild/" title="View all posts in AWS CodeBuild"><span property="articleSection">AWS CodeBuild</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/developer-tools/aws-codecommit/" title="View all posts in AWS CodeCommit"><span property="articleSection">AWS CodeCommit</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/developer-tools/aws-codepipeline/" title="View all posts in AWS CodePipeline"><span property="articleSection">AWS CodePipeline</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/compute/aws-lambda/" title="View all posts in AWS Lambda"><span property="articleSection">AWS Lambda</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/how-to/" title="View all posts in How-To"><span property="articleSection">How-To</span></a></span> | 
<a href="https://aws.amazon.com/blogs/devops/using-aws-codepipeline-aws-codebuild-and-aws-lambda-for-serverless-automated-ui-testing/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog=""><span class="span icon-share"></span>&nbsp;Share</a> 
<ul> 
</ul> 
</footer> 
<p>Testing the user interface of a web application is an important part of the development lifecycle. In this post, I’ll explain how to automate UI testing using serverless technologies, including <a href="https://aws.amazon.com/codepipeline/" target="_blank" rel="noopener noreferrer">AWS CodePipeline</a>, <a href="https://aws.amazon.com/codebuild/" target="_blank" rel="noopener noreferrer">AWS CodeBuild</a>, and <a href="https://aws.amazon.com/lambda/" target="_blank" rel="noopener noreferrer">AWS Lambda</a>.</p> 
<p>I built a website for UI testing that is hosted in S3. I used Selenium to perform cross-browser UI testing on Chrome, Firefox, and PhantomJS, a headless WebKit browser with <a href="https://github.com/detro/ghostdriver" target="_blank" rel="noopener noreferrer">Ghost Driver</a>, an implementation of the WebDriver Wire Protocol. I used Python to create test cases for ChromeDriver, FirefoxDriver, or PhatomJSDriver based the browser against which the test is being executed.</p> 
<p>Resources referred to in this post, including the AWS CloudFormation template, test and status websites hosted in S3, AWS CodeBuild build specification files, AWS Lambda function, and the Python script that performs the test are available in the <a href="https://github.com/awslabs/serverless-automated-ui-testing" target="_blank" rel="noopener noreferrer">serverless-automated-ui-testing</a> GitHub repository.</p> 
<p><span id="more-1588"></span></p> 
<p><strong>S3 Hosted Test Website:</strong></p> 
<p><img class="alignnone size-full wp-image-1589" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/09/13/Test_website.png" alt="" width="1464" height="918" /></p> 
<p>AWS CodeBuild supports custom containers so we can use the Selenium/standalone-Firefox and Selenium/standalone-Chrome containers, which include prebuild Firefox and Chrome browsers, respectively. <a href="https://www.x.org/releases/X11R7.7/doc/man/man1/Xvfb.1.xhtml" target="_blank" rel="noopener noreferrer">Xvfb</a> performs the graphical operation in virtual memory without any display hardware. It will be installed in the CodeBuild containers during the install phase.</p> 
<p><strong>Build Spec for Chrome and Firefox</strong></p> 
<p>The build specification for Chrome and Firefox testing includes multiple phases:</p> 
<ul> 
<li>The environment variables section contains a set of default variables that are overridden while creating the build project or triggering the build.</li> 
<li>As part of install phase, required packages like Xvfb and Selenium are installed using yum.</li> 
<li>During the pre_build phase, the test bed is prepared for test execution.</li> 
<li>During the build phase, the appropriate DISPLAY is set and the tests are executed.</li> 
</ul> 
<pre><code class="lang-yaml">version: 0.2
env:
&nbsp; variables:
&nbsp; &nbsp; BROWSER: &quot;chrome&quot;
&nbsp; &nbsp; WebURL: &quot;https://sampletestweb.s3-eu-west-1.amazonaws.com/website/index.html&quot;
&nbsp; &nbsp; ArtifactBucket: &quot;codebuild-demo-artifact-repository&quot;
&nbsp; &nbsp; MODULES: &quot;mod1&quot;
&nbsp; &nbsp; ModuleTable: &quot;test-modules&quot;
&nbsp; &nbsp; StatusTable: &quot;blog-test-status&quot;
phases:
&nbsp; install:
&nbsp; &nbsp; commands:
&nbsp; &nbsp; &nbsp; - apt-get update
&nbsp; &nbsp; &nbsp; - apt-get -y upgrade
&nbsp; &nbsp; &nbsp; - apt-get install xvfb python python-pip build-essential -y
&nbsp; &nbsp; &nbsp; - pip install --upgrade pip
&nbsp; &nbsp; &nbsp; - pip install selenium
&nbsp; &nbsp; &nbsp; - pip install awscli
&nbsp; &nbsp; &nbsp; - pip install requests
&nbsp; &nbsp; &nbsp; - pip install boto3
&nbsp; &nbsp; &nbsp; - cp xvfb.init /etc/init.d/xvfb
&nbsp; &nbsp; &nbsp; - chmod +x /etc/init.d/xvfb
&nbsp; &nbsp; &nbsp; - update-rc.d xvfb defaults
&nbsp; &nbsp; &nbsp; - service xvfb start
&nbsp; &nbsp; &nbsp; - export PATH=&quot;$PATH:`pwd`/webdrivers&quot;
&nbsp; pre_build:
&nbsp; &nbsp; commands:
&nbsp; &nbsp; &nbsp; - python prepare_test.py
&nbsp; build:
&nbsp; &nbsp; commands:
&nbsp; &nbsp; &nbsp; - export DISPLAY=:5
&nbsp; &nbsp; &nbsp; - cd tests
&nbsp; &nbsp; &nbsp; - echo &quot;Executing simple test...&quot;
&nbsp; &nbsp; &nbsp; - python testsuite.py</code></pre> 
<p>Because Ghost Driver runs headless, it can be executed on AWS Lambda. In keeping with a fire-and-forget model, I used CodeBuild to create the PhantomJS Lambda function and trigger the test invocations on Lambda in parallel. This is powerful because many tests can be executed in parallel on Lambda.</p> 
<p><strong>Build Spec for PhantomJS</strong></p> 
<p>The build specification for PhantomJS testing also includes multiple phases. It is a little different from the preceding example because we are using AWS Lambda for the test execution.</p> 
<ul> 
<li>The environment variables section contains a set of default variables that are overridden while creating the build project or triggering the build.</li> 
<li>As part of install phase, the required packages like Selenium and the AWS CLI are installed using yum.</li> 
<li>During the pre_build phase, the test bed is prepared for test execution.</li> 
<li>During the build phase, a zip file that will be used to create the PhantomJS Lambda function is created and tests are executed on the Lambda function.</li> 
</ul> 
<pre><code class="lang-yaml">version: 0.2
env:
&nbsp; variables:
&nbsp; &nbsp; BROWSER: &quot;phantomjs&quot;
&nbsp; &nbsp; WebURL: &quot;https://sampletestweb.s3-eu-west-1.amazonaws.com/website/index.html&quot;
&nbsp; &nbsp; ArtifactBucket: &quot;codebuild-demo-artifact-repository&quot;
&nbsp; &nbsp; MODULES: &quot;mod1&quot;
&nbsp; &nbsp; ModuleTable: &quot;test-modules&quot;
&nbsp; &nbsp; StatusTable: &quot;blog-test-status&quot;
&nbsp; &nbsp; LambdaRole: &quot;arn:aws:iam::account-id:role/role-name&quot;
phases:
&nbsp; install:
&nbsp; &nbsp; commands:
&nbsp; &nbsp; &nbsp; - apt-get update
&nbsp; &nbsp; &nbsp; - apt-get -y upgrade
&nbsp; &nbsp; &nbsp; - apt-get install python python-pip build-essential -y
&nbsp; &nbsp; &nbsp; - apt-get install zip unzip -y
&nbsp; &nbsp; &nbsp; - pip install --upgrade pip
&nbsp; &nbsp; &nbsp; - pip install selenium
&nbsp; &nbsp; &nbsp; - pip install awscli
&nbsp; &nbsp; &nbsp; - pip install requests
&nbsp; &nbsp; &nbsp; - pip install boto3
&nbsp; pre_build:
&nbsp; &nbsp; commands:
&nbsp; &nbsp; &nbsp; - python prepare_test.py
&nbsp; build:
&nbsp; &nbsp; commands:
&nbsp; &nbsp; &nbsp; - cd lambda_function
&nbsp; &nbsp; &nbsp; - echo &quot;Packaging Lambda Function...&quot;
&nbsp; &nbsp; &nbsp; - zip -r /tmp/lambda_function.zip ./*
&nbsp; &nbsp; &nbsp; - func_name=`echo $CODEBUILD_BUILD_ID | awk -F ':' '{print $1}'`-phantomjs
&nbsp; &nbsp; &nbsp; - echo &quot;Creating Lambda Function...&quot;
&nbsp; &nbsp; &nbsp; - chmod 777 phantomjs
&nbsp; &nbsp; &nbsp; - |
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; func_list=`aws lambda list-functions | grep FunctionName | awk -F':' '{print $2}' | tr -d ', &quot;'`
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; if echo &quot;$func_list&quot; | grep -qw $func_name
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; then
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; echo &quot;Lambda function already exists.&quot;
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; else
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; aws lambda create-function --function-name $func_name --runtime &quot;python2.7&quot; --role $LambdaRole --handler &quot;testsuite.lambda_handler&quot; --zip-file fileb:///tmp/lambda_function.zip --timeout 150 --memory-size 1024 --environment Variables=&quot;{WebURL=$WebURL, StatusTable=$StatusTable}&quot; --tags Name=$func_name
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; fi
&nbsp; &nbsp; &nbsp; - export PhantomJSFunction=$func_name
&nbsp; &nbsp; &nbsp; - cd ../tests/
&nbsp; &nbsp; &nbsp; - python testsuite.py
</code></pre> 
<p>The list of test cases and the test modules that belong to each case are stored in an <a href="https://aws.amazon.com/dynamodb/" target="_blank" rel="noopener noreferrer">Amazon DynamoDB</a> table. Based on the list of modules passed as an argument to the CodeBuild project, CodeBuild gets the test cases from that table and executes them. The test execution status and results are stored in another Amazon DynamoDB table. It will read the test status from the status table in DynamoDB and display it.</p> 
<p>AWS CodeBuild and AWS Lambda perform the test execution as individual tasks. AWS CodePipeline plays an important role here by enabling continuous delivery and parallel execution of tests for optimized testing.</p> 
<p>Here’s how to do it:</p> 
<p>In AWS CodePipeline, create a pipeline with four stages:</p> 
<ul> 
<li>Source (AWS CodeCommit)</li> 
<li>UI testing (AWS Lambda and AWS CodeBuild)</li> 
<li>Approval (manual approval)</li> 
<li>Production (AWS Lambda)</li> 
</ul> 
<p>Pipeline stages, the actions in each stage, and transitions between stages are shown in the following diagram.</p> 
<p><img class="alignnone size-full wp-image-1591" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/09/13/Automated_UI_Testing.png" alt="" width="1162" height="1121" /></p> 
<p>This design implemented in AWS CodePipeline looks like this:</p> 
<p><img class="alignnone size-full wp-image-1592" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/09/13/CodePipeline_Flow.png" alt="" width="529" height="890" /></p> 
<p>CodePipeline automatically detects a change in the source repository and triggers the execution of the pipeline.</p> 
<p>In the UITest stage, there are two parallel actions:</p> 
<ul> 
<li>DeployTestWebsite invokes a Lambda function to deploy the test website in S3 as an S3 website.</li> 
<li>DeployStatusPage invokes another Lambda function to deploy in parallel the status website in S3 as an S3 website.</li> 
</ul> 
<p>Next, there are three parallel actions that trigger the CodeBuild project:</p> 
<ul> 
<li>TestOnChrome launches a container to perform the Selenium tests on Chrome.</li> 
<li>TestOnFirefox launches another container to perform the Selenium tests on Firefox.</li> 
<li>TestOnPhantomJS creates a Lambda function and invokes individual Lambda functions per test case to execute the test cases in parallel.</li> 
</ul> 
<p>You can monitor the status of the test execution on the status website, as shown here:</p> 
<p><img class="alignnone size-full wp-image-1594" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/09/13/Test_Status.png" alt="" width="1622" height="1630" /></p> 
<p>When the UI testing is completed successfully, the pipeline continues to an Approval stage in which a notification is sent to the configured SNS topic. The designated team member reviews the test status and approves or rejects the deployment. Upon approval, the pipeline continues to the Production stage, where it invokes a Lambda function and deploys the website to a production S3 bucket.</p> 
<p>I used a CloudFormation template to set up my continuous delivery pipeline. The <a href="https://github.com/awslabs/serverless-automated-ui-testing/blob/master/automated-ui-testing.yaml" target="_blank" rel="noopener noreferrer">automated-ui-testing.yaml</a> template, available from GitHub, sets up a full-featured pipeline.</p> 
<p>When I use the template to create my pipeline, I specify the following:</p> 
<ul> 
<li>AWS CodeCommit repository.</li> 
<li>SNS topic to send approval notification.</li> 
<li>S3 bucket name where the artifacts will be stored.</li> 
</ul> 
<p><img class="alignnone size-full wp-image-1595" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/09/13/CFN_Params.png" alt="" width="2008" height="1020" /></p> 
<p>The stack name should follow the <a href="http://docs.aws.amazon.com/AmazonS3/latest/dev/BucketRestrictions.html" target="_blank" rel="noopener noreferrer">rules for S3 bucket naming</a> because it will be part of the S3 bucket name.</p> 
<p>When the stack is created successfully, the URLs for the test website and status website appear in the Outputs section, as shown here:</p> 
<p><img class="alignnone size-full wp-image-1596" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/09/13/CFN_Output.png" alt="" width="1928" height="606" /></p> 
<p><strong>Conclusion</strong></p> 
<p>In this post, I showed how you can use AWS CodePipeline, AWS CodeBuild, AWS Lambda, and a manual approval process to create a continuous delivery pipeline for serverless automated UI testing. Websites running on Amazon EC2 instances or AWS Elastic Beanstalk can also be tested using similar approach.</p> 
<hr /> 
<h3>About the author</h3> 
<p><strong><img class="alignleft wp-image-1260 size-thumbnail" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/06/07/PP1-150x150.jpg" alt="" width="150" height="150" />Prakash Palanisamy</strong> is a Solutions Architect for Amazon Web Services. When he is not working on Serverless, DevOps or Alexa, he will be solving problems in Project Euler. He also enjoys watching educational documentaries.</p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/devops/tag/aws-codebuild/" rel="tag">AWS CodeBuild</a>, <a href="https://aws.amazon.com/blogs/devops/tag/aws-codepipeline/" rel="tag">AWS CodePipeline</a>, <a href="https://aws.amazon.com/blogs/devops/tag/aws-lambda/" rel="tag">AWS Lambda</a></span> 
</footer> 
</article> 
<article class="post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b><a href="https://aws.amazon.com/blogs/devops/simplify-your-jenkins-builds-with-aws-codebuild/" property="url" rel="bookmark"><span property="name headline">Simplify Your Jenkins Builds with AWS CodeBuild</span></a></b> 
<footer class="meta">
by 
<span property="author" typeof="Person"><span property="name">Paul Roberts</span></span> | on 
<time property="datePublished" datetime="2017-09-15T09:20:26+00:00">15 SEP 2017</time> | 
<a href="https://aws.amazon.com/blogs/devops/simplify-your-jenkins-builds-with-aws-codebuild/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog=""><span class="span icon-share"></span>&nbsp;Share</a> 
<ul> 
</ul> 
</footer> 
<p>Jeff Bezos<a href="http://archive.oreilly.com/network/2006/12/20/web-20-bezos.html"> famously said</a>, “There’s a lot of undifferentiated heavy lifting that stands between your idea and that success.” He went on to say, “…70% of your time, energy, and dollars go into the undifferentiated heavy lifting and only 30% of your energy, time, and dollars gets to go into the core kernel of your idea.”</p> 
<p>If you subscribe to this maxim, you should not be spending valuable time focusing on operational issues related to maintaining the Jenkins build infrastructure. Companies such as Riot Games have over <a href="https://youtu.be/YViFZBoKqjg?t=203">1.25 million builds per year</a>&nbsp;and have written several lengthy&nbsp;<a href="https://engineering.riotgames.com/news/jenkins-ephemeral-docker-tutorial">blog </a>posts about their experiences designing a complex, custom Docker-powered Jenkins build farm. Dealing with Jenkins slaves at scale is a job in itself and Riot has engineers focused on managing the build infrastructure.</p> 
<img class="wp-image-1601 size-large" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/09/15/codebuild-fit-1024x465.png" alt="" width="640" height="291" /> 
<p class="wp-caption-text">Typical Jenkins Build Farm</p> 
<p>&nbsp;</p> 
<p>As with all technology, the Jenkins build farm architectures have evolved. Today, instead of manually building your own container infrastructure, there are Jenkins Docker <a href="https://wiki.jenkins.io/display/JENKINS/CloudBees+Docker+Custom+Build+Environment+Plugin">plugins</a>&nbsp;available to help reduce the operational burden of maintaining these environments. There is also a community-contributed <a href="https://aws.amazon.com/ecs/">Amazon EC2 Container Service</a> (Amazon ECS) <a href="https://wiki.jenkins.io/display/JENKINS/Amazon+EC2+Container+Service+Plugin">plugin</a> that helps remove some of the overhead, but you still need to configure and manage the overall Amazon ECS environment.</p> 
<p>There are various ways to create and manage your Jenkins build farm, but there has to be a way that significantly reduces your operational overhead.</p> 
<h3>Introducing AWS CodeBuild</h3> 
<p><a href="https://aws.amazon.com/codebuild">AWS CodeBuild</a> is a fully managed build service that removes the undifferentiated heavy lifting of provisioning, managing, and scaling your own build servers. With CodeBuild, there is no software to install, patch, or update. CodeBuild scales up automatically to meet the needs of your development teams. In addition, CodeBuild is an on-demand service where you pay as you go. You are charged based only on the number of minutes it takes to complete your build.</p> 
<p>One AWS customer, <a href="https://aws.amazon.com/codebuild/customer-testimonials/">Recruiterbox</a>, helps companies hire simply and predictably through their software platform. Two years ago, they began feeling the operational pain of maintaining their own Jenkins build farms. They briefly considered moving to Amazon ECS, but chose an even easier path forward instead. Recuiterbox transitioned to using Jenkins with CodeBuild and are very happy with the results. You can read more about their journey <a href="https://inside.recruiterbox.com/constant-time-ci-with-codebuild-eb3b22a111a5">here</a>.</p> 
<h3>Solution Overview: Jenkins and CodeBuild</h3> 
<p>To remove the heavy lifting from managing your Jenkins build farm, AWS has developed a Jenkins AWS CodeBuild <a href="https://wiki.jenkins.io/display/JENKINS/AWS+CodeBuild+Plugin">plugin</a>. After the plugin has been enabled, a developer can configure a Jenkins project to pick up new commits from their chosen source code repository and automatically run the associated builds. After the build is successful, it will create an artifact that is stored inside an S3 bucket that you have configured. If an error is detected somewhere, CodeBuild will capture the output and send it to <a href="https://aws.amazon.com/cloudwatch/">Amazon CloudWatch</a> logs. In addition to storing the logs on CloudWatch, Jenkins also captures the error so you do not have to go hunting for log files for your build.</p> 
<p>&nbsp;</p> 
<img class="wp-image-1602 size-large" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/09/15/jenkins-codebuild-1024x522.png" alt="" width="640" height="326" /> 
<p class="wp-caption-text">AWS CodeBuild with Jenkins Plugin</p> 
<p>&nbsp;</p> 
<p>The following example uses AWS CodeCommit (Git) as the source control management (SCM) and Amazon S3 for build artifact storage. Logs are stored in CloudWatch. A development pipeline that uses Jenkins with CodeBuild plugin architecture looks something like this:</p> 
<p>&nbsp;</p> 
<img class="wp-image-1603 size-large" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/09/15/codebuild-diagram-1024x368.png" alt="" width="640" height="230" /> 
<p class="wp-caption-text">AWS CodeBuild Diagram</p> 
<h3>Initial Solution Setup</h3> 
<p>To keep this blog post succinct, I assume that you are using the following components on AWS already and have applied the appropriate IAM policies:</p> 
<p>&middot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; AWS CodeCommit repo.</p> 
<p>&middot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Amazon S3 bucket for CodeBuild artifacts.</p> 
<p>&middot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; SNS notification for text messaging of the Jenkins admin password.</p> 
<p>&middot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; IAM user’s key and secret.</p> 
<p>&middot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; A role that has a policy with <a href="https://s3.amazonaws.com/proberts-public/example_policy.json">these permissions</a>. Be sure to edit the ARNs with your region, account, and resource name. Use this role in the AWS CloudFormation template referred to later in this post.</p> 
<p>&nbsp;</p> 
<h3>Jenkins Installation with CodeBuild Plugin Enabled</h3> 
<p>To make the integration with Jenkins as frictionless as possible, I have created an AWS CloudFormation template here: <a href="https://s3.amazonaws.com/proberts-public/jenkins.yaml">https://s3.amazonaws.com/proberts-public/jenkins.yaml</a>. Download the template, sign in the AWS CloudFormation console, and then use the template to create a stack.</p> 
<p>&nbsp;</p> 
<img class="wp-image-1604" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/09/15/jenkins1.png" alt="" width="640" height="542" /> 
<p class="wp-caption-text">CloudFormation Inputs</p> 
<h3>Jenkins Project Configuration</h3> 
<p>After the stack is complete, log in to the Jenkins EC2 instance using the user name “admin” and the password sent to your mobile device. Now that you have logged in to Jenkins, you need to create your first project. Start with a Freestyle project and configure the parameters based on your CodeBuild and CodeCommit settings.</p> 
<p>&nbsp;</p> 
<img class="wp-image-1605" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/09/15/jenkins2.png" alt="" width="640" height="550" /> 
<p class="wp-caption-text">AWS CodeBuild Plugin Configuration in Jenkins</p> 
<p>&nbsp;</p> 
<img class="wp-image-1606" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/09/15/jenkins3.png" alt="" width="640" height="665" /> 
<p class="wp-caption-text">Additional Jenkins AWS CodeBuild Plugin Configuration</p> 
<p>&nbsp;</p> 
<p>After you have configured the Jenkins project appropriately you should be able to check your build status on the Jenkins polling log under your project settings:</p> 
<p>&nbsp;</p> 
<img class="wp-image-1607 size-large" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/09/15/jenkins4-1024x252.png" alt="" width="640" height="158" /> 
<p class="wp-caption-text">Jenkins Polling Log</p> 
<p>&nbsp;</p> 
<p>Now that Jenkins is polling CodeCommit, you can check the CodeBuild dashboard under your Jenkins project to confirm your build was successful:</p> 
<img class="wp-image-1608 size-large" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/09/15/jenkins5-1024x335.png" alt="" width="640" height="209" /> 
<p class="wp-caption-text">Jenkins AWS CodeBuild Dashboard</p> 
<h3>Wrapping Up</h3> 
<p>In a matter of minutes, you have been able to provision Jenkins with the AWS CodeBuild plugin. This will greatly simplify your build infrastructure management. Now kick back and relax while CodeBuild does all the heavy lifting!</p> 
<hr /> 
<h4>About the Author</h4> 
<p><img class="wp-image-1613 size-thumbnail alignleft" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/09/15/headshot-small-150x150.png" alt="" width="150" height="150" />Paul Roberts&nbsp;is a Strategic Solutions Architect for Amazon Web Services. When he is not working on Serverless, DevOps, or Artificial Intelligence,&nbsp;he is often found in Lake Tahoe exploring the various mountain ranges with his family.</p> 
</article> 
<article class="post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b><a href="https://aws.amazon.com/blogs/devops/ensuring-security-of-your-code-in-a-cross-regioncross-account-deployment-solution/" property="url" rel="bookmark"><span property="name headline">Ensuring Security of Your Code in a Cross-Region/Cross-Account Deployment Solution</span></a></b> 
<footer class="meta">
by 
<span property="author" typeof="Person"><span property="name">BK Chaurasiya</span></span> | on 
<time property="datePublished" datetime="2017-08-16T12:03:10+00:00">16 AUG 2017</time> | in 
<span class="categories"><a href="https://aws.amazon.com/blogs/devops/category/best-practices/" title="View all posts in Best practices"><span property="articleSection">Best practices</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/how-to/" title="View all posts in How-To"><span property="articleSection">How-To</span></a></span> | 
<a href="https://aws.amazon.com/blogs/devops/ensuring-security-of-your-code-in-a-cross-regioncross-account-deployment-solution/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog=""><span class="span icon-share"></span>&nbsp;Share</a> 
<ul> 
</ul> 
</footer> 
<p>There are multiple ways you can protect your data while it is in transit and at rest. You can protect your data in transit by using SSL or by using client-side encryption.&nbsp;<a href="https://aws.amazon.com/kms/">AWS Key Management Service (AWS KMS)</a> is a managed service that makes it easy for you to create, control, rotate, and use your encryption keys. AWS KMS allows you to create custom keys. You can then share these keys with <a href="https://aws.amazon.com/iam/">AWS Identity and Access Management (IAM)</a> users and roles in your AWS account or in an AWS account owned by someone else.</p> 
<p>In my previous <a href="https://aws.amazon.com/blogs/devops/building-a-cross-regioncross-account-code-deployment-solution-on-aws/">post</a>, I described a solution for building a cross-region/cross-account code deployment solution on AWS. In this post, I describe a few options for&nbsp;protecting your source code as it travels between regions and between AWS accounts.</p> 
<p>To recap, you deployed the infrastructure as&nbsp;shown in the following diagram.</p> 
<p><img class="wp-image-255 aligncenter" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/24/Diagram10.png" alt="" width="938" height="511" /></p> 
<ul> 
<li>You had your development environment running in Region A in AWS Account A.</li> 
<li>You had your QA environment running in Region B in AWS Account B.</li> 
<li>You had a staging or production environment running in Region C in AWS Account C.</li> 
</ul> 
<p>An update to the source code in Region A triggered validation and deployment of source code changes in the pipeline in Region A. A successful processing of source code in all of its AWS CodePipeline states invoked a Lambda function, which copied the source code into an S3 bucket in Region B. After the source code was copied into this bucket, it triggered a similar chain of processes into the different AWS CodePipeline stages in Region B.</p> 
<p>&nbsp;</p> 
<h3><strong>Ensuring Security for Your Source Code</strong></h3> 
<p>You might&nbsp;choose to encrypt the source code .zip file before uploading to the S3 bucket that is in Account A, Region A, using Amazon S3 server-side encryption:</p> 
<h4><strong>1. Using the Amazon S3 service master key</strong></h4> 
<p>Refer back to the Lambda function created for you by the CloudFormation stack in the previous <a href="https://aws.amazon.com/blogs/devops/building-a-cross-regioncross-account-code-deployment-solution-on-aws/">post</a>. Go to the AWS Lambda console and your function name should be &lt;stackname&gt;-CopytoDest-XXXXXXX.</p> 
<p>&nbsp;</p> 
<p><img class="wp-image-1483 aligncenter" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/07/23/Lambda_BK.png" alt="" /></p> 
<p>&nbsp;</p> 
<p>Use the following parameter for the copyObject function – <em>ServerSideEncryption: ‘AES256’</em></p> 
<p><strong>Note</strong>: The set-up already uses this option by default.</p> 
<p>The <em>copyObject</em> function decrypts the .zip file and copies the object into account B.</p> 
<p>&nbsp;</p> 
<h4><strong>2. Using an AWS KMS master key</strong></h4> 
<p>Since the KMS keys are constrained in a region, copying the object (source code .zip file) into a different account across the region requires&nbsp;cross-account access to the KMS key. This must occur before Amazon S3 can use that key for encryption and decryption.</p> 
<p>Use the following parameter for the&nbsp;<em>copyObject</em> function – <em>ServerSideEncryption: ‘aws:kms’</em> and provide an&nbsp;<em>SSEKMSKeyId: ‘&lt;keyeid&gt;’</em></p> 
<p><strong>To enable cross-account access for the KMS key and use it in Lambda function</strong></p> 
<p>a. Create a KMS key in the source account (Account A), region B – for example,&nbsp;<strong><em>XRDepTestKey</em></strong></p> 
<p><strong>Note</strong>: This key must&nbsp;be created in region B. This is because the source code will&nbsp;be copied in an S3 bucket that exists in region B and the KMS key must&nbsp;be accessible in this region.</p> 
<p>b. To enable the&nbsp;Lambda function to be able to use this KMS key, add <strong><em>lambdaS3CopyRole</em></strong>&nbsp;as a user for this key. The Lambda function and associated role and policies are defined in the <a href="https://s3-us-west-2.amazonaws.com/aws-xregion-xaccount-sample/template/XregionCodePipeLineCF.template">CloudFormation template</a>.</p> 
<p>c. Note the ARN of the key that you generated.</p> 
<p><img class=" wp-image-1484 aligncenter" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/07/23/keyARN.jpg" alt="" width="1224" height="377" /></p> 
<p>d. Provide the external account (Account B) permission to use this key. For more information, see <a href="https://blogs.aws.amazon.com/security/post/Tx2N2SRHXSNEX91/Share-Custom-Encryption-Keys-More-Securely-Between-Accounts-by-Using-AWS-Key-Man">Sharing custom encryption keys securely between accounts</a>.</p> 
<p><em> arn:aws:iam::&lt;Account B ID&gt;:root</em></p> 
<p>e. In Account B, delegate the permission to use this key to the role that AWS CodePipeline is using. In the&nbsp;CloudFormation template, you can see&nbsp;that <em><strong>CodePipelineTrustRole</strong></em>&nbsp;is used. Attach the following policy to the role. Ensure that you update the region and Account ID accordingly.</p> 
<pre><code class="lang-js">{
&nbsp;&nbsp;&nbsp; &quot;Version&quot;: &quot;2012-10-17&quot;,
&nbsp;&nbsp;&nbsp; &quot;Statement&quot;: [
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; {
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;Sid&quot;: &quot;AllowUseOfTheKey&quot;,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;Effect&quot;: &quot;Allow&quot;,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;Action&quot;: [
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;kms:Encrypt&quot;,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;kms:Decrypt&quot;,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;kms:ReEncrypt*&quot;,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;kms:GenerateDataKey*&quot;,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;kms:DescribeKey&quot;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ],
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;Resource&quot;: [
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;arn:aws:kms:&lt;regionB&gt;:&lt;AccountA ID&gt;:key/&lt;KMS Key in Region B ID&gt;&quot;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ]
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; },
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; {
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;Sid&quot;: &quot;AllowAttachmentOfPersistentResources&quot;,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;Effect&quot;: &quot;Allow&quot;,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;Action&quot;: [
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;kms:CreateGrant&quot;,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;kms:ListGrants&quot;,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;kms:RevokeGrant&quot;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ],
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;Resource&quot;: [
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;arn:aws:kms:&lt;regionB&gt;:&lt;AccountA ID&gt;:key/&lt;KMS Key in Region B ID&gt;&quot;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ],
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;Condition&quot;: {
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;Bool&quot;: {
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;kms:GrantIsForAWSResource&quot;: true
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }
&nbsp;&nbsp;&nbsp; ]
}</code></pre> 
<p>f. Update the Lambda function, <strong><em>CopytoDest</em></strong>, to use the following in the parameter definition.</p> 
<p>&nbsp;</p> 
<pre><code class="lang-js">ServerSideEncryption: 'aws:kms',\n&quot;,
SSEKMSKeyId: '&lt; keyeid &gt;'&nbsp;&nbsp;
//ServerSideEncryption: 'AES256'\n&quot;,</code></pre> 
<p>And there you go! You have enabled secure delivery of your source code into your cross-region/cross-account deployment solution.</p> 
<h3><strong>About the Author</strong></h3> 
<p><img class="alignnone size-full wp-image-1582" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/08/16/BK.jpeg" alt="" width="119" height="160" /><br /> BK Chaurasiya&nbsp;is a Solutions Architect with Amazon Web Services. He provides technical guidance, design advice and thought leadership to some of the largest and successful AWS customers and partners.</p> 
</article> 
<article class="post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<meta property="image" content="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/08/10/devsecops2_1.jpg" /> 
<b><a href="https://aws.amazon.com/blogs/devops/bluegreen-infrastructure-application-deployment-blog/" property="url" rel="bookmark"><span property="name headline">Automating Blue/Green Deployments of Infrastructure and Application Code using AMIs, AWS Developer Tools, &amp; Amazon EC2 Systems Manager</span></a></b> 
<footer class="meta">
by 
<span property="author" typeof="Person"><span property="name">Ramesh Adabala</span></span> | on 
<time property="datePublished" datetime="2017-08-10T16:59:05+00:00">10 AUG 2017</time> | in 
<span class="categories"><a href="https://aws.amazon.com/blogs/devops/category/compute/amazon-ec2/" title="View all posts in Amazon EC2"><span property="articleSection">Amazon EC2</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/management-tools/amazon-ec2-systems-manager/" title="View all posts in Amazon EC2 Systems Manager"><span property="articleSection">Amazon EC2 Systems Manager</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/compute/auto-scaling/" title="View all posts in Auto Scaling"><span property="articleSection">Auto Scaling</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/management-tools/aws-cloudformation/" title="View all posts in AWS CloudFormation"><span property="articleSection">AWS CloudFormation</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/developer-tools/aws-codebuild/" title="View all posts in AWS CodeBuild"><span property="articleSection">AWS CodeBuild</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/developer-tools/aws-codecommit/" title="View all posts in AWS CodeCommit"><span property="articleSection">AWS CodeCommit</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/developer-tools/aws-codedeploy/" title="View all posts in AWS CodeDeploy"><span property="articleSection">AWS CodeDeploy</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/developer-tools/aws-codepipeline/" title="View all posts in AWS CodePipeline"><span property="articleSection">AWS CodePipeline</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/developer-tools/" title="View all posts in Developer Tools"><span property="articleSection">Developer Tools</span></a></span> | 
<a href="https://aws.amazon.com/blogs/devops/bluegreen-infrastructure-application-deployment-blog/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog=""><span class="span icon-share"></span>&nbsp;Share</a> 
<ul> 
</ul> 
</footer> 
<p>Previous <a href="https://aws.amazon.com/devops/">DevOps </a>blog posts have covered the following use cases for infrastructure and application deployment automation:</p> 
<ul> 
<li><a href="https://aws.amazon.com/blogs/apn/category/aws-codebuild/">Deploy to Production Using AWS CodeBuild and the AWS Developer Tools Suite</a>: Deploying a simple Java application in an in-place deployment model using <a href="https://aws.amazon.com/codecommit/">AWS CodeCommit</a>, <a href="https://aws.amazon.com/codebuild/">AWS CodeBuild</a>, and <a href="https://aws.amazon.com/codedeploy/">AWS CodeDeploy</a> orchestrated by <a href="https://aws.amazon.com/codepipeline/">AWS CodePipeline</a>.</li> 
<li><a href="https://aws.amazon.com/blogs/devops/performing-bluegreen-deployments-with-aws-codedeploy-and-auto-scaling-groups/">Performing Blue/Green Deployments with AWS CodeDeploy and Auto Scaling Groups</a>: Extending the CI/CD model by using the CodeDeploy blue/green deployment feature to create a production environment and make it easier to roll back to the previous environment if problems arise.</li> 
<li><a href="https://aws.amazon.com/blogs/aws/streamline-ami-maintenance-and-patching-using-amazon-ec2-systems-manager-automation/">Streamline AMI Maintenance and Patching Using Amazon EC2 Systems Manager | Automation</a>: Using EC2 Systems Manager and automation to patch, update agents, or bake applications into an Amazon Machine Image (AMI) and avoid the time and effort associated with manual image updates.</li> 
</ul> 
<p>An <a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AMIs.html">AMI </a>provides the information required to launch an instance, which is a virtual server in the cloud. You can use one AMI to launch as many instances as you need. It is security best practice to customize and harden your base AMI with required operating system updates and, if you are using AWS native services for continuous security monitoring and operations, you are strongly encouraged to bake into the base AMI agents such as those for <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/ssm-agent.html">Amazon EC2 Systems Manager (SSM)</a>, <a href="http://docs.aws.amazon.com/inspector/latest/userguide/inspector_agents.html">Amazon Inspector</a>, <a href="http://docs.aws.amazon.com/codedeploy/latest/userguide/codedeploy-agent-operations.html">CodeDeploy</a>, and <a href="http://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/QuickStartEC2Instance.html">CloudWatch Logs</a>. A customized and hardened AMI is often referred to as a “golden AMI.” The use of golden AMIs to create EC2 instances in your AWS environment allows for fast and stable application deployment and scaling, secure application stack upgrades, and versioning.</p> 
<p>In this post, using the DevOps automation capabilities of <a href="https://aws.amazon.com/ec2/systems-manager/">Systems Manager</a>,<a href="https://aws.amazon.com/products/developer-tools/"> AWS developer tools</a> (<a href="https://aws.amazon.com/codepipeline/">CodePipeLine</a>, <a href="https://aws.amazon.com/codedeploy/">CodeDeploy</a>, <a href="https://aws.amazon.com/codecommit/">CodeCommit</a>, <a href="https://aws.amazon.com/codebuild/">CodeBuild</a>), I will show you how to use <a href="https://aws.amazon.com/codepipeline/">AWS CodePipeline</a> to orchestrate the end-to-end <a href="https://aws.amazon.com/about-aws/whats-new/2017/01/aws-codedeploy-introduces-blue-green-deployments/">blue/green deployments</a> of a golden AMI and application code. Systems Manager Automation is a powerful security feature for enterprises that want to mature their DevSecOps practices.</p> 
<p>Here are the high-level phases and primary services covered in this use case:</p> 
<p><img class="aligncenter wp-image-1534" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/08/10/devsecops2_1.jpg" alt="" width="299" height="187" /></p> 
<p>&nbsp;</p> 
<p>You can access the source code for the sample used in this post here: <a href="https://github.com/awslabs/automating-governance-sample/tree/master/Bluegreen-AMI-Application-Deployment-blog">https://github.com/awslabs/automating-governance-sample/tree/master/Bluegreen-AMI-Application-Deployment-blog</a>.</p> 
<p>This sample will create a pipeline in AWS CodePipeline with the building blocks to support the blue/green deployments of infrastructure and application. The sample includes a custom Lambda step in the pipeline to execute Systems Manager Automation to build a golden AMI and update the Auto Scaling group with the golden AMI ID for every rollout of new application code. This guarantees that every new application deployment is on a fully patched and customized AMI in a continuous integration and deployment model. This enables the automation of hardened AMI deployment with every new version of application deployment.</p> 
<p>&nbsp;</p> 
<p><img class="alignnone wp-image-1549" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/08/10/devopsblog_conceptual_diagram.png" alt="" width="900" height="496" /></p> 
<p>&nbsp;</p> 
<p>We will build and run this sample in three parts.</p> 
<p><strong><u>Part 1</u></strong>: <strong>Setting up the AWS developer tools and deploying a base web application</strong> <a href="https://console.aws.amazon.com/cloudformation/home?region=us-east-1#/stacks/new?stackName=devsecopspart1&amp;templateURL=https://s3.amazonaws.com/devsecopsblog/blog_template_part1.json"><img class="wp-image-1536 alignright" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/08/10/devsecops2_3.jpg" alt="" width="123" height="23" /></a></p> 
<p>Part 1 of the <a href="https://s3.amazonaws.com/devsecopsblog/blog_template_part1.json">AWS CloudFormation</a> template creates the initial Java-based web application environment in a VPC. It also creates all the required components of Systems Manager Automation, CodeCommit, CodeBuild, and CodeDeploy to support the blue/green deployments of the infrastructure and application resulting from ongoing code releases.</p> 
<p>Part 1 of the AWS CloudFormation stack creates these resources:</p> 
<ul> 
<li>A Java-based web application running on <a href="https://aws.amazon.com/ec2/">EC2 </a>instances loaded with <a href="http://docs.aws.amazon.com/codedeploy/latest/userguide/codedeploy-agent.html">CodeDeploy agents</a> in an <a href="http://docs.aws.amazon.com/autoscaling/latest/userguide/AutoScalingGroup.html">Auto Scaling group</a> behind an <a href="https://aws.amazon.com/elasticloadbalancing/">Elastic Load Balancing load balancer</a>.</li> 
<li>A <a href="https://aws.amazon.com/ec2/systems-manager/automation/">Systems Manager Automation</a> document that patches the supplied base AMI and creates the <a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AMIs.html">golden AMI</a>.</li> 
<li>A <a href="http://docs.aws.amazon.com/codecommit/latest/userguide/repositories.html">CodeCommit repository</a> to securely store code and files for your application.</li> 
<li>A <a href="http://docs.aws.amazon.com/codebuild/latest/userguide/build-projects-working.html">CodeBuild project</a> with configuration details about how AWS CodeBuild builds your source code.</li> 
<li>A <a href="http://docs.aws.amazon.com/codedeploy/latest/userguide/deployment-groups.html">CodeDeploy deployment group</a> with Auto Scaling group details about the web application EC2 instances.</li> 
<li>A <a href="http://docs.aws.amazon.com/codedeploy/latest/userguide/applications-create.html">CodeDeploy application</a> with a deployment group configured with the <strong>Automatically copy Auto Scaling group</strong> setting.</li> 
<li>The following Lambda functions: 
<ol> 
<li>A function to get the Amazon-provided source AMI ID based on region and architecture.</li> 
<li>A function to update the Systems Manager parameter with the golden AMI ID.</li> 
<li>A function to update the <a href="http://docs.aws.amazon.com/codedeploy/latest/userguide/integrations-aws-auto-scaling.html">CodeDeploy deployment group</a> with required blue/green configurations. (Currently AWS CloudFormation does not support creating a deployment group with blue/green deployment configurations.)</li> 
</ol> </li> 
</ul> 
<p>After Part 1 of the AWS CloudFormation stack creation is complete, go to the Outputs tab and click the Elastic Load Balancing link. You will see the following home page for the base web application:</p> 
<p><img class="alignnone size-full wp-image-1559" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/08/10/devsecops2_4-1.jpg" alt="" width="881" height="115" /></p> 
<p>Make sure you have all the outputs from the Part 1 stack handy. You need to supply them as parameters in Part 3 of the stack.</p> 
<p><strong><u>Part 2</u></strong>: <strong>Setting up your CodeCommit repository</strong></p> 
<p>In this part, you will commit and push your sample application code into the CodeCommit repository created in Part 1. To access the initial git commands to clone the empty repository to your local machine, click Connect to go to the AWS CodeCommit console. Make sure you have the <a href="http://docs.aws.amazon.com/codecommit/latest/userguide/access-permissions.html">IAM permissions</a> required to access AWS CodeCommit from command line interface (CLI).</p> 
<p><img class="alignnone size-full wp-image-1538" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/08/10/devsecops2_5.jpg" alt="" width="910" height="234" /></p> 
<p>After you’ve cloned the repository locally, download the sample application files from the <a href="https://github.com/awslabs/automating-governance-sample/tree/master/Bluegreen-AMI-Application-Deployment-blog/part2">part2 folder</a> of the Git repository and place the files directly into your local repository. Do not include the aws-codedeploy-sample-tomcat folder. Go to the local directory and type the following commands to commit and push the files to the CodeCommit repository:</p> 
<pre><code class="lang-git">git add .
git commit -a -m &quot;add all files from the AWS Java Tomcat CodeDeploy application&quot;
git push</code></pre> 
<p>After all the files are pushed successfully, the repository should look like this:</p> 
<p><img class="alignnone wp-image-1539" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/08/10/devsecops2_6.jpg" alt="" width="600" height="602" /></p> 
<p>&nbsp;</p> 
<p><strong><u>Part 3</u></strong>: <strong>Setting up CodePipeline to enable blue/green deployments</strong>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <a href="https://console.aws.amazon.com/cloudformation/home?region=us-east-1#/stacks/new?stackName=devsecopspart3&amp;templateURL=https://s3.amazonaws.com/devsecopsblog/blog_template_part3.json"><img class="alignnone size-full wp-image-1536" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/08/10/devsecops2_3.jpg" alt="" width="144" height="27" /></a></p> 
<p>Part 3 of the <a href="https://s3.amazonaws.com/devsecopsblog/blog_template_part3.json">AWS CloudFormation</a> template creates the pipeline in AWS CodePipeline and all the required components.</p> 
<p><img class="alignnone size-full wp-image-1540" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/08/10/devsecops2_7.jpg" alt="" width="185" height="705" /></p> 
<p>a) <strong>Source</strong>: The pipeline is triggered by any change to the CodeCommit repository.</p> 
<p>b) <strong>BuildGoldenAMI</strong>: This Lambda step executes the Systems Manager Automation document to build the golden AMI. After the golden AMI is successfully created, a new launch configuration with the new AMI details will be updated into the Auto Scaling group of the application deployment group. You can watch the progress of the automation in the EC2 console from the <strong>Systems Manager –&gt; Automations</strong> menu.</p> 
<p><img class="alignnone size-full wp-image-1541" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/08/10/devsecops2_8.jpg" alt="" width="762" height="648" /></p> 
<p>c) <strong>Build</strong>: This step uses the application <a href="http://docs.aws.amazon.com/codebuild/latest/userguide/build-spec-ref.html">build spec</a> file to build the application build artifact. Here are the CodeBuild execution steps and their status:</p> 
<p><img class="alignnone size-full wp-image-1542" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/08/10/devsecops2_9.jpg" alt="" width="689" height="494" /></p> 
<p>d) <strong>Deploy</strong>: This <a href="http://docs.aws.amazon.com/codedeploy/latest/userguide/deployment-groups-create-blue-green.html">step </a>clones the Auto Scaling group, launches the new instances with the new AMI, deploys the application changes, reroutes the traffic from the elastic load balancer to the new instances and terminates the old Auto Scaling group. You can see the execution steps and their status in the CodeDeploy console.</p> 
<p><img class="alignnone size-full wp-image-1543" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/08/10/devsecops2_10.jpg" alt="" width="1556" height="499" /></p> 
<p>After the CodePipeline execution is complete, you can access the application by clicking the Elastic Load Balancing link. You can find it in the output of Part 1 of the AWS CloudFormation template. Any consecutive commits to the application code in the CodeCommit repository trigger the pipelines and deploy the infrastructure and code with an updated AMI and code.</p> 
<p><img class="alignnone wp-image-1578 " src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/08/15/Screen-Shot-2017-08-15-at-1.01.37-PM-1024x102.png" alt="" width="900" height="90" /></p> 
<p>If you have feedback about this post, add it to the Comments section below. If you have questions about implementing the example used in this post, open a thread on the <a href="https://forums.aws.amazon.com/category.jspa?categoryID=21">Developer Tools forum</a>.</p> 
<hr /> 
<h3>About the author</h3> 
<p><strong><img class="alignleft wp-image-1260 size-thumbnail" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/08/10/ramesh_passport.png" alt="" width="200" height="200" /></strong></p> 
<p>&nbsp;</p> 
<p><strong>Ramesh Adabala</strong> is a Solutions Architect in Southeast Enterprise Solution Architecture team at Amazon Web Services.</p> 
</article> 
<article class="post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b><a href="https://aws.amazon.com/blogs/devops/build-serverless-aws-codecommit-workflows-using-amazon-cloudwatch-events-and-jgit/" property="url" rel="bookmark"><span property="name headline">Build Serverless AWS CodeCommit Workflows using Amazon CloudWatch Events and JGit</span></a></b> 
<footer class="meta">
by 
<span property="author" typeof="Person"><span property="name">Chris Barclay</span></span> | on 
<time property="datePublished" datetime="2017-08-03T13:25:33+00:00">03 AUG 2017</time> | in 
<span class="categories"><a href="https://aws.amazon.com/blogs/devops/category/developer-tools/aws-codecommit/" title="View all posts in AWS CodeCommit"><span property="articleSection">AWS CodeCommit</span></a></span> | 
<a href="https://aws.amazon.com/blogs/devops/build-serverless-aws-codecommit-workflows-using-amazon-cloudwatch-events-and-jgit/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog=""><span class="span icon-share"></span>&nbsp;Share</a> 
<ul> 
</ul> 
</footer> 
<p><img src="https://s3.amazonaws.com/chrisb/samdengler.jpeg" /> Sam Dengler is a Solutions Architect at Amazon Web Services</p> 
<b>Summary</b> 
<p><a href="http://docs.aws.amazon.com/AmazonCloudWatch/latest/events/WhatIsCloudWatchEvents.html">Amazon CloudWatch Events</a> now supports <a href="http://docs.aws.amazon.com/codecommit/latest/userguide/welcome.html">AWS CodeCommit</a> <a href="http://docs.aws.amazon.com/AmazonCloudWatch/latest/events/EventTypes.html#codecommit_event_type">Repository State Changes</a> event types for activities like pushing new code to a repository. Using these new event types, customers can build Amazon CloudWatch Event rules to match AWS CodeCommit events and route them to one or more targets like an Amazon SNS Topic, AWS Step Functions state machine, or AWS Lambda function to trigger automated workflows to process repository changes.</p> 
<p>In this blog, I will provide three examples for using AWS Lambda and JGit to build cost-effective serverless solutions to securely process AWS CodeCommit repository state changes:</p> 
<ul> 
<li>Replicate CodeCommit Repository</li> 
<li>Enforce Git Commit Message Policy</li> 
<li>Backup Git Archive to Amazon S3</li> 
</ul> 
<p>Source code and Amazon CloudFormation templates for the examples are located in the following GitHub repository: <a href="https://github.com/awslabs/serverless-codecommit-examples">https://github.com/awslabs/serverless-codecommit-examples</a>.</p> 
<b>AWS CodeCommit CloudWatch Events</b> 
<p>Amazon CloudWatch Events delivers a near real-time stream of system events that describe changes in AWS resources. Below is an example Amazon CloudWatch Event for one of the new AWS CodeCommit Repository State Changes event types, referenceUpdated. Any change to the repository will trigger a referenceUpdated event, however triggers for particular branches can be filtered using the referenceType and referenceName fields in the event details.</p> 
<pre><code class="lang-json">{
&quot;version&quot;: &quot;0&quot;,
&quot;id&quot;: &quot;01234567-0123-0123-0123-012345678901&quot;,
&quot;detail-type&quot;: &quot;CodeCommit Repository State Change&quot;,
&quot;source&quot;: &quot;aws.codecommit&quot;,
&quot;account&quot;: &quot;123456789012&quot;,
&quot;time&quot;: &quot;2017-06-12T10:23:43Z&quot;,
&quot;region&quot;: &quot;us-east-1&quot;,
&quot;resources&quot;: [
&quot;arn:aws:codecommit:us-east-1:123456789012:myRepo&quot;
],
&quot;detail&quot;: {
&quot;event&quot;: &quot;referenceUpdated&quot;,
&quot;repositoryName&quot;: &quot;myRepo&quot;,
&quot;referenceType&quot;: &quot;head&quot;,
&quot;referenceName&quot;: &quot;myBranch&quot;,
&quot;commitId&quot;: &quot;3e5983EXAMPLE&quot;,
&quot;oldCommitId&quot;: &quot;1a7813EXAMPLE&quot;
}
}</code></pre> 
<p>We will use the Amazon CloudWatch Event’s fields to create a pattern to match the events for which we will trigger a target, in this case an AWS Lambda function.</p> 
<b>Accessing AWS CodeCommit using HTTPS URLs</b> 
<p>The HTTPS URL method for accessing an AWS CodeCommit repository is particularly suited to a serverless solution because an Amazon Lambda execution container already provides temporary AWS IAM key credentials associated to the function’s AWS IAM Execution Role. The function’s Execution Role is associated to one or more AWS IAM Policies, in which you specify permissions allowing the function to access AWS resources. For each function, we will limit the AWS IAM polices to only the AWS CodeCommit repository, Amazon S3 bucket, or Amazon SNS topics, following the AWS best practice to <a href="http://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html#grant-least-privilege">grant least privileged access</a>.</p> 
<p>For example, the AWS IAM Policy snippet below restricts the Amazon Lambda function to pull from the source repository and push to the target repository.</p> 
<pre><code class="lang-yaml">Policies:
- Version: '2012-10-17'
&nbsp;   Statement:
&nbsp; &nbsp; &nbsp; - Effect: Allow
&nbsp; &nbsp; &nbsp; &nbsp; Resource: !Sub 'arn:aws:codecommit:${AWS::Region}:${AWS::AccountId}:${SourceRepositoryName}'
&nbsp; &nbsp; &nbsp; &nbsp; Action:
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; - 'codecommit:GetRepository'
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; - 'codecommit:GitPull'
&nbsp; &nbsp; &nbsp; - Effect: Allow
&nbsp; &nbsp; &nbsp; &nbsp; Resource: !Sub 'arn:aws:codecommit:${TargetRepositoryRegion}:${AWS::AccountId}:${TargetRepositoryName}'
&nbsp; &nbsp; &nbsp; &nbsp; Action:
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; - 'codecommit:GetRepository'
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; - 'codecommit:GitPush'</code></pre> 
<p>When using the HTTPS URL access method, a credential helper is configured for the Git client, which executes the “aws codecommit credential-helper” command to provide a SigV4 compatible user name and password using AWS IAM credentials (<a href="http://docs.aws.amazon.com/codecommit/latest/userguide/setting-up-https-unixes.html#setting-up-https-unixes-credential-helper">see more</a>). When using JGit as the Git client, a CredentialsProvider can be supplied to Git commands to achieve the same result.</p> 
<p>The Spring Cloud Config project provides an implementation of the JGit CredentialsProvider for AwsCodeCommit (<a href="https://github.com/spring-cloud/spring-cloud-config/blob/dd08a3bbf4f0ee0bbde0107f63677f180ac786cc/spring-cloud-config-server/src/main/java/org/springframework/cloud/config/server/support/AwsCodeCommitCredentialProvider.java">source</a>), which conveniently uses the AWS DefaultAWSCredentialsProviderChain to discover AWS credentials in the standard priority order supported by Amazon Lambda. The <a href="https://github.com/spring-cloud/spring-cloud-config/blob/dd08a3bbf4f0ee0bbde0107f63677f180ac786cc/spring-cloud-config-server/src/main/java/org/springframework/cloud/config/server/support/AwsCodeCommitCredentialProvider.java#L207">AwsCodeCommit.calculateCodeCommitPassword</a> method is particularly interesting to review as an example of SigV4 transformation logic.</p> 
<p>Cloning a repository is repeated across examples, and the functionality has been delegated to a supporting CloneCommandBuilder Class below.</p> 
<pre><code class="lang-java">public class CloneCommandBuilder {
&nbsp; &nbsp; private File directory;
&nbsp; &nbsp; public CloneCommandBuilder() throws IOException {
&nbsp; &nbsp; &nbsp; &nbsp; directory = Files.createTempDirectory(null).toFile();
&nbsp; &nbsp; }
&nbsp; &nbsp; public CloneCommand buildCloneCommand(String sourceUrl) {
&nbsp; &nbsp; &nbsp; &nbsp; return buildCloneCommand(sourceUrl, new AwsCodeCommitCredentialProvider());
&nbsp; &nbsp; }
&nbsp; &nbsp; public CloneCommand buildCloneCommand(String sourceUrl,
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; AwsCodeCommitCredentialProvider credentialsProvider) {
&nbsp; &nbsp; &nbsp; &nbsp; return new CloneCommand().setDirectory(directory)
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; .setURI(sourceUrl)
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; .setCredentialsProvider(credentialsProvider)
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; .setBare(true);
&nbsp; &nbsp; }
}</code></pre> 
<p>Next we’ll look at some examples to process the repository events using Amazon Lambda.</p> 
<b>Example 1: Replicate CodeCommit Repository</b> 
<p>Customers often need to replicate commits from one repository to another to support disaster recovery or cross region CI/CD pipelines. In this example, the Amazon Lambda function will clone a repository from the source and push to the target. This example is intended to update an existing target repository, which should not be empty before configuring replication prior to configuring replication.</p> 
<p>Please note, Amazon Lambda functions are limited to 1.5GB memory, 512MB ephemeral disk capacity (“/tmp” space), and a 5 minute execution time. If your repository is unable to be processed within these limits, please see the <a href="https://aws.amazon.com/blogs/devops/replicating-and-automating-sync-ups-for-a-repository-with-aws-codecommit/">Replicating and Automating Sync-Ups for a Repository with AWS CodeCommit</a> blog article for an alternative approach to replicate repositories using an Amazon EC2 instance.</p> 
<p>Let’s take a look at some code!</p> 
<pre><code class="lang-java">public class ReplicateRepositoryHandler
&nbsp; &nbsp; &nbsp; &nbsp; implements RequestHandler&lt;CodeCommitEvent, HandlerResponse&gt; {
&nbsp; &nbsp; private static Logger logger = Logger.getLogger(ReplicateRepositoryHandler.class);
&nbsp; &nbsp; private final String targetUrl;
&nbsp; &nbsp; private final AwsCodeCommitCredentialProvider credentialsProvider;
&nbsp; &nbsp; public ReplicateRepositoryHandler() {
&nbsp; &nbsp; &nbsp; &nbsp; String targetName = System.getenv(&quot;TARGET_REPO_NAME&quot;);
&nbsp; &nbsp; &nbsp; &nbsp; String targetRegion = System.getenv(&quot;TARGET_REPO_REGION&quot;);
&nbsp; &nbsp; &nbsp; &nbsp; CodeCommitMetadata target = new CodeCommitMetadata(targetName, targetRegion);
&nbsp; &nbsp; &nbsp; &nbsp; targetUrl = target.getCloneUrlHttp();
&nbsp; &nbsp; &nbsp; &nbsp; credentialsProvider = new AwsCodeCommitCredentialProvider();
&nbsp; &nbsp; }
// ...</code></pre> 
<p>On instantiation, the Amazon Lambda function discovers the target AWS CodeCommit repository HTTPS URL by querying the repository metadata using the target repository name and region. This discovery process is repeated across the examples, and the code has been delegated to the CodeCommitMetadata class below.</p> 
<pre><code class="lang-java">public class CodeCommitMetadata {
&nbsp; &nbsp; private RepositoryMetadata repositoryMetadata;
&nbsp; &nbsp; public CodeCommitMetadata(String repoName, String repoRegion) {
&nbsp; &nbsp; &nbsp; &nbsp; AWSCodeCommitClientBuilder builder = AWSCodeCommitClientBuilder.standard();
&nbsp; &nbsp; &nbsp; &nbsp; AWSCodeCommit client = builder.withRegion(repoRegion).build();
&nbsp; &nbsp; &nbsp; &nbsp; GetRepositoryRequest request = new GetRepositoryRequest();
&nbsp; &nbsp; &nbsp; &nbsp; request.withRepositoryName(repoName);
&nbsp; &nbsp; &nbsp; &nbsp; GetRepositoryResult result = client.getRepository(request);
&nbsp; &nbsp; &nbsp; &nbsp; repositoryMetadata = result.getRepositoryMetadata();
&nbsp; &nbsp; }
&nbsp; &nbsp; public String getCloneUrlHttp() {
&nbsp; &nbsp; &nbsp; &nbsp; return repositoryMetadata.getCloneUrlHttp();
&nbsp; &nbsp; }
}</code></pre> 
<p>When the Amazon Lambda function is triggered by the AWS CloudWatch Event, the source repository name and region in the event are used to discover the source repository HTTPS URL. We use JGit to clone the source repository from this URL into a local repository stored in a temporary directory in the Amazon Lambda execution container.</p> 
<pre><code class="lang-java">public HandlerResponse handleRequest(CodeCommitEvent event, Context context) {
&nbsp; &nbsp; try {
&nbsp; &nbsp; &nbsp; &nbsp; String sourceName = event.getDetail().getRepositoryName();
&nbsp; &nbsp; &nbsp; &nbsp; String sourceRegion = event.getRegion();
&nbsp; &nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; // clone source repository
&nbsp; &nbsp; &nbsp; &nbsp; CodeCommitMetadata source = new CodeCommitMetadata(sourceName, sourceRegion);
&nbsp; &nbsp; &nbsp; &nbsp; String sourceUrl = source.getCloneUrlHttp();
&nbsp; &nbsp; &nbsp; &nbsp; Git git = new CloneCommandBuilder().buildCloneCommand(sourceUrl).call();
// ...</code></pre> 
<p>Once we’ve cloned the local repository to the Amazon Lambda execution container, the last step is to set the target AWS CodeCommit repository as a new remote location and push the local references using the reference specification “+refs/*:refs/*”.</p> 
<pre><code class="lang-java">// push target repository
git.push().setCredentialsProvider(credentialsProvider)
&nbsp;  &nbsp; &nbsp;&nbsp; &nbsp; .setRemote(targetUrl)
&nbsp;&nbsp; &nbsp; &nbsp;&nbsp; &nbsp; .setRefSpecs(new RefSpec(&quot;+refs/*:refs/*&quot;))
&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp; .call();
// ...</code></pre> 
<p>In the next example, we’ll review how we can build a Lambda function to enforce commit message policies.</p> 
<b>Example 2: Enforce Git Commit Message Policy</b> 
<p>Some customers choose to enforce policies on a Git repository to maintain code quality. In this example, we use the same tools described above to clone a repository and validate the commit messages from the Git log using a regular expression.</p> 
<pre><code class="lang-java">public class PolicyEnforcerHandler implements RequestHandler&lt;CodeCommitEvent, HandlerResponse&gt; {
&nbsp; &nbsp; private static Logger logger = LoggerFactory.getLogger(ArchiveRepositoryHandler.class);
&nbsp; &nbsp; private final String mainBranch;
&nbsp; &nbsp; private final String snsTopicArn;
&nbsp; &nbsp; private final Pattern pattern;
&nbsp; &nbsp; private final AmazonSNS snsClient;
&nbsp; &nbsp; public PolicyEnforcerHandler() {
&nbsp; &nbsp; &nbsp; &nbsp; mainBranch = System.getenv(&quot;MAIN_BRANCH_NAME&quot;);
&nbsp; &nbsp; &nbsp; &nbsp; snsTopicArn = System.getenv(&quot;SNS_TOPIC_ARN&quot;);
&nbsp; &nbsp; &nbsp; &nbsp; String messageRegex = System.getenv(&quot;MESSAGE_REGEX&quot;);
&nbsp; &nbsp; &nbsp; &nbsp; pattern = Pattern.compile(messageRegex);
&nbsp; &nbsp; &nbsp; &nbsp; String snsRegion = snsTopicArn.split(&quot;:&quot;)[3];
&nbsp; &nbsp; &nbsp; &nbsp; snsClient = AmazonSNSClientBuilder.standard().withRegion(snsRegion).build();
&nbsp; &nbsp; }
// ...</code></pre> 
<p>On instantiation, the Amazon Lambda function compiles the regular expression for message validation and creates an Amazon SNS client to send notifications.</p> 
<pre><code class="lang-java">@Override
public HandlerResponse handleRequest(CodeCommitEvent event, Context context) {
&nbsp; &nbsp; String sourceName = event.getDetail().getRepositoryName();
&nbsp; &nbsp; String sourceRegion = event.getRegion();
&nbsp; &nbsp; String commitId = event.getDetail().getCommitId();
&nbsp; &nbsp; String oldCommitId = event.getDetail().getOldCommitId();
&nbsp; &nbsp; try {
&nbsp; &nbsp; &nbsp; &nbsp; // clone source repository
&nbsp; &nbsp; &nbsp; &nbsp; CodeCommitMetadata source = new CodeCommitMetadata(sourceName, sourceRegion);
&nbsp; &nbsp; &nbsp; &nbsp; String sourceUrl = source.getCloneUrlHttp();
&nbsp; &nbsp; &nbsp; &nbsp; Git git = new CloneCommandBuilder().buildCloneCommand(sourceUrl).call();
&nbsp; &nbsp; &nbsp; &nbsp; // ...</code></pre> 
<p>When the Amazon Lambda function is triggered by the AWS CloudWatch Event, the process to clone the repository is the same, discovering the AWS CodeCommit HTTPS URL from the AWS CloudWatch Event and cloning a bare Git repository to the Amazon Lambda execution container.</p> 
<pre><code class="lang-java">// use the OldCommitId, or default to the main branch
String toGitReference = Optional.ofNullable(oldCommitId).orElse(mainBranch);
Repository repository = git.getRepository();
ObjectId to = repository.resolve(toGitReference);
ObjectId from = repository.resolve(commitId);
// ...</code></pre> 
<p>JGit RevWalk is used to determine the range of commits over which to validate the message policy. When commits are added to an existing branch, AWS CodeCommit will emit an referenceUpdated event, which includes commitId and oldCommitId fields that establish the range of commits.</p> 
<p>When commits are added to a new branch, AWS CodeCommit will emit a referenceCreated event, which includes a commitId but not the oldCommitId. In this case, we will use the main branch name to determine the common ancestry of the commit chains, called the <a href="https://git-scm.com/docs/git-merge-base">merge base</a>, in order to establish the range of commits.</p> 
<pre><code class="lang-java">// create a RevWalk and set the range of commits
try (RevWalk walk = new RevWalk(repository)) {
&nbsp; &nbsp; walk.markStart(walk.parseCommit(from));
&nbsp; &nbsp; walk.markUninteresting(walk.parseCommit(to));
// iterate the list of commits and validate each message
&nbsp; &nbsp; for (RevCommit commit : walk) {
&nbsp; &nbsp;     Matcher matcher = pattern.matcher(commit.getShortMessage());
// publish a message to the topic if the message does not match
&nbsp; &nbsp; &nbsp; &nbsp; if (!matcher.find()) {
&nbsp; &nbsp; &nbsp; &nbsp;     String message = buildMessage(commit);
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; logger.info(message);
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; snsClient.publish(snsTopicArn, message);
&nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; }
&nbsp; &nbsp;walk.dispose();
}
// ...</code></pre> 
<p>Once the range has been established, we iterate the list of commit messages, testing each against the message policy regular expression. If the message does not match the regular expression, then it is out of compliance from the policy, and a message is published to the Amazon SNS topic for notification.</p> 
<p>In the next example, I’ll review how to backup an archive of the files in a Git repository.</p> 
<b>Example 3: Backup Git Archive to Amazon S3</b> 
<p>The previous examples have focused on the bare Git repository <a href="https://git-scm.com/book/en/v2/Git-Internals-Git-Objects">objects</a>, however there are some use cases for processing the files in the Git repository at a particular reference. In this example, I’ll build a Lambda function to create a zip of the files in the repository and store it in Amazon S3 as a backup.</p> 
<pre><code class="lang-java">public class ArchiveRepositoryHandler
&nbsp; &nbsp; &nbsp; &nbsp; implements RequestHandler&lt;CodeCommitEvent, HandlerResponse&gt; {
&nbsp; &nbsp; private static Logger logger = LoggerFactory.getLogger(ArchiveRepositoryHandler.class);
private final String ZIP_FORMAT = &quot;zip&quot;
&nbsp; &nbsp; private final String targetS3Bucket;
&nbsp; &nbsp; private final AmazonS3 s3Client;
&nbsp; &nbsp; public ArchiveRepositoryHandler() {
&nbsp; &nbsp; &nbsp; &nbsp; targetS3Bucket = System.getenv(&quot;TARGET_S3_BUCKET&quot;);
&nbsp; &nbsp; &nbsp; &nbsp; s3Client = AmazonS3ClientBuilder.defaultClient();
&nbsp; &nbsp; &nbsp; &nbsp; ArchiveCommand.registerFormat(ZIP_FORMAT, new ZipFormat());
&nbsp; &nbsp; }
// ...</code></pre> 
<p>On instantiation, the Amazon Lambda function creates an Amazon S3 client and registers the ZipFormat with JGit.</p> 
<pre><code class="lang-java">@Override
public HandlerResponse handleRequest(CodeCommitEvent event, Context context) {
&nbsp; &nbsp; String sourceName = event.getDetail().getRepositoryName();
&nbsp; &nbsp; String sourceRegion = event.getRegion();
&nbsp; &nbsp; String commitId = event.getDetail().getCommitId();
&nbsp; &nbsp; try {
&nbsp; &nbsp; &nbsp; &nbsp; // clone source repository
&nbsp; &nbsp; &nbsp; &nbsp; CodeCommitMetadata source = new CodeCommitMetadata(sourceName, sourceRegion);
&nbsp; &nbsp; &nbsp; &nbsp; String sourceUrl = source.getCloneUrlHttp();
&nbsp; &nbsp; &nbsp; &nbsp; Git git = new CloneCommandBuilder().buildCloneCommand(sourceUrl).call();
// ...</code></pre> 
<p>When the Amazon Lambda function is triggered by the AWS CloudWatch Event, the process to clone the repository is the same, discovering the AWS CodeCommit HTTPS URL from the AWS CloudWatch Event and cloning a bare Git repository to the Amazon Lambda execution container.</p> 
<pre><code class="lang-java">// create and upload archive for commitId
File file = Files.createTempFile(null, null).toFile();
try (OutputStream out = new FileOutputStream(file)) {
ObjectId objectId = git.getRepository().resolve(commitId);
git.archive().setTree(objectId)
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; .setFormat(ZIP_FORMAT)
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; .setOutputStream(out)
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; .call();
String key = sourceName + &quot;.&quot; + commitId + &quot;.&quot; + ZIP_FORMAT;
s3Client.putObject(targetS3Bucket, key, file);
}
// ...</code></pre> 
<p>Once the repository has been cloned, we use a JGit ArchiveCommand to create a zip artifact representing the working files of repository at the commit triggering the event. The generated zip artifact is then uploaded to Amazon S3 using the repository name and commit shortId as the key.</p> 
<b>Conclusion</b> 
<p>AWS CloudWatch Event’s support for AWS CodeCommit Repository State Changes event types opens possibilities to build event-driven source code workflow automation using the same AWS CloudWatch Events service that acts as an event bus across many AWS services. Combining this new capability with Amazon Lambda, the JGit client, and AWS IAM policy controls provides builders with a set of tools to build serverless solutions that securely access AWS resources, scale on demand, and are cost effective.</p> 
<p>In this blog, I’ve demonstrated three example solutions built using these tools, however AWS CodeCommit’s integration with AWS CloudWatch Events allows you to integrate with other AWS CloudWatch Events targets, like Amazon SQS or AWS Step Functions.</p> 
<p>I encourage you to visit the GitHub repository (<a href="https://github.com/awslabs/serverless-codecommit-examples">https://github.com/awslabs/serverless-codecommit-examples</a>), which has instructions to launch these examples in your own AWS account. Please share your ideas and questions in the comments below, or submit pull requests and issues to the GitHub repository!</p> 
</article> 
<article class="post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="b post-title" property="name headline">Create Multiple Builds from the Same Source Using Different AWS CodeBuild Build Specification Files</b> 
<footer class="meta">
by 
<span property="author" typeof="Person"><span property="name">Prakash Palanisamy</span></span> | on 
<time property="datePublished" datetime="2017-08-01T14:25:49+00:00">01 AUG 2017</time> | in 
<span class="categories"><a href="https://aws.amazon.com/blogs/devops/category/developer-tools/aws-codebuild/" title="View all posts in AWS CodeBuild"><span property="articleSection">AWS CodeBuild</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/developer-tools/" title="View all posts in Developer Tools"><span property="articleSection">Developer Tools</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/how-to/" title="View all posts in How-To"><span property="articleSection">How-To</span></a></span> | 
<a href="https://aws.amazon.com/blogs/devops/create-multiple-builds-from-the-same-source-using-different-aws-codebuild-build-specification-files/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog=""><span class="span icon-share"></span>&nbsp;Share</a> 
<ul> 
</ul> 
</footer> 
<p>In June 2017, <a href="https://forums.aws.amazon.com/ann.jspa?annID=4762" target="_blank" rel="noopener noreferrer">AWS CodeBuild announced</a> you can now specify an alternate build specification file name or location in an AWS CodeBuild project.</p> 
<p>In this post, I’ll show you how to use different build specification files in the same repository to create different builds. You’ll find the source code for this post in our&nbsp;<a href="https://github.com/awslabs/aws-codebuild-multiple-buildspec" target="_blank" rel="noopener noreferrer">GitHub repo</a>.</p> 
<h3>Requirements</h3> 
<p>The <a href="https://aws.amazon.com/cli/" target="_blank" rel="noopener noreferrer">AWS CLI</a> must be installed and configured.</p> 
<h3>Solution Overview</h3> 
<p>I have created a C program (cbsamplelib.c) that will be used to create a shared library and another utility program (cbsampleutil.c) to use that library. I’ll use a Makefile to compile these files.</p> 
<p>I need to put this sample application in RPM and DEB packages so end users can easily deploy them. I have created a build specification file for RPM. It will use make to compile this code and the RPM specification file (cbsample.rpmspec) configured in the build specification to create the RPM package. Similarly, I have created a build specification file for DEB. It will create the DEB package based on the control specification file (cbsample.control) configured in this build specification.</p> 
<p><span id="more-1464"></span></p> 
<h4>RPM Build Project:</h4> 
<p>The following build specification file (<a href="https://github.com/awslabs/aws-codebuild-multiple-buildspec/blob/master/buildspec-rpm.yml" target="_blank" rel="noopener noreferrer">buildspec-rpm.yml</a>) uses build specification version 0.2. As described in <a href="http://docs.aws.amazon.com/codebuild/latest/userguide/build-spec-ref.html#build-spec-ref-versions" target="_blank" rel="noopener noreferrer">the documentation</a>, this version has different syntax for environment variables. This build specification includes multiple phases:</p> 
<ul> 
<li>As part of the install phase, the required packages is installed using yum.</li> 
<li>During the pre_build phase, the required directories are created and the required files, including the RPM build specification file, are copied to the appropriate location.</li> 
<li>During the build phase, the code is compiled, and then the RPM package is created based on the RPM specification.</li> 
</ul> 
<p>As defined in the artifact section, the RPM file will be uploaded as a build artifact.</p> 
<pre><code class="lang-yaml">version: 0.2
env:
&nbsp; variables:
&nbsp; &nbsp; build_version: &quot;0.1&quot;
phases:
&nbsp; install:
&nbsp; &nbsp; commands:
&nbsp; &nbsp; &nbsp; - yum install rpm-build make gcc glibc -y
&nbsp; pre_build:
&nbsp; &nbsp; commands:
&nbsp; &nbsp; &nbsp; - curr_working_dir=`pwd`
&nbsp; &nbsp; &nbsp; - mkdir -p ./{RPMS,SRPMS,BUILD,SOURCES,SPECS,tmp}
&nbsp; &nbsp; &nbsp; - filename=&quot;cbsample-$build_version&quot;
&nbsp; &nbsp; &nbsp; - echo $filename
&nbsp; &nbsp; &nbsp; - mkdir -p $filename
&nbsp; &nbsp; &nbsp; - cp ./*.c ./*.h Makefile $filename
&nbsp; &nbsp; &nbsp; - tar -zcvf /root/$filename.tar.gz $filename
&nbsp; &nbsp; &nbsp; - cp /root/$filename.tar.gz ./SOURCES/
&nbsp; &nbsp; &nbsp; - cp cbsample.rpmspec ./SPECS/
&nbsp; build:
&nbsp; &nbsp; commands:
&nbsp; &nbsp; &nbsp; - echo &quot;Triggering RPM build&quot;
&nbsp; &nbsp; &nbsp; - rpmbuild --define &quot;_topdir `pwd`&quot; -ba SPECS/cbsample.rpmspec
&nbsp; &nbsp; &nbsp; - cd $curr_working_dir
artifacts:
&nbsp; files:
&nbsp; &nbsp; - RPMS/x86_64/cbsample*.rpm
&nbsp; discard-paths: yes
</code></pre> 
<p>Using cb-centos-project.json as a reference, create the input JSON file for the CLI command. This project uses an AWS CodeCommit repository named codebuild-multispec and a file named buildspec-rpm.yml as the build specification file. To create the RPM package, we need to specify a custom image name. I’m using the latest CentOS 7 image available in the Docker Hub. I’m using a role named CodeBuildServiceRole. It contains permissions similar to those defined in CodeBuildServiceRole.json. (You need to change the resource fields in the policy, as appropriate.)</p> 
<pre><code class="lang-json">{
&nbsp; &nbsp; &quot;name&quot;: &quot;rpm-build-project&quot;,
&nbsp; &nbsp; &quot;description&quot;: &quot;Project which will build RPM from the source.&quot;,
&nbsp; &nbsp; &quot;source&quot;: {
&nbsp; &nbsp; &nbsp; &nbsp; &quot;type&quot;: &quot;CODECOMMIT&quot;,
&nbsp; &nbsp; &nbsp; &nbsp; &quot;location&quot;: &quot;https://git-codecommit.eu-west-1.amazonaws.com/v1/repos/codebuild-multispec&quot;,
&nbsp; &nbsp; &nbsp; &nbsp; &quot;buildspec&quot;: &quot;buildspec-rpm.yml&quot;
&nbsp; &nbsp; },
&nbsp; &nbsp; &quot;artifacts&quot;: {
&nbsp; &nbsp; &nbsp; &nbsp; &quot;type&quot;: &quot;S3&quot;,
&nbsp; &nbsp; &nbsp; &nbsp; &quot;location&quot;: &quot;codebuild-demo-artifact-repository&quot;
&nbsp; &nbsp; },
&nbsp; &nbsp; &quot;environment&quot;: {
&nbsp; &nbsp; &nbsp; &nbsp; &quot;type&quot;: &quot;LINUX_CONTAINER&quot;,
&nbsp; &nbsp; &nbsp; &nbsp; &quot;image&quot;: &quot;centos:7&quot;,
&nbsp; &nbsp; &nbsp; &nbsp; &quot;computeType&quot;: &quot;BUILD_GENERAL1_SMALL&quot;
&nbsp; &nbsp; },
&nbsp; &nbsp; &quot;serviceRole&quot;: &quot;arn:aws:iam::012345678912:role/service-role/CodeBuildServiceRole&quot;,
&nbsp; &nbsp; &quot;timeoutInMinutes&quot;: 15,
&nbsp; &nbsp; &quot;encryptionKey&quot;: &quot;arn:aws:kms:eu-west-1:012345678912:alias/aws/s3&quot;,
&nbsp; &nbsp; &quot;tags&quot;: [
&nbsp; &nbsp; &nbsp; &nbsp; {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;key&quot;: &quot;Name&quot;,
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;value&quot;: &quot;RPM Demo Build&quot;
&nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; ]
}
</code></pre> 
<p>After the <code class="lang-bash">cli-input-json</code> file is ready, execute the following command to create the build project.</p> 
<pre><code class="lang-json">$ aws codebuild create-project --name CodeBuild-RPM-Demo --cli-input-json file://cb-centos-project.json
{
&quot;project&quot;: {
&quot;name&quot;: &quot;CodeBuild-RPM-Demo&quot;, 
&quot;serviceRole&quot;: &quot;arn:aws:iam::012345678912:role/service-role/CodeBuildServiceRole&quot;, 
&quot;tags&quot;: [
{
&quot;value&quot;: &quot;RPM Demo Build&quot;, 
&quot;key&quot;: &quot;Name&quot;
}
], 
&quot;artifacts&quot;: {
&quot;namespaceType&quot;: &quot;NONE&quot;, 
&quot;packaging&quot;: &quot;NONE&quot;, 
&quot;type&quot;: &quot;S3&quot;, 
&quot;location&quot;: &quot;codebuild-demo-artifact-repository&quot;, 
&quot;name&quot;: &quot;CodeBuild-RPM-Demo&quot;
}, 
&quot;lastModified&quot;: 1500559811.13, 
&quot;timeoutInMinutes&quot;: 15, 
&quot;created&quot;: 1500559811.13, 
&quot;environment&quot;: {
&quot;computeType&quot;: &quot;BUILD_GENERAL1_SMALL&quot;, 
&quot;privilegedMode&quot;: false, 
&quot;image&quot;: &quot;centos:7&quot;, 
&quot;type&quot;: &quot;LINUX_CONTAINER&quot;, 
&quot;environmentVariables&quot;: []
}, 
&quot;source&quot;: {
&quot;buildspec&quot;: &quot;buildspec-rpm.yml&quot;, 
&quot;type&quot;: &quot;CODECOMMIT&quot;, 
&quot;location&quot;: &quot;https://git-codecommit.eu-west-1.amazonaws.com/v1/repos/codebuild-multispec&quot;
}, 
&quot;encryptionKey&quot;: &quot;arn:aws:kms:eu-west-1:012345678912:alias/aws/s3&quot;, 
&quot;arn&quot;: &quot;arn:aws:codebuild:eu-west-1:012345678912:project/CodeBuild-RPM-Demo&quot;, 
&quot;description&quot;: &quot;Project which will build RPM from the source.&quot;
}
}</code></pre> 
<p>When the project is created, run the following command to start the build. After the build has started, get the build ID. You can use the build ID to get the status of the build.</p> 
<pre><code class="lang-json">$ aws codebuild start-build --project-name CodeBuild-RPM-Demo
{
&nbsp; &nbsp; &quot;build&quot;: {
&nbsp; &nbsp; &nbsp; &nbsp; &quot;buildComplete&quot;: false,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &quot;initiator&quot;: &quot;prakash&quot;,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &quot;artifacts&quot;: {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;location&quot;: &quot;arn:aws:s3:::codebuild-demo-artifact-repository/CodeBuild-RPM-Demo&quot;
&nbsp; &nbsp; &nbsp; &nbsp; },&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &quot;projectName&quot;: &quot;CodeBuild-RPM-Demo&quot;,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &quot;timeoutInMinutes&quot;: 15,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &quot;buildStatus&quot;: &quot;IN_PROGRESS&quot;,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &quot;environment&quot;: {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;computeType&quot;: &quot;BUILD_GENERAL1_SMALL&quot;,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;privilegedMode&quot;: false,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;image&quot;: &quot;centos:7&quot;,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;type&quot;: &quot;LINUX_CONTAINER&quot;,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;environmentVariables&quot;: []
&nbsp; &nbsp; &nbsp; &nbsp; },&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &quot;source&quot;: {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;buildspec&quot;: &quot;buildspec-rpm.yml&quot;,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;type&quot;: &quot;CODECOMMIT&quot;,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;location&quot;: &quot;https://git-codecommit.eu-west-1.amazonaws.com/v1/repos/codebuild-multispec&quot;
&nbsp; &nbsp; &nbsp; &nbsp; },&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &quot;currentPhase&quot;: &quot;SUBMITTED&quot;,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &quot;startTime&quot;: 1500560156.761,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &quot;id&quot;: &quot;CodeBuild-RPM-Demo:57a36755-4d37-4b08-9c11-1468e1682abc&quot;,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &quot;arn&quot;: &quot;arn:aws:codebuild:eu-west-1: 012345678912:build/CodeBuild-RPM-Demo:57a36755-4d37-4b08-9c11-1468e1682abc&quot;
&nbsp; &nbsp; }
}
$ aws codebuild list-builds-for-project --project-name CodeBuild-RPM-Demo
{
&nbsp; &nbsp; &quot;ids&quot;: [
&nbsp; &nbsp; &nbsp; &nbsp; &quot;CodeBuild-RPM-Demo:57a36755-4d37-4b08-9c11-1468e1682abc&quot;
&nbsp; &nbsp; ]
}
$ aws codebuild batch-get-builds --ids CodeBuild-RPM-Demo:57a36755-4d37-4b08-9c11-1468e1682abc
{
&nbsp; &nbsp; &quot;buildsNotFound&quot;: [],&nbsp;
&nbsp; &nbsp; &quot;builds&quot;: [
&nbsp; &nbsp; &nbsp; &nbsp; {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;buildComplete&quot;: true,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;phases&quot;: [
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;phaseStatus&quot;: &quot;SUCCEEDED&quot;,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;endTime&quot;: 1500560157.164,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;phaseType&quot;: &quot;SUBMITTED&quot;,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;durationInSeconds&quot;: 0,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;startTime&quot;: 1500560156.761
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; },&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;contexts&quot;: [],&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;phaseType&quot;: &quot;PROVISIONING&quot;,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;phaseStatus&quot;: &quot;SUCCEEDED&quot;,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;durationInSeconds&quot;: 24,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;startTime&quot;: 1500560157.164,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;endTime&quot;: 1500560182.066
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; },&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;contexts&quot;: [],&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;phaseType&quot;: &quot;DOWNLOAD_SOURCE&quot;,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;phaseStatus&quot;: &quot;SUCCEEDED&quot;,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;durationInSeconds&quot;: 15,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;startTime&quot;: 1500560182.066,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;endTime&quot;: 1500560197.906
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; },&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;contexts&quot;: [],&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;phaseType&quot;: &quot;INSTALL&quot;,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;phaseStatus&quot;: &quot;SUCCEEDED&quot;,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;durationInSeconds&quot;: 19,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;startTime&quot;: 1500560197.906,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;endTime&quot;: 1500560217.515
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; },&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;contexts&quot;: [],&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;phaseType&quot;: &quot;PRE_BUILD&quot;,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;phaseStatus&quot;: &quot;SUCCEEDED&quot;,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;durationInSeconds&quot;: 0,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;startTime&quot;: 1500560217.515,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;endTime&quot;: 1500560217.662
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; },&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;contexts&quot;: [],&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;phaseType&quot;: &quot;BUILD&quot;,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;phaseStatus&quot;: &quot;SUCCEEDED&quot;,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;durationInSeconds&quot;: 0,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;startTime&quot;: 1500560217.662,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;endTime&quot;: 1500560217.995
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; },&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;contexts&quot;: [],&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;phaseType&quot;: &quot;POST_BUILD&quot;,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;phaseStatus&quot;: &quot;SUCCEEDED&quot;,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;durationInSeconds&quot;: 0,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;startTime&quot;: 1500560217.995,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;endTime&quot;: 1500560218.074
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; },&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;contexts&quot;: [],&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;phaseType&quot;: &quot;UPLOAD_ARTIFACTS&quot;,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;phaseStatus&quot;: &quot;SUCCEEDED&quot;,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;durationInSeconds&quot;: 0,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;startTime&quot;: 1500560218.074,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;endTime&quot;: 1500560218.542
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; },&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;contexts&quot;: [],&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;phaseType&quot;: &quot;FINALIZING&quot;,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;phaseStatus&quot;: &quot;SUCCEEDED&quot;,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;durationInSeconds&quot;: 4,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;startTime&quot;: 1500560218.542,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;endTime&quot;: 1500560223.128
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; },&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;phaseType&quot;: &quot;COMPLETED&quot;,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;startTime&quot;: 1500560223.128
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ],&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;logs&quot;: {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;groupName&quot;: &quot;/aws/codebuild/CodeBuild-RPM-Demo&quot;,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;deepLink&quot;: &quot;https://console.aws.amazon.com/cloudwatch/home?region=eu-west-1#logEvent:group=/aws/codebuild/CodeBuild-RPM-Demo;stream=57a36755-4d37-4b08-9c11-1468e1682abc&quot;,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;streamName&quot;: &quot;57a36755-4d37-4b08-9c11-1468e1682abc&quot;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; },&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;artifacts&quot;: {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;location&quot;: &quot;arn:aws:s3:::codebuild-demo-artifact-repository/CodeBuild-RPM-Demo&quot;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; },&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;projectName&quot;: &quot;CodeBuild-RPM-Demo&quot;,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;timeoutInMinutes&quot;: 15,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;initiator&quot;: &quot;prakash&quot;,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;buildStatus&quot;: &quot;SUCCEEDED&quot;,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;environment&quot;: {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;computeType&quot;: &quot;BUILD_GENERAL1_SMALL&quot;,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;privilegedMode&quot;: false,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;image&quot;: &quot;centos:7&quot;,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;type&quot;: &quot;LINUX_CONTAINER&quot;,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;environmentVariables&quot;: []
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; },&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;source&quot;: {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;buildspec&quot;: &quot;buildspec-rpm.yml&quot;,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;type&quot;: &quot;CODECOMMIT&quot;,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;location&quot;: &quot;https://git-codecommit.eu-west-1.amazonaws.com/v1/repos/codebuild-multispec&quot;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; },&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;currentPhase&quot;: &quot;COMPLETED&quot;,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;startTime&quot;: 1500560156.761,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;endTime&quot;: 1500560223.128,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;id&quot;: &quot;CodeBuild-RPM-Demo:57a36755-4d37-4b08-9c11-1468e1682abc&quot;,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;arn&quot;: &quot;arn:aws:codebuild:eu-west-1:012345678912:build/CodeBuild-RPM-Demo:57a36755-4d37-4b08-9c11-1468e1682abc&quot;
&nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; ]
}</code></pre> 
<h4>DEB Build Project:</h4> 
<p>In this project, we will use the build specification file named <a href="https://github.com/awslabs/aws-codebuild-multiple-buildspec/blob/master/buildspec-deb.yml" target="_blank" rel="noopener noreferrer">buildspec-deb.yml</a>. Like the RPM build project, this specification includes multiple phases. Here I use a Debian control file to create the package in DEB format. After a successful build, the DEB package will be uploaded as build artifact.</p> 
<pre><code class="lang-yaml">version: 0.2
env:
&nbsp; variables:
&nbsp; &nbsp; build_version: &quot;0.1&quot;
phases:
&nbsp; install:
&nbsp; &nbsp; commands:
&nbsp; &nbsp; &nbsp; - apt-get install gcc make -y
&nbsp; pre_build:
&nbsp; &nbsp; commands:
&nbsp; &nbsp; &nbsp; - mkdir -p ./cbsample-$build_version/DEBIAN
&nbsp; &nbsp; &nbsp; - mkdir -p ./cbsample-$build_version/usr/lib
&nbsp; &nbsp; &nbsp; - mkdir -p ./cbsample-$build_version/usr/include
&nbsp; &nbsp; &nbsp; - mkdir -p ./cbsample-$build_version/usr/bin
&nbsp; &nbsp; &nbsp; - cp -f cbsample.control ./cbsample-$build_version/DEBIAN/control
&nbsp; build:
&nbsp; &nbsp; commands:
&nbsp; &nbsp; &nbsp; - echo &quot;Building the application&quot;
&nbsp; &nbsp; &nbsp; - make
&nbsp; &nbsp; &nbsp; - cp libcbsamplelib.so ./cbsample-$build_version/usr/lib
&nbsp; &nbsp; &nbsp; - cp cbsamplelib.h ./cbsample-$build_version/usr/include
&nbsp; &nbsp; &nbsp; - cp cbsampleutil ./cbsample-$build_version/usr/bin
&nbsp; &nbsp; &nbsp; - chmod +x ./cbsample-$build_version/usr/bin/cbsampleutil
&nbsp; &nbsp; &nbsp; - dpkg-deb --build ./cbsample-$build_version
artifacts:
&nbsp; files:
&nbsp; &nbsp; - cbsample-*.deb</code></pre> 
<p>Here we use cb-ubuntu-project.json as a reference to create the CLI input JSON file. This project uses the same AWS CodeCommit repository (codebuild-multispec) but a different buildspec file in the same repository (buildspec-deb.yml). We use the default CodeBuild image to create the DEB package. We use the same IAM role (CodeBuildServiceRole).</p> 
<pre><code class="lang-json">{
&nbsp; &nbsp; &quot;name&quot;: &quot;deb-build-project&quot;,
&nbsp; &nbsp; &quot;description&quot;: &quot;Project which will build DEB from the source.&quot;,
&nbsp; &nbsp; &quot;source&quot;: {
&nbsp; &nbsp; &nbsp; &nbsp; &quot;type&quot;: &quot;CODECOMMIT&quot;,
&nbsp; &nbsp; &nbsp; &nbsp; &quot;location&quot;: &quot;https://git-codecommit.eu-west-1.amazonaws.com/v1/repos/codebuild-multispec&quot;,
&nbsp; &nbsp; &nbsp; &nbsp; &quot;buildspec&quot;: &quot;buildspec-deb.yml&quot;
&nbsp; &nbsp; },
&nbsp; &nbsp; &quot;artifacts&quot;: {
&nbsp; &nbsp; &nbsp; &nbsp; &quot;type&quot;: &quot;S3&quot;,
&nbsp; &nbsp; &nbsp; &nbsp; &quot;location&quot;: &quot;codebuild-demo-artifact-repository&quot;
&nbsp; &nbsp; },
&nbsp; &nbsp; &quot;environment&quot;: {
&nbsp; &nbsp; &nbsp; &nbsp; &quot;type&quot;: &quot;LINUX_CONTAINER&quot;,
&nbsp; &nbsp; &nbsp; &nbsp; &quot;image&quot;: &quot;aws/codebuild/ubuntu-base:14.04&quot;,
&nbsp; &nbsp; &nbsp; &nbsp; &quot;computeType&quot;: &quot;BUILD_GENERAL1_SMALL&quot;
&nbsp; &nbsp; },
&nbsp; &nbsp; &quot;serviceRole&quot;: &quot;arn:aws:iam::012345678912:role/service-role/CodeBuildServiceRole&quot;,
&nbsp; &nbsp; &quot;timeoutInMinutes&quot;: 15,
&nbsp; &nbsp; &quot;encryptionKey&quot;: &quot;arn:aws:kms:eu-west-1:012345678912:alias/aws/s3&quot;,
&nbsp; &nbsp; &quot;tags&quot;: [
&nbsp; &nbsp; &nbsp; &nbsp; {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;key&quot;: &quot;Name&quot;,
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;value&quot;: &quot;Debian Demo Build&quot;
&nbsp; &nbsp; &nbsp; &nbsp; }
&nbsp; &nbsp; ]
}</code></pre> 
<p>Using the CLI input JSON file, create the project, start the build, and check the status of the project.</p> 
<pre><code class="lang-bash">$ aws codebuild create-project --name CodeBuild-DEB-Demo --cli-input-json file://cb-ubuntu-project.json
$ aws codebuild list-builds-for-project --project-name CodeBuild-DEB-Demo
$ aws codebuild batch-get-builds --ids CodeBuild-DEB-Demo:e535c4b0-7067-4fbe-8060-9bb9de203789</code></pre> 
<p>After successful completion of the RPM and DEB builds, check the S3 bucket configured in the artifacts section for the build packages. Build projects will create a directory in the name of the build project and copy the artifacts inside it.</p> 
<pre><code class="lang-bash">$ aws s3 ls s3://codebuild-demo-artifact-repository/CodeBuild-RPM-Demo/
2017-07-20 16:16:59 &nbsp; &nbsp; &nbsp; 8108 cbsample-0.1-1.el7.centos.x86_64.rpm
$ aws s3 ls s3://codebuild-demo-artifact-repository/CodeBuild-DEB-Demo/
2017-07-20 16:37:22 &nbsp; &nbsp; &nbsp; 5420 cbsample-0.1.deb</code></pre> 
<h4>Override Buildspec During Build Start:</h4> 
<p>It’s also possible to override the build specification file of an existing project when starting a build. If we want to create the libs RPM package instead of the whole RPM, we will use the build specification file named <a href="https://github.com/awslabs/aws-codebuild-multiple-buildspec/blob/master/buildspec-libs-rpm.yml" target="_blank" rel="noopener noreferrer">buildspec-libs-rpm.yml</a>. This build specification file is similar to the earlier RPM build. The only difference is that it uses a different RPM specification file to create libs RPM.</p> 
<pre><code class="lang-yaml">version: 0.2
env:
&nbsp; variables:
&nbsp; &nbsp; build_version: &quot;0.1&quot;
phases:
&nbsp; install:
&nbsp; &nbsp; commands:
&nbsp; &nbsp; &nbsp; - yum install rpm-build make gcc glibc -y
&nbsp; pre_build:
&nbsp; &nbsp; commands:
&nbsp; &nbsp; &nbsp; - curr_working_dir=`pwd`
&nbsp; &nbsp; &nbsp; - mkdir -p ./{RPMS,SRPMS,BUILD,SOURCES,SPECS,tmp}
&nbsp; &nbsp; &nbsp; - filename=&quot;cbsample-libs-$build_version&quot;
&nbsp; &nbsp; &nbsp; - echo $filename
&nbsp; &nbsp; &nbsp; - mkdir -p $filename
&nbsp; &nbsp; &nbsp; - cp ./*.c ./*.h Makefile $filename
&nbsp; &nbsp; &nbsp; - tar -zcvf /root/$filename.tar.gz $filename
&nbsp; &nbsp; &nbsp; - cp /root/$filename.tar.gz ./SOURCES/
&nbsp; &nbsp; &nbsp; - cp cbsample-libs.rpmspec ./SPECS/
&nbsp; build:
&nbsp; &nbsp; commands:
&nbsp; &nbsp; &nbsp; - echo &quot;Triggering RPM build&quot;
&nbsp; &nbsp; &nbsp; - rpmbuild --define &quot;_topdir `pwd`&quot; -ba SPECS/cbsample-libs.rpmspec
&nbsp; &nbsp; &nbsp; - cd $curr_working_dir
artifacts:
&nbsp; files:
&nbsp; &nbsp; - RPMS/x86_64/cbsample-libs*.rpm
&nbsp; discard-paths: yes</code></pre> 
<p>Using the same RPM build project that we created earlier, start a new build and set the value of the `–buildspec-override` parameter to buildspec-libs-rpm.yml .</p> 
<pre><code class="lang-json">$ aws codebuild start-build --project-name CodeBuild-RPM-Demo --buildspec-override buildspec-libs-rpm.yml
{
&nbsp; &nbsp; &quot;build&quot;: {
&nbsp; &nbsp; &nbsp; &nbsp; &quot;buildComplete&quot;: false,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &quot;initiator&quot;: &quot;prakash&quot;,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &quot;artifacts&quot;: {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;location&quot;: &quot;arn:aws:s3:::codebuild-demo-artifact-repository/CodeBuild-RPM-Demo&quot;
&nbsp; &nbsp; &nbsp; &nbsp; },&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &quot;projectName&quot;: &quot;CodeBuild-RPM-Demo&quot;,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &quot;timeoutInMinutes&quot;: 15,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &quot;buildStatus&quot;: &quot;IN_PROGRESS&quot;,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &quot;environment&quot;: {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;computeType&quot;: &quot;BUILD_GENERAL1_SMALL&quot;,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;privilegedMode&quot;: false,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;image&quot;: &quot;centos:7&quot;,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;type&quot;: &quot;LINUX_CONTAINER&quot;,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;environmentVariables&quot;: []
&nbsp; &nbsp; &nbsp; &nbsp; },&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &quot;source&quot;: {
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;buildspec&quot;: &quot;buildspec-libs-rpm.yml&quot;,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;type&quot;: &quot;CODECOMMIT&quot;,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &quot;location&quot;: &quot;https://git-codecommit.eu-west-1.amazonaws.com/v1/repos/codebuild-multispec&quot;
&nbsp; &nbsp; &nbsp; &nbsp; },&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &quot;currentPhase&quot;: &quot;SUBMITTED&quot;,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &quot;startTime&quot;: 1500562366.239,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &quot;id&quot;: &quot;CodeBuild-RPM-Demo:82d05f8a-b161-401c-82f0-83cb41eba567&quot;,&nbsp;
&nbsp; &nbsp; &nbsp; &nbsp; &quot;arn&quot;: &quot;arn:aws:codebuild:eu-west-1:012345678912:build/CodeBuild-RPM-Demo:82d05f8a-b161-401c-82f0-83cb41eba567&quot;
&nbsp; &nbsp; }
}</code></pre> 
<p>After the build is completed successfully, check to see if the package appears in the artifact S3 bucket under the CodeBuild-RPM-Demo build project folder.</p> 
<pre><code class="lang-bash">$ aws s3 ls s3://codebuild-demo-artifact-repository/CodeBuild-RPM-Demo/
2017-07-20 16:16:59 &nbsp; &nbsp; &nbsp; 8108 cbsample-0.1-1.el7.centos.x86_64.rpm
2017-07-20 16:53:54 &nbsp; &nbsp; &nbsp; 5320 cbsample-libs-0.1-1.el7.centos.x86_64.rpm</code></pre> 
<h3>Conclusion</h3> 
<p>In this post, I have shown you how multiple buildspec files in the same source repository can be used to run multiple AWS CodeBuild build projects. I have also shown you how to provide a different buildspec file when starting the build.</p> 
<p>For more information about AWS CodeBuild, see the&nbsp;<a href="https://aws.amazon.com/documentation/codebuild/" target="_blank" rel="noopener noreferrer">AWS CodeBuild documentation</a>. You can&nbsp;get started&nbsp;with AWS CodeBuild by using <a href="http://docs.aws.amazon.com/codebuild/latest/userguide/getting-started.html" target="_blank" rel="noopener noreferrer">this step by step guide</a>.</p> 
<hr /> 
<h3>About the author</h3> 
<p><strong><img class="alignleft wp-image-1260 size-thumbnail" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/06/07/PP1-150x150.jpg" alt="" width="150" height="150" />Prakash Palanisamy</strong> is a Solutions Architect for Amazon Web Services. When he is not working on Serverless, DevOps or Alexa, he will be solving problems in Project Euler. He also enjoys watching educational documentaries.</p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/devops/tag/aws-codebuild/" rel="tag">AWS CodeBuild</a>, <a href="https://aws.amazon.com/blogs/devops/tag/codebuild/" rel="tag">codebuild</a></span> 
</footer> 
</article> 
<article class="post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="b post-title" property="name headline">Validating AWS CloudFormation Templates</b> 
<footer class="meta">
by 
<span property="author" typeof="Person"><span property="name">Remek Hetman</span></span> | on 
<time property="datePublished" datetime="2017-06-28T10:49:09+00:00">28 JUN 2017</time> | in 
<span class="categories"><a href="https://aws.amazon.com/blogs/devops/category/how-to/" title="View all posts in How-To"><span property="articleSection">How-To</span></a></span> | 
<a href="https://aws.amazon.com/blogs/devops/validating-aws-cloudformation-templates/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog=""><span class="span icon-share"></span>&nbsp;Share</a> 
<ul> 
</ul> 
</footer> 
<p>For their continuous integration and continuous deployment (CI/CD) pipeline path, many companies use tools like Jenkins, Chef, and <a href="https://aws.amazon.com/cloudformation">AWS CloudFormation</a>. Usually, the process is managed by two or more teams. One team is responsible for designing and developing an application, CloudFormation templates, and so on. The other team is generally responsible for integration and deployment.</p> 
<p>One of the challenges that a CI/CD team has is to validate the CloudFormation templates provided by the development team. Validation provides early warning about any incorrect syntax and ensures that the development team follows company policies in terms of security and the resources created by CloudFormation templates.</p> 
<p>In this post, I focus on the validation of <a href="https://aws.amazon.com/cloudformation">AWS CloudFormation</a> templates for syntax as well as in the context of business rules.</p> 
<p><span id="more-1318"></span></p> 
<h3>Scripted validation solution</h3> 
<p>For CloudFormation syntax validation, one option is to use the <a href="https://aws.amazon.com/cli">AWS CLI </a>to call the <a href="http://docs.aws.amazon.com/cli/latest/reference/cloudformation/validate-template.html">validate-template command</a>. For security and resource management, another approach is to run a Jenkins pipeline from an Amazon EC2 instance under an EC2 role that has been granted only the necessary permissions.</p> 
<p>What if you need more control over your CloudFormation templates, such as managing parameters or attributes? What if you have many development teams where permissions to the AWS environment required by one team are either too open or not open enough for another team?</p> 
<p>To have more control over the contents of your CloudFormation template, you can use the <a href="https://github.com/awslabs/aws-cloudformation-validator">cf-validator</a> Python script, which shows you how to validate different template aspects. With this script, you can validate:</p> 
<ul> 
<li>JSON syntax</li> 
<li>IAM capabilities</li> 
<li>Root tags</li> 
<li>Parameters</li> 
<li>CloudFormation resources</li> 
<li>Attributes</li> 
<li>Reference resources</li> 
</ul> 
<p>You can download this script from the <a href="https://github.com/awslabs/aws-cloudformation-validator">cf-validator</a> GitHub repo. Use the following command to run the script:</p> 
<pre>python cf-validator.py</pre> 
<p>The script takes the following parameters:</p> 
<ul> 
<li><strong>–cf_path [Required]</strong><br /> 
<blockquote> 
<p>The location of the CloudFormation template in JSON format. Supported location types:</p> 
<ul> 
<li>File system – Path to the CloudFormation template on the file system</li> 
<li>Web – URL, for example, https://my-file.com/my_cf.json</li> 
<li>Amazon S3 – Amazon S3 bucket, for example, s3://my_bucket/my_cf.json</li> 
</ul> 
</blockquote> </li> 
<li><strong>–cf_rules [Required]</strong><br /> 
<blockquote> 
<p>The location of the JSON file with the validation rules. This parameter supports the same locations as –cf_path. The next section of this post has more information about defining rules.</p> 
</blockquote> </li> 
<li><strong>–cf_res [Optional]</strong><br /> 
<blockquote> 
<p>The location of the JSON file with the defined AWS resources, which need to be confirmed before launching the CloudFormation template. A later section of this post has more information about resource validation.</p> 
</blockquote> </li> 
<li><strong>–allow_cap [Optional][yes/no]</strong><br /> 
<blockquote> 
<p>Controls whether you allow the creation of IAM resources by the CloudFormation template, such as policies, rules, or IAM users. The default value is no.</p> 
</blockquote> </li> 
<li><strong>–region [Optional]</strong><br /> 
<blockquote> 
<p>The AWS region where the existing resources were created. The default value is us-east-1.</p> 
</blockquote> </li> 
</ul> 
<h5>Defining rules</h5> 
<p>All rules are defined in the JSON format file. Rules consist of the following keys:</p> 
<ul> 
<li><strong>“allow_root_keys”</strong><br /> 
<blockquote> 
<p>Lists allowed root CloudFormation keys. Example of root keys are Parameters, Resources, Output, and so on. An empty list means that any key is allowed.</p> 
</blockquote> </li> 
<li><strong>“allow_parameters”</strong><br /> 
<blockquote> 
<p>Lists allowed CloudFormation parameters. For instance, to force each CloudFormation template to use only the set of parameters defined in your pipeline, list them under this key. An empty list means that any parameter is allowed.</p> 
</blockquote> </li> 
<li><strong>“allow_resources”</strong><br /> 
<blockquote> 
<p>Lists the AWS resources allowed for creation by a CloudFormation template. The format of the resource is the same as resource types in CloudFormation, but without the “AWS::” prefix. Examples:&nbsp; EC2::Instance, EC2::Volume, and so on. If you allow the creation of all resources from the given group, you can use a wildcard. For instance, if you allow all resources related to CloudFormation, you can add CloudFormation::* to the list instead of typing CloudFormation::Init, CloudFormation:Stack, and so on. An empty list means that all resources are allowed.</p> 
</blockquote> </li> 
<li><strong>“require_ref_attributes”</strong><br /> 
<blockquote> 
<p>Lists attributes (per resource) that have to be defined in CloudFormation. The value must be referenced and cannot be hardcoded. For instance, you can require that each EC2 instance must be created from a specific AMI where Image ID has to be a passed-in parameter. An empty list means that you are not requiring specific attributes to be present for a given resource.</p> 
</blockquote> </li> 
<li><strong>“allow_additional_attributes”</strong><br /> 
<blockquote> 
<p>Lists additional attributes (per resource) that can be defined and have any value in the CloudFormation template. An empty list means that any additional attribute is allowed. If you specify additional attributes for this key, then any resource attribute defined in a CloudFormation template that is not listed in this key or in the require_ref_attributes key causes validation to fail.</p> 
</blockquote> </li> 
<li><strong>“not_allow_attributes”</strong><br /> 
<blockquote> 
<p>Lists attributes (per resource) that are not allowed in the CloudFormation template. This key takes precedence over the require_ref_attributes and allow_additional_attributes keys.</p> 
</blockquote> </li> 
</ul> 
<h5>Rule file example</h5> 
<p>The following is an example of a rule file:</p> 
<pre><code class="lang-json">{
&quot;allow_root_keys&quot; : [&quot;AWSTemplateFormatVersion&quot;, &quot;Description&quot;, &quot;Parameters&quot;, &quot;Conditions&quot;, &quot;Resources&quot;, &quot;Outputs&quot;],
&quot;allow_parameters&quot; : [],
&quot;allow_resources&quot; : [
&quot;CloudFormation::*&quot;,
&quot;CloudWatch::Alarm&quot;,
&quot;EC2::Instance&quot;,
&quot;EC2::Volume&quot;,
&quot;EC2::VolumeAttachment&quot;,
&quot;ElasticLoadBalancing::LoadBalancer&quot;,
&quot;IAM::Role&quot;,
&quot;IAM::Policy&quot;,
&quot;IAM::InstanceProfile&quot;
],
&quot;require_ref_attributes&quot; :
{
&quot;EC2::Instance&quot; : [ &quot;InstanceType&quot;, &quot;ImageId&quot;, &quot;SecurityGroupIds&quot;, &quot;SubnetId&quot;, &quot;KeyName&quot;, &quot;IamInstanceProfile&quot; ],
&quot;ElasticLoadBalancing::LoadBalancer&quot; : [&quot;SecurityGroups&quot;, &quot;Subnets&quot;]
},
&quot;allow_additional_attributes&quot; : {},
&quot;not_allow_attributes&quot; : {}
}
</code></pre> 
<h4>Validating resources</h4> 
<p>You can use the –cf_res parameter to validate that the resources you are planning to reference in the CloudFormation template exist and are available. As a value for this parameter, point to the JSON file with defined resources. The format should be as follows:</p> 
<pre><code class="lang-json">[
{ &quot;Type&quot; : &quot;SG&quot;,
&quot;ID&quot; : &quot;sg-37c9b448A&quot;
},
{ &quot;Type&quot; : &quot;AMI&quot;,
&quot;ID&quot; : &quot;ami-e7e523f1&quot;
},
{ &quot;Type&quot; : &quot;Subnet&quot;,
&quot;ID&quot; : &quot;subnet-034e262e&quot;
}
]
</code></pre> 
<h3>Summary</h3> 
<p>At this moment, this CloudFormation template validation script supports only security groups, AMIs, and subnets. But anyone with some knowledge of Python and the boto3 package can add support for additional resources type, as needed.</p> 
<p>For more tips please visit our <a href="https://aws.amazon.com/blogs/aws/category/aws-cloud-formation/">AWS CloudFormation blog</a></p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/devops/tag/cloudformation/" rel="tag">CloudFormation</a>, <a href="https://aws.amazon.com/blogs/devops/tag/validation/" rel="tag">Validation</a></span> 
</footer> 
</article> 
<article class="post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="b post-title" property="name headline">Continuous Delivery of Nested AWS CloudFormation Stacks Using AWS CodePipeline</b> 
<footer class="meta">
by 
<span property="author" typeof="Person"><span property="name">Prakash Palanisamy</span></span> | on 
<time property="datePublished" datetime="2017-06-27T23:30:29+00:00">27 JUN 2017</time> | in 
<span class="categories"><a href="https://aws.amazon.com/blogs/devops/category/how-to/" title="View all posts in How-To"><span property="articleSection">How-To</span></a></span> | 
<a href="https://aws.amazon.com/blogs/devops/continuous-delivery-of-nested-aws-cloudformation-stacks-using-aws-codepipeline/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog=""><span class="span icon-share"></span>&nbsp;Share</a> 
<ul> 
</ul> 
</footer> 
<p>In <a href="https://aws.amazon.com/blogs/aws/codepipeline-update-build-continuous-delivery-workflows-for-cloudformation-stacks/" target="_blank" rel="noopener noreferrer">CodePipeline Update – Build Continuous Delivery Workflows for CloudFormation Stacks</a>, Jeff Barr discusses infrastructure as code and how to use <a href="https://aws.amazon.com/codepipeline/" target="_blank" rel="noopener noreferrer">AWS CodePipeline</a> for continuous delivery. In this blog post, I discuss the continuous delivery of nested CloudFormation stacks using AWS CodePipeline, with <a href="https://aws.amazon.com/codecommit/" target="_blank" rel="noopener noreferrer">AWS CodeCommit</a> as the source repository and <a href="https://aws.amazon.com/codebuild/" target="_blank" rel="noopener noreferrer">AWS CodeBuild</a> as a build and <a href="https://aws.amazon.com/about-aws/whats-new/2017/03/aws-codepipeline-adds-support-for-unit-testing/" target="_blank" rel="noopener noreferrer">testing tool</a>. I deploy the stacks using <a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-cfn-updating-stacks-changesets.html" target="_blank" rel="noopener noreferrer">CloudFormation change sets</a> following a <a href="http://docs.aws.amazon.com/codepipeline/latest/userguide/approvals.html" target="_blank" rel="noopener noreferrer">manual approval process</a>.</p> 
<p>Here’s how to do it:</p> 
<p>In AWS CodePipeline, create a pipeline with four stages:</p> 
<ul> 
<li>Source (AWS CodeCommit)</li> 
<li>Build and Test (AWS CodeBuild and AWS CloudFormation)</li> 
<li>Staging (AWS CloudFormation and manual approval)</li> 
<li>Production (AWS CloudFormation and manual approval)</li> 
</ul> 
<p><span id="more-1238"></span></p> 
<p>Pipeline stages, the actions in each stage, and transitions between stages are shown in the following diagram.</p> 
<p><img class="alignnone wp-image-1244" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/06/07/Pipeline_vertical_design-2-362x1024.png" alt="" width="400" height="1131" /></p> 
<p>CloudFormation templates, test scripts, and the build specification are stored in AWS CodeCommit repositories. These files are used in the Source stage of the pipeline in AWS CodePipeline.</p> 
<p>The <a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-stack.html" target="_blank" rel="noopener noreferrer">AWS::CloudFormation::Stack</a> resource type is used to create child stacks from a master stack. The CloudFormation stack resource requires the templates of the child stacks to be stored in the S3 bucket. The location of the template file is provided as a URL in the properties section of the resource definition.</p> 
<p>The following template creates three child stacks:</p> 
<ul> 
<li>Security (IAM, security groups).</li> 
<li>Database (an RDS instance).</li> 
<li>Web stacks (EC2 instances in an Auto Scaling group, elastic load balancer).</li> 
</ul> 
<pre><code class="lang-yaml">Description: Master stack which creates all required nested stacks
Parameters:
&nbsp; TemplatePath:
&nbsp; &nbsp; Type: String
&nbsp; &nbsp; Description: S3Bucket Path where the templates are stored
&nbsp; VPCID:
&nbsp; &nbsp; Type: &quot;AWS::EC2::VPC::Id&quot;
&nbsp; &nbsp; Description: Enter a valid VPC Id
&nbsp; PrivateSubnet1:
&nbsp; &nbsp; Type: &quot;AWS::EC2::Subnet::Id&quot;
&nbsp; &nbsp; Description: Enter a valid SubnetId of private subnet in AZ1
&nbsp; PrivateSubnet2:
&nbsp; &nbsp; Type: &quot;AWS::EC2::Subnet::Id&quot;
&nbsp; &nbsp; Description: Enter a valid SubnetId of private subnet in AZ2
&nbsp; PublicSubnet1:
&nbsp; &nbsp; Type: &quot;AWS::EC2::Subnet::Id&quot;
&nbsp; &nbsp; Description: Enter a valid SubnetId of public subnet in AZ1
&nbsp; PublicSubnet2:
&nbsp; &nbsp; Type: &quot;AWS::EC2::Subnet::Id&quot;
&nbsp; &nbsp; Description: Enter a valid SubnetId of public subnet in AZ2
&nbsp; S3BucketName:
&nbsp; &nbsp; Type: String
&nbsp; &nbsp; Description: Name of the S3 bucket to allow access to the Web Server IAM Role.
&nbsp; KeyPair:
&nbsp; &nbsp; Type: &quot;AWS::EC2::KeyPair::KeyName&quot;
&nbsp; &nbsp; Description: Enter a valid KeyPair Name
&nbsp; AMIId:
&nbsp; &nbsp; Type: &quot;AWS::EC2::Image::Id&quot;
&nbsp; &nbsp; Description: Enter a valid AMI ID to launch the instance
&nbsp; WebInstanceType:
&nbsp; &nbsp; Type: String
&nbsp; &nbsp; Description: Enter one of the possible instance type for web server
&nbsp; &nbsp; AllowedValues:
&nbsp; &nbsp; &nbsp; - t2.large
&nbsp; &nbsp; &nbsp; - m4.large
&nbsp; &nbsp; &nbsp; - m4.xlarge
&nbsp; &nbsp; &nbsp; - c4.large
&nbsp; WebMinSize:
&nbsp; &nbsp; Type: String
&nbsp; &nbsp; Description: Minimum number of instances in auto scaling group
&nbsp; WebMaxSize:
&nbsp; &nbsp; Type: String
&nbsp; &nbsp; Description: Maximum number of instances in auto scaling group
&nbsp; DBSubnetGroup:
&nbsp; &nbsp; Type: String
&nbsp; &nbsp; Description: Enter a valid DB Subnet Group
&nbsp; DBUsername:
&nbsp; &nbsp; Type: String
&nbsp; &nbsp; Description: Enter a valid Database master username
&nbsp; &nbsp; MinLength: 1
&nbsp; &nbsp; MaxLength: 16
&nbsp; &nbsp; AllowedPattern: &quot;[a-zA-Z][a-zA-Z0-9]*&quot;
&nbsp; DBPassword:
&nbsp; &nbsp; Type: String
&nbsp; &nbsp; Description: Enter a valid Database master password
&nbsp; &nbsp; NoEcho: true
&nbsp; &nbsp; MinLength: 1
&nbsp; &nbsp; MaxLength: 41
&nbsp; &nbsp; AllowedPattern: &quot;[a-zA-Z0-9]*&quot;
&nbsp; DBInstanceType:
&nbsp; &nbsp; Type: String
&nbsp; &nbsp; Description: Enter one of the possible instance type for database
&nbsp; &nbsp; AllowedValues:
&nbsp; &nbsp; &nbsp; - db.t2.micro
&nbsp; &nbsp; &nbsp; - db.t2.small
&nbsp; &nbsp; &nbsp; - db.t2.medium
&nbsp; &nbsp; &nbsp; - db.t2.large
&nbsp; Environment:
&nbsp; &nbsp; Type: String
&nbsp; &nbsp; Description: Select the appropriate environment
&nbsp; &nbsp; AllowedValues:
&nbsp; &nbsp; &nbsp; - dev
&nbsp; &nbsp; &nbsp; - test
&nbsp; &nbsp; &nbsp; - uat
&nbsp; &nbsp; &nbsp; - prod
Resources:
&nbsp; SecurityStack:
&nbsp; &nbsp; Type: &quot;AWS::CloudFormation::Stack&quot;
&nbsp; &nbsp; Properties:
&nbsp; &nbsp; &nbsp; TemplateURL:
&nbsp; &nbsp; &nbsp; &nbsp; Fn::Sub: &quot;https://s3.amazonaws.com/${TemplatePath}/security-stack.yml&quot;
&nbsp; &nbsp; &nbsp; Parameters:
&nbsp; &nbsp; &nbsp; &nbsp; S3BucketName:
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Ref: S3BucketName
&nbsp; &nbsp; &nbsp; &nbsp; VPCID:
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Ref: VPCID
&nbsp; &nbsp; &nbsp; &nbsp; Environment:
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Ref: Environment
&nbsp; &nbsp; &nbsp; Tags:
&nbsp; &nbsp; &nbsp; &nbsp; - Key: Name
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Value: SecurityStack
&nbsp; DatabaseStack:
&nbsp; &nbsp; Type: &quot;AWS::CloudFormation::Stack&quot;
&nbsp; &nbsp; Properties:
&nbsp; &nbsp; &nbsp; TemplateURL:
&nbsp; &nbsp; &nbsp; &nbsp; Fn::Sub: &quot;https://s3.amazonaws.com/${TemplatePath}/database-stack.yml&quot;
&nbsp; &nbsp; &nbsp; Parameters:
&nbsp; &nbsp; &nbsp; &nbsp; DBSubnetGroup:
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Ref: DBSubnetGroup
&nbsp; &nbsp; &nbsp; &nbsp; DBUsername:
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Ref: DBUsername
&nbsp; &nbsp; &nbsp; &nbsp; DBPassword:
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Ref: DBPassword
&nbsp; &nbsp; &nbsp; &nbsp; DBServerSecurityGroup:
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Fn::GetAtt: SecurityStack.Outputs.DBServerSG
&nbsp; &nbsp; &nbsp; &nbsp; DBInstanceType:
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Ref: DBInstanceType
&nbsp; &nbsp; &nbsp; &nbsp; Environment:
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Ref: Environment
&nbsp; &nbsp; &nbsp; Tags:
&nbsp; &nbsp; &nbsp; &nbsp; - Key: Name
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Value: &nbsp; DatabaseStack
&nbsp; ServerStack:
&nbsp; &nbsp; Type: &quot;AWS::CloudFormation::Stack&quot;
&nbsp; &nbsp; Properties:
&nbsp; &nbsp; &nbsp; TemplateURL:
&nbsp; &nbsp; &nbsp; &nbsp; Fn::Sub: &quot;https://s3.amazonaws.com/${TemplatePath}/server-stack.yml&quot;
&nbsp; &nbsp; &nbsp; Parameters:
&nbsp; &nbsp; &nbsp; &nbsp; VPCID:
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Ref: VPCID
&nbsp; &nbsp; &nbsp; &nbsp; PrivateSubnet1:
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Ref: PrivateSubnet1
&nbsp; &nbsp; &nbsp; &nbsp; PrivateSubnet2:
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Ref: PrivateSubnet2
&nbsp; &nbsp; &nbsp; &nbsp; PublicSubnet1:
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Ref: PublicSubnet1
&nbsp; &nbsp; &nbsp; &nbsp; PublicSubnet2:
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Ref: PublicSubnet2
&nbsp; &nbsp; &nbsp; &nbsp; KeyPair:
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Ref: KeyPair
&nbsp; &nbsp; &nbsp; &nbsp; AMIId:
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Ref: AMIId
&nbsp; &nbsp; &nbsp; &nbsp; WebSG:
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Fn::GetAtt: SecurityStack.Outputs.WebSG
&nbsp; &nbsp; &nbsp; &nbsp; ELBSG:
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Fn::GetAtt: SecurityStack.Outputs.ELBSG
&nbsp; &nbsp; &nbsp; &nbsp; DBClientSG:
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Fn::GetAtt: SecurityStack.Outputs.DBClientSG
&nbsp; &nbsp; &nbsp; &nbsp; WebIAMProfile:
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Fn::GetAtt: SecurityStack.Outputs.WebIAMProfile
&nbsp; &nbsp; &nbsp; &nbsp; WebInstanceType:
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Ref: WebInstanceType
&nbsp; &nbsp; &nbsp; &nbsp; WebMinSize:
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Ref: WebMinSize
&nbsp; &nbsp; &nbsp; &nbsp; WebMaxSize:
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Ref: WebMaxSize
&nbsp; &nbsp; &nbsp; &nbsp; Environment:
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Ref: Environment
&nbsp; &nbsp; &nbsp; Tags:
&nbsp; &nbsp; &nbsp; &nbsp; - Key: Name
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Value: ServerStack
Outputs:
&nbsp; WebELBURL:
&nbsp; &nbsp; Description: &quot;URL endpoint of web ELB&quot;
&nbsp; &nbsp; Value:
&nbsp; &nbsp; &nbsp; Fn::GetAtt: ServerStack.Outputs.WebELBURL
</code></pre> 
<p>During the Validate stage, AWS CodeBuild checks for changes to the AWS CodeCommit source repositories. It uses the <a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/APIReference/API_ValidateTemplate.html" target="_blank" rel="noopener noreferrer">ValidateTemplate</a> API to validate the CloudFormation template and copies the child templates and configuration files to the appropriate location in the S3 bucket.</p> 
<p>The following AWS CodeBuild build specification validates the CloudFormation templates listed under the TEMPLATE_FILES environment variable and copies them to the S3 bucket specified in the TEMPLATE_BUCKET environment variable in the AWS CodeBuild project. Optionally, you can use the TEMPLATE_PREFIX environment variable to specify a path inside the bucket. This updates the configuration files to use the location of the child template files. The location of the template files is provided as a parameter to the master stack.</p> 
<pre><code class="lang-yaml">version: 0.1
environment_variables:
&nbsp; plaintext:
&nbsp; &nbsp; CHILD_TEMPLATES: |
&nbsp; &nbsp; &nbsp; security-stack.yml
&nbsp; &nbsp; &nbsp; server-stack.yml
&nbsp; &nbsp; &nbsp; database-stack.yml
&nbsp; &nbsp; TEMPLATE_FILES: |
&nbsp; &nbsp; &nbsp; master-stack.yml
&nbsp; &nbsp; &nbsp; security-stack.yml
&nbsp; &nbsp; &nbsp; server-stack.yml
&nbsp; &nbsp; &nbsp; database-stack.yml
&nbsp; &nbsp; CONFIG_FILES: |
&nbsp; &nbsp; &nbsp; config-prod.json
&nbsp; &nbsp; &nbsp; config-test.json
&nbsp; &nbsp; &nbsp; config-uat.json
phases:
&nbsp; install:
&nbsp; &nbsp; commands:
&nbsp; &nbsp; &nbsp; npm install jsonlint -g
&nbsp; pre_build:
&nbsp; &nbsp; commands:
&nbsp; &nbsp; &nbsp; - echo &quot;Validating CFN templates&quot;
&nbsp; &nbsp; &nbsp; - |
&nbsp; &nbsp; &nbsp; &nbsp; for cfn_template in $TEMPLATE_FILES; do
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; echo &quot;Validating CloudFormation template file $cfn_template&quot;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; aws cloudformation validate-template --template-body file://$cfn_template
&nbsp; &nbsp; &nbsp; &nbsp; done
&nbsp; &nbsp; &nbsp; - |
&nbsp; &nbsp; &nbsp; &nbsp; for conf in $CONFIG_FILES; do
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; echo &quot;Validating CFN parameters config file $conf&quot;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; jsonlint -q $conf
&nbsp; &nbsp; &nbsp; &nbsp; done
&nbsp; build:
&nbsp; &nbsp; commands:
&nbsp; &nbsp; &nbsp; - echo &quot;Copying child stack templates to S3&quot;
&nbsp; &nbsp; &nbsp; - |
&nbsp; &nbsp; &nbsp; &nbsp; for child_template in $CHILD_TEMPLATES; do
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if [ &quot;X$TEMPLATE_PREFIX&quot; = &quot;X&quot; ]; then
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; aws s3 cp &quot;$child_template&quot; &quot;s3://$TEMPLATE_BUCKET/$child_template&quot;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; else
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; aws s3 cp &quot;$child_template&quot; &quot;s3://$TEMPLATE_BUCKET/$TEMPLATE_PREFIX/$child_template&quot;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; fi
&nbsp; &nbsp; &nbsp; &nbsp; done
&nbsp; &nbsp; &nbsp; - echo &quot;Updating template configurtion files to use the appropriate values&quot;
&nbsp; &nbsp; &nbsp; - |
&nbsp; &nbsp; &nbsp; &nbsp; for conf in $CONFIG_FILES; do
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if [ &quot;X$TEMPLATE_PREFIX&quot; = &quot;X&quot; ]; then
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; echo &quot;Replacing \&quot;TEMPLATE_PATH_PLACEHOLDER\&quot; for \&quot;$TEMPLATE_BUCKET\&quot; in $conf&quot;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; sed -i -e &quot;s/TEMPLATE_PATH_PLACEHOLDER/$TEMPLATE_BUCKET/&quot; $conf
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; else
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; echo &quot;Replacing \&quot;TEMPLATE_PATH_PLACEHOLDER\&quot; for \&quot;$TEMPLATE_BUCKET/$TEMPLATE_PREFIX\&quot; in $conf&quot;
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; sed -i -e &quot;s/TEMPLATE_PATH_PLACEHOLDER/$TEMPLATE_BUCKET\/$TEMPLATE_PREFIX/&quot; $conf
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; fi
&nbsp; &nbsp; &nbsp; &nbsp; done
artifacts:
&nbsp; files:
&nbsp; &nbsp; - master-stack.yml
&nbsp; &nbsp; - config-*.json
</code></pre> 
<p>After the template files are copied to S3, CloudFormation creates a test stack and triggers AWS CodeBuild as a test action.</p> 
<p>Then the AWS CodeBuild build specification executes <code class="lang-bash">validate-env.py</code>, the Python script used to determine whether resources created using the nested CloudFormation stacks conform to the specifications provided in the CONFIG_FILE.</p> 
<pre><code class="lang-yaml">version: 0.1
environment_variables:
&nbsp; plaintext:
&nbsp; &nbsp; CONFIG_FILE: env-details.yml
phases:
&nbsp; install:
&nbsp; &nbsp; commands:
&nbsp; &nbsp; &nbsp; - pip install --upgrade pip
&nbsp; &nbsp; &nbsp; - pip install boto3 --upgrade
&nbsp; &nbsp; &nbsp; - pip install pyyaml --upgrade
&nbsp; &nbsp; &nbsp; - pip install yamllint --upgrade
&nbsp; pre_build:
&nbsp; &nbsp; commands:
&nbsp; &nbsp; &nbsp; - echo &quot;Validating config file $CONFIG_FILE&quot;
&nbsp; &nbsp; &nbsp; - yamllint $CONFIG_FILE
&nbsp; build:
&nbsp; &nbsp; commands:
&nbsp; &nbsp; &nbsp; - echo &quot;Validating resources...&quot;
&nbsp; &nbsp; &nbsp; - python validate-env.py
&nbsp; &nbsp; &nbsp; - exit $?</code></pre> 
<p>Upon successful completion of the test action, CloudFormation deletes the test stack and proceeds to the UAT stage in the pipeline.</p> 
<p>During this stage, CloudFormation creates a change set against the UAT stack and then executes the change set. This updates the UAT environment and makes it available for acceptance testing. The process continues to a manual approval action. After the QA team validates the UAT environment and provides an approval, the process moves to the Production stage in the pipeline.</p> 
<p>During this stage, CloudFormation creates a change set for the nested production stack and the process continues to a manual approval step. Upon approval (usually by a designated executive), the change set is executed and the production deployment is completed.<br /> &nbsp;</p> 
<h3>Setting up a continuous delivery pipeline</h3> 
<p>&nbsp;<br /> I used a CloudFormation template to set up my continuous delivery pipeline. The <a href="https://github.com/awslabs/codepipeline-nested-cfn/blob/master/codepipeline-cfn-codebuild.yml" target="_blank" rel="noopener noreferrer">codepipeline-cfn-codebuild.yml</a> template, available from GitHub, sets up a full-featured pipeline.</p> 
<p>When I use the template to create my pipeline, I specify the following:</p> 
<ul> 
<li>AWS CodeCommit repositories.</li> 
<li>SNS topics to send approval notifications.</li> 
<li>S3 bucket name where the artifacts will be stored.</li> 
</ul> 
<p><img class="alignnone size-full wp-image-1172" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/06/07/Stack_Parameters.png" alt="" width="1894" height="802" /></p> 
<p>The CFNTemplateRepoName points to the AWS CodeCommit repository where CloudFormation templates, configuration files, and build specification files are stored.</p> 
<p>My repo contains following files:</p> 
<p><img class="alignnone size-full wp-image-1173" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/06/07/RepoContent.png" alt="" width="2102" height="626" /></p> 
<p>The continuous delivery pipeline is ready just seconds after clicking <strong>Create Stack</strong>. After it’s created, the pipeline executes each stage. Upon manual approvals for the UAT and Production stages, the pipeline successfully enables continuous delivery.</p> 
<p><img class="alignnone size-full wp-image-1205" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/06/07/CodePipeline_Flow_1.png" alt="" width="400" height="1764" /><br /> &nbsp;</p> 
<h3>Implementing a change in nested stack</h3> 
<p>&nbsp;<br /> To make changes to a child stack in a nested stack (for example, to update a parameter value or add or change resources), update the master stack. The changes must be made in the appropriate template or configuration files and then checked in to the AWS CodeCommit repository. This triggers the following deployment process:</p> 
<h3><img class="alignnone wp-image-1176 size-large" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/06/01/DeployChanges-517x1024.png" alt="" width="517" height="1024" /></h3> 
<p>&nbsp;</p> 
<h3>Conclusion</h3> 
<p>&nbsp;<br /> In this post, I showed how you can use AWS CodePipeline, AWS CloudFormation, AWS CodeBuild, and a manual approval process to create a continuous delivery pipeline for both infrastructure as code and application deployment.</p> 
<p>For more information about AWS CodePipeline, see the <a href="https://aws.amazon.com/documentation/codepipeline/" target="_blank" rel="noopener noreferrer">AWS CodePipeline documentation</a>. You can <a href="http://docs.aws.amazon.com/codepipeline/latest/userguide/getting-started-codepipeline.html" target="_blank" rel="noopener noreferrer">get started</a> in just a few clicks. All CloudFormation templates, AWS CodeBuild build specification files, and the Python script that performs the validation are available in <a href="https://github.com/awslabs/codepipeline-nested-cfn" target="_blank" rel="noopener noreferrer">codepipeline-nested-cfn</a> GitHub repository.</p> 
<hr /> 
<h3>About the author</h3> 
<p>&nbsp;<br /> <strong><img class="alignleft wp-image-1260 size-thumbnail" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/06/07/PP1-150x150.jpg" alt="" width="150" height="150" />Prakash Palanisamy</strong> is a Solutions Architect for Amazon Web Services. When he is not working on Serverless, DevOps or Alexa, he will be solving problems in Project Euler. He also enjoys watching educational documentaries.</p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/devops/tag/cloudformation/" rel="tag">CloudFormation</a>, <a href="https://aws.amazon.com/blogs/devops/tag/codebuild/" rel="tag">codebuild</a>, <a href="https://aws.amazon.com/blogs/devops/tag/codecommit/" rel="tag">CodeCommit</a>, <a href="https://aws.amazon.com/blogs/devops/tag/codedeploy/" rel="tag">CodeDeploy</a>, <a href="https://aws.amazon.com/blogs/devops/tag/codepipeline/" rel="tag">CodePipeline</a>, <a href="https://aws.amazon.com/blogs/devops/tag/continuous-delivery/" rel="tag">Continuous Delivery</a></span> 
</footer> 
</article> 
<p>
© 2017, Amazon Web Services, Inc. or its affiliates. All rights reserved.
</p>

    </div>
  </div>
</div>


    <div id="footer" class="navigation hidden-print">
      <div class="container">
        <div class="row">
          <div class="col-xs-12">
            <ul class="footer-links nav navbar-nav">
              <li><a href="../aws.html">AWS</a></li>
              <li><a href="../linux.html">Linux</a></li>
              <li><a href="../docker.html">Docker</a></li>
              <li><a href="../ibmpower.html">IBM Power</a></li>
              <li><a href="blogsataws1.html">Blogs@AWS (Kindle Friendly)</a></li>
            </ul>
            <ul class="footer-links nav navbar-nav navbar-right">
              <li><a href="../comments.html">Comments?</a></li>
            </ul>
          </div>
        </div>
      </div>
    </div>
  </body>
</html>
