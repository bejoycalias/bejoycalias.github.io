<!DOCTYPE html>
<html lang="en">
  <head>
<!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-593498H');</script>
<!-- End Google Tag Manager -->

    <meta charset="utf-8">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">

    <meta name="msapplication-config" content="/microsoft-tile.xml" />
    <meta name="theme-color" content="#ffffff">

    <meta property="og:url" content="https://bejoycalias.github.io/blogsataws/devopsblogs1.html" />
    <meta property="og:site_name" content="Bejoy's TechNotes"/>
    <meta property="og:title" content="Bejoy's TechNotes - Kindle Friendly AWS DevOps Blogs" />
    <meta property="og:image" content="https://bejoycalias.github.io/assets/images/og-image.png"/>
    <meta property="og:image:width" content="1200"/>
    <meta property="og:image:height" content="1200"/>
    <meta property="og:description" content="" />

    <title>Bejoy's TechNotes - Kindle Friendly AWS DevOps Blogs</title>
    <link href="../assets/stylesheets/application-832aa42c.css" rel="stylesheet" />

    <!--[if lt IE 9]>
      <script src="../assets/javascripts/ie-compat-c141a02d.js"></script>
    <![endif]-->
    <script src="../assets/javascripts/application-ff53d307.js"></script>

    <!-- Typekit script to import Klavika font -->
    <script src="https://use.typekit.net/wxf7mfi.js"></script>
    <script>try{Typekit.load({ async: true });}catch(e){}</script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-100043608-1', 'auto');
  ga('send', 'pageview');

</script>

    
  </head>

  <body id="uh-oh-" class="layout-inner page-uh-oh-">
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-593498H"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->


    <div id="header" class="navigation navbar-static-top hidden-print">
      <div class="container">
        <div class="row">
          <div class="col-xs-12">
            <div class="navbar-header">
              <div class="navbar-brand">
                <a href="/">
                  <svg version="1.0" xmlns="http://www.w3.org/2000/svg" width="135.000000pt" height="50" viewbox="0 0 135.000000 45.000000" preserveaspectratio="xMidYMid meet" class="logo">

<g transform="translate(0.000000,45.000000) scale(0.100000,-0.100000)" fill="#000000" stroke="none">
<path class="text" fill="#000000" d="M527 384 c-4 -4 -7 -18 -7 -31 0 -21 4 -24 28 -21 21 2 27 8 27 28 0
18 -6 26 -20 28 -12 2 -24 0 -28 -4z"></path>
<path class="text" fill="#000000" d="M1080 335 c0 -48 2 -55 20 -55 18 0 20 7 20 55 0 48 -2 55 -20 55
-18 0 -20 -7 -20 -55z"></path>
<path class="text" fill="#000000" d="M54 357 c-2 -7 -3 -69 -2 -138 l3 -124 65 -3 c90 -3 130 20 130 77 0
29 -6 44 -20 54 -20 14 -20 15 -3 45 14 25 15 34 5 56 -6 15 -23 31 -38 36
-38 15 -134 13 -140 -3z m110 -33 c19 -7 21 -45 4 -62 -7 -7 -22 -12 -35 -12
-20 0 -23 5 -23 40 0 41 13 50 54 34z m20 -130 c19 -18 19 -20 6 -45 -8 -13
-21 -19 -45 -19 -34 0 -35 1 -35 40 0 38 2 40 29 40 16 0 37 -7 45 -16z"></path>
<path class="text" fill="#000000" d="M319 271 c-23 -24 -29 -38 -29 -74 0 -25 3 -53 6 -62 20 -50 164 -64
164 -15 0 15 -7 17 -45 12 -46 -5 -75 8 -75 34 0 11 16 14 65 14 l65 0 0 35
c0 80 -92 114 -151 56z m99 -33 c3 -15 -4 -18 -37 -18 -43 0 -50 7 -29 28 18
18 62 11 66 -10z"></path>
<path class="text" fill="#000000" d="M520 184 c0 -107 -1 -116 -20 -121 -11 -3 -20 -12 -20 -19 0 -21 76
-19 84 2 3 9 6 69 6 135 l0 119 -25 0 -25 0 0 -116z"></path>
<path class="text" fill="#000000" d="M649 271 c-24 -25 -29 -37 -29 -78 1 -70 34 -103 105 -103 55 0 95
44 95 103 0 60 -7 75 -41 92 -47 25 -96 19 -130 -14z m111 -30 c25 -48 2 -111
-40 -111 -45 0 -69 80 -34 114 21 22 61 20 74 -3z"></path>
<path class="text" fill="#000000" d="M850 287 c0 -8 16 -57 36 -110 28 -76 33 -100 25 -116 -16 -28 -14
-31 18 -31 27 0 29 4 70 123 23 67 41 128 41 135 0 6 -11 12 -24 12 -21 0 -26
-8 -41 -65 -10 -36 -21 -68 -25 -70 -3 -2 -16 27 -29 66 -19 60 -25 69 -47 69
-13 0 -24 -6 -24 -13z"></path>
<path class="text" fill="#000000" d="M1192 284 c-17 -12 -22 -24 -20 -47 2 -26 10 -36 45 -52 49 -23 59
-55 17 -55 -14 0 -34 5 -45 10 -16 9 -19 7 -19 -13 0 -17 7 -27 23 -31 69 -18
117 6 117 60 0 32 -4 37 -45 55 -60 26 -62 54 -4 46 37 -5 40 -3 37 16 -2 18
-11 23 -43 25 -25 2 -49 -3 -63 -14z"></path>
</g>
</svg>

                </a>
              </div>
              <button class="navbar-toggle" type="button">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
              </button>
            </div>
            <div class="buttons hidden-xs">
              <nav class="navigation-links" role="navigation">
                <ul class="main-links nav navbar-nav navbar-right">
                  <li><a href="../aws.html">AWS</a></li>
                  <li><a href="../linux.html">Linux</a></li>
                  <li><a href="../docker.html">Docker</a></li>
                  <li><a href="../ibmpower.html">IBM Power</a></li>
                  <li><a href="blogsataws1.html">Blogs@AWS (Kindle Friendly)</a></li>
                </ul>
              </nav>
            </div>
          </div>
        </div>
      </div>
    </div>

    <div class="sidebar-overlay"></div>

<aside class="sidebar" role="navigation">
  <div class="sidebar-header">
    <svg version="1.0" xmlns="http://www.w3.org/2000/svg" width="135.000000pt" height="42" viewbox="0 0 135.000000 45.000000" preserveaspectratio="xMidYMid meet">

<g transform="translate(0.000000,45.000000) scale(0.100000,-0.100000)" fill="#000000" stroke="none">
<path class="text" fill="#000000" d="M527 384 c-4 -4 -7 -18 -7 -31 0 -21 4 -24 28 -21 21 2 27 8 27 28 0
18 -6 26 -20 28 -12 2 -24 0 -28 -4z"></path>
<path class="text" fill="#000000" d="M1080 335 c0 -48 2 -55 20 -55 18 0 20 7 20 55 0 48 -2 55 -20 55
-18 0 -20 -7 -20 -55z"></path>
<path class="text" fill="#000000" d="M54 357 c-2 -7 -3 -69 -2 -138 l3 -124 65 -3 c90 -3 130 20 130 77 0
29 -6 44 -20 54 -20 14 -20 15 -3 45 14 25 15 34 5 56 -6 15 -23 31 -38 36
-38 15 -134 13 -140 -3z m110 -33 c19 -7 21 -45 4 -62 -7 -7 -22 -12 -35 -12
-20 0 -23 5 -23 40 0 41 13 50 54 34z m20 -130 c19 -18 19 -20 6 -45 -8 -13
-21 -19 -45 -19 -34 0 -35 1 -35 40 0 38 2 40 29 40 16 0 37 -7 45 -16z"></path>
<path class="text" fill="#000000" d="M319 271 c-23 -24 -29 -38 -29 -74 0 -25 3 -53 6 -62 20 -50 164 -64
164 -15 0 15 -7 17 -45 12 -46 -5 -75 8 -75 34 0 11 16 14 65 14 l65 0 0 35
c0 80 -92 114 -151 56z m99 -33 c3 -15 -4 -18 -37 -18 -43 0 -50 7 -29 28 18
18 62 11 66 -10z"></path>
<path class="text" fill="#000000" d="M520 184 c0 -107 -1 -116 -20 -121 -11 -3 -20 -12 -20 -19 0 -21 76
-19 84 2 3 9 6 69 6 135 l0 119 -25 0 -25 0 0 -116z"></path>
<path class="text" fill="#000000" d="M649 271 c-24 -25 -29 -37 -29 -78 1 -70 34 -103 105 -103 55 0 95
44 95 103 0 60 -7 75 -41 92 -47 25 -96 19 -130 -14z m111 -30 c25 -48 2 -111
-40 -111 -45 0 -69 80 -34 114 21 22 61 20 74 -3z"></path>
<path class="text" fill="#000000" d="M850 287 c0 -8 16 -57 36 -110 28 -76 33 -100 25 -116 -16 -28 -14
-31 18 -31 27 0 29 4 70 123 23 67 41 128 41 135 0 6 -11 12 -24 12 -21 0 -26
-8 -41 -65 -10 -36 -21 -68 -25 -70 -3 -2 -16 27 -29 66 -19 60 -25 69 -47 69
-13 0 -24 -6 -24 -13z"></path>
<path class="text" fill="#000000" d="M1192 284 c-17 -12 -22 -24 -20 -47 2 -26 10 -36 45 -52 49 -23 59
-55 17 -55 -14 0 -34 5 -45 10 -16 9 -19 7 -19 -13 0 -17 7 -27 23 -31 69 -18
117 6 117 60 0 32 -4 37 -45 55 -60 26 -62 54 -4 46 37 -5 40 -3 37 16 -2 18
-11 23 -43 25 -25 2 -49 -3 -63 -14z"></path>
</g>
</svg>

  </div>

  <ul class="nav sidebar-nav">
    <li><a href="../aws.html">AWS</a></li>
    <li><a href="../linux.html">Linux</a></li>
    <li><a href="../docker.html">Docker</a></li>
    <li><a href="../ibmpower.html">IBM Power</a></li>
    <li><a href="blogsataws1.html">Blogs@AWS (Kindle Friendly)</a></li>
  </ul>
</aside>


    <div class="container">
  <div class="row">
    <div id="docs-sidebar" class="col-sm-3 col-md-3 col-xs-12 hidden-print" role="complementary">
      <ul class="nav docs-sidenav">
      <li><a href="blogsataws1.html">Blogs @ AWS</a></li>
      <li><a href="whatsnew1.html">What's New @ AWS</a></li>
      <li><a href="mgmtblogs1.html">Management Tools Blogs @ AWS</a></li>
      <li><a href="computeblogs1.html">Compute Blogs @ AWS</a></li>
      <li class="active"><a href="devopsblogs1.html">DevOps Blogs @ AWS</a></li>
      <li><a href="secblogs1.html">Security Blogs @ AWS</a></li>
      <li><a href="apnblogs1.html">APN Blogs @ AWS</a></li>

    </ul>
    </div>

    <div id="inner" class="col-sm-9 col-md-9 col-xs-12" role="main">
<p></p>
<p><i>Contents of this page is copied directly from AWS blog sites to make it Kindle friendly. Some styles & sections from these pages are removed to render this properly in 'Article Mode' of Kindle e-Reader browser. All the contents of this page is property of AWS.</i></p>
<p><a href="devopsblogs1.html">Page 1</a>|<a href="devopsblogs2.html">Page 2</a>|<a href="devopsblogs3.html">Page 3</a>|<a href="devopsblogs4.html">Page 4</a></p>
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<meta property="image" content="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/25/CB-GHE-1.png" /> 
<b class="lb-b blog-post-title" property="name headline">Announcing AWS CodeBuild Support for GitHub Enterprise as a Source Type and Shallow Cloning</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Karthik Thirugnanasambandam</span></span> | on 
<time property="datePublished" datetime="2018-01-25T11:08:36+00:00">25 JAN 2018</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/devops/category/developer-tools/aws-codebuild/" title="View all posts in AWS CodeBuild*"><span property="articleSection">AWS CodeBuild*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/devops/" title="View all posts in DevOps*"><span property="articleSection">DevOps*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/how-to/" title="View all posts in How-To*"><span property="articleSection">How-To*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/news/launch/" title="View all posts in Launch*"><span property="articleSection">Launch*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/devops/codebuild-support-for-github-enterprise/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><em>Thank you to my colleague&nbsp;<strong>Harvey Bendana</strong> for this blog on how to&nbsp;do shallow cloning on AWS CodeBuild using GitHub Enterprise as a source.</em></p> 
<p>Today we are announcing support for using GitHub Enterprise as a source type for CodeBuild. You can now initiate build tasks from changes in source code hosted on your own implementation of GitHub Enterprise.</p> 
<p>We are also announcing support for shallow cloning of a repo when you use CodeCommit, BitBucket, GitHub, or GitHub Enterprise as a source type. Shallow cloning allows you to truncate history of a repo in order to save space and speed up cloning times.</p> 
<p>In this post, I’ll walk you through how to configure GitHub Enterprise as a source type with a defined clone depth for an AWS CodeBuild project. I’ll also show you all the moving parts associated with a successful implementation.</p> 
<p><a href="https://aws.amazon.com/codebuild/">AWS CodeBuild</a> is a fully managed build service. There are no servers to provision and scale, or software to install, configure, and operate. You just specify the location of your source code, choose your build settings, and CodeBuild runs build scripts for compiling, testing, and packaging your code.</p> 
<p>GitHub Enterprise is the on-premises version of <a href="https://github.com/home">GitHub.com</a>. It makes collaborative coding possible and enjoyable for large-scale enterprise software development teams.</p> 
<p>Many enterprises choose GitHub Enterprise as their preferred source code/version control repository because it can be hosted in their own trusted network, whether that is an on-premises data center or their own Amazon VPCs.</p> 
<h3>Requirements</h3> 
<li>You’ll need an AWS account.</li> 
<li>You’ll need a GitHub Enterprise implementation with a repo. If you’d like to deploy one inside your own Amazon VPC, check out our <a href="https://aws.amazon.com/quickstart/architecture/github-enterprise/">Quick Start Guide</a>.</li> 
<li>You’ll need an S3 bucket to store your GitHub Enterprise self-signed SSL certificate.</li> 
<b>Download your GitHub Enterprise SSL certificate:</b> 
<p><strong>Note:</strong> The following steps are required only for self-signed certificates. You can forego installation of a certificate if you are using self-signed certificates and default to HTTP communication with your repo. For this post, I am using a self-signed certificate and the Firefox browser. These steps may vary, depending on your browser of choice.</p> 
<ol> 
<li>Navigate to your GitHub Enterprise environment and sign in with your credentials.</li> 
</ol> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/25/Picture1.png" /></p> 
<p>2. Choose the lock icon in the upper-left corner to view and export your GitHub Enterprise certificate.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/25/Picture2.png" /></p> 
<p>3. When you export and download your certificate, make sure you select the format type, which includes the entire certificate chain.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/25/Picture3.png">https://console.aws.amazon.com/s3</a> and upload your certificate to an S3 bucket in your AWS account.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/25/Picture4.png" /></p> 
<p>Now I will show you how to create an AWS CodeBuild project.</p> 
<b>Create a sample AWS CodeBuild project:</b> 
<ol> 
<li>Open the AWS CodeBuild console at <a href="https://console.aws.amazon.com/codebuild">https://console.aws.amazon.com/codebuild</a>.</li> 
</ol> 
<p>2. If there are no existing build projects, a welcome page is displayed. Choose <strong>Get started</strong>. If you already have build projects, then choose <strong>Create project</strong>.</p> 
<p>3. On the&nbsp;<strong>Configure your project</strong>&nbsp;page, type a name for your build project. Build project names must be unique across each AWS account.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/25/Picture5.png" /></p> 
<p>4. For <strong>Source provider</strong>, choose <strong>GitHub Enterprise</strong>.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/25/Picture6.png" /></p> 
<p>5. Generate a personal access token in your GitHub Enterprise environment. Under <strong>Select scopes</strong>, select <strong>repo</strong>. For information, see <a href="https://help.github.com/articles/creating-a-personal-access-token-for-the-command-line/">Creating a personal access token for the command line</a> on the GitHub Help website.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/25/Picture7.png" /></p> 
<p>6. Enter your personal access token in your CodeBuild project and choose <strong>Save Token</strong>.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/25/Picture8.png" /></p> 
<p>7. Enter the repository URL and choose a Git clone depth value that makes sense for you. Allowed values are <strong>1, 5, 25, or Full</strong>. For this post, I am using a depth of 1.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/25/Picture9.png" /></p> 
<p>8. Select the <strong>Webhook</strong> check box.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/25/Picture10.png" /></p> 
<p>9. Continue with the rest of the configuration for your project, choosing options that best suit your build needs. For this post, I am using an AWS CodeBuild managed image running the Ubuntu OS with the base runtime configuration. Enter your build specifications or build commands. I am using a simple build command of <strong>git log .</strong> so that it can be easily found in the CloudWatch logs of the CodeBuild project. It will also be used to demonstrate the shallow clone feature.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/25/Picture11.png" /></p> 
<p>10. Next, select <strong>Install certificate from your S3</strong> to install your GitHub Enterprise self-signed certificate from S3. For <strong>Bucket of certificate</strong>, I’ve entered the S3 bucket where I uploaded the certificate. For <strong>Object key of certificate</strong>, I’ve entered the name of the certificate.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/25/Picture12.png" /></p> 
<p>11. Lastly, configure artifacts, caching, IAM roles, and VPC configurations. For this post, I chose not to generate any artifacts from this build. From the following screenshot, you’ll see I’ve opted out of cache, requested a new IAM role with the required permissions, and have not defined VPC access. Choose <strong>Continue</strong> to validate and complete the creation of the CodeBuild project.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/25/Picture13.png" /></p> 
<p><strong>Note</strong>: If your GitHub Enterprise environment is in an Amazon VPC, configure VPC access for your project. Define the VPC ID, subnet ID, and security group so that your project has access to the EC2 instances hosting your GitHub Enterprise environment.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/25/Picture14.png" /></p> 
<p>12. After the project is created, a dialog box displays a CodeBuild payload URL and secret. They are used to create a webhook for the repo in the GitHub Enterprise environment.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/25/Picture15.png" /></p> 
<b>Create a webhook in your GitHub Enterprise repo:</b> 
<p>1. In your GitHub Enterprise repo, navigate to <strong>Settings</strong>, choose <strong>Hooks &amp; services</strong>, and then choose <strong>Add webhook</strong>.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/25/Picture16.png" /></p> 
<p>2. Paste the payload URL and secret into their respective fields. Under <strong>Which events would you like to trigger this webhook</strong>? choose an option. For this post, I am using <strong>Let me select individual events</strong>. I then chose <strong>Pull request</strong> and <strong>Push</strong> as the two event triggers.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/25/Picture17.png" /></p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/25/Picture18.png" /></p> 
<p>3. Make sure Active is selected and then choose Add webhook.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/25/Picture19.png" /></p> 
<p>4. A webhook has now been created in the GitHub Enterprise repo.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/25/Picture20.png" /></p> 
<p>Now I will show you how to test this.</p> 
<b>Trigger your AWS CodeBuild project by pushing a change to the GitHub Enterprise repo</b> 
<p>1. Clone the repo to the local file system. For information, see <a href="https://services.github.com/on-demand/github-cli/clone-repo-cli">Clone the Repository Using the Command Line</a> on the GitHub Help website. Now create a feature branch, push a change, and generate a pull request for review, and, ultimately, merge to master. Here is the state of the GitHub Enterprise repo and AWS CodeBuild project before pushing a change:</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/25/Picture21.png" /></p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/25/Picture22.png" /></p> 
<p>2. Use <a href="https://git-scm.com/book/en/v2/Getting-Started-The-Command-Line">Git command line tools</a> to create a new branch in the repo.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/25/Picture23.png" /></p> 
<p>3. Update the README.md for the repo with a link to the <a href="https://aws.amazon.com/codebuild/">AWS CodeBuild documentation</a>.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/25/Picture24.png" /></p> 
<p>4. After the changes have been saved, push them to the feature branch.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/25/Picture25.png" /></p> 
<p>5. There is now notification of a new branch in the GitHub Enterprise environment.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/25/Picture26.png" /></p> 
<p>6. Generate a pull request from the feature branch in preparation of review and merge to master.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/25/Picture27.png" /></p> 
<p>7. The reviewer(s) will then review and merge the pull request, pushing all changes to the master branch.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/25/Picture28.png" /></p> 
<p>8. Here is the updated repo:</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/25/Picture29.png" /></p> 
<p>9. After the change has been pushed successfully, a new build is initiated.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/25/Picture30.png" /></p> 
<p>10. In the following screenshot, you’ll see the initiator is <strong>Github-Hookshot/eb0c46</strong> and the source version is <strong>03169095b8f16ac077388471035becb2070aa12c</strong>.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/25/Picture31.png" /></p> 
<p>11. In the <strong>Recent Deliveries</strong> section, under the configuration of the GitHub Enterprise repo webhook, the CodeBuild project initiator is defined as <strong>User-Agent</strong>. The source version is denoted in the <strong>Payload</strong> output. They match!</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/25/Picture32.png" /></p> 
<p>12. A successfully completed build should appear under the CodeBuild project.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/25/Picture33.png" /></p> 
<p>13. The entire log output of the CodeBuild project can be viewed in CloudWatch logs. In the following screenshot, the source was downloaded successfully from the GitHub Enterprise repo and the build command of <strong>git log .</strong> was run successfully. Only the most recent commit appears in the git history output. This is because I defined a clone depth of 1.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/25/Picture34.png" /></p> 
<p>14. If I query the git history of the repo on the local repository, the output has the full commit history. This is expected because I am doing a full clone locally.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/25/Picture35.png" /></p> 
<b>Conclusion</b> 
<p>In this blog post, I showed you how to configure GitHub Enterprise as a source type for your AWS CodeBuild project with a clone depth of 1. These new features expand the capabilities of AWS CodeBuild and the suite of AWS Developer Tools for CI/CD and DevOps processes.</p> 
<p>I hope you found this post useful. Feel free to leave your feedback or suggestions in the comments.</p> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<meta property="image" content="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/12/automate_to_spot.png" /> 
<b class="lb-b blog-post-title" property="name headline">Automatic Deployment to New Amazon EC2 On-Demand and Spot Instances Using AWS CodeDeploy, Amazon CloudWatch Events, and AWS Lambda</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Tapodipta Ghosh</span></span> | on 
<time property="datePublished" datetime="2018-01-12T13:50:30+00:00">12 JAN 2018</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/devops/category/management-tools/amazon-cloudwatch/" title="View all posts in Amazon CloudWatch*"><span property="articleSection">Amazon CloudWatch*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/compute/amazon-ec2/" title="View all posts in Amazon EC2*"><span property="articleSection">Amazon EC2*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/developer-tools/aws-codedeploy/" title="View all posts in AWS CodeDeploy*"><span property="articleSection">AWS CodeDeploy*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/compute/aws-lambda/" title="View all posts in AWS Lambda*"><span property="articleSection">AWS Lambda*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/compute/" title="View all posts in Compute*"><span property="articleSection">Compute*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/developer-tools/" title="View all posts in Developer Tools*"><span property="articleSection">Developer Tools*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/management-tools/" title="View all posts in Management Tools*"><span property="articleSection">Management Tools*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/devops/automatic-deployment-to-new-amazon-ec2-on-demand-and-spot-instances-using-aws-codedeploy-amazon-cloudwatch-events-and-aws-lambda/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><a href="https://aws.amazon.com/codedeploy/">AWS CodeDeploy</a> is a service that automates application deployments to your compute infrastructure, including fleets of <a href="https://aws.amazon.com/ec2/">Amazon EC2</a> instances. AWS CodeDeploy can automatically deploy the latest app version to any new EC2 instance launched due to a scaling event. However, if your servers are not part of the Auto Scaling group, it might be a challenge to automate the code deployment for new EC2 launches. This is especially true if you are running your workload on an <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/spot-fleet.html">EC2 Spot Fleet</a>. In this post, I’ll show you how to use AWS CodeDeploy, an <a href="http://docs.aws.amazon.com/AmazonCloudWatch/latest/events/WhatIsCloudWatchEvents.html">Amazon CloudWatch Events rule</a>, EC2 tags, and <a href="https://aws.amazon.com/lambda/">AWS Lambda</a> to automate your deployments so that all EC2 instances run the same version of your application.</p> 
<p><strong>Solution overview:</strong></p> 
<p>An Amazon CloudWatch rule is triggered when a new Amazon EC2 instance is launched. The rule invokes an AWS Lambda function that extracts three tags:</p> 
<code class="lang-html">&middot;&nbsp;Name
&middot;&nbsp;CodeDeployDeploymentGroup
&middot;&nbsp;CodeDeployApplication</code> 
<p>The Lambda function then uses the instance tags to add the EC2 instance to the deployment group. After the instance has been added, Lambda queries AWS CodeDeploy to retrieve the last successful deployment in that deployment group and synchronizes the EC2 instance with the latest code. The following diagram shows the sequence:</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/11/solution-overview-1024x514.png" /></p> 
<p>&nbsp;</p> 
<p><strong>Note:</strong> For an EC2 Spot Fleet, the tags that you create for your Spot instance are not added automatically by the Spot service to fulfill the request. The Lambda function adds these tags after the Spot instance is launched.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/11/initial-deployment-group-1024x479.png" /></p> 
<p>&nbsp;</p> 
<p><strong>Example:</strong></p> 
<p>Let’s take an example of an AWS CodeDeploy application <code class="lang-html">cd-single-deploy-app</code>, and its deployment group, <code class="lang-html">cd-single-deploy-app-group</code>, which has two instances in it. These instances are not part of an Auto Scaling group.</p> 
<p>For information about the steps in deploying an application to an instance, see <a href="http://docs.aws.amazon.com/codedeploy/latest/userguide/tutorials-windows.html">this tutorial in the AWS CodeDeploy User Guide</a>.</p> 
<p>In the AWS CodeDeploy console, you’ll find the deployment ID, <code class="lang-markup">d-CSBCXR2GP</code>. We will use this ID later in the testing phase. Our workflow ensures that when a new EC2 instance is launched, it joins the deployment group automatically and the latest version of the application is deployed to it.</p> 
<p>You can configure the Lambda function, associated IAM role and policy, and the CloudWatch Events rule by running <a href="https://github.com/awslabs/aws-codedeploy-new-instance-sync-lambda/blob/master/codedeploy-sync-lambda-setup.json">this CloudFormation template</a> included in the code repository.</p> 
<p><a href="https://github.com/awslabs/aws-codedeploy-new-instance-sync-lambda">https://github.com/awslabs/aws-codedeploy-new-instance-sync-lambda</a></p> 
<p>The CloudFormation template does the following:</p> 
<p><strong>Step 1</strong>: Create an IAM role named <code class="lang-html">Auto-Deploy-EC2-Codedeploy</code> and attach the following policies:</p> 
<code class="lang-html">•	arn:aws:iam::aws:policy/AWSLambdaExecute 
•	arn:aws:iam::aws:policy/AmazonEC2ReadOnlyAccess 
•	arn:aws:iam::aws:policy/service-role/AmazonEC2SpotFleetTaggingRole 
</code> 
<p>Use the following JSON document to create another policy named CodeDeploy and attach it to the IAM role.</p> 
<code class="lang-json">{
&quot;Version&quot;: &quot;2012-10-17&quot;,
&quot;Statement&quot;: [
{
&quot;Action&quot;: [
&quot;codedeploy:Get*&quot;,
&quot;codedeploy:UpdateDeploymentGroup&quot;,
&quot;codedeploy:List*&quot;,
&quot;codedeploy:CreateDeployment&quot;
],
&quot;Resource&quot;: [
&quot;*&quot;
],
&quot;Effect&quot;: &quot;Allow&quot;,
&quot;Sid&quot;: &quot;StartContinuousAssessmentLambdaPolicyStmt&quot;
}
]
}
</code> 
<p>Make sure the CodeDeploy role has PassRole permission &nbsp;to the service role defined in the CodeDeploy deployment group.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/11/iam-role-policy-1024x460.png" /></p> 
<p><strong>Step 2:</strong> Follow these steps to create a Lambda function:</p> 
<p><a href="https://github.com/awslabs/aws-codedeploy-new-instance-sync-lambda/blob/master/README.md">https://github.com/awslabs/aws-codedeploy-new-instance-sync-lambda/blob/master/README.md</a></p> 
<p><strong>Step 3:</strong> In Amazon CloudWatch Events, set up a rule for running instances and configure the Lambda function as a target.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/11/create-cloudwatch-events-rule-1024x581.png" /></p> 
<p><strong>Step 4:</strong> In the AWS Lambda console, choose your Lambda function. On the Triggers tab, check that the trigger is enabled.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/11/lambda-trigger-1024x273.png" /></p> 
<p>You can now test to ensure if a new EC2 instance is launched, it gets synchronized automatically with the latest code</p> 
<p><strong>Test:</strong></p> 
<p>A new EC2 instance is launched from the EC2 console, the AWS CloudFormation template, or the EC2 APIs with CodeDeployApplication, CodeDeployDeploymentGroup, and&nbsp;Name tag.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/11/new-instance-launch.png" /></p> 
<p>&nbsp;</p> 
<p>Go to CloudWatch Logs console to check the Lambda execution logs.</p> 
<p>Here is an analysis of sample log:</p> 
<p>&middot;&nbsp; You should see the EC2 instance ID</p> 
<code class="lang-markup">{[
&quot;arn:aws:EC2:us-east-1:XXXXXXXXXXXX:instance/<strong>i-00203362b337dd743</strong>&quot;]
}
</code> 
<p>&middot;&nbsp; You should see the deployment ID of the last successful deployment. It should match the one you noted earlier</p> 
<p><code class="lang-markup"> DepId is <strong>d-CSBCXR2GP</strong></code></p> 
<p>&middot;&nbsp; &nbsp; Finally, you should see the deployment ID of the new deployment created by CodeDeploy</p> 
<code class="lang-markup">&quot;{u'deploymentId': u'<strong>d-W6E1TFFGP</strong>', 'ResponseMetadata': {'RetryAttempts': 0, '	HTTPStatusCode': 200, 'RequestId': '73046797-bb22-11e7-ad7b-25693e030410', 'HTTPHeaders': {'x-amzn-requestid': '73046797-bb22-11e7-ad7b-25693e030410', 'content-length': '30', 'content-type': 'application/x-amz-json-1.1'}}}
&quot;
</code> 
<p>Now, go to CodeDeploy console to confirm that the new deployment was successful.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/11/new-deployment-1024x503.png" /></p> 
<p>In this screenshot, you can see that the new EC2 instance was synched with latest code.</p> 
<p><strong>Summary:</strong></p> 
<p>In this post,&nbsp;I’ve&nbsp;demonstrated how to use AWS CodeDeploy, AWS Lambda, an Amazon CloudWatch Events rule, and EC2 tags to automate deployments to disparate EC2 instances. If you are running your workload on Spot instances or have a fleet of On-Demand EC2 instances as part of your application, you can use the steps in this blog post to solve the automation around the deployment for new instances.</p> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<meta property="image" content="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/12/CD_to_K8-934x630.png" /> 
<b class="lb-b blog-post-title" property="name headline">Continuous Deployment to Kubernetes using AWS CodePipeline, AWS CodeCommit, AWS CodeBuild, Amazon ECR and AWS Lambda</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Chris Barclay</span></span> | on 
<time property="datePublished" datetime="2018-01-11T09:45:58+00:00">11 JAN 2018</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/devops/category/developer-tools/aws-codebuild/" title="View all posts in AWS CodeBuild*"><span property="articleSection">AWS CodeBuild*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/developer-tools/aws-codecommit/" title="View all posts in AWS CodeCommit*"><span property="articleSection">AWS CodeCommit*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/developer-tools/aws-codepipeline/" title="View all posts in AWS CodePipeline*"><span property="articleSection">AWS CodePipeline*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/developer-tools/" title="View all posts in Developer Tools*"><span property="articleSection">Developer Tools*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/devops/continuous-deployment-to-kubernetes-using-aws-codepipeline-aws-codecommit-aws-codebuild-amazon-ecr-and-aws-lambda/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p>Thank you to my colleague Omar Lari for this blog on how to create a continuous deployment pipeline for Kubernetes!</p> 
<hr /> 
<p>You can use Kubernetes and AWS together to create a fully managed, continuous deployment pipeline for container based applications. This approach takes advantage of Kubernetes’ open-source system to manage your containerized applications, and the AWS developer tools to manage your source code, builds, and pipelines.</p> 
<p>This post describes how to create a continuous deployment architecture for containerized applications. It uses AWS CodeCommit, AWS CodePipeline, AWS CodeBuild, and AWS Lambda to deploy containerized applications into a Kubernetes cluster. In this environment, developers can remain focused on developing code without worrying about how it will be deployed, and development managers can be satisfied that the latest changes are always deployed.</p> 
<b>What is Continuous Deployment?</b> 
<p>There are many articles, posts and even conferences dedicated to the practice of continuous deployment. For the purposes of this post, I will summarize continuous delivery into the following points:</p> 
<li>Code is more frequently released into production environments</li> 
<li>More frequent releases allow for smaller, incremental changes reducing risk and enabling simplified roll backs if needed</li> 
<li>Deployment is automated and requires minimal user intervention</li> 
<p>For a more information, see “<a href="https://d1.awsstatic.com/whitepapers/DevOps/practicing-continuous-integration-continuous-delivery-on-AWS.pdf">Practicing Continuous Integration and Continuous Delivery on AWS</a>”.</p> 
<b>How can you use continuous deployment with AWS and Kubernetes?</b> 
<p>You can leverage AWS services that support continuous deployment to automatically take your code from a source code repository to production in a Kubernetes cluster with minimal user intervention. To do this, you can create a pipeline that will build and deploy committed code changes as long as they meet the requirements of each stage of the pipeline.</p> 
<p>To create the pipeline, you will use the following services:</p> 
<li><strong>AWS CodePipeline.</strong> AWS CodePipeline is a continuous delivery service that models, visualizes, and automates the steps required to release software. You define stages in a pipeline to retrieve code from a source code repository, build that source code into a releasable artifact, test the artifact, and deploy it to production. Only code that successfully passes through all these stages will be deployed. In addition, you can optionally add other requirements to your pipeline, such as manual approvals, to help ensure that only approved changes are deployed to production.</li> 
<li><strong>AWS CodeCommit.</strong> AWS CodeCommit is a secure, scalable, and managed source control service that hosts private Git repositories. You can privately store and manage assets such as your source code in the cloud and configure your pipeline to automatically retrieve and process changes committed to your repository.</li> 
<li><strong>AWS CodeBuild.</strong> AWS CodeBuild is a fully managed build service that compiles source code, runs tests, and produces artifacts that are ready to deploy. You can use AWS CodeBuild to both build your artifacts, and to test those artifacts before they are deployed.</li> 
<li><strong>AWS Lambda.</strong> AWS Lambda is a compute service that lets you run code without provisioning or managing servers. You can invoke a Lambda function in your pipeline to prepare the built and tested artifact for deployment by Kubernetes to the Kubernetes cluster.</li> 
<li><strong>Kubernetes.</strong> Kubernetes is an open-source system for automating deployment, scaling, and management of containerized applications. It provides a platform for running, deploying, and managing containers at scale.</li> 
<b>An Example of Continuous Deployment to Kubernetes:</b> 
<p>The following example illustrates leveraging AWS developer tools to continuously deploy to a Kubernetes cluster:</p> 
<p><img src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/11/k8s-code.png" /></p> 
<ol> 
<li>Developers commit code to an AWS CodeCommit repository and create pull requests to review proposed changes to the production code. When the pull request is merged into the master branch in the AWS CodeCommit repository, AWS CodePipeline automatically detects the changes to the branch and starts processing the code changes through the pipeline.</li> 
<li>AWS CodeBuild packages the code changes as well as any dependencies and builds a Docker image. Optionally, another pipeline stage tests the code and the package, also using AWS CodeBuild.</li> 
<li>The Docker image is pushed to Amazon ECR after a successful build and/or test stage.</li> 
<li>AWS CodePipeline invokes an AWS Lambda function that includes the Kubernetes Python client as part of the function’s resources. The Lambda function performs a string replacement on the tag used for the Docker image in the Kubernetes deployment file to match the Docker image tag applied in the build, one that matches the image in Amazon ECR.</li> 
<li>After the deployment manifest update is completed, AWS Lambda invokes the Kubernetes API to update the image in the Kubernetes application deployment.</li> 
<li>Kubernetes performs a rolling update of the pods in the application deployment to match the docker image specified in Amazon ECR.<br /> The pipeline is now live and responds to changes to the master branch of the CodeCommit repository. This pipeline is also fully extensible, you can add steps for performing testing or adding a step to deploy into a staging environment before the code ships into the production cluster.</li> 
</ol> 
<p>An example pipeline in AWS CodePipeline that supports this architecture can be seen below:</p> 
<p><img src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/11/codepipeline-k8s.png" /></p> 
<b>Conclusion</b> 
<p>We are excited to see how you leverage this pipeline to help ease your developer experience as you develop applications in Kubernetes.</p> 
<p>You’ll find an AWS CloudFormation template with everything necessary to spin up your own continuous deployment pipeline at the <a href="https://github.com/aws-samples/aws-kube-codesuite">CodeSuite – Continuous Deployment Reference Architecture for Kubernetes</a> repo on GitHub. The repository details exactly how the pipeline is provisioned and how you can use it to deploy your own applications. If you have any questions, feedback, or suggestions, please let us know!</p> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<meta property="image" content="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/03/HA_X-Ray_SOCIAL.png" /> 
<b class="lb-b blog-post-title" property="name headline">Aspect-Oriented Programming for AWS X-Ray Using Spring</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Bharath Kumar</span></span> | on 
<time property="datePublished" datetime="2017-12-28T14:26:41+00:00">28 DEC 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/devops/category/developer-tools/aws-x-ray/" title="View all posts in AWS X-Ray*"><span property="articleSection">AWS X-Ray*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/developer-tools/" title="View all posts in Developer Tools*"><span property="articleSection">Developer Tools*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/devops/aspect-oriented-programming-for-aws-x-ray-using-spring/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-2002" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-devops-blog&amp;disqus_identifier=2002&amp;disqus_title=Aspect-Oriented+Programming+for+AWS+X-Ray+Using+Spring&amp;disqus_url=https://aws.amazon.com/blogs/devops/aspect-oriented-programming-for-aws-x-ray-using-spring/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-2002');
});
</script> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p>This post was written by Andy Powell, Partner Solutions Architect.</p> 
<p>For developers, tracing and instrumenting code is one of the most valuable tools when debugging code. When you are developing locally, you can use local debugging and profiling tools, but when you deploy an application to the cloud, the task is more challenging. In this blog post, we will look at a new way to instrument your application using AWS X-Ray without adding tracing code to your business logic.</p> 
<b>AWS X-Ray</b> 
<p>Released to the public earlier this year, <a title="undefined" href="https://aws.amazon.com/xray/" target="null">AWS X-Ray</a> provides a mechanism for developers to instrument and trace their code while running on AWS. AWS X-Ray enables developers to analyze and debug distributed applications through the entire AWS stack. Developers and operations personnel can also follow the flow of a request through the entire AWS infrastructure. X-Ray works well in a monolithic or microservices model. Either way, developers can get a complete view of their application’s performance and behavior.</p> 
<p>X-Ray provides two key mechanisms for analyzing an application:</p> 
<li>The service map.</li> 
<li>The trace view.</li> 
<p>The service map, shown here, provides a high-level view of the services consumed by an application and their relative health:</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/12/26/Picture1.png" /></p> 
<p>Application developers often look for a more detailed view of their application to help them answer questions like “Which functions are my bottlenecks?” and “Where is the most latency in the application?” The trace view allows you to see the flow of an application through service calls. &nbsp;It&nbsp;shows you latency between services and the exact execution time of each X-Ray segment.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/12/27/Picture2.png" /></p> 
<p>Similar to other logging and metrics frameworks, X-Ray requires the developer to insert specific code throughout the application. This might cause issues because the logging and metrics code has the potential to increase the complexity of the application code. Increased complexity leads, in turn, to increased maintenance and testing costs. Ideally, developers should add X-Ray tracing to an application in a non-invasive manner, one that does not affect the underlying business logic.</p> 
<b>Aspect-oriented programming and the Spring Framework</b> 
<p>Aspect-oriented programming (AOP) is a mechanism by which code runs either before, after, or around a target function. The code that runs outside the target code is called an aspect. An aspect provides the ability to perform actions like logging, transaction management, and method retries. The goal is for the aspect to provide these capabilities without affecting the target code. Pointcuts define where these aspects should act in the code. AOP allows developers to leverage powerful functionality without affecting their business logic.</p> 
<p>An aspect-oriented approach is a perfect way to implement AWS X-Ray because it keeps the underlying code clean and provides non-invasive, reusable tracing logic.</p> 
<p>Simply creating an aspect to invoke X-Ray is not enough. We also have to create pointcuts that tell the aspect where to act. These pointcuts will define which methods we wrap with tracing logic. After they are defined, the aspect sends the entire call stack to X-Ray for visualization.</p> 
<p>The Spring Framework is a common application framework for the development of Java software. It provides an extensive programming and config method for modern Java applications.</p> 
<p>Spring provides facilities for a range of application functions, including web applications, messaging applications, and streaming data applications. Spring applications are capable of being cloud-native from the onset.</p> 
<p>AOP is one of the core components of the Spring Framework. Spring’s implementation of AOP “weaves” application code at runtime. Load-time weaving is also available, but it requires extra configuration at compile or application runtime to work properly. The Spring runtime weaving does not require any special compilation or agents.</p> 
<b>AWS X-Ray Spring extensions</b> 
<p>Starting with version 1.3.0, the AWS X-Ray SDK lets you use AOP in the Spring Framework to instrument code with no change to the application’s business logic. This means that there is now a non-invasive way to instrument your applications running remotely in AWS.</p> 
<p>To include the extension in the code, first add the dependency to the application. If you are using Maven, you add the dependency this way:</p> 
<code class="lang-xml">&lt;dependency&gt; 
&lt;groupId&gt;com.amazonaws&lt;/groupId&gt; 
&lt;artifactId&gt;aws-xray-recorder-sdk-spring&lt;/artifactId&gt; 
&lt;version&gt;1.3.0&lt;/version&gt; 
&lt;/dependency&gt;
</code> 
<p>If you are using Gradle, use the following syntax:</p> 
<code class="lang-xml">compile 'com.amazonaws:aws-xray-recorder-sdk-spring:1.3.0'</code> 
<p>After you’ve included this in your application, there are a couple of steps that need configuration before tracing is enabled. First, classes must either be annotated with the <em>@XRayEnabled</em> annotation, or implement the <em>XRayTraced</em> interface. This tells the AOP system to wrap the functions of the affected class for X-Ray instrumentation.</p> 
<p>Second, you need an interceptor to actually wrap the code. This involves extending an abstract class, <em>AbstractXRayInterceptor</em>, to activate X-Ray tracing in the application. The <em>AbstractXRayInterceptor</em> contains methods that must be overridden:</p> 
<li><em>generateMetadata</em> – This function allows customization of the metadata attached to the current function’s trace. &nbsp;By default, the class name of the executing function is recorded in the metadata. &nbsp;You can add more data if you need additional insights.</li> 
<li><em>xrayEnabledClasses</em> – This function is empty, and should remain so. &nbsp;It serves as the host for a pointcut instructing the interceptor about which methods to wrap. &nbsp; The developer should define the pointcut. &nbsp;&nbsp;You can specify which classes that are annotated with XRayEnabled you want traced. &nbsp;A pointcut statement of &nbsp;<em>@Pointcut(“@within(com.amazonaws.xray.spring.aop.XRayEnabled) &amp;&amp; bean(*Controller)”)</em>&nbsp;tells the interceptor to wrap all controller beans annotated with the <em>@XRayEnabled</em> annotation.</li> 
<p>Here is a sample implementation of the <em>AbstractXRayInterceptor</em> :</p> 
<code class="lang-java">@Aspect
@Component
public class XRayInspector extends AbstractXRayInterceptor {    
@Override    
protected Map&lt;String, Map&lt;String, Object&gt;&gt; generateMetadata(ProceedingJoinPoint proceedingJoinPoint, Subsegment subsegment) throws Exception {      
return super.generateMetadata(proceedingJoinPoint, subsegment);    
}    
@Override    
@Pointcut(&quot;@within(com.amazonaws.xray.spring.aop.XRayEnabled) &amp;&amp; bean(*Controller)&quot;)    
public void xrayEnabledClasses() {}
}
</code> 
<p>Here is an example of a Service class that will be instrumented by X-Ray:</p> 
<code class="lang-java">@Service
@XRayEnabled
public class MyServiceImpl implements MyService {    
private final MyEntityRepository myEntityRepository;    
@Autowired    
public MyServiceImpl(MyEntityRepository myEntityRepository) {        
this.myEntityRepository = myEntityRepository;    
}    
@Transactional(readOnly = true)    
public List&lt;MyEntity&gt; getMyEntities(){        
try(Stream&lt;MyEntity&gt; entityStream = this.myEntityRepository.streamAll()){            
return entityStream.sorted().collect(Collectors.toList());        
}    
}
}
</code> 
<p>By default, the <em>AbstractXRayInterceptor</em> instruments around all Spring data repository instances.</p> 
<p>After it’s configured, the Spring application runs as normal. The X-Ray interceptor&nbsp; picks up annotated classes automatically and builds a trace of the call stack. You can view this call stack in the Traces section of the X-Ray console.</p> 
<p><code><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/12/27/Picture3.png" /></code></p> 
<p>Looking at the trace, you will see the complete call stack of the application, from the controller down through the service calls. Stack traces are arranged in a hierarchy in the same way as typical X-Ray traces. Any exceptions that occur in the call stack are added to the trace by the interceptor automatically. This gives you a complete view of the application’s functionality, performance, and error states. &nbsp;X-Ray provides the convenience of a managed service of the tracing and reporting engine. &nbsp;Without it, the developer would have to manage the tracing and reporting infrastructure.</p> 
<b>Conclusion</b> 
<p>On its own, X-Ray provides powerful functionality to trace your applications running on AWS. When you combine the service with the ease of use of AOP and the Spring Framework, it is a natural fit.</p> 
<p>The demo app code is available for <a href="https://github.com/aws/aws-xray-sdk-java" title="undefined" target="null">download</a>. Download it today and start integrating deep tracing into your Spring applications.</p> 
<h4>Note</h4> 
<p><a href="https://github.com/aws/aws-xray-sdk-java" title="undefined" target="null">AWS X-Ray SDK for Java</a> v1.3.0 will be available on maven central in the next few days. In the meantime, you can follow the below steps to use the latest version from the GitHub repo:</p> 
<p>1. Clone the AWS X-Ray SDK for Java repo locally.<br /> 2. In the project root, run “mvn clean install -Dgpg.skip=true”.<br /> 3. Reference version 1.3.0 in your maven / gradle files as mentioned in the blog post.</p> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-2002');
});
</script> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">Instrumenting Web Apps Using AWS X-Ray</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Bharath Kumar</span></span> | on 
<time property="datePublished" datetime="2017-12-28T14:25:45+00:00">28 DEC 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/devops/category/developer-tools/aws-x-ray/" title="View all posts in AWS X-Ray*"><span property="articleSection">AWS X-Ray*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/developer-tools/" title="View all posts in Developer Tools*"><span property="articleSection">Developer Tools*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/devops/instrumenting-web-apps-using-aws-x-ray/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p>This post was written by James Bowman, Software Development Engineer, AWS X-Ray</p> 
<p><a title="undefined" href="https://aws.amazon.com/xray/" target="null">AWS X-Ray</a> helps developers analyze and debug distributed applications and underlying services in production. You can identify and analyze root-causes of performance issues and errors, understand customer impact, and extract statistical aggregations (such as histograms) for optimization.</p> 
<p>In this blog post, I will provide a step-by-step walkthrough for enabling X-Ray tracing in the Go programming language. You can use these steps to add X-Ray tracing to any distributed application.</p> 
<b>Revel: A web framework for the Go language</b> 
<p>This section will assist you with designing a guestbook application. Skip to <strong>“Instrumenting with AWS X-Ray”</strong> section below if you already have a Go language application.</p> 
<p><a title="undefined" href="https://revel.github.io/" target="null">Revel</a> is a web framework for the Go language. It facilitates the rapid development of web applications by providing a predefined framework for controllers, views, routes, filters, and more.</p> 
<p>To get started with Revel, run <code>revel new github.com/jamesdbowman/guestbook</code>. A project base is then copied to <code>$GOPATH/src/github.com/jamesdbowman/guestbook</code>.</p> 
<p><code>$ tree -L 2<br /> .<br /> ├── README.md<br /> ├── app<br /> │ ├── controllers<br /> │ ├── init.go<br /> │ ├── routes<br /> │ ├── tmp<br /> │ └── views<br /> ├── conf<br /> │ ├── app.conf<br /> │ └── routes<br /> ├── messages<br /> │ └── sample.en<br /> ├── public<br /> │ ├── css<br /> │ ├── fonts<br /> │ ├── img<br /> │ └── js<br /> └── tests<br /> └── apptest.go<br /> </code></p> 
<h3>Writing a guestbook application</h3> 
<p>A basic guestbook application can consist of just two routes: one to sign the guestbook and another to list all entries.<br /> Let’s set up these routes by adding a Book controller, which can be routed to by modifying <code>./conf/routes.</code></p> 
<code class="lang-go">./app/controllers/book.go:
package controllers
import (
&quot;math/rand&quot;
&quot;time&quot;
&quot;github.com/aws/aws-sdk-go/aws&quot;
&quot;github.com/aws/aws-sdk-go/aws/endpoints&quot;
&quot;github.com/aws/aws-sdk-go/aws/session&quot;
&quot;github.com/aws/aws-sdk-go/service/dynamodb&quot;
&quot;github.com/aws/aws-sdk-go/service/dynamodb/dynamodbattribute&quot;
&quot;github.com/bowmessage/test/xray&quot;
&quot;github.com/revel/revel&quot;
)
const tableName = &quot;guestbook&quot;
const success = &quot;Success.\n&quot;
var letters = []rune(&quot;ABCDEFGHIJKLMNOPQRSTUVWXYZ&quot;)
func init() {
rand.Seed(time.Now().UnixNano())
}
// randString returns a random string of len n, used for DynamoDB Hash key.
func randString(n int) string {
b := make([]rune, n)
for i := range b {
b[i] = letters[rand.Intn(len(letters))]
}
return string(b)
}
// Book controls interactions with the guestbook.
type Book struct {
*revel.Controller
ddbClient *dynamodb.DynamoDB
}
// Signature represents a user's signature.
type Signature struct {
Message string
Epoch   int64
ID      string
}
// ddb returns the controller's DynamoDB client, instatiating a new client if necessary.
func (c Book) ddb() *dynamodb.DynamoDB {
if c.ddbClient == nil {
sess := session.Must(session.NewSession(&amp;aws.Config{
Region:     aws.String(endpoints.UsWest2RegionID),
MaxRetries: aws.Int(3),
}))
c.ddbClient = dynamodb.New(sess)
xray.AWS(c.ddbClient.Client) // add subsegment-generating X-Ray handlers to this client
}
return c.ddbClient
}
// Sign allows users to sign the book.
// The message is to be passed as application/json typed content, listed under the &quot;message&quot; top level key.
func (c Book) Sign() revel.Result {
var s Signature
err := c.Params.BindJSON(&amp;s)
if err != nil {
return c.RenderError(err)
}
now := time.Now()
s.Epoch = now.Unix()
s.ID = randString(20)
item, err := dynamodbattribute.MarshalMap(s)
if err != nil {
return c.RenderError(err)
}
putItemInput := &amp;dynamodb.PutItemInput{
TableName: aws.String(tableName),
Item:      item,
}
goRequest := c.Request.In.(*revel.GoRequest)
_, err = c.ddb().PutItemWithContext(goRequest.Original.Context(), putItemInput)
if err != nil {
return c.RenderError(err)
}
return c.RenderText(success)
}
// List allows users to list all signatures in the book.
func (c Book) List() revel.Result {
scanInput := &amp;dynamodb.ScanInput{
TableName: aws.String(tableName),
Limit:     aws.Int64(100),
}
goRequest := c.Request.In.(*revel.GoRequest)
res, err := c.ddb().ScanWithContext(goRequest.Original.Context(), scanInput)
if err != nil {
return c.RenderError(err)
}
messages := make([]string, 0)
for _, v := range res.Items {
messages = append(messages, *(v[&quot;Message&quot;].S))
}
return c.RenderJSON(messages)
}
</code> 
<p><code>./conf/routes:<br /> POST /sign Book.Sign<br /> GET /list Book.List<br /> </code></p> 
<h3>Creating the resources and testing</h3> 
<p>For the purposes of this blog post, the application will be run and tested locally. We will store and retrieve messages from an <a title="undefined" href="https://aws.amazon.com/dynamodb/" target="null">Amazon DynamoDB</a> table. Use the following AWS CLI command to create the guestbook table:</p> 
<code class="lang-bash">aws dynamodb create-table --region us-west-2 --table-name &quot;guestbook&quot; --attribute-definitions AttributeName=ID,AttributeType=S AttributeName=Epoch,AttributeType=N --key-schema AttributeName=ID,KeyType=HASH AttributeName=Epoch,KeyType=RANGE --provisioned-throughput ReadCapacityUnits=5,WriteCapacityUnits=5</code> 
<p>Now, let’s test our sign and list routes. If everything is working correctly, the following result appears:</p> 
<code class="lang-bash">$ curl -d '{&quot;message&quot;:&quot;Hello from cURL!&quot;}' -H &quot;Content-Type: application/json&quot; http://localhost:9000/book/sign
Success.
$ curl http://localhost:9000/book/list
[
&quot;Hello from cURL!&quot;
]%
</code> 
<b>Integrating with AWS X-Ray</b> 
<h3>Download and run the AWS X-Ray daemon</h3> 
<p>The AWS SDKs emit trace segments over UDP on port 2000. (This port can be configured.) In order for the trace segments to make it to the X-Ray service, the daemon must listen on this port and batch the segments in calls to the PutTraceSegments API.<br /> For information about downloading and running the X-Ray daemon, see the <a title="undefined" href="http://docs.aws.amazon.com/xray/latest/devguide/xray-daemon.html" target="null">AWS X-Ray Developer Guide</a>.</p> 
<h3>Installing the AWS X-Ray SDK for Go</h3> 
<p>To download the SDK from GitHub, run <code>go get -u github.com/aws/aws-xray-sdk-go/...</code> The SDK will appear in the <code>$GOPATH</code>.</p> 
<h3>Enabling the incoming request filter</h3> 
<p>The first step to instrumenting an application with AWS X-Ray is to enable the generation of trace segments on incoming requests. The SDK conveniently provides an implementation of <code>http.Handler</code> which does exactly that. To ensure incoming web requests travel through this handler, we can modify <code>app/init.go</code>, adding a custom function to be run on application start.</p> 
<code class="lang-go">import (
&quot;github.com/aws/aws-xray-sdk-go/xray&quot;
&quot;github.com/revel/revel&quot;
)
...
func init() {
...
revel.OnAppStart(installXRayHandler)
}
func installXRayHandler() {
server := revel.CurrentEngine.Engine().(*http.Server)
server.Handler = xray.Handler(xray.NewFixedSegmentNamer(&quot;GuestbookApp&quot;), server.Handler)
}
</code> 
<p>The application will now emit a segment for each incoming web request. The service graph appears:<br /> <img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/12/28/Screen-Shot-2017-12-21-at-3.00.24-PM-1024x508.png" /></p> 
<p>You can customize the name of the segment to make it more descriptive by providing an alternate implementation of <code>SegmentNamer</code> to <code>xray.Handler</code>. For example, you can use <code>xray.NewDynamicSegmentNamer(fallback, pattern)</code> in place of the fixed namer. This namer will use the host name from the incoming web request (if it matches <code>pattern</code>) as the segment name. This is often useful when you are trying to separate different instances of the same application.</p> 
<p>In addition, HTTP-centric information such as method and URL is collected in the segment’s <code>http</code> subsection:</p> 
<code class="lang-json">&quot;http&quot;: {
&quot;request&quot;: {
&quot;url&quot;: &quot;/book/list&quot;,
&quot;method&quot;: &quot;GET&quot;,
&quot;user_agent&quot;: &quot;curl/7.54.0&quot;,
&quot;client_ip&quot;: &quot;::1&quot;
},
&quot;response&quot;: {
&quot;status&quot;: 200
}
},
</code> 
<h3>Instrumenting outbound calls</h3> 
<p>To provide detailed performance metrics for distributed applications, the AWS X-Ray SDK needs to measure the time it takes to make outbound requests. Trace context is passed to downstream services using the <code>X-Amzn-Trace-Id</code> header. To draw a detailed and accurate representation of a distributed application, outbound call instrumentation is required.</p> 
<h3>AWS SDK calls</h3> 
<p>The AWS X-Ray SDK for Go provides a one-line AWS client wrapper that enables the collection of detailed per-call metrics for any AWS client. We can modify the DynamoDB client instantiation to include this line:</p> 
<code class="lang-go">// ddb returns the controller's DynamoDB client, instatiating a new client if necessary.
func (c Book) ddb() *dynamodb.DynamoDB {
if c.ddbClient == nil {
sess := session.Must(session.NewSession(&amp;aws.Config{
Region: aws.String(endpoints.UsWest2RegionID),
}))
c.ddbClient = dynamodb.New(sess)
xray.AWS(c.ddbClient.Client) // add subsegment-generating X-Ray handlers to this client
}
return c.ddbClient
}
</code> 
<p>We also need to ensure that the segment generated by our <code>xray.Handler</code> is passed to these AWS calls so that the X-Ray SDK knows to which segment these generated subsegments belong. In Go, the <code>context.Context</code> object is passed throughout the call path to achieve this goal. (In most other languages, some variant of <code>ThreadLocal</code> is used.) AWS clients provide a <code>*WithContext</code> method variant for each AWS operation, which we need to switch to:</p> 
<code class="lang-go">_, err = c.ddb().PutItemWithContext(c.Request.Context(), putItemInput)
res, err := c.ddb().ScanWithContext(c.Request.Context(), scanInput)
</code> 
<p>We now see much more detail in the <strong>Timeline</strong> view of the trace for the sign and list operations:<br /> <img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/12/28/Screen-Shot-2017-12-21-at-3.02.51-PM-1024x722.png" /></p> 
<p>We can use this detail to help diagnose throttling on our DynamoDB table. In the following screenshot, the purple in the DynamoDB service graph node indicates that our table is underprovisioned. The red in the GuestbookApp node indicates that the application is throwing faults due to this throttling.<br /> <img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/12/28/Screen-Shot-2017-12-21-at-3.19.16-PM-1024x326.png" /></p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/12/28/Screen-Shot-2017-12-21-at-3.20.17-PM-1024x709.png" /></p> 
<h3>HTTP calls</h3> 
<p>Although the guestbook application does not make any non-AWS outbound HTTP calls in its current state, there is a similar one-liner to wrap HTTP clients that make outbound requests. <code>xray.Client(c *http.Client)</code> wraps an existing <code>http.Client</code> (or <code>nil</code> if you want to use a default HTTP client). For example:</p> 
<code class="lang-go">resp, err := ctxhttp.Get(ctx, xray.Client(nil), &quot;https://aws.amazon.com/&quot;)</code> 
<h3>Instrumenting local operations</h3> 
<p>X-Ray can also assist in measuring the performance of local compute operations. To see this in action, let’s create a custom subsegment inside the <code>randString</code> method:</p> 
<code class="lang-go">
// randString returns a random string of len n, used for DynamoDB Hash key.
func randString(ctx context.Context, n int) string {
xray.Capture(ctx, &quot;randString&quot;, func(innerCtx context.Context) {
b := make([]rune, n)
for i := range b {
b[i] = letters[rand.Intn(len(letters))]
}
s := string(b)
})
return s
}
// we'll also need to change the callsite
s.ID = randString(c.Request.Context(), 20)
</code> 
<b>Summary</b> 
<p>By now, you are an expert on how to instrument X-Ray for your Go applications. Instrumenting X-Ray with your applications is an easy way to analyze and debug performance issues and understand customer impact. Please feel free to give any feedback or comments below.</p> 
<p>For more information about advanced configuration of the AWS X-Ray SDK for Go, see the <a title="undefined" href="http://docs.aws.amazon.com/xray/latest/devguide/xray-sdk-go.html" target="null">AWS X-Ray SDK for Go</a> in the AWS X-Ray Developer Guide and the <a title="undefined" href="https://github.com/aws/aws-xray-sdk-go" target="null">aws/aws-xray-sdk-go GitHub repository</a>.</p> 
<p>For more information about some of the advanced X-Ray features such as histograms, annotations, and filter expressions, see the <a title="undefined" href="https://aws.amazon.com/blogs/compute/analyzing-performance-for-amazon-rekognition-apps-written-on-aws-lambda-using-aws-x-ray/" target="null">Analyzing Performance for Amazon Rekognition Apps Written on AWS Lambda Using AWS X-Ray</a> blog post.</p> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<meta property="image" content="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/03/architecture-1-1120x630.png" /> 
<b class="lb-b blog-post-title" property="name headline">Using Amazon CloudWatch and Amazon SNS to Notify when AWS X-Ray Detects Elevated Levels of Latency, Errors, and Faults in Your Application</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Bharath Kumar</span></span> | on 
<time property="datePublished" datetime="2017-12-20T13:11:00+00:00">20 DEC 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/devops/category/developer-tools/aws-x-ray/" title="View all posts in AWS X-Ray*"><span property="articleSection">AWS X-Ray*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/developer-tools/" title="View all posts in Developer Tools*"><span property="articleSection">Developer Tools*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/devops/using-amazon-cloudwatch-and-amazon-sns-to-notify-when-aws-x-ray-detects-elevated-levels-of-latency-errors-and-faults-in-your-application/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><a href="https://aws.amazon.com/xray/">AWS X-Ray</a> helps developers analyze and debug production applications built using microservices or serverless architectures and quantify customer impact. With X-Ray, you can understand how your application and its underlying services are performing and identify and troubleshoot the root cause of performance issues and errors. You can use these insights to identify issues and opportunities for optimization.</p> 
<p>In this blog post, I will show you how you can use <a href="https://aws.amazon.com/cloudwatch/">Amazon CloudWatch</a> and <a href="https://aws.amazon.com/sns/">Amazon SNS</a> to get notified when X-Ray detects high latency, errors, and faults in your application. Specifically, I will show you how to use this <a href="https://github.com/aws-samples/aws-xray-cloudwatch-event">sample app</a> to get notified through an email or SMS message when your end users observe high latencies or server-side errors when they use your application. You can customize the alarms and events by updating the sample app code.</p> 
<b>Sample App Overview</b> 
<p>The sample app uses the X-Ray GetServiceGraph API to get the following information:</p> 
<li>Aggregated response time.</li> 
<li>Requests that failed with 4xx status code (errors).</li> 
<li>429 status code (throttle).</li> 
<li>5xx status code (faults).</li> 
<img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/12/19/architecture-1024x576.png" /> 
<p class="wp-caption-text">Overview of sample app architecture</p> 
<h3>Getting started</h3> 
<p>The sample app uses AWS CloudFormation to deploy the required resources.<br /> To install the sample app:</p> 
<ol> 
<li>Run git clone to get the sample app.</li> 
<li>Update the JSON file in the Setup folder with threshold limits and notification details.</li> 
<li>Run the install.py script to install the sample app.</li> 
</ol> 
<p>For more information about the installation steps, see the <a title="undefined" href="https://github.com/aws-samples/aws-xray-cloudwatch-event/blob/master/README.md" target="null">readme</a> file on GitHub.</p> 
<p>You can update the app configuration to include your phone number or email to get notified when your application in X-Ray breaches the latency, error, and fault limits you set in the configuration. If you prefer to not provide your phone number and email, then you can use the CloudWatch alarm deployed by the sample app to monitor your application in X-Ray.</p> 
<p>The sample app deploys resources with the sample app namespace you provided during setup. This enables you to have multiple sample apps in the same region.</p> 
<h3>CloudWatch rules</h3> 
<p>The sample app uses two CloudWatch rules:</p> 
<ol> 
<li><em>SCHEDULEDLAMBDAFOR-sample_app_name</em> to trigger at regular intervals the AWS Lambda function that queries the GetServiceGraph API.</li> 
<li><em>XRAYALERTSFOR-sample_app_name</em> to look for published CloudWatch events that match the pattern defined in this rule.</li> 
</ol> 
<img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/12/19/CloudWatch-Rules-1024x255.png" /> 
<p class="wp-caption-text">CloudWatch rules created for the sample app</p> 
<h3>CloudWatch alarms</h3> 
<p>If you did not provide your phone number or email in the JSON file, the sample app uses a CloudWatch alarm named <em>XRayCloudWatchAlarm-sample_app_name</em> in combination with the CloudWatch event that you can use for monitoring.</p> 
<img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/12/19/CloudWatch-Alarm-1024x265.png" /> 
<p class="wp-caption-text">CloudWatch alarm created for the sample app</p> 
<h3>Amazon SNS messages</h3> 
<p>The sample app creates two SNS topics:</p> 
<li><em>sample_app_name-cloudwatcheventsnstopic</em> to send out an SMS message when the CloudWatch event matches a pattern published from the Lambda function.</li> 
<li><em>sample_app_name-cloudwatchalarmsnstopic</em> to send out an email message when the CloudWatch alarm goes into an ALARM state.</li> 
<img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/12/19/Amazon-SNS.png" /> 
<p class="wp-caption-text">Amazon SNS created for the sample app</p> 
<b>Getting notifications</b> 
<p>The CloudWatch event looks for the following matching pattern:<br /> <code></code></p> 
<code class="lang-json">{
&quot;detail-type&quot;: [
&quot;XCW Notification for Alerts&quot;
],
&quot;source&quot;: [
&quot;&lt;sample_app_name&gt;-xcw.alerts&quot;
]
}
</code> 
<p>The event then invokes an SNS topic that sends out an SMS message.</p> 
<img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/12/19/sms-169x300.png" /> 
<p class="wp-caption-text">SMS that is sent when CloudWatch Event invokes Amazon SNS topic</p> 
<p>The CloudWatch alarm looks for the <em><a title="undefined" href="http://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/cwe-metricscollected.html" target="null">TriggeredRules</a></em> metric that is published whenever the CloudWatch event matches the event pattern. It goes into the <em>ALARM</em> state whenever <em>TriggeredRules &gt; 0</em> for the specified evaluation period and invokes an SNS topic that sends an email message.</p> 
<img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/12/19/email-1024x488.png" /> 
<p class="wp-caption-text">Email that is sent when CloudWatch Alarm goes to ALARM state</p> 
<b>Stopping notifications</b> 
<p>If you provided your phone number or email address, but would like to stop getting notified, change the <em>SUBSCRIBE_TO_EMAIL_SMS</em> environment variable in the Lambda function to <strong>No</strong>. Then, go to the Amazon SNS console and delete the subscriptions. You can still monitor your application for elevated levels of latency, errors, and faults by using the CloudWatch console.</p> 
<img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/12/19/lambdaenvironmentvariable-1024x160.png" /> 
<p class="wp-caption-text">Change environment variable in Lambda</p> 
<p>&nbsp;</p> 
<img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/12/19/deletesubscriptions-1024x228.png" /> 
<p class="wp-caption-text">Delete subscriptions to stop getting notified</p> 
<b>Uninstalling the sample app</b> 
<p>To uninstall the sample app, run the <em>uninstall.py</em> script in the Setup folder.</p> 
<b>Extending the sample app</b> 
<p>The sample app notifes you when when X-Ray detects high latency, errors, and faults in your application. You can extend it to provide more value for your use cases (for example, to perform an action on a resource when the state of a CloudWatch alarm changes).</p> 
<p>To summarize, after this set up you will be able to get notified through Amazon SNS when X-Ray detects high latency, errors and faults in your application.</p> 
<p>I hope you found this information about setting up alarms and alerts for your application in AWS X-Ray helpful. Feel free to leave questions or other feedback in the comments. Feel free to learn more about <a href="https://aws.amazon.com/xray/">AWS X-Ray</a>, <a href="https://aws.amazon.com/sns/">Amazon SNS</a> and <a href="https://aws.amazon.com/cloudwatch">Amazon CloudWatch</a></p> 
<h3>About the Author</h3> 
<p><a title="undefined" href="https://www.linkedin.com/in/bharathkumarvenkateshkumar/" target="null">Bharath Kumar</a> is a Sr.Product Manager with AWS X-Ray. He has developed and launched mobile games, web applications on microservices and serverless architecture.</p> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<meta property="image" content="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/03/custom-source-actions.png" /> 
<b class="lb-b blog-post-title" property="name headline">Using Custom Source Actions in AWS CodePipeline for Increased Visibility for Third-Party Source Control</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Tom Schultz</span></span> | on 
<time property="datePublished" datetime="2017-11-27T11:11:57+00:00">27 NOV 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/devops/category/application-services/amazon-api-gateway-application-services/" title="View all posts in Amazon API Gateway*"><span property="articleSection">Amazon API Gateway*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/management-tools/aws-cloudformation/" title="View all posts in AWS CloudFormation*"><span property="articleSection">AWS CloudFormation*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/developer-tools/aws-codecommit/" title="View all posts in AWS CodeCommit*"><span property="articleSection">AWS CodeCommit*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/developer-tools/aws-codepipeline/" title="View all posts in AWS CodePipeline*"><span property="articleSection">AWS CodePipeline*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/compute/aws-lambda/" title="View all posts in AWS Lambda*"><span property="articleSection">AWS Lambda*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/devops/using-custom-source-actions-in-aws-codepipeline-for-increased-visibility-for-third-party-source-control/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p>In our previous post, <a href="https://aws.amazon.com/blogs/devops/integrating-git-with-aws-codepipeline/"><em>Integrating Git with AWS CodePipeline</em></a>, we demonstrated one way to integrate third-party Git repositories with <a href="https://aws.amazon.com/codepipeline/">AWS CodePipeline</a> by using <a href="https://aws.amazon.com/api-gateway/">Amazon API Gateway</a>, <a href="https://aws.amazon.com/lambda/">AWS Lambda</a>, and <a href="https://aws.amazon.com/s3/">Amazon S3</a>. That approach allows you to quickly integrate your Git repository with CodePipeline, but it doesn’t provide CodePipeline with any of the source metadata that many customers use in their CI/CD pipelines.</p> 
<p>In this post, we will describe CodePipeline custom source actions, which offer a different strategy for providing CodePipeline with more metadata from your source repositories. The most common source metadata are commit identifiers and commit messages. Commit identifiers are frequently used to track changes throughout the software lifecycle while commit messages provide a succinct, human-readable description of the change. Custom source actions allow you to integrate CodePipeline with any source repository in the same way that CodePipeline integrates with <a href="https://aws.amazon.com/codecommit/">CodeCommit</a> and GitHub, giving you access to the commit identifier and the commit message.</p> 
<p>This post covers setting up API Gateway and Lambda to trigger your pipeline, configuring your pipeline with a custom source action, and building a worker to handle jobs from your custom source action. This architecture allows you to access your source providers that are either hosted in a <a href="https://aws.amazon.com/vpc/">VPC</a> or are on premise and accessible from a VPC.</p> 
<h3>Architecture overview</h3> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/25/source_action_blog.png" /></p> 
<p>&nbsp;</p> 
<p>A webhook is a user-defined HTTP callback that occurs in response to an event. In our case, webhooks occur in response to a change in a source repository – a new revision. Webhooks have become a standard mechanism for integrating source repositories with continuous integration tools, such as CodePipeline.</p> 
<p>Here, the webhook is a call to API Gateway and AWS Lambda. The Lambda function calls the <a href="http://docs.aws.amazon.com/codepipeline/latest/APIReference/API_StartPipelineExecution.html">StartPipelineExecution </a>API, which triggers a CodePipeline execution. That execution starts with a custom source action that issues a job. That job is picked up by our worker, which pulls the latest source revision, extracts metadata, and publishes a new CodePipeline artifact for the rest of the pipeline to consume.</p> 
<p>Our example targets a Git repository (in this case, GitHub Enterprise). Although there are multiple methods for retrieving the contents of a Git repo, we do a simple git pull authenticated with SSH. Our example assumes your Git repository is accessible from your VPC. If that is not the case, remove the VpcConfig from the GitPullS3 Lambda function to give it access to internet resources.</p> 
<h3>Build the required AWS resources</h3> 
<p>For your convenience, there is an <a href="https://aws.amazon.com/cloudformation/">AWS CloudFormation</a> template that includes the AWS infrastructure and configuration required to build out this integration. It includes API Gateway, Lambda functions, and a simple pipeline. To launch the AWS CloudFormation stack setup wizard, choose the link for your region. The following AWS regions support all of the services required for this integration:</p> 
<table style="height: 159px" width="268"> 
<tbody> 
<tr> 
<td style="text-align: left">N. Virginia:</td> 
<td style="text-align: center"><a href="https://console.aws.amazon.com/cloudformation/home?region=us-east-1#/stacks/new?stackName=CustomSourceActionDemo&amp;templateURL=https://custom-source-action-blog-us-east-1.s3.amazonaws.com/cloudformation.yaml"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/24/launch-stack.png" /></a></td> 
</tr> 
<tr> 
<td style="text-align: left">Oregon:</td> 
<td><a href="https://console.aws.amazon.com/cloudformation/home?region=us-west-2#/stacks/new?stackName=CustomSourceActionDemo&amp;templateURL=https://custom-source-action-blog-us-west-2.s3.amazonaws.com/cloudformation.yaml"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/24/launch-stack.png" /></a></td> 
</tr> 
<tr> 
<td style="text-align: left">Ireland:</td> 
<td><a href="https://console.aws.amazon.com/cloudformation/home?region=eu-west-1#/stacks/new?stackName=CustomSourceActionDemo&amp;templateURL=https://custom-source-action-blog-eu-west-1.s3.amazonaws.com/cloudformation.yaml"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2016/10/24/launch-stack.png" /></a></td> 
</tr> 
</tbody> 
</table> 
<p>For a list of AWS services and the regions in which they are available, see <a href="http://docs.aws.amazon.com/general/latest/gr/rande.html">AWS Regions and Endpoints</a>.</p> 
<p>The stack setup wizard prompts you to enter several parameters. Many of these values must be obtained from your GitHub Enterprise service.</p> 
<p>&nbsp;</p> 
<p><strong>OutputBucketName</strong>: The bucket name for CodePipeline artifacts.</p> 
<p><strong>BranchName</strong>: The branch you want to use in the pipeline.</p> 
<p><strong>GitUrl</strong>: The HTTPS URL of the Git repository you want to clone. If your source repository isn’t exposed to the internet, make sure that you use the private IP address of your source repository.</p> 
<p><strong>ApiSecret</strong>: Webhook secrets for use with GitHub Enterprise and GitLab.</p> 
<p><strong>SourceActionVersion</strong>: The version of the custom source action to use. Because a custom action version cannot be deleted, you must increment this version every time you re-create the stack in a single account.</p> 
<p><strong>GitPullLambdaVPC</strong>: The VPC in which your Lambda function exists. This VPC must have access to the source repository and the public internet for access to CodePipeline.</p> 
<p><strong>GitPullLambdaSubnet</strong>: The subnet in which your Lambda function exists. This subnet must have access to your source repository and be private (that is, no internet gateway) with NAT access to the internet.</p> 
<p>After you have entered values for these parameters, you can complete the steps in the wizard and start the stack creation. If your values change, you can use the update stack functionality in CloudFormation to modify your parameters. When the stack creation is complete, make a note of the WebhookEndpoint and PublicSSHKey. You need these values in the following steps.</p> 
<p>&nbsp;</p> 
<h3>Configure the source repository</h3> 
<ol> 
<li>Sign in to GitHub Enterprise and navigate to the source repository.</li> 
<li>Choose the Settings tab, and then choose Webhooks.</li> 
<li>Choose Add Webhook.</li> 
<li>In Payload URL, enter the WebhookEndpoint value. In Secret, enter your webhook secret.</li> 
<li>Choose Add Webhook.</li> 
<li>Go to your user settings and choose SSH and GPG Keys. Add a new SSH key with the PublicSSHKey value from AWS CloudFormation.</li> 
</ol> 
<h3>Test a commit and clean up resources</h3> 
<p>After you have set up the webhook, push a new commit. In a few minutes, you should see a new execution passing through your pipeline with the correct revision ID and commit message.</p> 
<p>To clean up resources used in this solution, delete the AWS CloudFormation stack.</p> 
<h3>Conclusion</h3> 
<p>We hope you find this blog post useful for injecting source control metadata into your CI/CD pipeline. As always, chime in with your thoughts and suggestions in the comments.</p> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">UI Testing at Scale with AWS Lambda</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Stas Neyman</span></span> | on 
<time property="datePublished" datetime="2017-11-24T13:45:14+00:00">24 NOV 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/devops/category/compute/aws-lambda/" title="View all posts in AWS Lambda*"><span property="articleSection">AWS Lambda*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/compute/" title="View all posts in Compute*"><span property="articleSection">Compute*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/devops/" title="View all posts in DevOps*"><span property="articleSection">DevOps*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/devops/ui-testing-at-scale-with-aws-lambda/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><em>This is a guest blog post by Wes Couch and Kurt Waechter from the Blackboard Internal Product Development team about their experience using AWS Lambda.</em></p> 
<p>One year ago, one of our UI test suites took hours to run. Last month, it took 16 minutes. Today, it takes <strong>39 seconds</strong>. Here’s how we did it.</p> 
<h4>The backstory:</h4> 
<p>Blackboard is a global leader in delivering robust and innovative education software and services to clients in higher education, government, K12, and corporate training. We have a large product development team working across the globe in at least 10 different time zones, with an internal tools team providing support for quality and workflows. We have been using Selenium Webdriver to perform automated cross-browser UI testing since 2007. Because we are now practicing continuous delivery, the automated UI testing challenge has grown due to the faster release schedule. On top of that, every commit made to each branch triggers an execution of our automated UI test suite. If you have ever implemented an automated UI testing infrastructure, you know that it can be very challenging to scale and maintain. Although there are services that are useful for testing different browser/OS combinations, they don’t meet our scale needs.</p> 
<p>It used to take three hours to synchronously run our functional UI suite, which revealed the obvious need for parallel execution. Previously, we used Mesos to orchestrate a Selenium Grid Docker container for each test run. This way, we were able to run eight concurrent threads for test execution, which took an average of 16 minutes. Although this setup is fine for a single workflow, the cracks started to show when we reached the scale required for Blackboard’s mature product lines. Going beyond eight concurrent sessions on a single container introduced performance problems that impact the reliability of tests (for example, issues in Webdriver or the browser popping up frequently). We tried Mesos and considered Kubernetes for Selenium Grid orchestration, but the answer to scaling a Selenium Grid was to think smaller, not larger. This led to our breakthrough with AWS Lambda.</p> 
<p><span id="more-1936"></span></p> 
<h4>The solution:</h4> 
<p>We started using AWS Lambda for UI testing because it doesn’t require costly infrastructure or countless man hours to maintain. The steps we outline in this blog post took one work day, from inception to implementation. By simply packaging the UI test suite into a Lambda function, we can execute these tests in parallel on a massive scale. We use a custom JUnit test runner that invokes the Lambda function with a request to run each test from the suite. The runner then aggregates the results returned from each Lambda test execution.</p> 
<p>Selenium is the industry standard for testing UI at scale. Although there are other options to achieve the same thing in Lambda, we chose this mature suite of tools. Selenium is backed by Google, Firefox, and others to help the industry drive their browsers with code. This makes Lambda and Selenium a compelling stack for achieving UI testing at scale.</p> 
<h4>Making Chrome Run in Lambda</h4> 
<p>Currently, Chrome for Linux will not run in Lambda due to an absent mount point. By rebuilding Chrome with a slight modification, as Marco L&uuml;thy originally <a href="https://github.com/adieuadieu/serverless-chrome/tree/master/chrome">demonstrated</a>, you can run it inside Lambda anyway! It took about two hours to build the current master branch of Chromium to build on a c4.4xlarge. Unfortunately, the current version of ChromeDriver, 2.33, does not support any version of Chrome above 62, so we’ll be using Marco’s modified version of version 60 for the near future.</p> 
<h4>Required System Libraries</h4> 
<p>The Lambda runtime environment comes with a subset of common shared libraries. This means we need to include some extra libraries to get Chrome and ChromeDriver to work. Anything that exists in the java resources folder during compile time is included in the base directory of the compiled jar file. When this jar file is deployed to Lambda, it is placed in the /var/task/ directory. This allows us to simply place the libraries in the java resources folder under a folder named lib/ so they are <a href="http://docs.aws.amazon.com/lambda/latest/dg/current-supported-versions.html">right where they need to be</a> when the Lambda function is invoked.</p> 
<p>To get these libraries, create an EC2 instance and choose the Amazon Linux AMI.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/24/Choose_an_AMI.png" /></p> 
<p>Next, use ssh to connect to the server. After you connect to the new instance, search for the libraries to find their locations.</p> 
<code class="lang-markup">sudo find / -name libgconf-2.so.4
sudo find / -name libORBit-2.so.0
</code> 
<p>Now that you have the locations of the libraries, copy these files from the EC2 instance and place them in the java resources folder under lib/.</p> 
<h4>Packaging the Tests</h4> 
<p>To deploy the test suite to Lambda, we used a simple Gradle tool called <a href="https://github.com/johnrengelman/shadow">ShadowJar</a>, which is similar to the <a href="https://maven.apache.org/plugins/maven-shade-plugin/">Maven Shade Plugin</a>. It packages the libraries and dependencies inside the jar that is built. Usually test dependencies and sources aren’t included in a jar, but for this instance we want to include them. To include the test dependencies, add this section to the build.gradle file.</p> 
<code class="lang-markup">shadowJar {
from sourceSets.test.output
configurations = [project.configurations.testRuntime]
}
</code> 
<h4>Deploying the Test Suite</h4> 
<p>Now that our tests are packaged with the dependencies in a jar, we need to get them into a running Lambda function. We use &nbsp;simple SAM &nbsp;templates to upload the packaged jar into S3, and then deploy it to Lambda with our settings.</p> 
<code class="lang-json">{
&quot;AWSTemplateFormatVersion&quot;: &quot;2010-09-09&quot;,
&quot;Transform&quot;: &quot;AWS::Serverless-2016-10-31&quot;,
&quot;Resources&quot;: {
&quot;LambdaTestHandler&quot;: {
&quot;Type&quot;: &quot;AWS::Serverless::Function&quot;,
&quot;Properties&quot;: {
&quot;CodeUri&quot;: &quot;./build/libs/your-test-jar-all.jar&quot;,
&quot;Runtime&quot;: &quot;java8&quot;,
&quot;Handler&quot;: &quot;com.example.LambdaTestHandler::handleRequest&quot;,
&quot;Role&quot;: &quot;&lt;YourLambdaRoleArn&gt;&quot;,
&quot;Timeout&quot;: 300,
&quot;MemorySize&quot;: 1536
}
}
}
}</code> 
<p>We use the maximum timeout available to ensure our tests have plenty of time to run. We also use the maximum memory size because this ensures our Lambda function can support Chrome and other resources required to run a UI test.</p> 
<p>Specifying the handler is important because this class executes the desired test. The test handler should be able to receive a test class and method. With this information it will then execute the test and respond with the results.</p> 
<code class="lang-json">public LambdaTestResult handleRequest(TestRequest testRequest, Context context) {
LoggerContainer.LOGGER = new Logger(context.getLogger());
BlockJUnit4ClassRunner runner = getRunnerForSingleTest(testRequest);
Result result = new JUnitCore().run(runner);
return new LambdaTestResult(result);
}
</code> 
<h4>Creating a Lambda-Compatible ChromeDriver</h4> 
<p>We provide developers with an easily accessible ChromeDriver for local test writing and debugging. When we are running tests on AWS, we have configured ChromeDriver to run them in Lambda.</p> 
<p>To configure ChromeDriver, we first need to tell ChromeDriver where to find the Chrome binary. Because we know that ChromeDriver is going to be unzipped into the root task directory, we should point the ChromeDriver configuration at that location.</p> 
<p>The settings for getting ChromeDriver running are mostly related to Chrome, which must have its working directories pointed at the tmp/ folder.</p> 
<p>Start with the default DesiredCapabilities for ChromeDriver, and then add the following settings to enable your ChromeDriver to start in Lambda.</p> 
<code class="lang-json">public ChromeDriver createLambdaChromeDriver() {
ChromeOptions options = new ChromeOptions();
// Set the location of the chrome binary from the resources folder
options.setBinary(&quot;/var/task/chrome&quot;);
// Include these settings to allow Chrome to run in Lambda
options.addArguments(&quot;--disable-gpu&quot;);
options.addArguments(&quot;--headless&quot;);
options.addArguments(&quot;--window-size=1366,768&quot;);
options.addArguments(&quot;--single-process&quot;);
options.addArguments(&quot;--no-sandbox&quot;);
options.addArguments(&quot;--user-data-dir=/tmp/user-data&quot;);
options.addArguments(&quot;--data-path=/tmp/data-path&quot;);
options.addArguments(&quot;--homedir=/tmp&quot;);
options.addArguments(&quot;--disk-cache-dir=/tmp/cache-dir&quot;);
DesiredCapabilities desiredCapabilities = DesiredCapabilities.chrome();
desiredCapabilities.setCapability(ChromeOptions.CAPABILITY, options);
return new ChromeDriver(desiredCapabilities);
}
</code> 
<h4>Executing Tests in Parallel</h4> 
<p>You can approach parallel test execution in Lambda in many different ways. Your approach depends on the structure and design of your test suite. For our solution, we implemented a custom test runner that uses reflection and JUnit libraries to create a list of test cases we want run. When we have the list, we create a TestRequest object to pass into the Lambda function that we have deployed. In this TestRequest, we place the class name, test method, and the test run identifier. When the Lambda function receives this TestRequest, our LambdaTestHandler generates and runs the JUnit test. After the test is complete, the test result is sent to the test runner. The test runner compiles a result after all of the tests are complete. By executing the same Lambda function multiple times with different test requests, we can effectively run the entire test suite in parallel.</p> 
<p>To get screenshots and other test data, we pipe those files during test execution to an S3 bucket under the test run identifier prefix. When the tests are complete, we link the files to each test execution in the report generated from the test run. This lets us easily investigate test executions.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/24/Parallell_testing.png" /></p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/24/Parallell_testing2.png" /></p> 
<h4>Pro Tip: Dynamically Loading Binaries</h4> 
<p><a href="http://docs.aws.amazon.com/lambda/latest/dg/limits.html">AWS Lambda has a limit of 250 MB of uncompressed space</a> for packaged Lambda functions. Because we have libraries and other dependencies to our test suite, we hit this limit when we tried to upload a function that contained Chrome and ChromeDriver (~140 MB). This test suite was not originally intended to be used with Lambda. Otherwise, we would have scrutinized some of the included libraries. To get around this limit, we used the Lambda functions temporary directory, which allows up to 500 MB of space at runtime. Downloading these binaries at runtime moves some of that space requirement into the temporary directory. This allows more room for libraries and dependencies. You can do this by grabbing Chrome and ChromeDriver from an S3 bucket and marking them as executable using built-in Java libraries. If you take this route, be sure to point to the new location for these executables in order to create a ChromeDriver.</p> 
<code class="lang-json">private static void downloadS3ObjectToExecutableFile(String key) throws IOException {
File file = new File(&quot;/tmp/&quot; + key);
GetObjectRequest request = new GetObjectRequest(&quot;s3-bucket-name&quot;, key);
FileUtils.copyInputStreamToFile(s3client.getObject(request).getObjectContent(), file);
file.setExecutable(true);
}
</code> 
<h4>Lambda-Selenium Project Source</h4> 
<p>We have compiled an open source example that you can grab from the Blackboard Github repository. Grab the code and try it out!</p> 
<p><a href="https://blackboard.github.io/lambda-selenium/">https://blackboard.github.io/lambda-selenium/</a></p> 
<h4>Conclusion</h4> 
<p>One year ago, one of our UI test suites took hours to run. Last month, it took 16 minutes. Today, it takes <strong>39 seconds</strong>. Thanks to AWS Lambda, we can reduce our build times and perform automated UI testing at scale!</p> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<meta property="image" content="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/02/CodeBuild-social.jpg" /> 
<b class="lb-b blog-post-title" property="name headline">How to Enable Caching for AWS CodeBuild</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Karthik Thirugnanasambandam</span></span> | on 
<time property="datePublished" datetime="2017-11-21T11:35:36+00:00">21 NOV 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/devops/category/developer-tools/aws-codebuild/" title="View all posts in AWS CodeBuild*"><span property="articleSection">AWS CodeBuild*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/developer-tools/" title="View all posts in Developer Tools*"><span property="articleSection">Developer Tools*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/devops/" title="View all posts in DevOps*"><span property="articleSection">DevOps*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/how-to/" title="View all posts in How-To*"><span property="articleSection">How-To*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/devops/how-to-enable-caching-for-aws-codebuild/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><a href="https://aws.amazon.com/codebuild/">AWS CodeBuild</a> is a fully managed build service. There are no servers to provision and scale, or software to install, configure, and operate. You just specify the location of your source code, choose your build settings, and CodeBuild runs build scripts for compiling, testing, and packaging your code.</p> 
<p>A typical application build process includes phases like preparing the environment, updating the configuration, downloading dependencies, running unit tests, and finally, packaging the built artifact.</p> 
<p>Downloading dependencies is a critical phase in the build process.&nbsp;These dependent files can range in size from a few KBs to multiple MBs. Because most of the dependent files do not change frequently between builds, you can noticeably reduce your build time by caching dependencies.</p> 
<p>In this post, I will show you how to enable caching for AWS CodeBuild.</p> 
<b>Requirements</b> 
<li>Create an <a href="http://docs.aws.amazon.com/AmazonS3/latest/gsg/CreatingABucket.html">Amazon S3</a> bucket&nbsp;for storing cache archives (You can use existing s3 bucket as well).</li> 
<li>Create a <a href="https://github.com/">GitHub account</a>&nbsp;(if you don’t have one).</li> 
<b>Create a sample build project:</b> 
<p>1. Open the AWS CodeBuild console at&nbsp;<a href="https://console.aws.amazon.com/codebuild/">https://console.aws.amazon.com/codebuild/</a>.</p> 
<p>2. If a welcome page is displayed, choose&nbsp;<strong>Get started</strong>.</p> 
<p>If a welcome page is not displayed, on the navigation pane, choose&nbsp;<strong>Build projects</strong>, and then choose&nbsp;<strong>Create project</strong>.</p> 
<p>3. On the&nbsp;<strong>Configure your project</strong>&nbsp;page, for&nbsp;<strong>Project name</strong>, type a name for this build project. Build project names must be unique across each AWS account.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/18/project.png" /></p> 
<p>4. <strong>In&nbsp;Source</strong>: <strong>What to build</strong>, for&nbsp;<strong>Source provider</strong>, choose <strong>GitHub</strong>.</p> 
<li><strong>For Repository</strong>,&nbsp;select <strong>Use a public repository</strong></li> 
<li>For&nbsp;<strong>Repository URL</strong>, type <a href="https://github.com/jenkinsci/aws-codebuild-plugin">https://github.com/jenkinsci/aws-codebuild-plugin</a></li> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/18/Screen-Shot-2017-11-18-at-12.12.01-PM.png" /></p> 
<p>5. <strong>In&nbsp;Environment</strong>: <strong>How to build</strong>, for&nbsp;<strong>Environment image</strong>, select <strong>Use an image managed by AWS CodeBuild</strong>.</p> 
<li>For <strong>Operating system</strong>, choose <strong>Ubuntu</strong>.</li> 
<li>For <strong>Runtime</strong>, choose <strong>Java</strong>.</li> 
<li>For <strong>Version</strong>, &nbsp;choose <strong>aws/codebuild/java:openjdk-8</strong>.</li> 
<li>For <strong>Build specification</strong>, select <strong>Insert build commands</strong>.</li> 
<p><strong>Note:</strong> The&nbsp;build specification file (<strong>buildspec.yml</strong>) can be configured in two ways. You can package it along with your source root directory, or you can override it by using a project environment configuration. In this example, I will use the override option and will use the console editor to specify the build specification.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/18/environment.png" /></p> 
<p>6. Under <strong>Build commands</strong>, click <strong>Switch to editor</strong> to enter the build specification.</p> 
<p>Copy the following text.</p> 
<code class="lang-yaml">version: 0.2
phases:
build:
commands:
- mvn install
cache:
paths:
- '/root/.m2/**/*'</code> 
<p><strong>Note:</strong> The cache section in the build specification instructs AWS CodeBuild about the paths to be cached. Like the&nbsp;artifacts section, the cache paths are relative to&nbsp;$CODEBUILD_SRC_DIR and specify the directories to be cached. In this example, Maven stores the downloaded dependencies to the /root/.m2/ folder, but other tools use different folders. For example, pip uses the /root/.cache/pip folder, and Gradle uses the /root/.gradle/caches folder. You might need to configure the cache paths based on your language platform.</p> 
<p>7. <strong>In Artifacts:&nbsp;</strong>Where to put the artifacts from this build project:</p> 
<li>For <strong>Type</strong>, choose <strong>No artifacts</strong>.</li> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/18/Screen-Shot-2017-11-18-at-12.08.08-PM.png" /></p> 
<p>8. In <strong>Cache</strong>:</p> 
<li>For <strong>Type</strong>, choose <strong>Amazon S3</strong>.</li> 
<li>For <strong>Bucket</strong>, choose your S3 bucket.</li> 
<li>For <strong>Path prefix</strong>, type cache/archives/</li> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/18/cache.png" /></p> 
<p>9. In&nbsp;<strong>Service role</strong>, the <strong>Create a service role in your account option</strong> will display a default role name. &nbsp;You can accept the default name or type your own.</p> 
<p>If you already have an AWS CodeBuild service role, choose&nbsp;<strong>Choose an existing service role from your account</strong>.</p> 
<p>10. Choose&nbsp;<strong>Continue</strong>.</p> 
<p>11. On the&nbsp;<strong>Review</strong>&nbsp;page, to run a build, choose&nbsp;<strong>Save and build</strong>.</p> 
<code class="lang-yaml"></code> 
<b>Review build and cache behavior:</b> 
<p>Let us review our first build for the project.</p> 
<p>In the first run, where no cache exists, overall build time would look something like&nbsp;below (notice the time for <strong>DOWNLOAD_SOURCE</strong>, <strong>BUILD</strong> and <strong>POST_BUILD</strong>):</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/18/pre-build-img.png" /></p> 
<p>If you check the build logs, you will see log entries for dependency downloads. The dependencies are downloaded directly from&nbsp;configured&nbsp;external repositories. At the end of the log, you will see an entry for the cache uploaded to your S3 bucket.</p> 
<p>Let’s review the S3 bucket for the cached archive. You’ll see the cache from our first successful build is uploaded to the configured S3 path.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/18/s3-preview.png" /></p> 
<p>Let’s try another build with the same CodeBuild project. This time the build should pick up the dependencies from the cache.</p> 
<p>In the second run, there was a cache hit (cache was generated from the first run):</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/18/post-build-img.png" /></p> 
<p>You’ll notice a few things:</p> 
<ol> 
<li><strong>DOWNLOAD_SOURCE</strong> took slightly longer. Because, in addition to the source code, this time the build also downloaded the cache from user’s s3 bucket.</li> 
<li><strong>BUILD</strong> time was faster. As the dependencies didn’t need to get downloaded, but were reused from cache.</li> 
<li><strong>POST_BUILD</strong> took slightly longer, but was relatively the same.</li> 
</ol> 
<p>Overall, build duration was improved with cache.</p> 
<b>Best practices for cache</b> 
<li style="text-align: left">By default, the cache archive is encrypted on the server side with the customer’s artifact <a href="https://aws.amazon.com/kms/">KMS</a> key.</li> 
<li style="text-align: left">You can expire the cache by manually removing the cache archive from S3. Alternatively, you can expire the cache by using an <a href="http://docs.aws.amazon.com/AmazonS3/latest/user-guide/create-lifecycle.html">S3 lifecycle policy</a>.</li> 
<li style="text-align: left">You can override cache behavior by updating the project. You can use the AWS CodeBuild <a href="https://aws.amazon.com/Users/allysona/AppData/Local/Temp/docs.aws.amazon.com/codebuild/latest/userguide/change-project.html">the AWS CodeBuild console, AWS CLI, or AWS SDKs</a> to update the project. You can also invalidate cache setting by using the new <strong>InvalidateProjectCache</strong> API. This API forces a new InvalidationKey to be generated, ensuring that future builds receive an empty cache. This API does&nbsp;not&nbsp;remove the existing cache, because this could cause inconsistencies with builds currently in flight.</li> 
<li style="text-align: left">The cache can be enabled for any folders in the build environment, but we recommend you only cache dependencies/files that will not change frequently between builds. Also, to avoid unexpected application behavior, don’t cache configuration and sensitive information.</li> 
<b>Conclusion</b> 
<p>In this blog post, I showed you how to enable and configure cache setting for AWS CodeBuild. As you see, this can save considerable build time. It also improves resiliency by avoiding external network connections to an artifact repository.</p> 
<p>I hope you found this post useful. Feel free to leave your feedback or suggestions in the comments.</p> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<meta property="image" content="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2018/01/02/CodeBuild-social.jpg" /> 
<b class="lb-b blog-post-title" property="name headline">Access Resources in a VPC from AWS CodeBuild Builds</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">John Pignata</span></span> | on 
<time property="datePublished" datetime="2017-11-21T11:32:09+00:00">21 NOV 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/devops/category/developer-tools/aws-codebuild/" title="View all posts in AWS CodeBuild*"><span property="articleSection">AWS CodeBuild*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/developer-tools/" title="View all posts in Developer Tools*"><span property="articleSection">Developer Tools*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/news/launch/" title="View all posts in Launch*"><span property="articleSection">Launch*</span></a>, <a href="https://aws.amazon.com/blogs/devops/category/news/" title="View all posts in News*"><span property="articleSection">News*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/devops/access-resources-in-a-vpc-from-aws-codebuild-builds/" property="url">Permalink</a> | 
<a id="aws-comment-trigger-1886" href="https://commenting.awsblogs.com/embed.html?disqus_shortname=aws-devops-blog&amp;disqus_identifier=1886&amp;disqus_title=Access+Resources+in+a+VPC+from+AWS+CodeBuild+Builds&amp;disqus_url=https://aws.amazon.com/blogs/devops/access-resources-in-a-vpc-from-aws-codebuild-builds/" data-sandbox-attr="allow-forms allow-scripts allow-popups allow-same-origin" property="discussionUrl"><i class="icon-comment"></i> Comments</a> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-1886');
});
</script> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><em>John Pignata, Startup Solutions Architect, Amazon Web Services</em></p> 
<p>In this blog post we’re going to discuss a new <a href="https://aws.amazon.com/codebuild/">AWS CodeBuild</a> feature that is available starting today. CodeBuild&nbsp;builds can now access resources in a VPC&nbsp;directly without these resources being exposed to the public internet. These resources include <a href="https://aws.amazon.com/rds">Amazon Relational Database Service (Amazon RDS)</a>&nbsp;databases, <a href="https://aws.amazon.com/elasticache">Amazon ElastiCache</a> clusters, internal services running on <a href="https://aws.amazon.com/ec2/">Amazon Elastic Compute Cloud (Amazon EC2)</a>, and <a href="https://aws.amazon.com/ecs/">Amazon EC2 Container Service (Amazon ECS)</a>, or any service endpoints that are only reachable from within a specific VPC.</p> 
<p>CodeBuild is a fully managed build service that compiles source code, runs tests, and produces software packages that are ready to deploy. As part of the build process, developers often require access to resources that should be isolated from the public Internet. Now CodeBuild builds can be optionally configured to have VPC connectivity and access these resources directly.</p> 
<p><strong>Accessing Resources in a VPC</strong></p> 
<p>You can configure builds to have access to a VPC when you create a CodeBuild project or you can update an existing CodeBuild project with VPC configuration attributes. Here’s how it looks in the console:</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/7719a1c782a1ba91c031a682a0a2f8658209adbf/2017/11/16/Picture1.png" /></p> 
<p>&nbsp;</p> 
<p>To configure VPC connectivity: select a VPC, one or more subnets within that VPC, and one or more VPC security groups that CodeBuild should apply when attaching to your VPC. Once configured, commands running as part of your build will be able to access resources in your VPC without transiting across the public Internet.</p> 
<p><strong>Use Cases</strong></p> 
<p>The availability of VPC connectivity from CodeBuild builds unlocks many potential uses. For example, you can:</p> 
<li>Run integration tests from your build against data in an Amazon RDS instance that’s isolated on a private subnet.</li> 
<li>Query data in an ElastiCache cluster directly from tests.</li> 
<li>Interact with internal web services hosted on Amazon EC2, Amazon ECS, or services that use internal Elastic Load Balancing.</li> 
<li>Retrieve dependencies from self-hosted, internal artifact repositories such as PyPI for Python, Maven for Java, npm for Node.js, and so on.</li> 
<li>Access objects in an Amazon S3 bucket configured to allow access only through a VPC endpoint.</li> 
<li>Query external web services that require fixed IP addresses through the Elastic IP address of the NAT gateway associated with your subnet(s).</li> 
<p>… and more! Your builds can now access any resource that’s hosted in your VPC without any compromise on network isolation.</p> 
<p><strong>Internet Connectivity</strong></p> 
<p>CodeBuild requires access to resources on the public Internet to successfully execute builds. At a minimum, it must be able to reach your source repository system (such as <a href="https://aws.amazon.com/codecommit/">AWS CodeCommit</a>, <a href="https://github.com">GitHub</a>, <a href="https://www.bitbucket.org">Bitbucket</a>), <a href="https://aws.amazon.com/s3/">Amazon Simple Storage Service (Amazon S3)</a> to deliver build artifacts, and <a href="http://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/WhatIsCloudWatchLogs.html">Amazon CloudWatch Logs</a> to stream logs from the build process. The interface attached to your VPC will not be assigned a public IP address so to enable Internet access from your builds, you will need to set up a managed <a href="http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/vpc-nat-gateway.html">NAT Gateway</a> or <a href="http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_NAT_Instance.html">NAT instance</a> for the subnets you configure. You must also ensure your security groups allow outbound access to these services.</p> 
<p><strong>IP Address Space</strong></p> 
<p>Each running build will be assigned an IP address from one of the subnets in your VPC that you designate for CodeBuild to use. As CodeBuild scales to meet your build volume, ensure that you select subnets with enough address space to accommodate your expected number of concurrent builds.</p> 
<p><strong>Service Role Permissions</strong></p> 
<p>CodeBuild requires new permissions in order to manage network interfaces on your VPCs. If you create a service role for your new projects, these permissions will be included in that role’s policy automatically. For existing service roles, you can edit the policy document to include the additional actions. For the full policy document to apply to your service role, see <a href="http://docs.aws.amazon.com/codebuild/latest/userguide/setting-up.html#setting-up-service-permissions-group">Advanced Setup</a> in the CodeBuild documentation.</p> 
<p>For more information, see <a href="https://docs.aws.amazon.com/codebuild/latest/userguide/vpc-support.html">VPC Support</a> in the CodeBuild documentation. We hope you find the ability to access internal resources on a VPC useful&nbsp;in your build processes! If you have any questions or feedback, feel free to reach out to us through the <a href="https://forums.aws.amazon.com/forum.jspa?forumID=230">AWS CodeBuild forum</a> or leave a comment!</p> 
<script>
require(['blog'], function() {
AWS.Blog.commenting('#aws-comment-trigger-1886');
});
</script> 
</article> 
<p>
© 2018 Amazon Web Services, Inc. or its affiliates. All rights reserved.
</p>

    </div>
  </div>
</div>


    <div id="footer" class="navigation hidden-print">
      <div class="container">
        <div class="row">
          <div class="col-xs-12">
            <ul class="footer-links nav navbar-nav">
              <li><a href="../aws.html">AWS</a></li>
              <li><a href="../linux.html">Linux</a></li>
              <li><a href="../docker.html">Docker</a></li>
              <li><a href="../ibmpower.html">IBM Power</a></li>
              <li><a href="blogsataws1.html">Blogs@AWS (Kindle Friendly)</a></li>
            </ul>
            <ul class="footer-links nav navbar-nav navbar-right">
              <li><a href="../comments.html">Comments?</a></li>
            </ul>
          </div>
        </div>
      </div>
    </div>
  </body>
</html>
