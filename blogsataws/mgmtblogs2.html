<!DOCTYPE html>
<html lang="en">
  <head>
<!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-593498H');</script>
<!-- End Google Tag Manager -->

    <meta charset="utf-8">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">

    <meta name="msapplication-config" content="/microsoft-tile.xml" />
    <meta name="theme-color" content="#ffffff">

    <meta property="og:url" content="https://bejoycalias.github.io/blogsataws/mgmtblogs1.html" />
    <meta property="og:site_name" content="Bejoy's TechNotes"/>
    <meta property="og:title" content="Bejoy's TechNotes - Kindle Friendly AWS Management Tools Blogs" />
    <meta property="og:image" content="https://bejoycalias.github.io/assets/images/og-image.png"/>
    <meta property="og:image:width" content="1200"/>
    <meta property="og:image:height" content="1200"/>
    <meta property="og:description" content="" />

    <title>Bejoy's TechNotes - Kindle Friendly AWS Management Tools Blogs</title>
    <link href="../assets/stylesheets/application-832aa42c.css" rel="stylesheet" />

    <!--[if lt IE 9]>
      <script src="../assets/javascripts/ie-compat-c141a02d.js"></script>
    <![endif]-->
    <script src="../assets/javascripts/application-ff53d307.js"></script>

    <!-- Typekit script to import Klavika font -->
    <script src="https://use.typekit.net/wxf7mfi.js"></script>
    <script>try{Typekit.load({ async: true });}catch(e){}</script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-100043608-1', 'auto');
  ga('send', 'pageview');

</script>

    
  </head>

  <body id="uh-oh-" class="layout-inner page-uh-oh-">
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-593498H"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->


    <div id="header" class="navigation navbar-static-top hidden-print">
      <div class="container">
        <div class="row">
          <div class="col-xs-12">
            <div class="navbar-header">
              <div class="navbar-brand">
                <a href="/">
                  <svg version="1.0" xmlns="http://www.w3.org/2000/svg" width="135.000000pt" height="50" viewbox="0 0 135.000000 45.000000" preserveaspectratio="xMidYMid meet" class="logo">

<g transform="translate(0.000000,45.000000) scale(0.100000,-0.100000)" fill="#000000" stroke="none">
<path class="text" fill="#000000" d="M527 384 c-4 -4 -7 -18 -7 -31 0 -21 4 -24 28 -21 21 2 27 8 27 28 0
18 -6 26 -20 28 -12 2 -24 0 -28 -4z"></path>
<path class="text" fill="#000000" d="M1080 335 c0 -48 2 -55 20 -55 18 0 20 7 20 55 0 48 -2 55 -20 55
-18 0 -20 -7 -20 -55z"></path>
<path class="text" fill="#000000" d="M54 357 c-2 -7 -3 -69 -2 -138 l3 -124 65 -3 c90 -3 130 20 130 77 0
29 -6 44 -20 54 -20 14 -20 15 -3 45 14 25 15 34 5 56 -6 15 -23 31 -38 36
-38 15 -134 13 -140 -3z m110 -33 c19 -7 21 -45 4 -62 -7 -7 -22 -12 -35 -12
-20 0 -23 5 -23 40 0 41 13 50 54 34z m20 -130 c19 -18 19 -20 6 -45 -8 -13
-21 -19 -45 -19 -34 0 -35 1 -35 40 0 38 2 40 29 40 16 0 37 -7 45 -16z"></path>
<path class="text" fill="#000000" d="M319 271 c-23 -24 -29 -38 -29 -74 0 -25 3 -53 6 -62 20 -50 164 -64
164 -15 0 15 -7 17 -45 12 -46 -5 -75 8 -75 34 0 11 16 14 65 14 l65 0 0 35
c0 80 -92 114 -151 56z m99 -33 c3 -15 -4 -18 -37 -18 -43 0 -50 7 -29 28 18
18 62 11 66 -10z"></path>
<path class="text" fill="#000000" d="M520 184 c0 -107 -1 -116 -20 -121 -11 -3 -20 -12 -20 -19 0 -21 76
-19 84 2 3 9 6 69 6 135 l0 119 -25 0 -25 0 0 -116z"></path>
<path class="text" fill="#000000" d="M649 271 c-24 -25 -29 -37 -29 -78 1 -70 34 -103 105 -103 55 0 95
44 95 103 0 60 -7 75 -41 92 -47 25 -96 19 -130 -14z m111 -30 c25 -48 2 -111
-40 -111 -45 0 -69 80 -34 114 21 22 61 20 74 -3z"></path>
<path class="text" fill="#000000" d="M850 287 c0 -8 16 -57 36 -110 28 -76 33 -100 25 -116 -16 -28 -14
-31 18 -31 27 0 29 4 70 123 23 67 41 128 41 135 0 6 -11 12 -24 12 -21 0 -26
-8 -41 -65 -10 -36 -21 -68 -25 -70 -3 -2 -16 27 -29 66 -19 60 -25 69 -47 69
-13 0 -24 -6 -24 -13z"></path>
<path class="text" fill="#000000" d="M1192 284 c-17 -12 -22 -24 -20 -47 2 -26 10 -36 45 -52 49 -23 59
-55 17 -55 -14 0 -34 5 -45 10 -16 9 -19 7 -19 -13 0 -17 7 -27 23 -31 69 -18
117 6 117 60 0 32 -4 37 -45 55 -60 26 -62 54 -4 46 37 -5 40 -3 37 16 -2 18
-11 23 -43 25 -25 2 -49 -3 -63 -14z"></path>
</g>
</svg>

                </a>
              </div>
              <button class="navbar-toggle" type="button">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
              </button>
            </div>
            <div class="buttons hidden-xs">
              <nav class="navigation-links" role="navigation">
                <ul class="main-links nav navbar-nav navbar-right">
                  <li><a href="../aws.html">AWS</a></li>
                  <li><a href="../linux.html">Linux</a></li>
                  <li><a href="../docker.html">Docker</a></li>
                  <li><a href="../ibmpower.html">IBM Power</a></li>
                  <li><a href="blogsataws1.html">Blogs@AWS (Kindle Friendly)</a></li>
                </ul>
              </nav>
            </div>
          </div>
        </div>
      </div>
    </div>

    <div class="sidebar-overlay"></div>

<aside class="sidebar" role="navigation">
  <div class="sidebar-header">
    <svg version="1.0" xmlns="http://www.w3.org/2000/svg" width="135.000000pt" height="42" viewbox="0 0 135.000000 45.000000" preserveaspectratio="xMidYMid meet">

<g transform="translate(0.000000,45.000000) scale(0.100000,-0.100000)" fill="#000000" stroke="none">
<path class="text" fill="#000000" d="M527 384 c-4 -4 -7 -18 -7 -31 0 -21 4 -24 28 -21 21 2 27 8 27 28 0
18 -6 26 -20 28 -12 2 -24 0 -28 -4z"></path>
<path class="text" fill="#000000" d="M1080 335 c0 -48 2 -55 20 -55 18 0 20 7 20 55 0 48 -2 55 -20 55
-18 0 -20 -7 -20 -55z"></path>
<path class="text" fill="#000000" d="M54 357 c-2 -7 -3 -69 -2 -138 l3 -124 65 -3 c90 -3 130 20 130 77 0
29 -6 44 -20 54 -20 14 -20 15 -3 45 14 25 15 34 5 56 -6 15 -23 31 -38 36
-38 15 -134 13 -140 -3z m110 -33 c19 -7 21 -45 4 -62 -7 -7 -22 -12 -35 -12
-20 0 -23 5 -23 40 0 41 13 50 54 34z m20 -130 c19 -18 19 -20 6 -45 -8 -13
-21 -19 -45 -19 -34 0 -35 1 -35 40 0 38 2 40 29 40 16 0 37 -7 45 -16z"></path>
<path class="text" fill="#000000" d="M319 271 c-23 -24 -29 -38 -29 -74 0 -25 3 -53 6 -62 20 -50 164 -64
164 -15 0 15 -7 17 -45 12 -46 -5 -75 8 -75 34 0 11 16 14 65 14 l65 0 0 35
c0 80 -92 114 -151 56z m99 -33 c3 -15 -4 -18 -37 -18 -43 0 -50 7 -29 28 18
18 62 11 66 -10z"></path>
<path class="text" fill="#000000" d="M520 184 c0 -107 -1 -116 -20 -121 -11 -3 -20 -12 -20 -19 0 -21 76
-19 84 2 3 9 6 69 6 135 l0 119 -25 0 -25 0 0 -116z"></path>
<path class="text" fill="#000000" d="M649 271 c-24 -25 -29 -37 -29 -78 1 -70 34 -103 105 -103 55 0 95
44 95 103 0 60 -7 75 -41 92 -47 25 -96 19 -130 -14z m111 -30 c25 -48 2 -111
-40 -111 -45 0 -69 80 -34 114 21 22 61 20 74 -3z"></path>
<path class="text" fill="#000000" d="M850 287 c0 -8 16 -57 36 -110 28 -76 33 -100 25 -116 -16 -28 -14
-31 18 -31 27 0 29 4 70 123 23 67 41 128 41 135 0 6 -11 12 -24 12 -21 0 -26
-8 -41 -65 -10 -36 -21 -68 -25 -70 -3 -2 -16 27 -29 66 -19 60 -25 69 -47 69
-13 0 -24 -6 -24 -13z"></path>
<path class="text" fill="#000000" d="M1192 284 c-17 -12 -22 -24 -20 -47 2 -26 10 -36 45 -52 49 -23 59
-55 17 -55 -14 0 -34 5 -45 10 -16 9 -19 7 -19 -13 0 -17 7 -27 23 -31 69 -18
117 6 117 60 0 32 -4 37 -45 55 -60 26 -62 54 -4 46 37 -5 40 -3 37 16 -2 18
-11 23 -43 25 -25 2 -49 -3 -63 -14z"></path>
</g>
</svg>

  </div>

  <ul class="nav sidebar-nav">
    <li><a href="../aws.html">AWS</a></li>
    <li><a href="../linux.html">Linux</a></li>
    <li><a href="../docker.html">Docker</a></li>
    <li><a href="../ibmpower.html">IBM Power</a></li>
    <li><a href="blogsataws1.html">Blogs@AWS (Kindle Friendly)</a></li>
  </ul>
</aside>


    <div class="container">
  <div class="row">
    <div id="docs-sidebar" class="col-sm-3 col-md-3 col-xs-12 hidden-print" role="complementary">
      <ul class="nav docs-sidenav">
      <li><a href="blogsataws1.html">Blogs @ AWS</a></li>
      <li><a href="whatsnew1.html">What's New @ AWS</a></li>
      <li><a href="secblogs1.html">Security Blogs @ AWS</a></li>
      <li><a href="computeblogs1.html">Compute Blogs @ AWS</a></li>
      <li><a href="apnblogs1.html">APN Blogs @ AWS</a></li>
      <li><a href="devopsblogs1.html">DevOps Blogs @ AWS</a></li>
      <li class="active"><a href="mgmtblogs1.html">Management Tools Blogs @ AWS</a></li>

    </ul>
    </div>

    <div id="inner" class="col-sm-9 col-md-9 col-xs-12" role="main">
<p></p>
<p><i>Contents of this page is copied directly from AWS blog sites to make it Kindle friendly. Some styles & sections from these pages are removed to render this properly in 'Article Mode' of Kindle e-Reader browser. All the contents of this page is property of AWS.</i></p>
<p><a href="mgmtblogs1.html">Page 1</a>|<a href="mgmtblogs2.html">Page 2</a>|<a href="mgmtblogs3.html">Page 3</a>|<a href="mgmtblogs4.html">Page 4</a</p>
<br>
<article class="post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="b post-title" property="name headline">Recover your impaired instances using EC2Rescue and Amazon EC2 Systems Manager Automation</b> 
<footer class="meta">
by 
<span property="author" typeof="Person"><span property="name">Venkat Krish</span></span> | on 
<time property="datePublished" datetime="2017-10-02T16:07:40+00:00">02 OCT 2017</time> | in 
<span class="categories"><a href="https://aws.amazon.com/blogs/mt/category/compute/amazon-ec2/" title="View all posts in Amazon EC2"><span property="articleSection">Amazon EC2</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/amazon-ec2-systems-manager/" title="View all posts in Amazon EC2 Systems Manager"><span property="articleSection">Amazon EC2 Systems Manager</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/compute/" title="View all posts in Compute"><span property="articleSection">Compute</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools"><span property="articleSection">Management Tools</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/recover-your-impaired-instances-using-ec2rescue-and-amazon-ec2-systems-manager-automation/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog=""><span class="span icon-share"></span>&nbsp;Share</a> 
<ul> 
</ul> 
</footer> 
<p>Have you ever had an issue connecting to your <a href="https://aws.amazon.com/ec2">Amazon EC2 </a>Windows instance? This can be caused by any number of different reasons, but is almost always related to how the instance is configured. Unfortunately, if you can’t connect to it, you can’t fix it!</p> 
<p>Earlier this year, AWS <a href="https://aws.amazon.com/about-aws/whats-new/2017/03/amazon-ec2rescue-is-now-available/">announced EC2Rescue for Windows</a>, a convenient, straightforward, GUI-based troubleshooting tool that can be run on your Windows instances to troubleshoot operating system-level issues and collect advanced logs and configuration files for further analysis.</p> 
<p>AWS listened to your feedback, and now EC2Rescue is available as a one-click, self-service, scalable automated solution for you to use via&nbsp;<a href="https://aws.amazon.com/ec2/systems-manager/automation/">Systems Manager Automation</a>. Starting today, there’s a new public Systems Manager Automation document, called <strong><em>AWSSupport-ExecuteEC2Rescue</em></strong>. <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/automation-ec2rescue.html">Documentation for EC2Rescue</a> has more details about this Automation document.</p> 
<p><span id="more-1406"></span></p> 
<p>In Automation, you can define a sequence of actions to perform: &nbsp;stopping or starting EC2 instances, creating backup AMIs, invoking AWS Lambda functions, creating AWS CloudFormation templates, and more. In this blog we will show you how you can use AWSSupport-ExecuteEC2Rescue Automation document to orchestrate&nbsp;EC2Rescue workflow.</p> 
<h3>Introducing EC2Rescue powered by Systems Manager Automation</h3> 
<p>While the symptom is always the same (you can’t remotely access your Windows instance), there could be multiple causes for it. AWS Support regularly publishes the most frequent questions and requests received from AWS customers in <a href="https://aws.amazon.com/premiumsupport/knowledge-center/#ec2">Knowledge Center</a>.<br /> The most common reasons AWS Support has dealt with over the years are:</p> 
<ul> 
<li>Network adapter misconfiguration: &nbsp;There is an incorrect static IP address assigned to the network interface, or the DHCP client can’t renew the DHCP lease.</li> 
<li>RDP service issues: &nbsp;The service is disabled or you are using a non-default configuration, that is, a TCP port other than 3389.</li> 
<li>Firewall: &nbsp;The Windows firewall is blocking RDP traffic.</li> 
</ul> 
<h3>What are your troubleshooting options?</h3> 
<p>To start, you can take a <a href="https://aws.amazon.com/premiumsupport/knowledge-center/capture-instance-screenshot/">console screenshot</a>. It may show, for example, that Windows is installing updates. In that case, you just need to wait.</p> 
<p>For issues like RDP and firewall misconfiguration, you can use <a href="https://aws.amazon.com/ec2/run-command/">Systems Manager Run Command</a>, to start your investigation or even fix the problem.</p> 
<p>After you have exhausted these options, or you don’t know exactly what the issue might be, the next available step is to investigate the Amazon EBS root volume of your instance, by attempting an offline Windows registry analysis. This requires deep understanding of the Windows operating system, and a wrong action could worsen the problem.</p> 
<p>EC2Rescue for Windows is able to detect and attempt to resolve all the issues listed above directly from an offline EBS volume, reducing troubleshooting and remediation of common Windows issues to a matter of clicks. Download the tool on a helper EC2 instance that has access to the EBS root volume to inspect, and EC2Rescue guides you through the analysis and remediation, with no advanced Windows knowledge required.</p> 
<p>There are <a href="http://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/Windows-Server-EC2Rescue.html#w2ab1c32c19">multiple preparation steps</a> to execute when using EC2Rescue in offline mode. You need to create a new “helper” EC2 instance in your VPC (or use an existing instance that you can access), detach the EBS root volume from your impaired instance, and attach it to the helper instance. Finally, you need to attach the volume back to its original instance after EC2Rescue completes its work.</p> 
<p>While the remediation is guided and happens in a matter of minutes, the preparation is prone to human error, and is usually done under the pressure of fixing the problem as soon as possible.</p> 
<p>All the steps are now automated, from the helper instance setup to the EC2Rescue remediation, thanks to Systems Manager Automation. You can now use EC2Rescue on your Windows instance consistently. Here’s how to use the new public document, <strong>AWSSupport-ExecuteEC2Rescue</strong>.</p> 
<h3>How to use AWSSupport-ExecuteEC2Rescue</h3> 
<p>A Windows instance is not passing the instance health check:</p> 
<p><img class="alignnone size-full wp-image-1418" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/29/EC2Rescue1.png" alt="" width="1037" height="153" /></p> 
<p>You can use EC2Rescue with your Windows instances from the AWS Management Console or the AWS CLI. The <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/automation-ec2rescue.html#automation-ec2rescue-begin">documentation has a walkthrough of the console experience</a>, so I’m going through the CLI experience here.</p> 
<p>You can now use EC2Rescue on this instance with one CLI command. In the following code example, I am passing the instance ID to use with EC2Rescue, and an IAM role with the required permissions to run this Automation document:</p> 
<pre><code class="lang-json">aws ssm start-automation-execution --document-name &quot;AWSSupport-ExecuteEC2Rescue&quot; --parameters &quot;ImpairedInstanceId=YOURINSTANCEID ,AssumeRole=arn:aws:iam::YOURACCOUNTID:role/YOURSSMAUTOMATIONROLE&quot;
{
&quot;AutomationExecutionId&quot;: &quot;ae6b3617-843e-11e7-8f65-57a040263d53&quot;
}
</code></pre> 
<p>You can start the automation from the EC2 console as well, in which case an IAM role is not necessary as Automation can impersonate the current user (make sure to have the required&nbsp;<a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/automation-ec2rescue.html#automation-ec2rescue-begin">permissions</a> though!).</p> 
<p><img class="alignnone size-full wp-image-1419" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/29/EC2Rescue2.png" alt="" width="1878" height="842" /></p> 
<p>You can monitor the execution with the returned ID. The execution is still in progress:</p> 
<pre><code class="lang-json">aws ssm get-automation-execution --automation-execution-id &quot;ae6b3617-843e-11e7-8f65-57a040263d53”
{
&quot;AutomationExecution&quot;: {
&quot;AutomationExecutionStatus&quot;: &quot;InProgress&quot;,
&quot;Parameters&quot;: {
(..)
},
&quot;Outputs&quot;: {
(..)
},
&quot;DocumentName&quot;: &quot;AWSSupport-ExecuteEC2Rescue&quot;,
&quot;AutomationExecutionId&quot;: &quot;ae6b3617-843e-11e7-8f65-57a040263d53&quot;,
&quot;DocumentVersion&quot;: &quot;1&quot;,
&quot;ExecutionStartTime&quot;: 1503079041.084,
&quot;StepExecutions&quot;: [
{
(..)
}
]
}
}</code></pre> 
<p>After about 25 minutes, the Automation document completed successfully. The instance is passing both health checks now. Check to see what the problem was!</p> 
<p><img class="alignnone size-full wp-image-1420" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/29/EC2Rescue3.png" alt="" width="1208" height="147" /></p> 
<p>You can run this CLI command to review the analysis and changes that EC2Rescue made, or review the execution output from the EC2 console:</p> 
<pre><code class="lang-json">aws ssm get-automation-execution --automation-execution-id &quot;ae6b3617-843e-11e7-8f65-57a040263d53&quot; --query 'AutomationExecution.Outputs.&quot;runEC2Rescue.Output&quot;' --output text</code></pre> 
<p>&nbsp;</p> 
<p>===== System Information =====</p> 
<p>&nbsp;</p> 
<p>Operating System: Windows Server 2008 R2 Datacenter</p> 
<p>&nbsp;</p> 
<p>Service Pack: Service Pack 1</p> 
<p>Version: 6.1.7601</p> 
<p>Computer Name: WIN-0KEEGO57HHS</p> 
<p>Time Zone: UTC</p> 
<p>.NET Framework:</p> 
<p>v4.7 (4.7.02053)</p> 
<p>EC2Config Version: 4.9.1981</p> 
<p>===== Analysis =====</p> 
<p>System Time</p> 
<p>OK – RealTimeIsUniversal (Enabled): This registry value should be enabled when timezone is not UTC.</p> 
<p>&nbsp;</p> 
<p>Windows Firewall</p> 
<p>Warning – Domain networks (Enabled): Windows Firewall will be disabled.</p> 
<p>Warning – Private networks (Enabled): Windows Firewall will be disabled.</p> 
<p>Warning – Guest or public networks (Enabled): Windows Firewall will be disabled.</p> 
<p>Remote Desktop</p> 
<p>OK – Service Start (Manual): Sets Remote Desktop service start to automatic.</p> 
<p>OK – Remote Desktop Connections (Enabled): The RDP listening port will be changed to TCP/3389.</p> 
<p>OK – TCP Port (3389): The RDP listening port will be changed to TCP/3389.</p> 
<p>&nbsp;</p> 
<p>EC2Config</p> 
<p>OK – Installation (Installed): EC2Config 4.9.1981 is installed.</p> 
<p>OK – Service Start (Automatic): The service will be set to start automatically.</p> 
<p>Information – Ec2SetPassword (Disabled): Re-generates Administrator’s password on next boot.</p> 
<p>Information – Ec2HandleUserData (Disabled): Executes User Data script on next boot.</p> 
<p>Network Interface</p> 
<p>OK – DHCP Service Startup (Automatic): The service will be set to start automatically.</p> 
<p>Information – Local Area Connection detail (N/A): AWS PV Network Device (7.4.6.0)</p> 
<p><strong>Warning – DHCP on Local Area Connection (Disabled (Static: 169.254.0.1)): DHCP will be enabled.</strong></p> 
<p><strong>===== Changes =====</strong></p> 
<p><strong>Windows Firewall</strong></p> 
<p><strong>OK – Domain networks (Disabled)</strong></p> 
<p><strong>OK – Private networks (Disabled)</strong></p> 
<p><strong>OK – Guest or public networks (Disabled)</strong></p> 
<p><strong>Network Interface</strong></p> 
<p><strong>OK – DHCP on Local Area Connection (Enabled)</strong></p> 
<p>EC2Rescue found that the Windows Firewall and a static IP address configured on the network adapter may have caused the connectivity issue, and made some changes in an attempt to resolve them. Update your custom AMI to make sure that you can launch new EC2 instances consistently in your VPC.</p> 
<h3>Under the hood</h3> 
<p><strong>AWSSupport-ExecuteEC2Rescue</strong> automates the use of <a href="http://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/Windows-Server-EC2Rescue.html">EC2Rescue for Windows</a> in <a href="http://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/Windows-Server-EC2Rescue.html#w2ab1c32c19">offline mode</a>. This document leverages an AWS CloudFormation template and AWS Lambda functions, orchestrated by Systems Manager Automation, to automate the steps normally required to use EC2Rescue, including:</p> 
<ul> 
<li>Creating an instance to assist with recovery in the appropriate Availability Zone</li> 
<li>Attaching and detaching EBS volumes</li> 
<li>Running the EC2Rescue tool</li> 
</ul> 
<p>This provides a one-click solution to remediate common Windows issues that prevent remote access to the instance.</p> 
<p><strong>AWSSupport-ExecuteEC2Rescue</strong> creates a VPC where EC2Rescue can run, completely isolated from your environment, and creates a backup AMI of the instance on which to run EC2Rescue before any further action is taken.</p> 
<p>&nbsp;</p> 
<p><img class="alignnone wp-image-1438 size-full" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/03/timeline.png" alt="" width="1263" height="595" /></p> 
<p>After you have detected that your Windows instance is unreachable (1), you can pass its instance ID to <strong>AWSSupport-ExecuteEC2Rescue</strong>, which stages a VPC and a number of Lambda functions (2-3) to rescue it. <strong>AWSSupport-ExecuteEC2Rescue</strong> stops your original instance (5), and creates a backup before taking any action on it (6).</p> 
<p>The Automation document identifies which subnet to use in the EC2Rescue VPC that was created (it uses one in the same Availability Zone as your instance), and gets the latest Windows Server 2016 AMI to launch an EC2Rescue instance (4). The Automation document uses <a href="http://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/ec2rw-ssm.html">RunCommand</a> and <a href="http://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/ec2rw-cli.html">EC2Rescue</a> CLI on this instance, and attempts to fix the issues identified on your instance (7) before the Automation document starts it back up (9). The EC2Rescue instance is terminated as part of the flow (8).</p> 
<h3>How can this document fix my instance automatically?</h3> 
<p><strong>AWSSupport-ExecuteEC2Rescue</strong> creates the EC2Rescue instance in the same Availability Zone as your instance (but in an isolated VPC).</p> 
<p>&nbsp;</p> 
<p><img class="alignnone size-full wp-image-1439" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/03/step1.png" alt="" width="922" height="526" /></p> 
<p><strong>AWSSupport-ExecuteEC2Rescue</strong> then attaches the root volume of your instance to the EC2Rescue instance.</p> 
<p>&nbsp;</p> 
<p><img class="alignnone size-full wp-image-1440" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/03/step2.png" alt="" width="922" height="526" /></p> 
<p>At this stage, <strong>AWSSupport-ExecuteEC2Rescue</strong> runs a new Run Command document, called <a href="http://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/ec2rw-ssm.html">AWSSupport-RunEC2RescueForWindowsTool</a>, against the EC2Rescue instance. The document:</p> 
<ul> 
<li>Downloads EC2Rescue.</li> 
<li>Runs the EC2Rescue for Windows tool CLI to diagnose and attempts to fix all the issues that it can identify in the offline root volume that was just attached.</li> 
</ul> 
<p>&nbsp;</p> 
<p><img class="alignnone size-full wp-image-1441" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/03/step3.png" alt="" width="922" height="526" /></p> 
<p>The root volume is then automatically reattached to your instance. The Automation document terminates the EC2Rescue instance, and deletes the EC2Rescue VPC.</p> 
<p>&nbsp;</p> 
<h3><img class="alignnone size-full wp-image-1442" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/03/step4.png" alt="" width="922" height="526" /></h3> 
<h3>Summary</h3> 
<p>AWSSupport-ExecuteEC2Rescue is a new Automation document that automates all the steps required to fix common Windows issues on your unreachable Windows instance using the <a href="https://aws.amazon.com/premiumsupport/knowledge-center/ec2rescue-windows-troubleshoot/">EC2Rescue for Windows tool</a>.</p> 
<p>The Automation document uses the new <a href="http://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/ec2rw-cli.html">EC2Rescue </a>for Windows CLI for a fully automated end-to-end fully experience.</p> 
<p>With the recent integration between CloudWatch Events and Systems Manager Automation, you can run AWSSupport-ExecuteEC2Rescue automatically in response to an event in your infrastructure.</p> 
<p>You can start using this document today. We are planning to add support for <a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/Linux-Server-EC2Rescue.html">EC2Rescue for Linux</a> soon.</p> 
<p>If you have any questions or suggestions, please leave a comment for us. Happy EC2Rescue!</p> 
<h3>About the Author</h3> 
<p><img class="size-full wp-image-1432 alignleft" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/02/AMartini.jpg" alt="" width="119" height="160" /></p> 
<p>Alessandro Martini is a Senior Cloud Support Engineer in the AWS Support organization.&nbsp;He likes working with customers, understanding and solving problems and loves to write blogs outlining&nbsp;his solutions on multiple AWS products.&nbsp;He also loves pizza, especially when there is no pineapple on it.</p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/mt/tag/automation/" rel="tag">Automation</a>, <a href="https://aws.amazon.com/blogs/mt/tag/aws-iam/" rel="tag">AWS IAM</a>, <a href="https://aws.amazon.com/blogs/mt/tag/aws-systems-manager/" rel="tag">AWS Systems Manager</a>, <a href="https://aws.amazon.com/blogs/mt/tag/ec2-systems-manager/" rel="tag">EC2 Systems Manager</a>, <a href="https://aws.amazon.com/blogs/mt/tag/ec2-systems-manager-automation/" rel="tag">EC2 Systems Manager Automation</a>, <a href="https://aws.amazon.com/blogs/mt/tag/ec2-windows/" rel="tag">EC2 Windows</a>, <a href="https://aws.amazon.com/blogs/mt/tag/run-command/" rel="tag">Run Command</a>, <a href="https://aws.amazon.com/blogs/mt/tag/ssm/" rel="tag">SSM</a></span> 
</footer> 
</article> 
<article class="post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="b post-title" property="name headline">Use AWS CloudFormation Stack Termination Protection and Rollback Triggers to Maintain Infrastructure Availability</b> 
<footer class="meta">
by 
<span property="author" typeof="Person"><span property="name">Chuck Meyer</span></span> | on 
<time property="datePublished" datetime="2017-09-29T16:06:07+00:00">29 SEP 2017</time> | in 
<span class="categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/aws-cloudformation/" title="View all posts in AWS CloudFormation"><span property="articleSection">AWS CloudFormation</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools"><span property="articleSection">Management Tools</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/use-aws-cloudformation-stack-termination-protection-and-rollback-triggers-to-maintain-infrastructure-availability/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog=""><span class="span icon-share"></span>&nbsp;Share</a> 
<ul> 
</ul> 
</footer> 
<p>Managing your infrastructure as code using <a href="https://aws.amazon.com/cloudformation">AWS CloudFormation</a> provides a consistent way to rapidly deliver AWS environments for your applications. As your pace of delivery increases, it’s important to ensure you have the appropriate guardrails to protect your most critical infrastructure resources.</p> 
<p>AWS CloudFormation now includes two additional tools to help you ensure the consistent health and stability of your application environments:</p> 
<ul> 
<li><strong>Stack Termination Protection</strong> provides a low friction mechanism to quickly protect stacks that contain critical resources.</li> 
<li><strong>Rollback Triggers</strong> allow you to quickly revert infrastructure changes that are having a negative impact to the performance of your applications.</li> 
</ul> 
<p>In this post, I’m going to examine strategies for adding these new features to your infrastructure management tool belt.</p> 
<p><span id="more-1375"></span></p> 
<h3>Stack Termination Protection</h3> 
<p>Take advantage of the new Stack Termination Protection parameter to prevent the accidental deletion of stacks that contain critical resources. You can enable termination protection while creating a new stack, and AWS CloudFormation will deny any delete actions against that stack. This new features gives you an extra layer of protection for stacks containing critical resources such as AWS IAM roles or AWS CloudTrail trails.</p> 
<p>You can enable termination protection while creating a new stack using the <a href="https://aws.amazon.com/cli/">AWS Command Line Interface </a>(CLI), AWS APIs, or in the AWS Management Console. In this blog, I’m using the CloudFormation console to create a new stack. Under the <strong>Advanced</strong> section, next to<strong> Termination Protection</strong>, I’ve selected the <strong>Enable</strong> check box. This protects my stack that contains a critical application deployment pipeline from deletion.</p> 
<p><img class="alignnone size-full wp-image-1392" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/29/Screen-Shot-2017-09-21-at-12.56.54-PM.png" alt="" width="661" height="545" /></p> 
<p>After you create your stack, you can verify the stack termination protection icon in the <strong>Overview</strong> section of your stack. If you are using nested stacks, termination protection cascades down to in sub-stacks of the parent without the need to individually manage protections on each stack.</p> 
<p>Here you can see I’ve enabled termination protection for the stack that contains the AWS CodePipeline for deploying my application.</p> 
<p><img class="alignnone size-full wp-image-1396" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/29/Screen-Shot-2017-09-20-at-8.16.10-AM.png" alt="" width="377" height="249" /></p> 
<p>With termination protection enabled, you will see the following message when you attempt to delete the stack:</p> 
<p><img class="alignnone size-full wp-image-1394" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/29/Screen-Shot-2017-09-18-at-2.06.42-PM.png" alt="" width="562" height="228" /></p> 
<p>You can add or remove termination protection from existing stacks using a simple API call. Control access to this API operation using IAM permissions. Make sure protection is removed only when you’re ready to delete the stack.</p> 
<p><img class="alignnone size-full wp-image-1397" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/29/Screen-Shot-2017-09-20-at-8.50.38-AM.png" alt="" width="556" height="362" /></p> 
<p>You can start adding termination protection&nbsp;to your critical stacks right now.</p> 
<h3>Rollback Triggers</h3> 
<p>We <a href="https://aws.amazon.com/about-aws/whats-new/2017/08/aws-cloudformation-adds-rollback-triggers-feature/">announced rollback triggers</a> back in August, but I wanted to take a little time to revisit them in this context.</p> 
<p>The rollback triggers functionality allows you to integrate application- and resource-level alarms from Amazon CloudWatch into the update process for your stacks. If a change to the stack causes any of the registered alarms to fire, CloudFormation immediately stops the update and rolls back to the last good state. You can include a monitoring window after all updates are complete to allow additional time for the change to stabilize. This window happens prior to the CloudFormation cleanup phase, allowing attribute changes and replaced resources to be quickly restored.</p> 
<p>For an example of rollback triggers in action, this blog starts with the <a href="https://github.com/awslabs/ecs-refarch-batch-processing">reference architecture for containerized batch processing using Amazon ECS</a>.&nbsp;&nbsp;The stack in this reference architecture contains an Amazon EC2 Container Service&nbsp;(ECS) cluster running an image processing service and the Amazon Simple Queue Service (SQS) queue that feeds it. To begin, follow this first three steps in the reference architecture’s instructions.&nbsp;&nbsp;When you come to step four, deploy your ECS service using the following simple CloudFormation template along with the parameter values from the stack that you created in Step 2:</p> 
<p><strong>batch-service.yml</strong></p> 
<pre><code class="lang-yaml">AWSTemplateFormatVersion: '2010-09-09'
Parameters:
TaskDefinition:
Type: String
Description: &quot;ARN of an existing ECS Task Definition&quot;
ECSCluster:
Type: String
Description: &quot;Existing ECS Cluster&quot;
ProcessCount:
Type: Number
Default: 1
Description: &quot;Number of processes to run&quot;
Resources:
service:
Type: AWS::ECS::Service
Properties:
Cluster: !Ref 'ECSCluster'
DesiredCount: !Ref 'ProcessCount'
TaskDefinition: !Ref 'TaskDefinition'
Outputs:
ecsservice:
Value: !Ref 'service'</code></pre> 
<p>You can put your parameter values into a JSON document to make it easier to quickly perform stack creation and updates:</p> 
<p><strong>batch-service-config.jsn</strong></p> 
<pre><code class="lang-json">[
{
&quot;ParameterKey&quot;: &quot;TaskDefinition&quot;,
&quot;ParameterValue&quot;: &quot;arn:aws:ecs:us-east-2:xxxxxxxxxxxx:task-definition/ecs-batch-processing-TaskDefinition-xxxxxxxxxxxx:1&quot;
},
{
&quot;ParameterKey&quot;: &quot;ProcessCount&quot;,
&quot;ParameterValue&quot;: &quot;1&quot;
},
{
&quot;ParameterKey&quot;: &quot;ECSCluster&quot;,
&quot;ParameterValue&quot;: &quot;ecs-batch-processing-ECSCluster-xxxxxxxxxxxxxx&quot;
}
]
</code></pre> 
<p>Then, you can create your stack from the AWS CLI like this:</p> 
<pre class="hide-language">aws cloudformation create-stack --region us-east-2 \
&nbsp;--stack-name ImageProcService \
&nbsp;--template-body file://batch-service.yml \
&nbsp;--parameters file://batch-service-config.json</pre> 
<p>You can skip step five in the reference architecture. We don’t need Auto Scaling for this example. After stack creation is completed, you should have a single batch-processing worker up and running and ready to receive <code class="lang-bash">.jpg</code> files in the input bucket. Upload a few images to make sure it’s working.</p> 
<p>Now you will make a breaking change to your batch service, but with a rollback trigger in place to protect your processing capabilities. As part of the stack you deployed in step two, CloudFormation created a CloudWatch alarm monitoring the SQS queue that feeds your batch workers. You can build a rollback trigger using this alarm. For example:</p> 
<p><strong>batch-service-rollbacktrigger.jsn</strong></p> 
<pre><code class="lang-json">{
&quot;RollbackTriggers&quot;: [
{
&quot;Arn&quot;: &quot;arn:aws:cloudwatch:us-east-2:225704381548:alarm:SQSQueueDepth&quot;,
&quot;Type&quot;: &quot;AWS::CloudWatch::Alarm&quot;
}
],
&quot;MonitoringTimeInMinutes&quot;: 10
}
</code></pre> 
<p>This trigger will wait 10 minutes after the deployment is completed to see if the queue goes into an alarm state.</p> 
<p>Reduce the number of processes in your configuration file to 0 by modifying the value in your parameter file:</p> 
<p><strong>batch-service-config.jsn</strong></p> 
<pre><code class="lang-json">[
{
&quot;ParameterKey&quot;: &quot;TaskDefinition&quot;,
&quot;ParameterValue&quot;: &quot;arn:aws:ecs:us-east-2:xxxxxxxxxxxx:task-definition/ecs-batch-processing-TaskDefinition-xxxxxxxxxxxx:1&quot;
},
{
&quot;ParameterKey&quot;: &quot;ProcessCount&quot;,
&quot;ParameterValue&quot;: &quot;0&quot;
},
{
&quot;ParameterKey&quot;: &quot;ECSCluster&quot;,
&quot;ParameterValue&quot;: &quot;ecs-batch-processing-ECSCluster-xxxxxxxxxxxxxx&quot;
}
]</code></pre> 
<p>Now you can update your stack using the rollback trigger you defined earlier:</p> 
<pre>aws cloudformation update-stack --region us-east-2 \
&nbsp;--stack-name ImageProcService \
&nbsp;--template-body file://batch-service.yml \
&nbsp;--parameters file://batch-service-config.json \
&nbsp;--rollback-configuration file://batch-service-rollbacktrigger.json</pre> 
<p>After you make a change to decrease the number of ECS processes running in your stack, there won’t be&nbsp;any workers to handle the queue. Upload at least five more <code class="lang-bash">.jpg</code> files to the input bucket before the monitoring time ends (you have 10 minutes).&nbsp;&nbsp;Things will continue to run for a little while, but soon the CloudWatch alarm is triggered as queue depth crosses a critical threshold. Since this alarm is registered as a rollback trigger, CloudFormation will automatically begin rolling back the update when the alarm triggers.</p> 
<p><img class="alignnone size-full wp-image-1398" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/29/Screen-Shot-2017-09-19-at-11.13.00-AM.png" alt="" width="1129" height="473" /></p> 
<p>Once the rollback is completed, batch processing is restored and the SQS queue will begin to drain, removing the alarm.</p> 
<p>Use rollback triggers to monitor the state of your application during the stack creation and update process. You can specify the alarms and the thresholds you want AWS CloudFormation to monitor, and if any of the alarms are breached, CloudFormation rolls back the entire stack operation to the previous deployed state.</p> 
<p>You can start using rollback triggers to allow CloudFormation to monitor critical metrics for your application in continuous integration/continuous deployment (CI/CD) pipelines and other deployment automation today.</p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/mt/tag/amazon-cloudwatch/" rel="tag">Amazon CloudWatch</a>, <a href="https://aws.amazon.com/blogs/mt/tag/amazon-cloudwatch-alarm/" rel="tag">Amazon CloudWatch Alarm</a>, <a href="https://aws.amazon.com/blogs/mt/tag/aws-cloudformation/" rel="tag">AWS CloudFormation</a></span> 
</footer> 
</article> 
<article class="post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="b post-title" property="name headline">Amazon EC2 Systems Manager as a General-Purpose DevOps Tool</b> 
<footer class="meta">
by 
<span property="author" typeof="Person"><span property="name">Ananth Vaidyanathan</span></span> | on 
<time property="datePublished" datetime="2017-09-28T12:31:50+00:00">28 SEP 2017</time> | in 
<span class="categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/amazon-ec2-systems-manager/" title="View all posts in Amazon EC2 Systems Manager"><span property="articleSection">Amazon EC2 Systems Manager</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools"><span property="articleSection">Management Tools</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/amazon-ec2-systems-manager-as-a-general-purpose-devops-tool/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog=""><span class="span icon-share"></span>&nbsp;Share</a> 
<ul> 
</ul> 
</footer> 
<p><em>This guest post was written by Andrew Rout, Engineer at Riverbed SteelCentral Office of the CTO</em></p> 
<p>A long time ago, a manufacturer in Cincinnati invented Play-Doh to be used as a wallpaper cleaner. Twenty years later, an even better purpose was found for it, and kids everywhere rejoiced.</p> 
<p>History repeats itself with Amazon EC2 Systems Manager as we discover new ways to use this service from AWS. The following walk through shows you how Run Command can be used as a DevOps tool for orchestration and for systems introspection.</p> 
<h3>The need to communicate with EC2 instances</h3> 
<p>To manage the EC2 instances that power Riverbed Technology’s <a href="https://www.riverbed.com/products/steelcentral/use-as-a-service.html">SteelCentral SaaS</a> offering, Riverbed’s DevOps team built an internal tool that allows them to perform tasks on the EC2 instances and gives them insight into the state of the environment. A UI sits on top of a backend that communicates with the EC2 instances and various other AWS services.</p> 
<p>This internal DevOps tool allows our operations team to do the following:</p> 
<ul> 
<li>See dashboards describing the overall health of all infrastructure components and software components of SteelCentral SaaS</li> 
<li>Provision new resources as necessary</li> 
<li>Troubleshoot services running on EC2 instances</li> 
<li>Manage users and licensing<span id="more-1345"></span></li> 
</ul> 
<p><img class="size-full wp-image-1346 alignnone" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/25/steelcentral_saas.png" alt="" width="1000" height="431" /></p> 
<p>In addition to a DevOps tool, Riverbed’s SaaS environment includes an event-driven service that also needs to communicate with EC2 instances. The event-driven system is used to provision additional resources on an EC2 instance as the system scales.</p> 
<p>Each of the tasks executed by the DevOps tool and the event-driven service requires one or more remote shell commands to be executed on an EC2 instance to either fetch information from an application or make a change to it.</p> 
<p>The Riverbed DevOps tool initially issued these commands via SSH, but the need to maintain an SSH key in multiple places was a headache from a logistics and security point-of-view. We preferred not to manage the key bits or the access control for SSH keys on our own, nor did we not want to develop and run a web service on all EC2 instances to handle our specific use cases.</p> 
<p><strong>EC2 Systems Manager makes software inventory management easier</strong></p> 
<p>Enter EC2 Systems Manager…</p> 
<p>EC2 Systems Manager was initially designed to be a tool for managing the software packages installed on EC2 instances, but it can be used for much more than just that.</p> 
<p>The original thinking was that if you needed to install or upgrade software on multiple EC2 instances, you could execute the yum, apt-get, Windows PowerShell, or other package manager command via EC2 Systems Manager, and it would do it for you without the user needing to SSH into each EC2 instance individually.</p> 
<p><strong>No, EC2 Systems Manager makes issuing remote commands easier</strong></p> 
<p>Really what <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/execute-remote-commands.html">Run Command</a> did was provide a way to execute ANY command on a remote EC2 instance. Anywhere an SSH command is needed, a Run Command call can take its place.</p> 
<p>The benefits of using Run Command instead of SSH have been stated in other <a href="https://aws.amazon.com/blogs/aws/manage-instances-at-scale-without-ssh-access-using-ec2-run-command/">blog posts</a>, so I’ll briefly list them here.</p> 
<ul> 
<li>No need to store SSH keys anywhere</li> 
<li>Ability to execute remote shell commands is controlled by IAM policies</li> 
<li>Commands issued via Run Command are auditable</li> 
<li>Command output can be stored in Amazon S3 for historical reference</li> 
</ul> 
<p>Essentially, EC2 Systems Manager is used as a communication service between a client and your EC2 instances.&nbsp; In Riverbed’s case, the DevOps tool is the client that wants to communicate with our EC2 instances.</p> 
<p><img class="size-full wp-image-1385 alignnone" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/29/riverbed_arch-diagram.png" alt="" width="695" height="443" /></p> 
<p>Riverbed’s SteelCentral SaaS uses EC2 Systems Manager to issue commands to stop, start, and modify services running on EC2 instances. For example, when a new user signs up, an event is triggered and Run Command sends commands to ensure additional services are provisioned and configured as the system scales.</p> 
<p>In the Riverbed internal DevOps tool, a human operator can visit a page that displays the overall health of all of the services running on the EC2 instance serving the new user. To get that information, a Run Command is sent to the EC2 instance to query process status, and the output is populated into the DevOps tool’s UI.</p> 
<p><img class="size-full wp-image-1347 alignnone" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/25/riverbed_devops.png" alt="" width="1100" height="752" /></p> 
<p>Using Run Command in place of SSH has allowed Riverbed Technology to save tens of hours of engineering time each year due to no longer needing to manage and maintain SSH keys or troubleshoot SSH keys that aren’t working.</p> 
<p>More importantly, EC2 Systems Manager makes our security policies simpler to enforce because access controls are moved out of the code and into Amazon IAM. This saves time during compliance reviews and makes it easier for management to get a picture of what access paths are defined.</p> 
<p><strong>Setting up your AWS account to use the SSM Agent</strong></p> 
<p>Before you can execute commands on your EC2 instances using the SSM Agent, you need to do the following:</p> 
<ol> 
<li><a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/ssm-agent.html">Install the SSM Agent on your EC2 instances</a>.</li> 
<li>Update your EC2 instance’s IAM role to include the AWS managed policy named “AmazonEC2RoleforSSM”. Or, you can <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/systems-manager-access.html">create a custom policy</a> for SSM as an alternative to using a managed policy.</li> 
<li>Grant permission to your user’s IAM role to allow it to execute SSM commands. This simple policy grants access to all of SSM:<code class="lang-json"></code></li> 
</ol> 
<pre><code class="lang-json">{
&quot;Effect&quot;: &quot;Allow&quot;,
&quot;Action&quot;: [
&quot;ssm:*”
],
&quot;Resource&quot;: &quot;*&quot;
}
</code></pre> 
<p><strong>Here’s an example of how to execute a command using Run Command<br /> </strong></p> 
<p>As a simple test, let’s execute “whoami” on an EC2 instance via SSM.</p> 
<p>Note: This example is written in Python using the <a href="https://aws.amazon.com/sdk-for-python/">AWS SDK for Python (boto3)</a> to communicate with AWS services, but you can use any SDK of your choice, including the AWS CLI.</p> 
<p>First, send your command to SSM, and note the returned CommandId:</p> 
<pre><code class="lang-python">import boto3
import time
instance_id = 'i-abcdef123456'
cmd = 'whoami'
ssm = boto3.client('ssm', region_name='us-east-1')
response = ssm.send_command(
InstanceIds=[instance_id],
DocumentName='AWS-RunShellScript',
Parameters={&quot;commands&quot;:[cmd]}
)
command_id = response.get('Command', {}).get(&quot;CommandId&quot;, None)</code></pre> 
<p>Second, wait for the command to finish (use the CommandId from the previous step):</p> 
<pre><code class="lang-python">while True:
response = ssm.list_command_invocations(CommandId=command_id, Details=True)
# If the command hasn't started to run yet, keep waiting
#
if len(response['CommandInvocations']) == 0:
time.sleep(1)
continue
# There could be &gt;1 CommandInvocation if the command was sent to multiple
# EC2 instances, but in this example, we just sent the command to one.
#
invocation = response['CommandInvocations'][0]
# Once we detect the command is done, exit the while loop
if invocation['Status'] not in ('Pending', 'InProgress', 'Cancelling'):
break
time.sleep(1)</code></pre> 
<p>Last, grab the command output:</p> 
<pre><code class="lang-python">command_plugin = invocation['CommandPlugins'][-1]
output = command_plugin['Output']
status = command_plugin['ResponseCode']
print &quot;Output =&quot;, output
print &quot;Status =&quot;, status</code></pre> 
<p>If the SSM command succeeded, you should see output that looks like the following:</p> 
<p>Output = root</p> 
<p>Status = 0</p> 
<p>It’s important to note that the command output returned in the SSM response is truncated at 2,500 characters. If you expect your command output to be more than 2,500 characters, you can store the full command output in Amazon S3 and fetch it from there.</p> 
<p>To store the command output in Amazon S3, add the parameter “OutputS3BucketName” when running “send_command”:</p> 
<pre><code class="lang-python">response = ssm.send_command(
InstanceIds=[instance_id],
DocumentName='AWS-RunShellScript',
Parameters={&quot;commands&quot;:[cmd]},
OutputS3BucketName='&lt;bucket-name&gt;'
)</code></pre> 
<h3><strong>Summary</strong></h3> 
<p>Run Command is an ideal service to use inside an application that needs to communicate with EC2 instances. It provides a way to execute any remote command on any of your EC2 instances. With a little bit of IAM configuration, you can throw away your SSH keys forever and let Run Command handle executing your remote shell commands.</p> 
<p>The use cases for using Run Command are as expansive as the use cases for using SSH. Whether it be controlling the applications running on your EC2 instances or fetching system and application level information, AWS has given users a reliable and easy way to manage EC2 instances and the software running on them.</p> 
<h3>About Riverbed Technology</h3> 
<p><img class="alignleft size-full wp-image-1413" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/29/riverbed-logo.png" alt="" width="165" height="49" />Riverbed’s <a href="https://www.riverbed.com/products/steelcentral/use-as-a-service.html">SteelCentral SaaS</a> provides full-Stack Application Performance Monitoring with real-time visibility into the end-user experience, network, infrastructure and applications for applications hosted on or off the cloud. Users can diagnose application performance problems down to the offending code, SQL, web service, network, or system resource.</p> 
<h3>About the Author</h3> 
<p><a href="http://www.linkedin.com/in/andrew-r-a425162">Andrew Rout</a> joined Riverbed Technology in 2013. As an engineer in Riverbed’s SteelCentral Office of the CTO, he evaluates new technologies for product integration and has recently spent time leveraging AWS and Docker. He currently builds and manages the tools and AWS infrastructure that power <a href="https://www.riverbed.com/products/steelcentral/use-as-a-service.html">SteelCentral SaaS</a>. He has a strong interest in using Python to drive DevOps activities.</p> 
<p><code class="lang-json"></code><br /> <code class="lang-json"></code></p> 
<p><code class="lang-json"><br /> </code></p> 
<p>&nbsp;</p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/mt/tag/ec2-systems-manager/" rel="tag">EC2 Systems Manager</a>, <a href="https://aws.amazon.com/blogs/mt/tag/run-command/" rel="tag">Run Command</a>, <a href="https://aws.amazon.com/blogs/mt/tag/ssm/" rel="tag">SSM</a></span> 
</footer> 
</article> 
<article class="post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="b post-title" property="name headline">Automate remediation actions for Amazon EC2 notifications and beyond using EC2 Systems Manager Automation and AWS Health</b> 
<footer class="meta">
by 
<span property="author" typeof="Person"><span property="name">Venkat Krish</span></span> | on 
<time property="datePublished" datetime="2017-09-27T13:40:09+00:00">27 SEP 2017</time> | in 
<span class="categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/amazon-cloudwatch/" title="View all posts in Amazon CloudWatch*"><span property="articleSection">Amazon CloudWatch*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/amazon-ec2-systems-manager/" title="View all posts in Amazon EC2 Systems Manager*"><span property="articleSection">Amazon EC2 Systems Manager*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools*"><span property="articleSection">Management Tools*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/automate-remediation-actions-for-amazon-ec2-notifications-and-beyond-using-ec2-systems-manager-automation-and-aws-health/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog=""><span class="span icon-share"></span>&nbsp;Share</a> 
<ul> 
</ul> 
</footer> 
<p>You can use EC2 <a href="https://aws.amazon.com/ec2/systems-manager/">Systems Manager Automation</a> to take remediation actions in response to events that may impact your AWS resources. To illustrate this concept, this post guides you through setting up automated remediation actions when an <a href="https://aws.amazon.com/ebs/">Amazon EBS</a> backed <a href="https://aws.amazon.com/ec2/systems-manager/">Amazon EC2</a> instance is scheduled for retirement.</p> 
<p>An instance is scheduled to be retired when AWS detects irreparable failure of the underlying hardware hosting the instance. If your instance root device is an Amazon EBS volume you can stop and start the instance at any time of your convenience before the retirement.</p> 
<p>Amazon EC2 Systems Manager (SSM) Automation is an AWS-hosted service that simplifies common instance and system maintenance and deployment tasks at no additional cost.</p> 
<p><span id="more-1352"></span></p> 
<p><a href="http://docs.aws.amazon.com/health/latest/ug/what-is-aws-health.html">AWS Health</a> provides ongoing visibility into the state of your AWS resources, services, and accounts. The service gives you awareness and remediation guidance for resource performance or availability issues that may affect your applications that run on AWS.</p> 
<p>Both services are integrated with <a href="http://docs.aws.amazon.com/AmazonCloudWatch/latest/events/WhatIsCloudWatchEvents.html">Amazon CloudWatch Events</a>, allowing AWS Health events to trigger SSM Automation documents.</p> 
<p>SSM Automation also offers an Approval action which temporarily pauses an Automation execution until your designated principals (e.g. IAM user) either approve or reject the action. More information about SSM automated actions is available <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/automation-actions.html">Systems Manager Automation Actions</a>.</p> 
<p><img class="alignnone wp-image-1353" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/26/Ec2InstanceRetirement1-1024x441.png" alt="" width="800" height="344" /></p> 
<p>&nbsp;</p> 
<h6>Figure 1: AWS Services feed events into AWS Health which triggers EC2 Systems Manager</h6> 
<p>&nbsp;</p> 
<p>This post will walk through the four steps to setup Stop and Start of EC2 instances using SSM Automation in response to EC2 retirement events from AWS Health. To launch the solution in the us-east-1 region using AWS CloudFormation please click <a href="https://console.aws.amazon.com/cloudformation/home?region=us-east-1#/stacks/new?stackName=StopStartEC2InstancewithApproval&amp;templateURL=https://s3.amazonaws.com/aws-health-tools-assets/cloudformation-templates/AWS-StopStartEC2InstancewithApproval.template">here</a>. Please change the region as required. We recommend reviewing the manual steps below before deploying the CloudFormation stack to have an understanding of the solution.</p> 
<p><strong>Step 1:</strong> Set up required <a href="https://aws.amazon.com/iam/">AWS IAM</a> role<br /> <strong>Step 2:</strong> Set up the <a href="https://aws.amazon.com/sns/">Amazon SNS</a> Topic if you don’t have one already<br /> <strong>Step 3:</strong> Set up the <a href="http://docs.aws.amazon.com/AmazonCloudWatch/latest/events/WhatIsCloudWatchEvents.html">Amazon CloudWatch Events</a> rule with the Automation document<br /> <strong>Step 4:</strong> Test it out and approve the Automation</p> 
<h3></h3> 
<h3>Setup Instructions</h3> 
<p><strong>Step 1: Set up required IAM role</strong></p> 
<p>First setup the required IAM permissions for CloudWatch Events to use by creating an IAM policy and associating with an IAM role for CloudWatch. For the purpose of this example we will call the IAM role the AutomationCWRole. Here is an example of an IAM policy that could be used for this purpose:</p> 
<pre><code class="lang-json">{
&quot;Version&quot;: &quot;2012-10-17&quot;,
&quot;Statement&quot;: [
{
&quot;Effect&quot;: &quot;Allow&quot;,
&quot;Action&quot;: [
&quot;ec2:StartInstances&quot;,
&quot;ec2:StopInstances&quot;,
&quot;ec2:DescribeInstanceStatus&quot;
],
&quot;Resource&quot;: [
&quot;*&quot;
]
},
{
&quot;Effect&quot;: &quot;Allow&quot;,
&quot;Action&quot;: [
&quot;ssm:*&quot;
],
&quot;Resource&quot;: [
&quot;*&quot;
]
},
{
&quot;Effect&quot;: &quot;Allow&quot;,
&quot;Action&quot;: [
&quot;sns:Publish&quot;
],
&quot;Resource&quot;: [
&quot;arn:aws:sns:*:*:Automation*&quot;
]
},
{
&quot;Effect&quot;: &quot;Allow&quot;,
&quot;Action&quot;: [
&quot;iam:PassRole&quot;
],
&quot;Resource&quot;: &quot;arn:aws:iam::&lt;AccountId&gt;:role/AutomationCWRole&quot;
}
]
}</code></pre> 
<p>Please make sure to update the role ARN which account Id and role name. You need to ensure that the role has events.amazonaws.com and ssm.amazonaws.com configured as a trusted entity for the IAM role as shown here:</p> 
<pre><code class="lang-json">{
&quot;Version&quot;: &quot;2012-10-17&quot;,
&quot;Statement&quot;: [
{
&quot;Effect&quot;: &quot;Allow&quot;,
&quot;Principal&quot;: {
&quot;Service&quot;: [
&quot;ssm.amazonaws.com&quot;,
&quot;events.amazonaws.com&quot;
]
},
&quot;Action&quot;: &quot;sts:AssumeRole&quot;
}
]
}
</code></pre> 
<p>More information about CloudWatch and IAM see <a href="http://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/auth-and-access-control-cw.html">Authentication and Access Control for Amazon CloudWatch</a>. For more information about Systems Manager and IAM, see <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/sysman-configuring-access-policies.html">Configuring Access Using Systems Manager Managed Policies</a>.</p> 
<p><strong>Step 2: Set up the Amazon SNS Topic if you don’t have one already</strong></p> 
<p>If you choose to use Automation Approval actions, then you will also need to create an SNS topic that the approval notification will be published to or use an existing one. You will also need to subscribe the approvers to that SNS topic. More information on how to set this up is available <a href="http://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/US_SetupSNS.html">here</a>.</p> 
<p>We will use the SNS topic name AutomationStopStart for this example. Please note that the SNS Topic name must start with the Prefix: Automation.</p> 
<p><strong>Step 3: Set up the Amazon CloudWatch Events rule with the Automation document</strong></p> 
<p>First create a SSM Automation document named StopStartEC2InstancewithApproval by creating a json file using your preferred editor named “StopStartEC2InstancewithApproval.json”:</p> 
<pre><code class="lang-json">{
&quot;description&quot;:&quot;Stop and Start EC2 instances(s) with Approval&quot;,
&quot;schemaVersion&quot;:&quot;0.3&quot;,
&quot;assumeRole&quot;:&quot;{{ AutomationAssumeRole }}&quot;,
&quot;parameters&quot;:{
&quot;AutomationAssumeRole&quot;:{
&quot;type&quot;:&quot;String&quot;,
&quot;description&quot;:&quot;The ARN of the role that allows Automation to perform the actions on your behalf.&quot;,
&quot;default&quot;:&quot;arn:aws:iam::{{global:ACCOUNT_ID}}:role/AutomationServiceRole&quot;
},
&quot;InstanceIds&quot;:{
&quot;type&quot;:&quot;String&quot;,
&quot;description&quot;:&quot;EC2 Instance(s) to Stop and Start&quot;
},
&quot;Approvers&quot;:{
&quot;type&quot;:&quot;StringList&quot;,
&quot;description&quot;:&quot;IAM user or user arn of approvers for the automation action&quot;
},
&quot;SNSTopicArn&quot;:{
&quot;type&quot;:&quot;String&quot;,
&quot;description&quot;:&quot;The SNS topic ARN that you are using to get notifications on about EC2 retirement notifications. The SNS topic name must start with Automation.&quot;
}
},
&quot;mainSteps&quot;:[
{
&quot;name&quot;:&quot;approve&quot;,
&quot;action&quot;:&quot;aws:approve&quot;,
&quot;timeoutSeconds&quot;:999999,
&quot;onFailure&quot;:&quot;Abort&quot;,
&quot;inputs&quot;:{
&quot;NotificationArn&quot;:&quot;{{ SNSTopicArn }}&quot;, 
&quot;Message&quot;: &quot;Your approval is required to proceed with the stop and start of an EC2 instance using the EC2 systems manager automation document that is scheduled for retirement.&quot;,
&quot;MinRequiredApprovals&quot;:1,
&quot;Approvers&quot;:[
&quot;{{Approvers}}&quot;
]
}
},
{
&quot;name&quot;:&quot;stopInstance&quot;,
&quot;action&quot;:&quot;aws:changeInstanceState&quot;,
&quot;maxAttempts&quot;:2,
&quot;timeoutSeconds&quot;:120,
&quot;onFailure&quot;:&quot;Continue&quot;,
&quot;inputs&quot;:{
&quot;InstanceIds&quot;:[
&quot;{{ InstanceIds }}&quot;
],
&quot;DesiredState&quot;:&quot;stopped&quot;
}
},
{
&quot;name&quot;:&quot;forceStopInstance&quot;,
&quot;action&quot;:&quot;aws:changeInstanceState&quot;,
&quot;maxAttempts&quot;:1,
&quot;timeoutSeconds&quot;:60,
&quot;onFailure&quot;:&quot;Continue&quot;,
&quot;inputs&quot;:{
&quot;InstanceIds&quot;:[
&quot;{{ InstanceIds }}&quot;
],
&quot;Force&quot;:true,
&quot;DesiredState&quot;:&quot;stopped&quot;
}
},
{
&quot;name&quot;:&quot;startInstance&quot;,
&quot;action&quot;:&quot;aws:changeInstanceState&quot;,
&quot;maxAttempts&quot;:3,
&quot;timeoutSeconds&quot;:120,
&quot;onFailure&quot;:&quot;Continue&quot;,
&quot;inputs&quot;:{
&quot;InstanceIds&quot;:[
&quot;{{ InstanceIds }}&quot;
],
&quot;DesiredState&quot;:&quot;running&quot;
}
}
]
}
</code></pre> 
<p>Then use the AWS CLI to create the SSM Automation document using the JSON file above:</p> 
<pre><code class="lang-json">[
<em>aws ssm create-document --content file://StopStartEC2InstancewithApproval.json --name &quot; StopStartEC2InstancewithApproval&quot; --document-type &quot;Automation&quot;</em>
]</code></pre> 
<p>More information about creating creating SSM documents can be found at <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/create-ssm-doc.html">Creating Systems Manager Documents</a>.</p> 
<p>You can then create the CloudWatch Events rule that will trigger the Automation document each time an EC2 retirement notification occurs. As an example you can use the following command using the AWS CLI:</p> 
<pre><code class="lang-json">aws events put-rule --name &quot;EC2RetirementNotification&quot; --event-pattern &quot;{\&quot;source\&quot;:[\&quot;aws.health\&quot;],\&quot;detail-type\&quot;:[\&quot;AWS Health Event\&quot;],\&quot;detail\&quot;:{\&quot;service&quot;\&quot;:[\&quot;EC2\&quot;],\&quot;eventTypeCategory&quot;\&quot;:[\&quot;scheduledChange\&quot;],\&quot;eventTypeCode&quot;\&quot;:[\&quot;AWS_EC2_INSTANCE_RETIREMENT_SCHEDULED\&quot;]}&quot;}&quot;</code></pre> 
<p>To set this up you can create a JSON file named <em>targets.json</em> using your preferred editor and then use that to create the CloudWatch Events target:</p> 
<pre><code class="lang-json">[
{
&quot;Id&quot;:&quot;1&quot;,
&quot;Arn&quot;:&quot;arn:aws:ssm:&lt;region&gt;:&lt;accountId&gt;:automation-definition/AWS-StopStartEC2InstancewithApproval&quot;,
&quot;RoleArn&quot;:&quot;arn:aws:iam::&lt;accountId&gt;:role/AutomationCWRole&quot;,
&quot;InputTransformer&quot;:{
&quot;InputPathsMap&quot;:{
&quot;Instances&quot;: &quot;$.resources&quot;
},
&quot;InputTemplate&quot;: &quot;{ \&quot;AutomationAssumeRole\&quot;:[\&quot;aws:iam::&lt;accountId&gt;:role/AutomationCWRole\&quot;],\&quot;Approvers\&quot;:[\&quot;&lt;IAMusername&gt;\&quot;],\&quot;SNSTopicArn\&quot;:[\&quot;arn:aws:sns:&lt;region&gt;:&lt;accountId&gt;:AutomationStopStart\&quot;],\&quot;InstanceIds\&quot;: &lt;Instances&gt; }&quot;
}
}
]</code></pre> 
<p>Please update the region, accountId, SNS topic ARN, IAM role ARN and IAM username in the json file above per your requirements. The target in this case is the Automation document StopStartEC2InstancewithApproval which Stops and Starts the instance(s) provided.</p> 
<p>Then use the AWS CLI to create the target specifying the json file you created:</p> 
<p><em> aws events put-targets –rule EC2RetirementNotification –targets file://targets.json</em></p> 
<p><strong>Step 4: Test it out and approve the Automation</strong></p> 
<p>You can test against the document using direct inputs as well:</p> 
<p><em> aws ssm start-automation-execution –document-name AmazonEC2InstanceStopStartwithApproval –parameters AutomationAssumeRole=”aws:iam::&lt;AccountId&gt;:role/AutomationCWRole”,Approvers=&lt;IAMusername&gt;,SNSTopicArn=”arn:aws:sns:us-east-1:&lt;AccountId&gt;:AutomationStopStart”,InstanceIds=&lt;InstanceId&gt;</em></p> 
<p>You can get the execution status using the AutomationExecutionId returned from the command above: aws ssm&nbsp; get-automation-execution –automation-execution-id &lt;value&gt;</p> 
<p>Once you get the approval message published to your SNS topic’s subscribers, you can choose to approve or reject the action:</p> 
<p><em> aws ssm send-automation-signal –automation-execution-id &lt;automation-execution-id&gt; –signal-type Approve –payload Comment=Replace_This_With_Approve_Comment</em></p> 
<p>The automation can also be approved from the EC2 console in the Automation section:</p> 
<p><img class="alignnone size-full wp-image-1354" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/26/Ec2InstanceRetirement2.png" alt="" width="416" height="145" /></p> 
<p>Please note that the approval will trigger the stop and start of the EC2 Instance, regardless of the comments provided.</p> 
<p>You can also skip the approval step and instead use the AmazonEC2InstanceStopStart SSM Automation document. Please note that in very rare situations EC2 instances might not stop even after a force stop; you should contact AWS support if that happens.</p> 
<h3>Conclusion</h3> 
<p>You can use EC2 Systems Manager Automation to take remediation actions on your AWS resources in response to events that may impact. You can take this example and apply it to other EC2 scheduled changes (e.g. system reboot maintenance) or any event with any AWS resource that may suit your needs. You can also use the document provided to Stop and Start EC2 instances in an automated way. We recommend tailoring it and testing for your use-case before deploying in a production environment.</p> 
<h3>About the Author</h3> 
<p><img class=" wp-image-1355 alignleft" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/26/Tipu_Quershi.jpg" alt="" width="80" height="111" /></p> 
<p>Tipu Qureshi is a principal engineer in the AWS support organization. He works with customers to implement automation, solve problems and setup new workloads on the AWS platform. He has created various architectures and certifications for cost-optimization and agility through DevOps.</p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/mt/tag/amazon-cloudwatch-events/" rel="tag">Amazon Cloudwatch Events</a>, <a href="https://aws.amazon.com/blogs/mt/tag/automation/" rel="tag">Automation</a>, <a href="https://aws.amazon.com/blogs/mt/tag/aws-iam/" rel="tag">AWS IAM</a>, <a href="https://aws.amazon.com/blogs/mt/tag/aws-sns/" rel="tag">AWS SNS</a>, <a href="https://aws.amazon.com/blogs/mt/tag/ec2-systems-manager/" rel="tag">EC2 Systems Manager</a>, <a href="https://aws.amazon.com/blogs/mt/tag/ec2-windows/" rel="tag">EC2 Windows</a>, <a href="https://aws.amazon.com/blogs/mt/tag/ssm/" rel="tag">SSM</a></span> 
</footer> 
</article> 
<article class="post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="b post-title" property="name headline">Get Disk Utilization of Your Fleet Using EC2 Systems Manager Custom Inventory Types</b> 
<footer class="meta">
by 
<span property="author" typeof="Person"><span property="name">Tanu Mutreja</span></span> | on 
<time property="datePublished" datetime="2017-09-20T14:23:32+00:00">20 SEP 2017</time> | in 
<span class="categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/amazon-ec2-systems-manager/" title="View all posts in Amazon EC2 Systems Manager"><span property="articleSection">Amazon EC2 Systems Manager</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools"><span property="articleSection">Management Tools</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/get-disk-utilization-of-your-fleet-using-ec2-systems-manager-custom-inventory-types/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog=""><span class="span icon-share"></span>&nbsp;Share</a> 
<ul> 
</ul> 
</footer> 
<p><a href="https://aws.amazon.com/ec2/systems-manager/inventory/">Amazon EC2 Systems Manager Inventory</a> provides a centralized way to collect and query system, application, and instance metadata. Using the resource data sync feature, you can sync this metadata to Amazon S3. In Amazon S3 you can aggregate the metadata for different AWS Regions and accounts. After you sync this inventory data to Amazon S3, you can create various visuals of the data using Amazon Athena and Amazon QuickSight.</p> 
<p>The inventory data collection policy is configured using <a href="https://aws.amazon.com/ec2/systems-manager/state-manager/">State Manager</a> , which in turn gets executed by <a href="https://github.com/aws/amazon-ssm-agent/tree/master/agent/plugins/inventory">aws:softwareInventory plugin</a> in <a href="https://github.com/aws/amazon-ssm-agent">amazon-ssm-agent</a>.</p> 
<p>Amazon EC2 Systems Manager Inventory provides two ways to define the types of data that it collects: predefined and custom.</p> 
<p>&middot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <strong>Predefined data types (with prefix AWS)</strong> are natively supported by the inventory plugin via multiple <a href="https://github.com/aws/amazon-ssm-agent/tree/master/agent/plugins/inventory/gatherers">gatherers</a>. Some examples of predefined inventory types are AWS:Application and AWS:WindowsUpdate.</p> 
<p>&middot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <strong>Custom data type (with prefix Custom)</strong> is a special inventory data type that can be defined by end users. This data type provides the flexibility of collecting additional inventory data, such as server rack location of a managed instance.</p> 
<p>In this blog, I’ll walk you through an example that shows how to use the custom inventory data type to collect disk utilization for Windows instances. We’ll use PowerShell scripts to collect disk utilization data in the Inventory. After the data is collected, we’ll use this data to get fleet-level aggregation of disk usage.</p> 
<p><span id="more-1234"></span></p> 
<h3>Step1: Create Inventory Policy Document with aws:runPowerShellScript plugin</h3> 
<p>By default, you can use AWS-GatherSoftwareInventory document to collect Inventory data. However, for this example we’ll create a document with <strong>aws:runPowerShellScript &amp; aws:softwareInventory</strong> plugins to ensure that a PowerShell script is invoked before Inventory collection begins. Since amazon-ssm-agent preserves the order of the plugin’s executions, it ensures that the latest Disk Utilization data is captured before Inventory data is collected.</p> 
<h4>Option 1: Create Document using the AWS Management Console</h4> 
<p>You can create the document in the AWS console by going to EC2 -&gt; Systems Manager Shared Resources -&gt; Documents. Here is the document content.</p> 
<pre><code class="lang-json">{
&quot;schemaVersion&quot;: &quot;2.2&quot;,
&quot;description&quot;: &quot;Run first a shell script &amp; then inventory plugin.&quot;,
&quot;mainSteps&quot;: [
{
&quot;action&quot;: &quot;aws:runPowerShellScript&quot;,
&quot;name&quot;: &quot;runPowerShellScript&quot;,
&quot;inputs&quot;: {
&quot;runCommand&quot;: &quot;{{ commands }}&quot;
}
},
{
&quot;action&quot;: &quot;aws:softwareInventory&quot;,
&quot;name&quot;: &quot;collectSoftwareInventoryItems&quot;,
&quot;inputs&quot;: {
&quot;applications&quot;: &quot;{{ applications }}&quot;,
&quot;awsComponents&quot;: &quot;{{ awsComponents }}&quot;,
&quot;networkConfig&quot;: &quot;{{ networkConfig }}&quot;,
&quot;windowsUpdates&quot;: &quot;{{ windowsUpdates }}&quot;,
&quot;customInventory&quot;: &quot;{{ customInventory }}&quot;
}
}
],
&quot;parameters&quot;: {
&quot;commands&quot;: {
&quot;type&quot;: &quot;StringList&quot;,
&quot;description&quot;: &quot;(Required) Specify a shell script or a command to run.&quot;,
&quot;minItems&quot;: 1,
&quot;displayType&quot;: &quot;textarea&quot;
},
&quot;applications&quot;: {
&quot;type&quot;: &quot;String&quot;,
&quot;default&quot;: &quot;Enabled&quot;,
&quot;description&quot;: &quot;(Optional) Collect data for installed applications.&quot;,
&quot;allowedValues&quot;: [
&quot;Enabled&quot;,
&quot;Disabled&quot;
]
},
&quot;awsComponents&quot;: {
&quot;type&quot;: &quot;String&quot;,
&quot;default&quot;: &quot;Enabled&quot;,
&quot;description&quot;: &quot;(Optional) Collect data for AWSComponents like amazon-ssm-agent.&quot;,
&quot;allowedValues&quot;: [
&quot;Enabled&quot;,
&quot;Disabled&quot;
]
},
&quot;networkConfig&quot;: {
&quot;type&quot;: &quot;String&quot;,
&quot;default&quot;: &quot;Enabled&quot;,
&quot;description&quot;: &quot;(Optional) Collect data for Network configurations.&quot;,
&quot;allowedValues&quot;: [
&quot;Enabled&quot;,
&quot;Disabled&quot;
]
},
&quot;windowsUpdates&quot;: {
&quot;type&quot;: &quot;String&quot;,
&quot;default&quot;: &quot;Enabled&quot;,
&quot;description&quot;: &quot;(Optional) Collect data for all WindowsUpdates.&quot;,
&quot;allowedValues&quot;: [
&quot;Enabled&quot;,
&quot;Disabled&quot;
]
},
&quot;customInventory&quot;: {
&quot;type&quot;: &quot;String&quot;,
&quot;default&quot;: &quot;Enabled&quot;,
&quot;description&quot;: &quot;(Optional) Collect data for custom inventory.&quot;,
&quot;allowedValues&quot;: [
&quot;Enabled&quot;,
&quot;Disabled&quot;
]
}
}
}</code></pre> 
<h4>Option 2: Create Document using the AWS command line (aws-cli)</h4> 
<p>a.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Create the document by running the aws-cli command that creates the document:</p> 
<pre><code class="lang-bash">aws ssm create-document --content file://<em>path to your file\FileName</em> --name &quot;CustomInventory-Doc&quot; --document-type Command</code></pre> 
<p>b.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Verify the document’s status by running following command:</p> 
<p><code class="lang-python">aws ssm list-documents --document-filter-list key=Name,value= CustomInventory-Doc<br /> </code></p> 
<p>Here is a sample output that you should see:<br /> <em>{</em><br /> <em>&nbsp;&nbsp;&nbsp; “DocumentIdentifiers”: [</em><br /> <em>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; {</em><br /> <em>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; “Name”: ” CustomInventory-Doc “, </em><br /> <em>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; “PlatformTypes”: [</em><br /> <em>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; “Windows”, </em><br /> <em>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; “Linux”</em><br /> <em>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ], </em><br /> <em>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; “DocumentVersion”: “1”, </em><br /> <em>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; “DocumentType”: “Command”, </em><br /> <em>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; “Owner”: “xxx”, </em><br /> <em>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; “SchemaVersion”: “2.0”</em><br /> <em>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }</em><br /> <em>&nbsp;&nbsp;&nbsp; ]</em><br /> <em>}</em></p> 
<h3>Step2: Create association using CustomInventory-Doc</h3> 
<p>Now that the inventory policy document is created, we will “Create Association,” that is we’ll associate this policy document to the targeted instances. To use the EC2 console to Create Association, go to State Manager under Systems Manager Service.</p> 
<p><img class="alignnone wp-image-1319 size-full" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/18/s1-1.png" alt="Create Association" width="975" height="306" /></p> 
<p>Next, you need to pick instances to which you want to attach this Association. In addition, define a schedule for this inventory collection. After you pick the instances and schedule, you can paste following PowerShell script in the Commands parameter (as shown in the screenshot that follows). This script is executed by the <em><strong>aws:runPowerShellScript</strong></em> plugin before the Inventory plugin is invoked.</p> 
<p>Script:</p> 
<pre><code class="lang-powershell">$data = get-wmiobject win32_logicaldisk | Select-Object @{n=&quot;DeviceId&quot;;e={$_.&quot;DeviceID&quot;}}, @{n=&quot;VolumeName&quot;;e={$_.&quot;VolumeName&quot;}}, @{n=&quot;Use%&quot;;e={&quot;{0}&quot; -f [math]::Round(($_.&quot;Size&quot; - $_.&quot;FreeSpace&quot;) * 100 / $_.&quot;Size&quot;,0)}}, @{n=&quot;Size(GB)&quot;;e={&quot;{0}&quot; -f [math]::Round($_.&quot;Size&quot; / 1GB ,0)}} | ConvertTo-Json
$content = &quot;{`&quot;SchemaVersion`&quot; : `&quot;1.0`&quot;, `&quot;TypeName`&quot;: `&quot;Custom:DiskUtilization`&quot;, `&quot;Content`&quot;: $data}&quot;
$instanceId = Invoke-RestMethod -uri http://169.254.169.254/latest/meta-data/instance-id
$filepath = &quot;C:\ProgramData\Amazon\SSM\InstanceData\&quot; + $instanceId + &quot;\inventory\custom\CustomDiskUsage.json&quot;
if (-NOT (Test-Path $filepath)) {
New-Item $filepath -ItemType file
}
Set-Content -Path $filepath -Value $content</code></pre> 
<p>This script gets disk utilization data using win32_logicaldisk. It uses <a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-metadata.html">Instance-Metadata </a>to get InstanceId, which is required in order to save the content in the path: <em>%SystemDrive%\ProgramData\Amazon\SSM\InstanceData\&lt;instance-id&gt;\inventory\custom</em></p> 
<p><img class="alignnone wp-image-1236 size-full" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/08/s2.png" alt="" width="975" height="1000" /></p> 
<p>Choose Create Association and that’s it. After the policy runs on the targeted instances, disk utilization data will be collected and become ready for consumption.</p> 
<p>Let’s go to Managed Instances and check disk utilization for an instance by choosing the Inventory tab. The following screenshot shows the new Custom data for one of my instances.</p> 
<p>&nbsp;</p> 
<p><img class="alignnone size-full wp-image-1337" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/20/ss1-1.png" alt="" width="731" height="412" /></p> 
<p>We can also apply various filters to determine the fleet’s Disk Utilization health.</p> 
<p>Let’s apply a filter to list all instances with disk utilization of more than 50 percent. The following screenshot shows instances matching the filter.</p> 
<p><img class="alignnone wp-image-1321 size-full" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/18/s3-1.png" alt="" width="975" height="206" /></p> 
<h3>Conclusion</h3> 
<p>This blog shows you how to create a custom document with <em><strong>aws:runPowerShellScript</strong></em> &amp; <em><strong>aws:softwareInventory plugin</strong></em>s. This allows you to collect and then send Custom Inventory data from an instance every time the Inventory policy is run. The data can then be queried at both the fleet and instance level.</p> 
<p>In this blog, we used a PowerShell script to get the custom data, however the same document can also be used to trigger any third-party application running in the instance to collect custom data.</p> 
<h4>About the Author</h4> 
<p><img class="size-full wp-image-1282 alignleft" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/13/SaurabhShankar.jpeg" alt="" width="119" height="160" /></p> 
<p>Saurabh Shankar is a Software Development Engineer with the Amazon EC2 Systems Manager team. He has been with Amazon for four years, working on Inventory and other features of Amazon EC2 Systems Manager. Outside work, he enjoys trekking and taking photographs.</p> 
<p>&nbsp;</p> 
<p>&nbsp;</p> 
<p>&nbsp;</p> 
<p>&nbsp;</p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/mt/tag/aws-systems-manager-inventory/" rel="tag">AWS Systems Manager Inventory</a>, <a href="https://aws.amazon.com/blogs/mt/tag/custom-inventory/" rel="tag">Custom Inventory</a>, <a href="https://aws.amazon.com/blogs/mt/tag/custom-inventory-type/" rel="tag">Custom Inventory Type</a>, <a href="https://aws.amazon.com/blogs/mt/tag/ec2-systems-manager-inventory/" rel="tag">EC2 Systems Manager Inventory</a>, <a href="https://aws.amazon.com/blogs/mt/tag/inventory/" rel="tag">Inventory</a>, <a href="https://aws.amazon.com/blogs/mt/tag/ssm/" rel="tag">SSM</a>, <a href="https://aws.amazon.com/blogs/mt/tag/ssm-inventory/" rel="tag">SSM Inventory</a></span> 
</footer> 
</article> 
<article class="post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="b post-title" property="name headline">Manage your fleet at scale using EC2 Systems Manager</b> 
<footer class="meta">
by 
<span property="author" typeof="Person"><span property="name">Venkat Krish</span></span> | on 
<time property="datePublished" datetime="2017-09-19T10:28:04+00:00">19 SEP 2017</time> | in 
<span class="categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/amazon-ec2-systems-manager/" title="View all posts in Amazon EC2 Systems Manager"><span property="articleSection">Amazon EC2 Systems Manager</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools"><span property="articleSection">Management Tools</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/manage-your-fleet-at-scale-using-ec2-systems-manager/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog=""><span class="span icon-share"></span>&nbsp;Share</a> 
<ul> 
</ul> 
</footer> 
<p><em>This guest post was written by Michael Baker, who works as a DevOps Engineer for the Infrastructure Engineering team at Bulletproof</em></p> 
<h3>Introduction</h3> 
<p>The Bulletproof Group Limited has spent many years investing in system automation to assist with fleet management at scale. More recently, we have spent a significant amount of time working with <a href="https://aws.amazon.com/ec2/systems-manager/">Amazon EC2 Systems Manager</a>. In this blog post, I describe how we have utilized Amazon EC2 Systems Manager&nbsp;on two recent customer engagements. Much has been written about the rapid change within managed services for the public cloud, but the requirement for patching operating systems is ever present. With an increasing focus on security, patching is arguably higher up our customers’ list of priorities than ever before. Our customers increasingly focus on improving the agility of their businesses. So in addition to understanding the basics, including patching, we are now designing pipelines to be both rugged and as fast as possible.</p> 
<p><span id="more-1287"></span></p> 
<h3>Customer One: Extending Amazon Auto Scaling with automated Amazon Machine Image (AMI) patching and deployment</h3> 
<p>Bulletproof recently has been charged with building a fully automated patching and deployment pipeline as an extension to an existing environment that was built with, among other things,&nbsp;Auto Scaling from AWS. &nbsp;It was important that this pipeline enabled both scheduled and ad hoc operating system and key service patching. &nbsp;During requirements gathering it became clear that owing to governance policy within our customer’s business we were unable to deliver an entirely automated deployment pipeline. A manual approval step was a part of their key requirements.</p> 
<p>After a quick review of tooling in-place within the customer build process, we took a mixture of Bulletproof’s current best practice recommendations and elected to use the following primary toolkit:</p> 
<ul> 
<li><a href="https://aws.amazon.com/ec2/systems-manager/">Amazon EC2 Systems Manager</a></li> 
<li><a href="https://aws.amazon.com/cloudformation/">AWS CloudFormation</a></li> 
<li><a href="https://aws.amazon.com/codedeploy/">AWS CodeDeploy</a></li> 
<li><a href="https://aws.amazon.com/getting-started/projects/setup-jenkins-build-server/">Jenkins (running on Amazon EC2)</a></li> 
</ul> 
<p>Diving in a little more deeply on the Jenkins configuration, the following key steps occur after our customer initiates the deployment job by logging on to their EC2 instances over VPN:</p> 
<ul> 
<li>We clone the customer’s GitHub repository (to pick up the most recent changes).</li> 
<li>Then we execute a Systems Manager Automation to launch an EC2 instance running the up-to-date customer code.</li> 
<li>Next we send and store the SSM command ID within the <a href="https://aws.amazon.com/ec2/systems-manager/parameter-store/">Systems Manager Parameter Store</a>. (We can now use this command ID to view the state of the SSM execution.)</li> 
<li>When the Systems Manager job state reaches complete, we wait 60 seconds and then begin a CodeDeploy run. (The delay is to ensure that the instance is available in time for CodeDeploy.)</li> 
<li>Jenkins queries the parameter store with the command ID of the first job executed and asks Systems Manager for the new AMI ID.</li> 
<li>We then initiate a stack update in the relevant&nbsp;<a href="https://aws.amazon.com/cloudformation/">CloudFormation </a>stack. This updates the <a href="https://aws.amazon.com/autoscaling/">Auto Scaling</a> group configuration with the new AMI. &nbsp;(This happens in such a way as to reduce the chance of service interruption.)</li> 
</ul> 
<p><img class="size-full wp-image-1316 alignleft" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/18/1-1.png" alt="" width="1760" height="1152" /></p> 
<p>The final key requirement was to enable rapid deployments. Previously even basic change required multiple stakeholders and a brief service outage. &nbsp;Today our customers create change with confidence, knowing that the integration work is&nbsp;successful and it happens without interruption to service. &nbsp;A side effect of rapid deployment is that both Developer and Operations teams are able to collaborate more closely, without one team being slowed down by the other. Continuous improvement or cloud optimization from both teams now happens on a daily basis.</p> 
<h3>Customer Two: Migration of internal services onto Amazon EC2 Container Service (ECS)</h3> 
<p>Bulletproof is currently in the process of migrating a number of internal services from our customer’s environment onto <a href="https://aws.amazon.com/ecs/">Amazon ECS</a>. Because AWS CodeDeploy doesn’t currently support using SSH keys for access to GitHub, we developed a solution to clone data from GitHub into a container. &nbsp;This container contains a deployment for a private GitHub repository.</p> 
<p>First, we use a webhook from GitHub to Amazon API Gateway to initiate a <a href="https://aws.amazon.com/lambda/">Lambda function</a>. That Lambda function then logs the GitHub pull request information into EC2 Systems Manager Parameter Store and calls Systems Manager to perform the artifact build. Next, the repo is cloned into a container. We then have automation systems in place that will create and push a build artifact into an <a href="https://aws.amazon.com/s3/">Amazon S3</a> bucket. Automated testing ensures the validity of the artifact.</p> 
<p>After the artifact is built, it’s copied to Amazon S3, and a Systems Manager Automation document is executed. Next, it calls an Amazon SNS topic, which in turn starts an AWS CodeDeploy task via <a href="https://aws.amazon.com/codepipeline/">AWS CodePipeline</a>. AWS CodeDeploy deploys the build artifact onto the underlying EC2 instance onto shared storage currently provided by Amazon EFS. &nbsp;After a successful deployment, the containers will automatically reload the underlying process based on a file change that happens post-deploy.</p> 
<p>The patching of the underlying EC2 instances is managed with Amazon CloudWatch Events, AWS Lambda, and Systems Manager. &nbsp;On a monthly basis a scheduled CloudWatch Event will trigger an event that calls a Lambda function. This Lambda function then executes a Systems Manager Automation document to to launch an AMI from a pre-baked image&nbsp;because there have been a number of custom changes made to the base AMI. &nbsp;The underlying EC2 instance is then patched with latest updates. After the updates are complete a notification is sent to Bulletproof and the customer via integrations with collaboration software (HipChat/Slack). &nbsp;Lastly, SSM will shut down the server, create the AMI, and update the AWS CloudFormation stack as appropriate.</p> 
<p>With the release of Systems Manager as a target for CloudWatch Events Bulletproof is in the process of migrating the automation across. The workflow for this automation will be a CloudWatch Event schedule that will trigger a <a href="https://aws.amazon.com/ec2/systems-manager/automation/">Systems Manager Automation </a>document with parameters. These parameters are statically set in the event rule. After each AMI baking process is complete the CloudWatch Events parameters are updated with the new base AMI via a Lambda function that is triggered via Amazon SNS after the Systems Manager Automation has been completed.</p> 
<p><img class="alignnone size-full wp-image-1317" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/18/2-1.png" alt="" width="1379" height="919" /></p> 
<h3>Summary</h3> 
<p>The migration to Amazon ECS has provided Bulletproof Support and our customer with the ability to quickly and automatically or manually deploy updates to services. &nbsp;By leveraging AWS Services such as Systems Manager Automation, CodePipeline, and CloudFormation we have managed to achieve an increase of 40% efficiency over our previous static&nbsp;infrastructure. Bulletproof teams can now work from production-like systems on their local machines both online and offline. Since our teams are global this gives them a solution with minimal latency. The teams know that when they commit changes to production the system will behave in a manner that is identical to their local development environments. If an application terminates while it is running we know that Amazon ECS and Elastic Load Balancing health checks will take care of it and bring up a new one. The same applies to the underlying EC2 instances: if they hit capacity a new EC2 instance will be added to the cluster by Auto Scaling. This reduces operational overhead for our support and operations teams.&nbsp;Development teams are now able to run replicas of production systems within the development environment. This minimizes risk and accelerates change.</p> 
<h3>About the Author</h3> 
<p><img class="wp-image-1308 size-thumbnail alignleft" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/18/mbaker-150x150.jpg" alt="" width="150" height="150" /></p> 
<p><a href="https://www.linkedin.com/in/lidder/?ppe=1">Michael Baker</a> works as a DevOps Engineer for the Infrastructure Engineering team at <a href="https://www.bulletproof.net.au/">Bulletproof Group Limited</a>. Bulletproof is an AWS Premium Partner headquartered in Sydney, Australia.</p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/mt/tag/amazon-cloudwatch-events/" rel="tag">Amazon Cloudwatch Events</a>, <a href="https://aws.amazon.com/blogs/mt/tag/aws-codedeploy/" rel="tag">AWS CodeDeploy</a>, <a href="https://aws.amazon.com/blogs/mt/tag/aws-opsworks/" rel="tag">AWS OpsWorks</a>, <a href="https://aws.amazon.com/blogs/mt/tag/documents/" rel="tag">Documents</a>, <a href="https://aws.amazon.com/blogs/mt/tag/ec2-systems-manager/" rel="tag">EC2 Systems Manager</a>, <a href="https://aws.amazon.com/blogs/mt/tag/ec2-windows/" rel="tag">EC2 Windows</a>, <a href="https://aws.amazon.com/blogs/mt/tag/maintenance-window/" rel="tag">Maintenance Window</a>, <a href="https://aws.amazon.com/blogs/mt/tag/patch-complaince/" rel="tag">Patch Complaince</a>, <a href="https://aws.amazon.com/blogs/mt/tag/patch-manager/" rel="tag">Patch Manager</a>, <a href="https://aws.amazon.com/blogs/mt/tag/ssm/" rel="tag">SSM</a>, <a href="https://aws.amazon.com/blogs/mt/tag/state-manager/" rel="tag">State Manager</a></span> 
</footer> 
</article> 
<article class="post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="b post-title" property="name headline">Reducing Configuration Drift with Amazon EC2 Systems Manager State Manager and Amazon CloudWatch Events</b> 
<footer class="meta">
by 
<span property="author" typeof="Person"><span property="name">Ananth Vaidyanathan</span></span> | on 
<time property="datePublished" datetime="2017-09-14T12:16:35+00:00">14 SEP 2017</time> | in 
<span class="categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/amazon-ec2-systems-manager/" title="View all posts in Amazon EC2 Systems Manager"><span property="articleSection">Amazon EC2 Systems Manager</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools"><span property="articleSection">Management Tools</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/reducing-configuration-drift-with-amazon-ec2-systems-manager-state-manager-and-amazon-cloudwatch-events/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog=""><span class="span icon-share"></span>&nbsp;Share</a> 
<ul> 
</ul> 
</footer> 
<p><em>This post was written by Anupam Shrivastava, Software Development Engineer with Amazon Web Services.</em></p> 
<p>State Manager helps you automate the process of keeping your EC2 instances or virtual machines (VM) in your on-premises data center in a desired state. Some use cases for State Manager include:</p> 
<ul> 
<li>Ensuring that instances are joined to a Windows domain</li> 
<li>Ensuring that instances are patched with specific software throughout their lifecycle. For more information, see <a href="https://aws.amazon.com/blogs/mt/configure-amazon-ec2-instances-in-an-auto-scaling-group-using-state-manager/">Configure Amazon EC2 Instances in an Auto Scaling Group</a>.</li> 
<li>Executing Linux shell scripts or PowerShell scripts at scheduled times during the instances lifecycle. For more information, see <a href="https://aws.amazon.com/blogs/mt/combating-configuration-drift-using-amazon-ec2-systems-manager-and-windows-powershell-dsc/">Combating Configuration Drift Using Amazon EC2 Systems Manager and Windows PowerShell DSC</a>.</li> 
<li>Using other configuration management tools like Ansible. For more information, see <a href="https://aws.amazon.com/blogs/mt/running-ansible-playbooks-using-ec2-systems-manager-run-command-and-state-manager/">Running Ansible Playbooks using EC2 Systems Manager, Run Command and State Manager</a></li> 
</ul> 
<p>In State Manager, an association is a binding between your expressed configuration in a document, and a set of targets, on a specific schedule, to ensure consistent state. As part of the recent launch, we have made it easy for customers to easily remediate their instances when they drift from a desired configuration, provide you more control on when you can reapply configurations, and also make it easy for you to track changes to State Manager associations.</p> 
<p>In this post, I demonstrate some new State Manager features such as association names and versions, rate expressions, and <a href="http://docs.aws.amazon.com/AmazonCloudWatch/latest/events/WhatIsCloudWatchEvents.html">Amazon CloudWatch Events</a> integration. You start by specifying the configuration in a Systems Manager document.</p> 
<p><span id="more-1243"></span></p> 
<h3>Walkthrough</h3> 
<p>Here are the steps that you take to demonstrate these new features of State Manager:</p> 
<ol> 
<li>Create an association to install Windows updates on one of the EC2 instances, using the rate expression of every 1 day. Give the association a name as well.</li> 
<li>Configure CloudWatch Events for this association such that you receive status update notifications on an Amazon SNS topic, which can then be used to send email alerts.</li> 
<li>Update the association’s schedule to execute every 30 minutes, to be more aggressive with checking and installing Windows updates. Use the association name filter to quickly find the right association to update.</li> 
<li>View the different association versions after updating.</li> 
</ol> 
<h4>Step 1: &nbsp;Create an association</h4> 
<p>Open the EC2 console and choose <strong>Systems Manager, State Manager.</strong></p> 
<p>On the State Manager page, create an association with the following settings:</p> 
<ul> 
<li>For <strong>Association Name</strong>, type ‘CriticalWindowsUpdates’.</li> 
<li>For <strong>Select Document</strong>, select the AWS-InstallWindowsUpdates document.</li> 
<li>For <strong>Targets</strong>, select a Windows instance.</li> 
<li>For <strong>Schedule</strong>, choose <strong>Rate schedule builder</strong> and specify a rate expression of every 1 day.</li> 
<li>For <strong>Parameters</strong>, select the following: 
<ul> 
<li>Action: Install</li> 
<li>Allow Reboot: True</li> 
<li>Categories: CriticalUpdates</li> 
</ul> </li> 
<li>Choose <strong>Create Association</strong>.</li> 
</ul> 
<p>You can also perform the same operations with the AWS CLI, using the following command:</p> 
<pre><code class="lang-bash">aws ssm create-association --name AWS-InstallWindowsUpdates --targets &quot;Key=InstanceIds,Values=i-0ca45fddbf4ce950f&quot; --schedule-expression &quot;rate(1 day)&quot; --parameters Action=Install,Categories=CriticalUpdates,AllowReboot=True –-association-name CriticalWindowsUpdates</code></pre> 
<p>If you have not upgraded the SSM agent on your EC2 instance to the latest version, you might get a failed association error of ‘UnsupportedAgent’. In that case, upgrade the SSM agent to the latest version by executing a command using Run Command and the AWS-UpdateSSMAgent document. After you upgrade the agent, the association should start succeeding.</p> 
<h4>Step 2: Configure CloudWatch Events to send notifications for a failed association</h4> 
<p>Because you have created an association to ensure that an instance always has the latest critical Windows updates, you should also configure CloudWatch Events to notify you in case the association failed to check and apply the critical Windows updates.</p> 
<p>Create an Amazon SNS topic that is configured to send you email. In the example below, I have an SNS topic already created with the topic ‘WindowsCriticalUpdates’.</p> 
<p>Open the CloudWatch console and choose <strong>Events, Create rule</strong>. Use the following values:</p> 
<ul> 
<li><strong>Service Name</strong>: EC2 Simple Systems Manager (SSM)</li> 
<li><strong>Event Type</strong>: State Manager</li> 
<li><strong>Specific type</strong>: EC2 State Manager Association State Change</li> 
<li><strong>Specific status</strong>: Failed</li> 
<li><strong>Edit Event Pattern</strong>:&nbsp; Add the Association Name to track the status for a specific Association</li> 
<li>Choose <strong>Configure details</strong>.</li> 
</ul> 
<p>When you’re done, the event pattern should look like the following:</p> 
<pre><code class="lang-json">{
&quot;source&quot;: [&quot;aws.ssm&quot;],
&quot;detail-type&quot;: [&quot;EC2 State Manager Association State Change&quot;],
&quot;detail&quot;: {
&quot;status&quot;: [&quot;Failed&quot;],
&quot;association-name&quot;: [&quot;CriticalWindowsUpdates&quot;]
}
}</code></pre> 
<p><img class="alignleft size-full wp-image-1290" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/14/cwe.png" alt="" width="1478" height="840" /></p> 
<p>Bind the rule to the SNS topic ‘WindowsCriticalUpdates’, which is configured to send you emails for notification purposes.</p> 
<h4>&nbsp;Step 3: Update the association schedule</h4> 
<p>After a few days, you might realize that you want to have a more aggressive schedule of checking every 30 minutes for critical Windows updates. On the State Manager page, filter the associations by the word ‘Critical’. Select ‘CriticalWindowsUpdates’ and edit it.</p> 
<p>On the Edit association page, choose Rate schedule builder and specify a rate expression of every 30 minutes. For Parameters, again select the following:</p> 
<ul> 
<li>Action: Install</li> 
<li>Allow Reboot: True</li> 
<li>Categories: CriticalUpdates</li> 
</ul> 
<p>Choose Edit association. You can also perform the same operations with the AWS CLI, using the following command:</p> 
<pre><code class="lang-bash">aws ssm update-association --association-id 21da58e2-c9e1-4da5-a12a-d7d37eb981a2 --schedule-expression &quot;rate(30 minutes)&quot; --parameters Action=Install,Categories=CriticalUpdates,AllowReboot=True</code></pre> 
<p>After the association is edited, it is immediately scheduled for execution on the target instances.</p> 
<h4>Step 4: Track association changes using versioning</h4> 
<p>The Versions tab provides an audit trail of all the updates that were made to the association. The attributes that can be updated are:</p> 
<ul> 
<li>Association name</li> 
<li>Document name</li> 
<li>Document version</li> 
<li>Parameters</li> 
<li>Targets</li> 
<li>Schedule expression</li> 
</ul> 
<p>When you update any of the fields in an association, State Manager creates a new version. You can see all previous versions, along with the various field values. This enables you to track changes across various versions.</p> 
<p>In the earlier example, you can see two association versions corresponding to the two different rate schedule expressions.</p> 
<p><img class="size-full wp-image-1293 alignnone" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/14/versioning.png" alt="" width="1732" height="716" /></p> 
<p>You can also perform the same operations with the AWS CLI, using the following command:</p> 
<pre><code class="lang-bash">aws ssm list-association-versions --association-id 21da58e2-c9e1-4da5-a12a-d7d37eb981a2</code></pre> 
<h3>Conclusion</h3> 
<p>In this post, I showed you how to use several new features in State Manager that will ensure your instances are in a desired state and do not drift:</p> 
<ul> 
<li>Naming associations and filtering by names</li> 
<li>Granular scheduling by rate expressions</li> 
<li>Association status notifications through CloudWatch Events</li> 
<li>Tracking association changes through versions</li> 
</ul> 
<hr /> 
<h3>About the Author</h3> 
<p><img class="size-full wp-image-1294 alignleft" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/14/anupam.jpg" alt="" width="119" height="160" /><a href="https://www.linkedin.com/in/anupamsh/">Anupam Shrivastava</a> is a software development engineer on the Amazon EC2 Systems Manager team. He enjoys being part of AWS and building easy-to-use scalable solutions for customers across the globe. Outside of work, he enjoys playing tennis and cricket, swimming, and traveling.</p> 
<p>&nbsp;</p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/mt/tag/aws-systems-manager/" rel="tag">AWS Systems Manager</a>, <a href="https://aws.amazon.com/blogs/mt/tag/configuration-management/" rel="tag">Configuration Management</a>, <a href="https://aws.amazon.com/blogs/mt/tag/ssm/" rel="tag">SSM</a>, <a href="https://aws.amazon.com/blogs/mt/tag/state-manager/" rel="tag">State Manager</a></span> 
</footer> 
</article> 
<article class="post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="b post-title" property="name headline">Introducing the AWS Config Rule Development Kit (RDK)</b> 
<footer class="meta">
by 
<span property="author" typeof="Person"><span property="name">Henry Huang</span></span> | on 
<time property="datePublished" datetime="2017-09-12T13:59:42+00:00">12 SEP 2017</time> | in 
<span class="categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/aws-config/" title="View all posts in AWS Config"><span property="articleSection">AWS Config</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools"><span property="articleSection">Management Tools</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/introducing-the-aws-config-rule-development-kit-rdk/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog=""><span class="span icon-share"></span>&nbsp;Share</a> 
<ul> 
</ul> 
</footer> 
<p>Recently, <a href="https://aws.amazon.com/config">AWS Config</a> released a Rule Development Kit (RDK) that greatly simplifies your custom rule authoring experience. The RDK is an open-source tool that helps you set up AWS Config, author rules, and then test them using a variety of AWS resource types. This allows you to focus on the development of the rule itself. The AWS Config RDK is now available for download from the <a href="https://github.com/awslabs/aws-config-rdk">aws-config-rdk</a> GitHub repo. We follow semantic versioning, and are dedicated to maintaining backwards compatibility for each major version.</p> 
<h3>About AWS Config</h3> 
<p>AWS Config is a service that enables you to assess, audit, and evaluate the configurations of your AWS resources. AWS Config continuously monitors and records your AWS resource configurations and allows you to automate the evaluation of recorded configurations against desired configurations. Rules enable you to automatically check the configuration of AWS resources recorded by AWS Config. There are 37 managed AWS Config rules by default and 34 custom rules maintained by the community in the <a href="https://github.com/awslabs/aws-config-rules">aws-config-rules</a> GitHub repo.</p> 
<p><span id="more-1254"></span></p> 
<b>Getting started</b> 
<p>You can get started with AWS Config RDK and create a rule named “Hello World” in just a few minutes.</p> 
<ul> 
<li>Prerequisites</li> 
<li>Enable AWS Config</li> 
<li>Create your first rule</li> 
<li>Test your rule</li> 
</ul> 
<b>Prerequisites</b> 
<p>The AWS Config RDK requires the latest version of the <a href="https://aws.amazon.com/cli">AWS CLI</a>. You must also log in to an AWS account. Use the following command to install the AWS CLI (<a href="http://docs.aws.amazon.com/cli/latest/userguide/installing.html">requires pip to be installed already</a>):</p> 
<pre><code class="lang-bash">pip install --upgrade --user awscli</code></pre> 
<p>Use the following command to configure the AWS CLI. For more information, see <a style="font-family: Georgia, 'Times New Roman', 'Bitstream Charter', Times, serif" href="http://docs.aws.amazon.com/cli/latest/userguide/cli-chap-getting-started.html">Configuring the AWS CLI</a><span style="font-family: Georgia, 'Times New Roman', 'Bitstream Charter', Times, serif">.</span></p> 
<pre><code class="lang-bash">aws configure --profile myCLIprofile 
AWS Access Key ID [None]: AKIAI44QH8DHBEXAMPLE
AWS Secret Access Key [None]: je7MtGbClwBF/2Zp9Utk/h3yCo8nvbEXAMPLEKEY
Default region name [None]: us-east-1
Default output format [None]: text</code></pre> 
<p>Use the following command to clone the AWS Config RDK on macOS, Linux, or Windows platforms:</p> 
<pre><code class="lang-bash">git clone https://github.com/awslabs/aws-config-rdk.git</code></pre> 
<p>Choose your platform (MacLinux or Windows).<br /> <img src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/12/blog-post-01.png" /></p> 
<b>Enable AWS Config</b> 
<p>To begin, enable AWS Config in your AWS account for the region configured in the AWS CLI. For example, on macOS or Linux, use the following command to configure your profile:</p> 
<pre><code class="lang-bash">cd MacLinux/setup; ./setup myCLIprofile </code></pre> 
<p>You see the following results:<br /> <img src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/12/blog-post-02.png" /><br /> On Windows, use the following command to configure your profile:</p> 
<pre><code class="lang-bash">cd Windows/setup; ./setup.cmd myCLIprofile </code></pre> 
<p>You see the following results:<br /> <img src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/12/blog-post-03.png" /></p> 
<p>In this example, AWS Config in the us-east-1 region has been enabled by RDK setup.<br /> <img src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/12/blog-post-04.png" /></p> 
<b>Create your first rule</b> 
<p>Now you can create your first rule. Use the following command to create the EBS_OPTIMIZED_INSTANCE managed rule, which checks whether Amazon EBS optimization is enabled for your EC2 instances that can be EBS-optimized. Create the rule under the folder /aws-config-rdk/MacLinux/rules on macOS or Linux:</p> 
<pre><code class="lang-bash">cd MacLinux/rules; ./createRule myCLIprofile hello_world AWS::EC2::Instance </code></pre> 
<p>You see the following results:<br /> <img src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/12/blog-post-05.png" /></p> 
<p>On Windows, use the following command:</p> 
<pre><code class="lang-bash">cd Windows/rules; ./createRule.cmd myCLIprofile hello_world AWS::EC2::Instance </code></pre> 
<p>You see the following results:</p> 
<p><img src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/12/blog-post-06.png" /></p> 
<p>The following resources were created:</p> 
<ul> 
<li>The parameter “APPLICABLE_RESOURCE_TYPES” has the same value as “APPLICABLE_RESOURCES” already defined in the rule code</li> 
<li>The AWS Lambda function named “hello_world”</li> 
<li>An AWS Config rule named “hello_world”, which was also associated with the Lambda function</li> 
</ul> 
<p>The rule has started to evaluate EC2 instances for compliance with EBS optimization.<br /> <img src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/12/blog-post-07.png" /><br /> Now you can replace the default values with your own code. Make sure that resource types are consistent between the rule_code.py and createRule.cmd script parameters. Otherwise, your rule returns NOT_APPLICABLE. The rules/ruleCode/rule_util.py script handles the boring parts of a rule, and should not need to be modified.</p> 
<b>Test your rule</b> 
<p>The AWS Config RDK supports testing your rule by invoking the Lambda function with configuration items (used as test cases) from the /rules/testUtil/compliantCIs and /rules/testUtil/noncompliantCIs directories. The RDK checks that the Lambda function returns the corresponding result.</p> 
<p>On macOS or Linux, use the following command:</p> 
<pre><code class="lang-bash">cd MacLinux/rules; ./test myCLIprofile hello_world </code></pre> 
<p>You see the following results:</p> 
<p><img src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/12/blog-post-08.png" /></p> 
<p>On Windows, use the following command:</p> 
<pre><code class="lang-bash">cd Windows/rules; ./test.cmd myCLIprofile hello_world </code></pre> 
<p>You see the following results:</p> 
<p><img src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/12/blog-post-09.png" /></p> 
<p>Besides, we have provided Configuration Item examples in “rules/testUtil/exampleCIs” to help you to write test cases by the modification to make them represent compliant or non-compliant resources.<br /> <img src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/12/blog-post-10.png" /></p> 
<b>Summary</b> 
<p>The AWS Config RDK helps you build rules easily, including the following:</p> 
<ul> 
<li>Preparing the initial rule development environment, by enabling AWS Config with a variety of automatically created AWS resources.</li> 
<li>Creating Lambda functions, rules, and the association between them so that you don’t have to.</li> 
<li>Supporting multiple platforms: &nbsp;macOS, Linux, and Windows.</li> 
<li>Testing rules just by the code, with no more manual setup in complicated test environments.</li> 
</ul> 
<p>We would love to hear your feedback. Feel free to leave comments or suggestions on the&nbsp;<a href="https://github.com/awslabs/aws-config-rdk">aws-config-rdk</a> GitHub page.</p> 
<h3>About the Author</h3> 
<p><img class="alignleft" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/12/blog-post-11.png" /><br /> Henry Huang is a DevOps Consultant for the Professional Services Team&nbsp;at Amazon Web Services in China.</p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/mt/tag/aws-config/" rel="tag">AWS Config</a>, <a href="https://aws.amazon.com/blogs/mt/tag/config-rule/" rel="tag">Config Rule</a>, <a href="https://aws.amazon.com/blogs/mt/tag/rdk/" rel="tag">RDK</a>, <a href="https://aws.amazon.com/blogs/mt/tag/rule-development-kit/" rel="tag">Rule Development Kit</a></span> 
</footer> 
</article> 
<article class="post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<meta property="image" content="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/08/23/prof-473x630.jpg" /> 
<b class="b post-title" property="name headline">Smart Budgeting Using Lambda and Service Catalog</b> 
<footer class="meta">
by 
<span property="author" typeof="Person"><span property="name">Tapodipta Ghosh</span></span> | on 
<time property="datePublished" datetime="2017-09-07T11:42:37+00:00">07 SEP 2017</time> | in 
<span class="categories"><a href="https://aws.amazon.com/blogs/mt/category/messaging/amazon-simple-notification-service-sns/" title="View all posts in Amazon Simple Notification Service (SNS)"><span property="articleSection">Amazon Simple Notification Service (SNS)</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/aws-cost-management/aws-budgets/" title="View all posts in AWS Budgets"><span property="articleSection">AWS Budgets</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/aws-cost-management/" title="View all posts in AWS Cost Management"><span property="articleSection">AWS Cost Management</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/compute/aws-lambda/" title="View all posts in AWS Lambda"><span property="articleSection">AWS Lambda</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/aws-service-catalog/" title="View all posts in AWS Service Catalog"><span property="articleSection">AWS Service Catalog</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/smart-budgeting-using-lambda-and-service-catalog/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog=""><span class="span icon-share"></span>&nbsp;Share</a> 
<ul> 
</ul> 
</footer> 
<p>If you have a lot of development activity in your organization, it’s important to keep track of your non-production AWS accounts.</p> 
<p>If these accounts aren’t monitored closely, you might easily end up exceeding your budget.</p> 
<p>In this blog post, I demonstrate how you can use the <a href="https://aws.amazon.com/about-aws/whats-new/2015/06/aws-introduces-budgets-a-simple-way-to-manage-your-aws-costs/">AWS Budgets</a> alert in conjunction with<a href="https://aws.amazon.com/lambda/"> AWS Lambda</a> and <a href="https://aws.amazon.com/servicecatalog/">AWS Service Catalog</a> to automate management of your IT budget for non-production environments.<span id="more-1163"></span></p> 
<h3>Workflow</h3> 
<p>For this example, I have created a billing alarm to notify me when the cost for a sandbox account overshoots the forecast by 30 percent. The billing alarm is tied to an Amazon SNS Topic which is subscribed by a Lambda function. This ensures that when the billing alert occurs, the IT administrator gets notified via SNS about the possibility of an overage. At the same time, the Lambda function calls the AWS Service Catalog API to enforce the template constraint to freeze all EC2 instance creation to only the t2.medium type.</p> 
<p>&nbsp;</p> 
<p><img class="aligncenter wp-image-1165 size-large" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/08/23/Screen-Shot-2017-08-07-at-2.00.50-PM-1024x508.png" alt="" width="640" height="318" /></p> 
<h3>Create the SNS topic and subscription</h3> 
<p>In the SNS console, choose&nbsp;Create topic&nbsp;and enter appropriate values for the &nbsp;Topic name&nbsp;(such as BudgetAlert) and&nbsp;Display name&nbsp;(Budget-Alert).</p> 
<p>Choose&nbsp;Create topic. Select the topic and view the details.</p> 
<p>Next, choose&nbsp;Create subscription.</p> 
<p>For&nbsp;Protocol, choose&nbsp;Email. Enter the email address where notifications should be sent and choose&nbsp;Create subscription.</p> 
<p>An email is sent to confirm the SNS topic subscription. In the email, open the&nbsp;SubscribeURL&nbsp;link to complete the subscription. Note the SNS topic Amazon Resource Name (ARN) because it’s used later by the Lambda function.</p> 
<p><img class="aligncenter wp-image-1166" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/07/sns.png" alt="" width="683" height="258" /></p> 
<p>For more information, see&nbsp;<a href="http://docs.aws.amazon.com/sns/latest/dg/CreateTopic.html">Create a Topic</a>&nbsp;in the Amazon SNS Developer Guide.</p> 
<h3>Create the Lambda function</h3> 
<p>In the Lambda console, choose&nbsp;Functions,&nbsp;Create a Lambda function. Choose Blank Function and on the&nbsp;Configure trigger page, choose&nbsp;Next.</p> 
<p>On the next page, enter the following values:</p> 
<p>&middot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Runtime:&nbsp;Python 2.7</p> 
<p>&middot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Code entry type:&nbsp;Inline</p> 
<p>&middot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Role:&nbsp;Create a custom role (takes you to another page). Call the role service-catalog-lambda-&lt;region&gt;-role</p> 
<p>For the policy document, enter the following policy:</p> 
<pre><code class="lang-json">{
&nbsp;&nbsp;&nbsp; &quot;Version&quot;: &quot;2012-10-17&quot;,
&nbsp;&nbsp;&nbsp; &quot;Statement&quot;: [
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; {
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;Action&quot;: [
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;servicecatalog:*&quot;,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;s3:*&quot;,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;cloudformation:ValidateTemplate&quot;,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;iam:GetRole&quot;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ],
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;Resource&quot;: [
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;*&quot;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ],
&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;Effect&quot;: &quot;Allow&quot;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; },
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; {
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;Action&quot;: [
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;logs:CreateLogGroup&quot;,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;logs:CreateLogStream&quot;,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;logs:PutLogEvents&quot;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ],
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;Resource&quot;: &quot;arn:aws:logs:*:*:*&quot;,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&quot;Effect&quot;: &quot;Allow&quot;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }
&nbsp;&nbsp;&nbsp; ]
}</code></pre> 
<p>On the&nbsp;Configure function&nbsp;page, choose&nbsp;Next. Review the configuration settings before choosing&nbsp;Create function.</p> 
<p>You can also follow the instructions here:</p> 
<p><a href="https://github.com/awslabs/aws-service-catalog-enforce-template-constraints/">https://github.com/awslabs/aws-service-catalog-enforce-template-constraints/</a></p> 
<h3>Budget alert</h3> 
<p>Create the AWS Budgets alert and add the IT administrator’s email to notify the administrator when the forecasted budget is greater than the percentage that you choose (in our example, it’s 30 %). Add the SNS Topic ARN and Verify. You should see “Verified” next to the topic ARN.</p> 
<p><img class="aligncenter wp-image-1167 size-full" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/08/23/BudgetAlert.png" alt="" width="975" height="398" /></p> 
<p>For more information on how to create AWS budgets, you can refer the AWS Budgets Update blog post.</p> 
<p>After the alert condition is met, the IT administrator will receive an email from AWS Budgets similar to the sample that follows:</p> 
<pre><code class="lang-json">{&nbsp;&quot;Subject&quot; : &quot;Budget&nbsp;Notification: Test is in Alarm State&quot;,
&nbsp; &quot;Message&quot; : &quot;AWS&nbsp;Budget&nbsp;Notification\n\nDear AWS Customer,\n\nYou requested that we notify you when your Actual Cost for your&nbsp;budget&nbsp;\&quot;BudgetAlert\&quot; is greater than $50000. Your Actual Cost for this&nbsp;budget&nbsp;is now $50393. You can find further details below and by accessing your AWS&nbsp;Budgets&nbsp;dashboard.\n\nBudget
}</code></pre> 
<p>The Lambda function also gets triggered. It looks for all portfolios in the Service Catalog, looks for InstanceType template constraints, and it changes the constraint to “t2.medium or small only.” The following example shows how the updated constraint looks after the Lambda function has successfully run.<br /> <img class="aligncenter wp-image-1168 size-full" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/08/23/post_lambda_run.png" alt="" width="975" height="525" /></p> 
<h3>Summary</h3> 
<p>In this post, I’ve demonstrated an easy way to keep track of your non-prod accounts budget, while you are also focused on continuous development.</p> 
<hr /> 
<h3>About the Author</h3> 
<p><img class="size-full wp-image-1230 alignleft" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/07/tapo.jpg" alt="" width="119" height="160" /></p> 
<p>Tapodipta Ghosh is a Solutions Architect focusing on AWS Marketplace.&nbsp;&nbsp;Tapo&nbsp;is passionate about cloud computing and loves helping customers on-board their products into AWS Marketplace.</p> 
<p>&nbsp;</p> 
<p>&nbsp;</p> 
<p>&nbsp;</p> 
<p>&nbsp;</p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/mt/tag/aws-budgets/" rel="tag">AWS Budgets</a>, <a href="https://aws.amazon.com/blogs/mt/tag/aws-lambda/" rel="tag">AWS Lambda</a>, <a href="https://aws.amazon.com/blogs/mt/tag/aws-service-catalog/" rel="tag">AWS Service Catalog</a>, <a href="https://aws.amazon.com/blogs/mt/tag/aws-sns/" rel="tag">AWS SNS</a></span> 
</footer> 
</article> 
<article class="post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="b post-title" property="name headline">The Right Way to Store Secrets using Parameter Store</b> 
<footer class="meta">
by 
<span property="author" typeof="Person"><span property="name">Ananth Vaidyanathan</span></span> | on 
<time property="datePublished" datetime="2017-08-27T23:00:38+00:00">27 AUG 2017</time> | in 
<span class="categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/amazon-ec2-systems-manager/" title="View all posts in Amazon EC2 Systems Manager"><span property="articleSection">Amazon EC2 Systems Manager</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools"><span property="articleSection">Management Tools</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/the-right-way-to-store-secrets-using-parameter-store/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog=""><span class="span icon-share"></span>&nbsp;Share</a> 
<ul> 
</ul> 
</footer> 
<p><em>This guest post was written by Evan Johnson, who works in the Security team at Segment.</em></p> 
<p>The way companies manage application secrets is critical. Even today, the most high profile security companies can suffer breaches from improper secrets management practices. Having internet facing credentials is like leaving your house key under a doormat that millions of people walk over daily. Even if the secrets are hard to find, it is a game of hide and seek that you eventually lose.</p> 
<p>At <a href="https://segment.com/">Segment</a>, we centrally and securely manage our secrets with <a href="https://aws.amazon.com/ec2/systems-manager/parameter-store/">Amazon EC2 Systems Manager Parameter Store</a>, lots of Terraform code, and <a href="https://github.com/segmentio/chamber">chamber</a>. Parameter store is a great tool for achieving secrets management. If you are running workloads on AWS, then using Parameter Store as a managed secrets store is worth serious consideration. This post has all the information you need to get running with Parameter Store in production.</p> 
<p><span id="more-1184"></span></p> 
<h3>Service Identity</h3> 
<p>At Segment, we run hundreds of services that communicate with one another, AWS APIs, and third-party APIs. The services we run have different needs and should only have access to systems that are strictly necessary. This is called the ‘principle of least privilege’.</p> 
<p>As an example, our main webserver should never have access to security audit logs for our infrastructure. Without giving containers and services an identity, it is not possible to protect and restrict access to secrets with access control policies. Our services identify themselves using IAM roles. From the AWS docs – “<em>An IAM role … is an AWS identity with permission policies that determine what the identity can and cannot do in AWS</em>.”</p> 
<p>For example, our IAM roles for instances have write-only access to an Amazon S3 bucket for appending audit logs, but prevent the deletion and reading of those logs.</p> 
<h4>How do containers get their role securely?</h4> 
<p>A requirement to using <a href="https://aws.amazon.com/ecs/">Amazon ECS</a> is that all containers must run the <a href="https://github.com/aws/amazon-ecs-agent">Amazon ECS container agent</a> (ecs-agent). The agent runs as a container that orchestrates and provides an API with which other containers can communicate. The agent is the central nervous system of how containers fetch IAM role credentials.</p> 
<p><img class="size-full wp-image-1188 alignnone" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/08/25/Diagram1a.png" alt="" width="450" height="337" /></p> 
<p>One important piece to the agent is that it runs an HTTP API that MUST be accessible to the other containers that are running in the cluster. To make this API available, an iptables rule is set on the host instance. This iptables rule forwards traffic destined for a magic IP address to the ecs-agent container.</p> 
<pre><code class="lang-bash">iptables -t nat \
-A OUTPUT \
-d 169.254.170.2 \
-p tcp \
-m tcp \
--dport 80 \
-j REDIRECT \
--to-ports 51679</code></pre> 
<p>Before the agent starts a container, it first fetches credentials for the container’s task role from the AWS credential service. The agent next sets the credentials key ID, a UUID, as the AWS_CONTAINER_CREDENTIALS_RELATIVE_URI environment variable inside the container when it is started.</p> 
<pre><code class="lang-bash">$ env
...
AWS_CONTAINER_CREDENTIALS_RELATIVE_URI=/v2/credentials/53875b56-621a-4b07-8ab6-02ea315b5693
...</code></pre> 
<p>Using this relative URI and UUID, containers fetch AWS credentials from the agent over HTTP. One container cannot access the authentication credentials to impersonate another container because the UUID is sufficiently difficult to guess.</p> 
<pre><code class="lang-bash">$ curl 169.254.170.2$AWS_CONTAINER_CREDENTIALS_RELATIVE_URI | jq .
{
&quot;RoleArn&quot;: &quot;arn:aws:iam::111111111111:role/test-service&quot;,
&quot;AccessKeyId&quot;: &quot;ASIAIYLSOW5USUQCZAAQ&quot;,
&quot;SecretAccessKey&quot;: &quot;REDACTRED&quot;,
&quot;Token&quot;: &quot;REDACTED&quot;,
&quot;Expiration&quot;: &quot;2017-08-10T02:01:43Z&quot;
}</code></pre> 
<h4>Additional security details</h4> 
<p>As heavy Amazon ECS users, we did find security foot-guns associated with ECS task roles. It’s important to realize that any container that can access the Amazon EC2 metadata service on behalf of its host can become any other task role on the system. This could allow containers to circumvent access control policies and gain access to unauthorized systems.</p> 
<p><img class="size-full wp-image-1190 alignnone" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/08/25/Diagram2.png" alt="" width="450" height="337" /></p> 
<p>The two ways a container can access the metadata service is using host networking and over the docker bridge. When a container is run with <span style="text-decoration: underline">–network=’host’</span>, it is always able to connect to the EC2 metadata service using its host’s network. Setting the <span style="text-decoration: underline">ECS_ENABLE_TASK_IAM_ROLE_NETWORK_HOST</span> variable to false in the ecs-agent config file prevents containers from running with this permission.</p> 
<p>Additionally, it’s important to block access to the metadata service IP address over the Docker bridge using iptables. The <a href="http://docs.aws.amazon.com/AmazonECS/latest/developerguide/task-iam-roles.html">IAM task role documentation</a> recommends preventing access to the EC2 metadata service with this specific rule.</p> 
<pre><code class="lang-bash">$ iptables --insert FORWARD 1 --in-interface docker+ --destination 169.254.169.254/32 --jump DROP</code></pre> 
<p>The principle of least privilege is always important to keep in mind when building a security system. Setting <span style="text-decoration: underline">ECS_DISABLE_PRIVILEGED</span> to true in the host’s ecs-agent config file can prevent privileged Docker containers from being run and causing other more nuanced security problems.</p> 
<h3>Parameter Store</h3> 
<p>Parameter Store is an AWS service that stores strings. It can store secret data and non-secret data alike. Secrets stored in Parameter Store are secure strings, encrypted with a customer-specific AWS KMS key.</p> 
<p>Under the hood, a service that requests secure strings from the Parameter Store has a lot of things happening behind the scenes.</p> 
<ol> 
<li>The ECS container agent requests the host instance’s temporary credentials.</li> 
<li>The agent continuously generates temporary credentials for each ECS task role running on ECS, using an undocumented service called ACS.</li> 
<li>When the agent starts each task, it sets a secret UUID in the environment of the container.</li> 
<li>When the task needs its task role credentials, it requests them from the ecs-agent API and authenticates with the secret UUID.</li> 
<li>The ECS task requests its secrets from Parameter Store using the task role credentials.</li> 
<li>Parameter Store transparently decrypts these secure strings before returning them to the ECS task.</li> 
</ol> 
<p><img class="size-full wp-image-1198 alignnone" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/08/25/diagram3-1.png" alt="" width="350" height="466" /></p> 
<p>Using roles with Parameter Store is especially nice because it does not require maintaining additional authentication tokens. This would create additional headache and additional secrets to manage!</p> 
<h4>Parameter Store IAM Policies</h4> 
<p>Each role that accesses the Parameter Store requires the <span style="text-decoration: underline">ssm:GetParameters</span> permission. “SSM” stands for “Simple System Manager”, the previous name for Systems Manager, and is how <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/sysman-paramstore-access.html">AWS denotes Parameter Store operations</a>.</p> 
<p>The ssm:GetParameters permission is the policy used to enforce access control and protect one service’s secrets from another. Segment gives all services an IAM role that grants access to secrets that match the format&nbsp; {{service_name}}/*.&nbsp; Parameter Store <a href="https://aws.amazon.com/blogs/mt/organize-parameters-by-hierarchy-tags-or-amazon-cloudwatch-events-with-amazon-ec2-systems-manager-parameter-store/">supports hierarchies natively</a>, so this permission provides each service with its own directory of secrets.</p> 
<pre><code class="lang-json">{
&quot;Sid&quot;: &quot;&quot;,
&quot;Effect&quot;: &quot;Allow&quot;,
&quot;Action&quot;: &quot;ssm:GetParameters&quot;,
&quot;Resource&quot;: [
&quot;arn:aws:ssm:*:*:parameter/{{service_name}}/*&quot;,
]
},</code></pre> 
<p>In addition to the access control policies, Segment uses a dedicated AWS KMS key to encrypt secure strings within the Parameter Store. Each IAM role is granted a small set of KMS permissions in order to decrypt the secrets they store in Parameter Store.</p> 
<pre><code class="lang-json">{
&quot;Sid&quot;: &quot;&quot;,
&quot;Effect&quot;: &quot;Allow&quot;,
&quot;Action&quot;: [
&quot;kms:ListKeys&quot;,
&quot;kms:ListAliases&quot;,
&quot;kms:Describe*&quot;,
&quot;kms:Decrypt&quot;
],
&quot;Resource&quot;: &quot;parameter_store_key&quot;
}</code></pre> 
<h3>Automating service identity and policies</h3> 
<p class="hide-language">Segment has a small Terraform module that abstracts away the creation of a unique IAM role, load balancers, DNS records, Auto Scaling, and CloudWatch alarms. Below, I show how our nginx load balancer is defined using our service module.</p> 
<pre><code class="lang-yaml">module &quot;nginx&quot; {
source            = &quot;../modules/service&quot;
name              = &quot;nginx&quot;
image             = &quot;segment/nginx&quot;
product_area      = &quot;foudation-security&quot;
health_check_path = &quot;/healthcheck&quot;
environment       = &quot;${var.environment}&quot;
}</code></pre> 
<p>Under the hood, the task role given to each service has all of the IAM policies we previously listed, restricting access to Parameter Store by the value in the name field. No configuration required.</p> 
<p>Additionally, developers have the option to override which secrets their service has access to by providing a “secret label”. This secret label replaces their service name in their IAM policy. If NGINX were to need the same secrets as an HAProxy instance, the two services can share credentials by using the same secret label.</p> 
<pre><code class="lang-yaml"></code><code class="lang-yaml">module &quot;nginx&quot; {
source            = &quot;../modules/service&quot;
name              = &quot;nginx&quot;
image             = &quot;segment/nginx&quot;
product_area      = &quot;foudation-security&quot;
health_check_path = &quot;/healthcheck&quot;
environment       = &quot;${var.environment}&quot;
# Share secrets with loadbalancers
<strong>secret_label = &quot;loadbalancers&quot;</strong>
}</code></pre> 
<h3>Parameter Store in production</h3> 
<p>All Segment employees authenticate with AWS using aws-vault, which can securely store AWS credentials in the macOS keychain or in an encrypted file for Linux users. Segment has several AWS accounts. Engineers can interact with each account using aws-vault, and execute commands locally with their AWS credentials populated in their environment.<code class="lang-json"><br /> </code></p> 
<pre><code class="lang-bash">$ aws-vault exec development -- aws s3 ls s3://segmentio-bucket</code></pre> 
<h4>Using Chamber with Parameter Store</h4> 
<p>Chamber is a CLI tool that Segment built to allow developers and code to communicate with Parameter Store in a consistent manner. By allowing developers to use the same tools that run in production, we decrease the number of differences between code running in development with staging and production.</p> 
<p>Chamber works with aws-vault, and has only a few key subcommands:</p> 
<ul> 
<li>exec—a command after loading secrets in to the environment.</li> 
<li>history—of changes made to a secret in parameter store.</li> 
<li>list—the names of all secrets in a services path.</li> 
<li>write—a secret to the Parameter Store.</li> 
</ul> 
<p>Chamber leverages Parameter Store’s built in search and history mechanisms to implement the list and history subcommands. All strings stored in Parameter Store are automatically versioned. The subcommand used to fetch secrets from the Parameter Store is exec. When developers use the exec subcommand, they use it with aws-vault.</p> 
<p><code class="lang-bash">$ aws-vault exec development -- chamber exec loadbalancers -- nginx</code></p> 
<p>In the preceding command, chamber is executed with the credentials and permissions of the employee in the development account, and it fetches the secrets associated with loadbalancers from Parameter Store. After chamber populates the environment, it runs the NGINX server.</p> 
<h4 class="hide-language">Running chamber in production</h4> 
<p>Chamber is packaged inside our Docker containers as a binary and is the entry point of the container. Chamber passes signals to the program it executes in order to allow the program to gracefully handle them.</p> 
<p>Here’s a diff of what it required to make our main website chamber ready.</p> 
<pre><code class="lang-bash">-ENTRYPOINT [&quot;node&quot;, &quot;server/boot.js&quot;] 
+ENTRYPOINT [&quot;chamber&quot;, &quot;exec&quot;, &quot;app&quot;, &quot;--&quot;, &quot;node&quot;, &quot;server/boot.js&quot;]</code></pre> 
<p>Non-Docker containers can also use chamber to populate the environment before creating configuration files out of templates, run daemons, etc.</p> 
<h3>Auditing</h3> 
<p>All access to Parameter Store is logged with AWS CloudTrail. This makes keeping a full audit trail for all parameters simple and inexpensive. It also makes building custom alerting and audit logging straightforward.</p> 
<pre><code class="lang-json">...
&quot;eventTime&quot;: &quot;2017-08-02T18:54:06Z&quot;,
&quot;eventSource&quot;: &quot;ssm.amazonaws.com&quot;,
&quot;eventName&quot;: &quot;GetParameters&quot;,
&quot;awsRegion&quot;: &quot;us-west-2&quot;,
&quot;sourceIPAddress&quot;: &quot;127.0.0.1&quot;,
&quot;userAgent&quot;: &quot;aws-sdk-go/1.8.1 (go1.8.3; linux; amd64)&quot;,
&quot;requestParameters&quot;: {
&quot;withDecryption&quot;: true,
&quot;names&quot;: [
&quot;test-service.secretname&quot;
]
},
&quot;responseElements&quot;: null,
&quot;requestID&quot;: &quot;88888888-4444-4444-4444-121212121212&quot;,
&quot;eventID&quot;: &quot;88888888-4444-4444-4444-121212121212&quot;,
&quot;readOnly&quot;: true,
...</code></pre> 
<p>CloudTrail makes it possible to determine exactly what secrets are used and can make discovering unused secrets or unauthorized access to secrets possible.</p> 
<p>AWS logs all Parameter Store access for free as a CloudTrail management event. Most security information and events management (SIEM) solutions can be configured to watch, and read data from S3.</p> 
<h3>Summary</h3> 
<p>Using Parameter Store and IAM, Segment was able to build a small tool that provides all of the properties most important in a secrets management system.</p> 
<ul> 
<li>Protect the secrets at rest with strong encryption.</li> 
<li>Enforce strong access control policies.</li> 
<li>Create audit logs of authentication and access history.</li> 
<li>Great developer experience.</li> 
</ul> 
<p>Secrets management is very challenging to get right. Many products have been built to manage secrets, but none fit the use cases needed by Segment better than Parameter Store.</p> 
<h3>About the Author</h3> 
<p><img class="size-full wp-image-1192 alignnone" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/08/25/evan.png" alt="" width="125" height="165" /><a href="https://www.linkedin.com/in/evan-j-johnson-35871871/">Evan Johnson</a> works on security at <a href="http://segment.com/">Segment</a>. Segment is the infrastructure for customer data. Businesses use Segment’s API to unlock 200+ tools for every team across their organization. With Segment, developers can stop building tedious and expensive one-off data integrations, turning on their favorite apps right from the Segment dashboard.</p> 
<p><a href="https://segment.com/"><img class="alignleft size-full wp-image-1193" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/08/25/segment.png" alt="" width="375" height="85" /></a></p> 
<p>&nbsp;</p> 
<p>&nbsp;</p> 
<hr /> 
<p><em>AWS is not responsible for the content or accuracy of this post. The content and opinions in this blog are solely those of the third party author.</em></p> 
<p><code class="lang-bash"></code><code class="lang-bash"></code></p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/mt/tag/configuration-secrets/" rel="tag">Configuration Secrets</a>, <a href="https://aws.amazon.com/blogs/mt/tag/ec2-systems-manager/" rel="tag">EC2 Systems Manager</a>, <a href="https://aws.amazon.com/blogs/mt/tag/parameter-store/" rel="tag">Parameter Store</a>, <a href="https://aws.amazon.com/blogs/mt/tag/ssm/" rel="tag">SSM</a></span> 
</footer> 
</article> 
<p>
© 2017, Amazon Web Services, Inc. or its affiliates. All rights reserved.
</p>

    </div>
  </div>
</div>


    <div id="footer" class="navigation hidden-print">
      <div class="container">
        <div class="row">
          <div class="col-xs-12">
            <ul class="footer-links nav navbar-nav">
              <li><a href="../aws.html">AWS</a></li>
              <li><a href="../linux.html">Linux</a></li>
              <li><a href="../docker.html">Docker</a></li>
              <li><a href="../ibmpower.html">IBM Power</a></li>
              <li><a href="blogsataws1.html">Blogs@AWS (Kindle Friendly)</a></li>
            </ul>
            <ul class="footer-links nav navbar-nav navbar-right">
              <li><a href="../comments.html">Comments?</a></li>
            </ul>
          </div>
        </div>
      </div>
    </div>
  </body>
</html>
