<!DOCTYPE html>
<html lang="en">
  <head>
<!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-593498H');</script>
<!-- End Google Tag Manager -->

    <meta charset="utf-8">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">

    <meta name="msapplication-config" content="/microsoft-tile.xml" />
    <meta name="theme-color" content="#ffffff">

    <meta property="og:url" content="https://bejoycalias.github.io/blogsataws/mgmtblogs1.html" />
    <meta property="og:site_name" content="Bejoy's TechNotes"/>
    <meta property="og:title" content="Bejoy's TechNotes - Kindle Friendly AWS Management Tools Blogs" />
    <meta property="og:image" content="https://bejoycalias.github.io/assets/images/og-image.png"/>
    <meta property="og:image:width" content="1200"/>
    <meta property="og:image:height" content="1200"/>
    <meta property="og:description" content="" />

    <title>Bejoy's TechNotes - Kindle Friendly AWS Management Tools Blogs</title>
    <link href="../assets/stylesheets/application-832aa42c.css" rel="stylesheet" />

    <!--[if lt IE 9]>
      <script src="../assets/javascripts/ie-compat-c141a02d.js"></script>
    <![endif]-->
    <script src="../assets/javascripts/application-ff53d307.js"></script>

    <!-- Typekit script to import Klavika font -->
    <script src="https://use.typekit.net/wxf7mfi.js"></script>
    <script>try{Typekit.load({ async: true });}catch(e){}</script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-100043608-1', 'auto');
  ga('send', 'pageview');

</script>

    
  </head>

  <body id="uh-oh-" class="layout-inner page-uh-oh-">
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-593498H"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->


    <div id="header" class="navigation navbar-static-top hidden-print">
      <div class="container">
        <div class="row">
          <div class="col-xs-12">
            <div class="navbar-header">
              <div class="navbar-brand">
                <a href="/">
                  <svg version="1.0" xmlns="http://www.w3.org/2000/svg" width="135.000000pt" height="50" viewbox="0 0 135.000000 45.000000" preserveaspectratio="xMidYMid meet" class="logo">

<g transform="translate(0.000000,45.000000) scale(0.100000,-0.100000)" fill="#000000" stroke="none">
<path class="text" fill="#000000" d="M527 384 c-4 -4 -7 -18 -7 -31 0 -21 4 -24 28 -21 21 2 27 8 27 28 0
18 -6 26 -20 28 -12 2 -24 0 -28 -4z"></path>
<path class="text" fill="#000000" d="M1080 335 c0 -48 2 -55 20 -55 18 0 20 7 20 55 0 48 -2 55 -20 55
-18 0 -20 -7 -20 -55z"></path>
<path class="text" fill="#000000" d="M54 357 c-2 -7 -3 -69 -2 -138 l3 -124 65 -3 c90 -3 130 20 130 77 0
29 -6 44 -20 54 -20 14 -20 15 -3 45 14 25 15 34 5 56 -6 15 -23 31 -38 36
-38 15 -134 13 -140 -3z m110 -33 c19 -7 21 -45 4 -62 -7 -7 -22 -12 -35 -12
-20 0 -23 5 -23 40 0 41 13 50 54 34z m20 -130 c19 -18 19 -20 6 -45 -8 -13
-21 -19 -45 -19 -34 0 -35 1 -35 40 0 38 2 40 29 40 16 0 37 -7 45 -16z"></path>
<path class="text" fill="#000000" d="M319 271 c-23 -24 -29 -38 -29 -74 0 -25 3 -53 6 -62 20 -50 164 -64
164 -15 0 15 -7 17 -45 12 -46 -5 -75 8 -75 34 0 11 16 14 65 14 l65 0 0 35
c0 80 -92 114 -151 56z m99 -33 c3 -15 -4 -18 -37 -18 -43 0 -50 7 -29 28 18
18 62 11 66 -10z"></path>
<path class="text" fill="#000000" d="M520 184 c0 -107 -1 -116 -20 -121 -11 -3 -20 -12 -20 -19 0 -21 76
-19 84 2 3 9 6 69 6 135 l0 119 -25 0 -25 0 0 -116z"></path>
<path class="text" fill="#000000" d="M649 271 c-24 -25 -29 -37 -29 -78 1 -70 34 -103 105 -103 55 0 95
44 95 103 0 60 -7 75 -41 92 -47 25 -96 19 -130 -14z m111 -30 c25 -48 2 -111
-40 -111 -45 0 -69 80 -34 114 21 22 61 20 74 -3z"></path>
<path class="text" fill="#000000" d="M850 287 c0 -8 16 -57 36 -110 28 -76 33 -100 25 -116 -16 -28 -14
-31 18 -31 27 0 29 4 70 123 23 67 41 128 41 135 0 6 -11 12 -24 12 -21 0 -26
-8 -41 -65 -10 -36 -21 -68 -25 -70 -3 -2 -16 27 -29 66 -19 60 -25 69 -47 69
-13 0 -24 -6 -24 -13z"></path>
<path class="text" fill="#000000" d="M1192 284 c-17 -12 -22 -24 -20 -47 2 -26 10 -36 45 -52 49 -23 59
-55 17 -55 -14 0 -34 5 -45 10 -16 9 -19 7 -19 -13 0 -17 7 -27 23 -31 69 -18
117 6 117 60 0 32 -4 37 -45 55 -60 26 -62 54 -4 46 37 -5 40 -3 37 16 -2 18
-11 23 -43 25 -25 2 -49 -3 -63 -14z"></path>
</g>
</svg>

                </a>
              </div>
              <button class="navbar-toggle" type="button">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
              </button>
            </div>
            <div class="buttons hidden-xs">
              <nav class="navigation-links" role="navigation">
                <ul class="main-links nav navbar-nav navbar-right">
                  <li><a href="../aws.html">AWS</a></li>
                  <li><a href="../linux.html">Linux</a></li>
                  <li><a href="../docker.html">Docker</a></li>
                  <li><a href="../ibmpower.html">IBM Power</a></li>
                  <li><a href="blogsataws1.html">Blogs@AWS (Kindle Friendly)</a></li>
                </ul>
              </nav>
            </div>
          </div>
        </div>
      </div>
    </div>

    <div class="sidebar-overlay"></div>

<aside class="sidebar" role="navigation">
  <div class="sidebar-header">
    <svg version="1.0" xmlns="http://www.w3.org/2000/svg" width="135.000000pt" height="42" viewbox="0 0 135.000000 45.000000" preserveaspectratio="xMidYMid meet">

<g transform="translate(0.000000,45.000000) scale(0.100000,-0.100000)" fill="#000000" stroke="none">
<path class="text" fill="#000000" d="M527 384 c-4 -4 -7 -18 -7 -31 0 -21 4 -24 28 -21 21 2 27 8 27 28 0
18 -6 26 -20 28 -12 2 -24 0 -28 -4z"></path>
<path class="text" fill="#000000" d="M1080 335 c0 -48 2 -55 20 -55 18 0 20 7 20 55 0 48 -2 55 -20 55
-18 0 -20 -7 -20 -55z"></path>
<path class="text" fill="#000000" d="M54 357 c-2 -7 -3 -69 -2 -138 l3 -124 65 -3 c90 -3 130 20 130 77 0
29 -6 44 -20 54 -20 14 -20 15 -3 45 14 25 15 34 5 56 -6 15 -23 31 -38 36
-38 15 -134 13 -140 -3z m110 -33 c19 -7 21 -45 4 -62 -7 -7 -22 -12 -35 -12
-20 0 -23 5 -23 40 0 41 13 50 54 34z m20 -130 c19 -18 19 -20 6 -45 -8 -13
-21 -19 -45 -19 -34 0 -35 1 -35 40 0 38 2 40 29 40 16 0 37 -7 45 -16z"></path>
<path class="text" fill="#000000" d="M319 271 c-23 -24 -29 -38 -29 -74 0 -25 3 -53 6 -62 20 -50 164 -64
164 -15 0 15 -7 17 -45 12 -46 -5 -75 8 -75 34 0 11 16 14 65 14 l65 0 0 35
c0 80 -92 114 -151 56z m99 -33 c3 -15 -4 -18 -37 -18 -43 0 -50 7 -29 28 18
18 62 11 66 -10z"></path>
<path class="text" fill="#000000" d="M520 184 c0 -107 -1 -116 -20 -121 -11 -3 -20 -12 -20 -19 0 -21 76
-19 84 2 3 9 6 69 6 135 l0 119 -25 0 -25 0 0 -116z"></path>
<path class="text" fill="#000000" d="M649 271 c-24 -25 -29 -37 -29 -78 1 -70 34 -103 105 -103 55 0 95
44 95 103 0 60 -7 75 -41 92 -47 25 -96 19 -130 -14z m111 -30 c25 -48 2 -111
-40 -111 -45 0 -69 80 -34 114 21 22 61 20 74 -3z"></path>
<path class="text" fill="#000000" d="M850 287 c0 -8 16 -57 36 -110 28 -76 33 -100 25 -116 -16 -28 -14
-31 18 -31 27 0 29 4 70 123 23 67 41 128 41 135 0 6 -11 12 -24 12 -21 0 -26
-8 -41 -65 -10 -36 -21 -68 -25 -70 -3 -2 -16 27 -29 66 -19 60 -25 69 -47 69
-13 0 -24 -6 -24 -13z"></path>
<path class="text" fill="#000000" d="M1192 284 c-17 -12 -22 -24 -20 -47 2 -26 10 -36 45 -52 49 -23 59
-55 17 -55 -14 0 -34 5 -45 10 -16 9 -19 7 -19 -13 0 -17 7 -27 23 -31 69 -18
117 6 117 60 0 32 -4 37 -45 55 -60 26 -62 54 -4 46 37 -5 40 -3 37 16 -2 18
-11 23 -43 25 -25 2 -49 -3 -63 -14z"></path>
</g>
</svg>

  </div>

  <ul class="nav sidebar-nav">
    <li><a href="../aws.html">AWS</a></li>
    <li><a href="../linux.html">Linux</a></li>
    <li><a href="../docker.html">Docker</a></li>
    <li><a href="../ibmpower.html">IBM Power</a></li>
    <li><a href="blogsataws1.html">Blogs@AWS (Kindle Friendly)</a></li>
  </ul>
</aside>


    <div class="container">
  <div class="row">
    <div id="docs-sidebar" class="col-sm-3 col-md-3 col-xs-12 hidden-print" role="complementary">
      <ul class="nav docs-sidenav">
      <li><a href="blogsataws1.html">Blogs @ AWS</a></li>
      <li><a href="whatsnew1.html">What's New @ AWS</a></li>
      <li><a href="secblogs1.html">Security Blogs @ AWS</a></li>
      <li><a href="computeblogs1.html">Compute Blogs @ AWS</a></li>
      <li><a href="apnblogs1.html">APN Blogs @ AWS</a></li>
      <li><a href="devopsblogs1.html">DevOps Blogs @ AWS</a></li>
      <li class="active"><a href="mgmtblogs1.html">Management Tools Blogs @ AWS</a></li>

    </ul>
    </div>

    <div id="inner" class="col-sm-9 col-md-9 col-xs-12" role="main">
<p></p>
<p><i>Contents of this page is copied directly from AWS blog sites to make it Kindle friendly. Some styles & sections from these pages are removed to render this properly in 'Article Mode' of Kindle e-Reader browser. All the contents of this page is property of AWS.</i></p>
<p><a href="mgmtblogs1.html">Page 1</a>|<a href="mgmtblogs2.html">Page 2</a>|<a href="mgmtblogs3.html">Page 3</a>|<a href="mgmtblogs4.html">Page 4</a</p>
<br>
<article class="post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="b post-title" property="name headline">Reducing Configuration Drift with Amazon EC2 Systems Manager State Manager and Amazon CloudWatch Events</b> 
<footer class="meta">
by 
<span property="author" typeof="Person"><span property="name">Ananth Vaidyanathan</span></span> | on 
<time property="datePublished" datetime="2017-09-14T12:16:35+00:00">14 SEP 2017</time> | in 
<span class="categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/amazon-ec2-systems-manager/" title="View all posts in Amazon EC2 Systems Manager"><span property="articleSection">Amazon EC2 Systems Manager</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools"><span property="articleSection">Management Tools</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/reducing-configuration-drift-with-amazon-ec2-systems-manager-state-manager-and-amazon-cloudwatch-events/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog=""><span class="span icon-share"></span>&nbsp;Share</a> 
<ul> 
</ul> 
</footer> 
<p><em>This post was written by Anupam Shrivastava, Software Development Engineer with Amazon Web Services.</em></p> 
<p>State Manager helps you automate the process of keeping your EC2 instances or virtual machines (VM) in your on-premises data center in a desired state. Some use cases for State Manager include:</p> 
<ul> 
<li>Ensuring that instances are joined to a Windows domain</li> 
<li>Ensuring that instances are patched with specific software throughout their lifecycle. For more information, see <a href="https://aws.amazon.com/blogs/mt/configure-amazon-ec2-instances-in-an-auto-scaling-group-using-state-manager/">Configure Amazon EC2 Instances in an Auto Scaling Group</a>.</li> 
<li>Executing Linux shell scripts or PowerShell scripts at scheduled times during the instances lifecycle. For more information, see <a href="https://aws.amazon.com/blogs/mt/combating-configuration-drift-using-amazon-ec2-systems-manager-and-windows-powershell-dsc/">Combating Configuration Drift Using Amazon EC2 Systems Manager and Windows PowerShell DSC</a>.</li> 
<li>Using other configuration management tools like Ansible. For more information, see <a href="https://aws.amazon.com/blogs/mt/running-ansible-playbooks-using-ec2-systems-manager-run-command-and-state-manager/">Running Ansible Playbooks using EC2 Systems Manager, Run Command and State Manager</a></li> 
</ul> 
<p>In State Manager, an association is a binding between your expressed configuration in a document, and a set of targets, on a specific schedule, to ensure consistent state. As part of the recent launch, we have made it easy for customers to easily remediate their instances when they drift from a desired configuration, provide you more control on when you can reapply configurations, and also make it easy for you to track changes to State Manager associations.</p> 
<p>In this post, I demonstrate some new State Manager features such as association names and versions, rate expressions, and <a href="http://docs.aws.amazon.com/AmazonCloudWatch/latest/events/WhatIsCloudWatchEvents.html">Amazon CloudWatch Events</a> integration. You start by specifying the configuration in a Systems Manager document.</p> 
<p><span id="more-1243"></span></p> 
<h3>Walkthrough</h3> 
<p>Here are the steps that you take to demonstrate these new features of State Manager:</p> 
<ol> 
<li>Create an association to install Windows updates on one of the EC2 instances, using the rate expression of every 1 day. Give the association a name as well.</li> 
<li>Configure CloudWatch Events for this association such that you receive status update notifications on an Amazon SNS topic, which can then be used to send email alerts.</li> 
<li>Update the association’s schedule to execute every 30 minutes, to be more aggressive with checking and installing Windows updates. Use the association name filter to quickly find the right association to update.</li> 
<li>View the different association versions after updating.</li> 
</ol> 
<h4>Step 1: &nbsp;Create an association</h4> 
<p>Open the EC2 console and choose <strong>Systems Manager, State Manager.</strong></p> 
<p>On the State Manager page, create an association with the following settings:</p> 
<ul> 
<li>For <strong>Association Name</strong>, type ‘CriticalWindowsUpdates’.</li> 
<li>For <strong>Select Document</strong>, select the AWS-InstallWindowsUpdates document.</li> 
<li>For <strong>Targets</strong>, select a Windows instance.</li> 
<li>For <strong>Schedule</strong>, choose <strong>Rate schedule builder</strong> and specify a rate expression of every 1 day.</li> 
<li>For <strong>Parameters</strong>, select the following: 
<ul> 
<li>Action: Install</li> 
<li>Allow Reboot: True</li> 
<li>Categories: CriticalUpdates</li> 
</ul> </li> 
<li>Choose <strong>Create Association</strong>.</li> 
</ul> 
<p>You can also perform the same operations with the AWS CLI, using the following command:</p> 
<pre><code class="lang-bash">aws ssm create-association --name AWS-InstallWindowsUpdates --targets &quot;Key=InstanceIds,Values=i-0ca45fddbf4ce950f&quot; --schedule-expression &quot;rate(1 day)&quot; --parameters Action=Install,Categories=CriticalUpdates,AllowReboot=True –-association-name CriticalWindowsUpdates</code></pre> 
<p>If you have not upgraded the SSM agent on your EC2 instance to the latest version, you might get a failed association error of ‘UnsupportedAgent’. In that case, upgrade the SSM agent to the latest version by executing a command using Run Command and the AWS-UpdateSSMAgent document. After you upgrade the agent, the association should start succeeding.</p> 
<h4>Step 2: Configure CloudWatch Events to send notifications for a failed association</h4> 
<p>Because you have created an association to ensure that an instance always has the latest critical Windows updates, you should also configure CloudWatch Events to notify you in case the association failed to check and apply the critical Windows updates.</p> 
<p>Create an Amazon SNS topic that is configured to send you email. In the example below, I have an SNS topic already created with the topic ‘WindowsCriticalUpdates’.</p> 
<p>Open the CloudWatch console and choose <strong>Events, Create rule</strong>. Use the following values:</p> 
<ul> 
<li><strong>Service Name</strong>: EC2 Simple Systems Manager (SSM)</li> 
<li><strong>Event Type</strong>: State Manager</li> 
<li><strong>Specific type</strong>: EC2 State Manager Association State Change</li> 
<li><strong>Specific status</strong>: Failed</li> 
<li><strong>Edit Event Pattern</strong>:&nbsp; Add the Association Name to track the status for a specific Association</li> 
<li>Choose <strong>Configure details</strong>.</li> 
</ul> 
<p>When you’re done, the event pattern should look like the following:</p> 
<pre><code class="lang-json">{
&quot;source&quot;: [&quot;aws.ssm&quot;],
&quot;detail-type&quot;: [&quot;EC2 State Manager Association State Change&quot;],
&quot;detail&quot;: {
&quot;status&quot;: [&quot;Failed&quot;],
&quot;association-name&quot;: [&quot;CriticalWindowsUpdates&quot;]
}
}</code></pre> 
<p><img class="alignleft size-full wp-image-1290" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/14/cwe.png" alt="" width="1478" height="840" /></p> 
<p>Bind the rule to the SNS topic ‘WindowsCriticalUpdates’, which is configured to send you emails for notification purposes.</p> 
<h4>&nbsp;Step 3: Update the association schedule</h4> 
<p>After a few days, you might realize that you want to have a more aggressive schedule of checking every 30 minutes for critical Windows updates. On the State Manager page, filter the associations by the word ‘Critical’. Select ‘CriticalWindowsUpdates’ and edit it.</p> 
<p>On the Edit association page, choose Rate schedule builder and specify a rate expression of every 30 minutes. For Parameters, again select the following:</p> 
<ul> 
<li>Action: Install</li> 
<li>Allow Reboot: True</li> 
<li>Categories: CriticalUpdates</li> 
</ul> 
<p>Choose Edit association. You can also perform the same operations with the AWS CLI, using the following command:</p> 
<pre><code class="lang-bash">aws ssm update-association --association-id 21da58e2-c9e1-4da5-a12a-d7d37eb981a2 --schedule-expression &quot;rate(30 minutes)&quot; --parameters Action=Install,Categories=CriticalUpdates,AllowReboot=True</code></pre> 
<p>After the association is edited, it is immediately scheduled for execution on the target instances.</p> 
<h4>Step 4: Track association changes using versioning</h4> 
<p>The Versions tab provides an audit trail of all the updates that were made to the association. The attributes that can be updated are:</p> 
<ul> 
<li>Association name</li> 
<li>Document name</li> 
<li>Document version</li> 
<li>Parameters</li> 
<li>Targets</li> 
<li>Schedule expression</li> 
</ul> 
<p>When you update any of the fields in an association, State Manager creates a new version. You can see all previous versions, along with the various field values. This enables you to track changes across various versions.</p> 
<p>In the earlier example, you can see two association versions corresponding to the two different rate schedule expressions.</p> 
<p><img class="size-full wp-image-1293 alignnone" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/14/versioning.png" alt="" width="1732" height="716" /></p> 
<p>You can also perform the same operations with the AWS CLI, using the following command:</p> 
<pre><code class="lang-bash">aws ssm list-association-versions --association-id 21da58e2-c9e1-4da5-a12a-d7d37eb981a2</code></pre> 
<h3>Conclusion</h3> 
<p>In this post, I showed you how to use several new features in State Manager that will ensure your instances are in a desired state and do not drift:</p> 
<ul> 
<li>Naming associations and filtering by names</li> 
<li>Granular scheduling by rate expressions</li> 
<li>Association status notifications through CloudWatch Events</li> 
<li>Tracking association changes through versions</li> 
</ul> 
<hr /> 
<h3>About the Author</h3> 
<p><img class="size-full wp-image-1294 alignleft" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/14/anupam.jpg" alt="" width="119" height="160" /><a href="https://www.linkedin.com/in/anupamsh/">Anupam Shrivastava</a> is a software development engineer on the Amazon EC2 Systems Manager team. He enjoys being part of AWS and building easy-to-use scalable solutions for customers across the globe. Outside of work, he enjoys playing tennis and cricket, swimming, and traveling.</p> 
<p>&nbsp;</p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/mt/tag/aws-systems-manager/" rel="tag">AWS Systems Manager</a>, <a href="https://aws.amazon.com/blogs/mt/tag/configuration-management/" rel="tag">Configuration Management</a>, <a href="https://aws.amazon.com/blogs/mt/tag/ssm/" rel="tag">SSM</a>, <a href="https://aws.amazon.com/blogs/mt/tag/state-manager/" rel="tag">State Manager</a></span> 
</footer> 
</article> 
<article class="post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="b post-title" property="name headline">Introducing the AWS Config Rule Development Kit (RDK)</b> 
<footer class="meta">
by 
<span property="author" typeof="Person"><span property="name">Henry Huang</span></span> | on 
<time property="datePublished" datetime="2017-09-12T13:59:42+00:00">12 SEP 2017</time> | in 
<span class="categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/aws-config/" title="View all posts in AWS Config"><span property="articleSection">AWS Config</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools"><span property="articleSection">Management Tools</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/introducing-the-aws-config-rule-development-kit-rdk/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog=""><span class="span icon-share"></span>&nbsp;Share</a> 
<ul> 
</ul> 
</footer> 
<p>Recently, <a href="https://aws.amazon.com/config">AWS Config</a> released a Rule Development Kit (RDK) that greatly simplifies your custom rule authoring experience. The RDK is an open-source tool that helps you set up AWS Config, author rules, and then test them using a variety of AWS resource types. This allows you to focus on the development of the rule itself. The AWS Config RDK is now available for download from the <a href="https://github.com/awslabs/aws-config-rdk">aws-config-rdk</a> GitHub repo. We follow semantic versioning, and are dedicated to maintaining backwards compatibility for each major version.</p> 
<h3>About AWS Config</h3> 
<p>AWS Config is a service that enables you to assess, audit, and evaluate the configurations of your AWS resources. AWS Config continuously monitors and records your AWS resource configurations and allows you to automate the evaluation of recorded configurations against desired configurations. Rules enable you to automatically check the configuration of AWS resources recorded by AWS Config. There are 37 managed AWS Config rules by default and 34 custom rules maintained by the community in the <a href="https://github.com/awslabs/aws-config-rules">aws-config-rules</a> GitHub repo.</p> 
<p><span id="more-1254"></span></p> 
<b>Getting started</b> 
<p>You can get started with AWS Config RDK and create a rule named “Hello World” in just a few minutes.</p> 
<ul> 
<li>Prerequisites</li> 
<li>Enable AWS Config</li> 
<li>Create your first rule</li> 
<li>Test your rule</li> 
</ul> 
<b>Prerequisites</b> 
<p>The AWS Config RDK requires the latest version of the <a href="https://aws.amazon.com/cli">AWS CLI</a>. You must also log in to an AWS account. Use the following command to install the AWS CLI (<a href="http://docs.aws.amazon.com/cli/latest/userguide/installing.html">requires pip to be installed already</a>):</p> 
<pre><code class="lang-bash">pip install --upgrade --user awscli</code></pre> 
<p>Use the following command to configure the AWS CLI. For more information, see <a style="font-family: Georgia, 'Times New Roman', 'Bitstream Charter', Times, serif" href="http://docs.aws.amazon.com/cli/latest/userguide/cli-chap-getting-started.html">Configuring the AWS CLI</a><span style="font-family: Georgia, 'Times New Roman', 'Bitstream Charter', Times, serif">.</span></p> 
<pre><code class="lang-bash">aws configure --profile myCLIprofile 
AWS Access Key ID [None]: AKIAI44QH8DHBEXAMPLE
AWS Secret Access Key [None]: je7MtGbClwBF/2Zp9Utk/h3yCo8nvbEXAMPLEKEY
Default region name [None]: us-east-1
Default output format [None]: text</code></pre> 
<p>Use the following command to clone the AWS Config RDK on macOS, Linux, or Windows platforms:</p> 
<pre><code class="lang-bash">git clone https://github.com/awslabs/aws-config-rdk.git</code></pre> 
<p>Choose your platform (MacLinux or Windows).<br /> <img src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/12/blog-post-01.png" /></p> 
<b>Enable AWS Config</b> 
<p>To begin, enable AWS Config in your AWS account for the region configured in the AWS CLI. For example, on macOS or Linux, use the following command to configure your profile:</p> 
<pre><code class="lang-bash">cd MacLinux/setup; ./setup myCLIprofile </code></pre> 
<p>You see the following results:<br /> <img src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/12/blog-post-02.png" /><br /> On Windows, use the following command to configure your profile:</p> 
<pre><code class="lang-bash">cd Windows/setup; ./setup.cmd myCLIprofile </code></pre> 
<p>You see the following results:<br /> <img src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/12/blog-post-03.png" /></p> 
<p>In this example, AWS Config in the us-east-1 region has been enabled by RDK setup.<br /> <img src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/12/blog-post-04.png" /></p> 
<b>Create your first rule</b> 
<p>Now you can create your first rule. Use the following command to create the EBS_OPTIMIZED_INSTANCE managed rule, which checks whether Amazon EBS optimization is enabled for your EC2 instances that can be EBS-optimized. Create the rule under the folder /aws-config-rdk/MacLinux/rules on macOS or Linux:</p> 
<pre><code class="lang-bash">cd MacLinux/rules; ./createRule myCLIprofile hello_world AWS::EC2::Instance </code></pre> 
<p>You see the following results:<br /> <img src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/12/blog-post-05.png" /></p> 
<p>On Windows, use the following command:</p> 
<pre><code class="lang-bash">cd Windows/rules; ./createRule.cmd myCLIprofile hello_world AWS::EC2::Instance </code></pre> 
<p>You see the following results:</p> 
<p><img src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/12/blog-post-06.png" /></p> 
<p>The following resources were created:</p> 
<ul> 
<li>The parameter “APPLICABLE_RESOURCE_TYPES” has the same value as “APPLICABLE_RESOURCES” already defined in the rule code</li> 
<li>The AWS Lambda function named “hello_world”</li> 
<li>An AWS Config rule named “hello_world”, which was also associated with the Lambda function</li> 
</ul> 
<p>The rule has started to evaluate EC2 instances for compliance with EBS optimization.<br /> <img src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/12/blog-post-07.png" /><br /> Now you can replace the default values with your own code. Make sure that resource types are consistent between the rule_code.py and createRule.cmd script parameters. Otherwise, your rule returns NOT_APPLICABLE. The rules/ruleCode/rule_util.py script handles the boring parts of a rule, and should not need to be modified.</p> 
<b>Test your rule</b> 
<p>The AWS Config RDK supports testing your rule by invoking the Lambda function with configuration items (used as test cases) from the /rules/testUtil/compliantCIs and /rules/testUtil/noncompliantCIs directories. The RDK checks that the Lambda function returns the corresponding result.</p> 
<p>On macOS or Linux, use the following command:</p> 
<pre><code class="lang-bash">cd MacLinux/rules; ./test myCLIprofile hello_world </code></pre> 
<p>You see the following results:</p> 
<p><img src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/12/blog-post-08.png" /></p> 
<p>On Windows, use the following command:</p> 
<pre><code class="lang-bash">cd Windows/rules; ./test.cmd myCLIprofile hello_world </code></pre> 
<p>You see the following results:</p> 
<p><img src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/12/blog-post-09.png" /></p> 
<p>Besides, we have provided Configuration Item examples in “rules/testUtil/exampleCIs” to help you to write test cases by the modification to make them represent compliant or non-compliant resources.<br /> <img src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/12/blog-post-10.png" /></p> 
<b>Summary</b> 
<p>The AWS Config RDK helps you build rules easily, including the following:</p> 
<ul> 
<li>Preparing the initial rule development environment, by enabling AWS Config with a variety of automatically created AWS resources.</li> 
<li>Creating Lambda functions, rules, and the association between them so that you don’t have to.</li> 
<li>Supporting multiple platforms: &nbsp;macOS, Linux, and Windows.</li> 
<li>Testing rules just by the code, with no more manual setup in complicated test environments.</li> 
</ul> 
<p>We would love to hear your feedback. Feel free to leave comments or suggestions on the&nbsp;<a href="https://github.com/awslabs/aws-config-rdk">aws-config-rdk</a> GitHub page.</p> 
<h3>About the Author</h3> 
<p><img class="alignleft" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/12/blog-post-11.png" /><br /> Henry Huang is a DevOps Consultant for the Professional Services Team&nbsp;at Amazon Web Services in China.</p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/mt/tag/aws-config/" rel="tag">AWS Config</a>, <a href="https://aws.amazon.com/blogs/mt/tag/config-rule/" rel="tag">Config Rule</a>, <a href="https://aws.amazon.com/blogs/mt/tag/rdk/" rel="tag">RDK</a>, <a href="https://aws.amazon.com/blogs/mt/tag/rule-development-kit/" rel="tag">Rule Development Kit</a></span> 
</footer> 
</article> 
<article class="post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<meta property="image" content="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/08/23/prof-473x630.jpg" /> 
<b class="b post-title" property="name headline">Smart Budgeting Using Lambda and Service Catalog</b> 
<footer class="meta">
by 
<span property="author" typeof="Person"><span property="name">Tapodipta Ghosh</span></span> | on 
<time property="datePublished" datetime="2017-09-07T11:42:37+00:00">07 SEP 2017</time> | in 
<span class="categories"><a href="https://aws.amazon.com/blogs/mt/category/messaging/amazon-simple-notification-service-sns/" title="View all posts in Amazon Simple Notification Service (SNS)"><span property="articleSection">Amazon Simple Notification Service (SNS)</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/aws-cost-management/aws-budgets/" title="View all posts in AWS Budgets"><span property="articleSection">AWS Budgets</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/aws-cost-management/" title="View all posts in AWS Cost Management"><span property="articleSection">AWS Cost Management</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/compute/aws-lambda/" title="View all posts in AWS Lambda"><span property="articleSection">AWS Lambda</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/aws-service-catalog/" title="View all posts in AWS Service Catalog"><span property="articleSection">AWS Service Catalog</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/smart-budgeting-using-lambda-and-service-catalog/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog=""><span class="span icon-share"></span>&nbsp;Share</a> 
<ul> 
</ul> 
</footer> 
<p>If you have a lot of development activity in your organization, it’s important to keep track of your non-production AWS accounts.</p> 
<p>If these accounts aren’t monitored closely, you might easily end up exceeding your budget.</p> 
<p>In this blog post, I demonstrate how you can use the <a href="https://aws.amazon.com/about-aws/whats-new/2015/06/aws-introduces-budgets-a-simple-way-to-manage-your-aws-costs/">AWS Budgets</a> alert in conjunction with<a href="https://aws.amazon.com/lambda/"> AWS Lambda</a> and <a href="https://aws.amazon.com/servicecatalog/">AWS Service Catalog</a> to automate management of your IT budget for non-production environments.<span id="more-1163"></span></p> 
<h3>Workflow</h3> 
<p>For this example, I have created a billing alarm to notify me when the cost for a sandbox account overshoots the forecast by 30 percent. The billing alarm is tied to an Amazon SNS Topic which is subscribed by a Lambda function. This ensures that when the billing alert occurs, the IT administrator gets notified via SNS about the possibility of an overage. At the same time, the Lambda function calls the AWS Service Catalog API to enforce the template constraint to freeze all EC2 instance creation to only the t2.medium type.</p> 
<p>&nbsp;</p> 
<p><img class="aligncenter wp-image-1165 size-large" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/08/23/Screen-Shot-2017-08-07-at-2.00.50-PM-1024x508.png" alt="" width="640" height="318" /></p> 
<h3>Create the SNS topic and subscription</h3> 
<p>In the SNS console, choose&nbsp;Create topic&nbsp;and enter appropriate values for the &nbsp;Topic name&nbsp;(such as BudgetAlert) and&nbsp;Display name&nbsp;(Budget-Alert).</p> 
<p>Choose&nbsp;Create topic. Select the topic and view the details.</p> 
<p>Next, choose&nbsp;Create subscription.</p> 
<p>For&nbsp;Protocol, choose&nbsp;Email. Enter the email address where notifications should be sent and choose&nbsp;Create subscription.</p> 
<p>An email is sent to confirm the SNS topic subscription. In the email, open the&nbsp;SubscribeURL&nbsp;link to complete the subscription. Note the SNS topic Amazon Resource Name (ARN) because it’s used later by the Lambda function.</p> 
<p><img class="aligncenter wp-image-1166" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/07/sns.png" alt="" width="683" height="258" /></p> 
<p>For more information, see&nbsp;<a href="http://docs.aws.amazon.com/sns/latest/dg/CreateTopic.html">Create a Topic</a>&nbsp;in the Amazon SNS Developer Guide.</p> 
<h3>Create the Lambda function</h3> 
<p>In the Lambda console, choose&nbsp;Functions,&nbsp;Create a Lambda function. Choose Blank Function and on the&nbsp;Configure trigger page, choose&nbsp;Next.</p> 
<p>On the next page, enter the following values:</p> 
<p>&middot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Runtime:&nbsp;Python 2.7</p> 
<p>&middot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Code entry type:&nbsp;Inline</p> 
<p>&middot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Role:&nbsp;Create a custom role (takes you to another page). Call the role service-catalog-lambda-&lt;region&gt;-role</p> 
<p>For the policy document, enter the following policy:</p> 
<pre><code class="lang-json">{
&nbsp;&nbsp;&nbsp; &quot;Version&quot;: &quot;2012-10-17&quot;,
&nbsp;&nbsp;&nbsp; &quot;Statement&quot;: [
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; {
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;Action&quot;: [
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;servicecatalog:*&quot;,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;s3:*&quot;,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;cloudformation:ValidateTemplate&quot;,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;iam:GetRole&quot;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ],
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;Resource&quot;: [
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;*&quot;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ],
&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;Effect&quot;: &quot;Allow&quot;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; },
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; {
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;Action&quot;: [
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;logs:CreateLogGroup&quot;,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;logs:CreateLogStream&quot;,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;logs:PutLogEvents&quot;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ],
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;Resource&quot;: &quot;arn:aws:logs:*:*:*&quot;,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&quot;Effect&quot;: &quot;Allow&quot;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }
&nbsp;&nbsp;&nbsp; ]
}</code></pre> 
<p>On the&nbsp;Configure function&nbsp;page, choose&nbsp;Next. Review the configuration settings before choosing&nbsp;Create function.</p> 
<p>You can also follow the instructions here:</p> 
<p><a href="https://github.com/awslabs/aws-service-catalog-enforce-template-constraints/">https://github.com/awslabs/aws-service-catalog-enforce-template-constraints/</a></p> 
<h3>Budget alert</h3> 
<p>Create the AWS Budgets alert and add the IT administrator’s email to notify the administrator when the forecasted budget is greater than the percentage that you choose (in our example, it’s 30 %). Add the SNS Topic ARN and Verify. You should see “Verified” next to the topic ARN.</p> 
<p><img class="aligncenter wp-image-1167 size-full" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/08/23/BudgetAlert.png" alt="" width="975" height="398" /></p> 
<p>For more information on how to create AWS budgets, you can refer the AWS Budgets Update blog post.</p> 
<p>After the alert condition is met, the IT administrator will receive an email from AWS Budgets similar to the sample that follows:</p> 
<pre><code class="lang-json">{&nbsp;&quot;Subject&quot; : &quot;Budget&nbsp;Notification: Test is in Alarm State&quot;,
&nbsp; &quot;Message&quot; : &quot;AWS&nbsp;Budget&nbsp;Notification\n\nDear AWS Customer,\n\nYou requested that we notify you when your Actual Cost for your&nbsp;budget&nbsp;\&quot;BudgetAlert\&quot; is greater than $50000. Your Actual Cost for this&nbsp;budget&nbsp;is now $50393. You can find further details below and by accessing your AWS&nbsp;Budgets&nbsp;dashboard.\n\nBudget
}</code></pre> 
<p>The Lambda function also gets triggered. It looks for all portfolios in the Service Catalog, looks for InstanceType template constraints, and it changes the constraint to “t2.medium or small only.” The following example shows how the updated constraint looks after the Lambda function has successfully run.<br /> <img class="aligncenter wp-image-1168 size-full" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/08/23/post_lambda_run.png" alt="" width="975" height="525" /></p> 
<h3>Summary</h3> 
<p>In this post, I’ve demonstrated an easy way to keep track of your non-prod accounts budget, while you are also focused on continuous development.</p> 
<hr /> 
<h3>About the Author</h3> 
<p><img class="size-full wp-image-1230 alignleft" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/09/07/tapo.jpg" alt="" width="119" height="160" /></p> 
<p>Tapodipta Ghosh is a Solutions Architect focusing on AWS Marketplace.&nbsp;&nbsp;Tapo&nbsp;is passionate about cloud computing and loves helping customers on-board their products into AWS Marketplace.</p> 
<p>&nbsp;</p> 
<p>&nbsp;</p> 
<p>&nbsp;</p> 
<p>&nbsp;</p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/mt/tag/aws-budgets/" rel="tag">AWS Budgets</a>, <a href="https://aws.amazon.com/blogs/mt/tag/aws-lambda/" rel="tag">AWS Lambda</a>, <a href="https://aws.amazon.com/blogs/mt/tag/aws-service-catalog/" rel="tag">AWS Service Catalog</a>, <a href="https://aws.amazon.com/blogs/mt/tag/aws-sns/" rel="tag">AWS SNS</a></span> 
</footer> 
</article> 
<article class="post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="b post-title" property="name headline">The Right Way to Store Secrets using Parameter Store</b> 
<footer class="meta">
by 
<span property="author" typeof="Person"><span property="name">Ananth Vaidyanathan</span></span> | on 
<time property="datePublished" datetime="2017-08-27T23:00:38+00:00">27 AUG 2017</time> | in 
<span class="categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/amazon-ec2-systems-manager/" title="View all posts in Amazon EC2 Systems Manager"><span property="articleSection">Amazon EC2 Systems Manager</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools"><span property="articleSection">Management Tools</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/the-right-way-to-store-secrets-using-parameter-store/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog=""><span class="span icon-share"></span>&nbsp;Share</a> 
<ul> 
</ul> 
</footer> 
<p><em>This guest post was written by Evan Johnson, who works in the Security team at Segment.</em></p> 
<p>The way companies manage application secrets is critical. Even today, the most high profile security companies can suffer breaches from improper secrets management practices. Having internet facing credentials is like leaving your house key under a doormat that millions of people walk over daily. Even if the secrets are hard to find, it is a game of hide and seek that you eventually lose.</p> 
<p>At <a href="https://segment.com/">Segment</a>, we centrally and securely manage our secrets with <a href="https://aws.amazon.com/ec2/systems-manager/parameter-store/">Amazon EC2 Systems Manager Parameter Store</a>, lots of Terraform code, and <a href="https://github.com/segmentio/chamber">chamber</a>. Parameter store is a great tool for achieving secrets management. If you are running workloads on AWS, then using Parameter Store as a managed secrets store is worth serious consideration. This post has all the information you need to get running with Parameter Store in production.</p> 
<p><span id="more-1184"></span></p> 
<h3>Service Identity</h3> 
<p>At Segment, we run hundreds of services that communicate with one another, AWS APIs, and third-party APIs. The services we run have different needs and should only have access to systems that are strictly necessary. This is called the ‘principle of least privilege’.</p> 
<p>As an example, our main webserver should never have access to security audit logs for our infrastructure. Without giving containers and services an identity, it is not possible to protect and restrict access to secrets with access control policies. Our services identify themselves using IAM roles. From the AWS docs – “<em>An IAM role … is an AWS identity with permission policies that determine what the identity can and cannot do in AWS</em>.”</p> 
<p>For example, our IAM roles for instances have write-only access to an Amazon S3 bucket for appending audit logs, but prevent the deletion and reading of those logs.</p> 
<h4>How do containers get their role securely?</h4> 
<p>A requirement to using <a href="https://aws.amazon.com/ecs/">Amazon ECS</a> is that all containers must run the <a href="https://github.com/aws/amazon-ecs-agent">Amazon ECS container agent</a> (ecs-agent). The agent runs as a container that orchestrates and provides an API with which other containers can communicate. The agent is the central nervous system of how containers fetch IAM role credentials.</p> 
<p><img class="size-full wp-image-1188 alignnone" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/08/25/Diagram1a.png" alt="" width="450" height="337" /></p> 
<p>One important piece to the agent is that it runs an HTTP API that MUST be accessible to the other containers that are running in the cluster. To make this API available, an iptables rule is set on the host instance. This iptables rule forwards traffic destined for a magic IP address to the ecs-agent container.</p> 
<pre><code class="lang-bash">iptables -t nat \
-A OUTPUT \
-d 169.254.170.2 \
-p tcp \
-m tcp \
--dport 80 \
-j REDIRECT \
--to-ports 51679</code></pre> 
<p>Before the agent starts a container, it first fetches credentials for the container’s task role from the AWS credential service. The agent next sets the credentials key ID, a UUID, as the AWS_CONTAINER_CREDENTIALS_RELATIVE_URI environment variable inside the container when it is started.</p> 
<pre><code class="lang-bash">$ env
...
AWS_CONTAINER_CREDENTIALS_RELATIVE_URI=/v2/credentials/53875b56-621a-4b07-8ab6-02ea315b5693
...</code></pre> 
<p>Using this relative URI and UUID, containers fetch AWS credentials from the agent over HTTP. One container cannot access the authentication credentials to impersonate another container because the UUID is sufficiently difficult to guess.</p> 
<pre><code class="lang-bash">$ curl 169.254.170.2$AWS_CONTAINER_CREDENTIALS_RELATIVE_URI | jq .
{
&quot;RoleArn&quot;: &quot;arn:aws:iam::111111111111:role/test-service&quot;,
&quot;AccessKeyId&quot;: &quot;ASIAIYLSOW5USUQCZAAQ&quot;,
&quot;SecretAccessKey&quot;: &quot;REDACTRED&quot;,
&quot;Token&quot;: &quot;REDACTED&quot;,
&quot;Expiration&quot;: &quot;2017-08-10T02:01:43Z&quot;
}</code></pre> 
<h4>Additional security details</h4> 
<p>As heavy Amazon ECS users, we did find security foot-guns associated with ECS task roles. It’s important to realize that any container that can access the Amazon EC2 metadata service on behalf of its host can become any other task role on the system. This could allow containers to circumvent access control policies and gain access to unauthorized systems.</p> 
<p><img class="size-full wp-image-1190 alignnone" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/08/25/Diagram2.png" alt="" width="450" height="337" /></p> 
<p>The two ways a container can access the metadata service is using host networking and over the docker bridge. When a container is run with <span style="text-decoration: underline">–network=’host’</span>, it is always able to connect to the EC2 metadata service using its host’s network. Setting the <span style="text-decoration: underline">ECS_ENABLE_TASK_IAM_ROLE_NETWORK_HOST</span> variable to false in the ecs-agent config file prevents containers from running with this permission.</p> 
<p>Additionally, it’s important to block access to the metadata service IP address over the Docker bridge using iptables. The <a href="http://docs.aws.amazon.com/AmazonECS/latest/developerguide/task-iam-roles.html">IAM task role documentation</a> recommends preventing access to the EC2 metadata service with this specific rule.</p> 
<pre><code class="lang-bash">$ iptables --insert FORWARD 1 --in-interface docker+ --destination 169.254.169.254/32 --jump DROP</code></pre> 
<p>The principle of least privilege is always important to keep in mind when building a security system. Setting <span style="text-decoration: underline">ECS_DISABLE_PRIVILEGED</span> to true in the host’s ecs-agent config file can prevent privileged Docker containers from being run and causing other more nuanced security problems.</p> 
<h3>Parameter Store</h3> 
<p>Parameter Store is an AWS service that stores strings. It can store secret data and non-secret data alike. Secrets stored in Parameter Store are secure strings, encrypted with a customer-specific AWS KMS key.</p> 
<p>Under the hood, a service that requests secure strings from the Parameter Store has a lot of things happening behind the scenes.</p> 
<ol> 
<li>The ECS container agent requests the host instance’s temporary credentials.</li> 
<li>The agent continuously generates temporary credentials for each ECS task role running on ECS, using an undocumented service called ACS.</li> 
<li>When the agent starts each task, it sets a secret UUID in the environment of the container.</li> 
<li>When the task needs its task role credentials, it requests them from the ecs-agent API and authenticates with the secret UUID.</li> 
<li>The ECS task requests its secrets from Parameter Store using the task role credentials.</li> 
<li>Parameter Store transparently decrypts these secure strings before returning them to the ECS task.</li> 
</ol> 
<p><img class="size-full wp-image-1198 alignnone" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/08/25/diagram3-1.png" alt="" width="350" height="466" /></p> 
<p>Using roles with Parameter Store is especially nice because it does not require maintaining additional authentication tokens. This would create additional headache and additional secrets to manage!</p> 
<h4>Parameter Store IAM Policies</h4> 
<p>Each role that accesses the Parameter Store requires the <span style="text-decoration: underline">ssm:GetParameters</span> permission. “SSM” stands for “Simple System Manager”, the previous name for Systems Manager, and is how <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/sysman-paramstore-access.html">AWS denotes Parameter Store operations</a>.</p> 
<p>The ssm:GetParameters permission is the policy used to enforce access control and protect one service’s secrets from another. Segment gives all services an IAM role that grants access to secrets that match the format&nbsp; {{service_name}}/*.&nbsp; Parameter Store <a href="https://aws.amazon.com/blogs/mt/organize-parameters-by-hierarchy-tags-or-amazon-cloudwatch-events-with-amazon-ec2-systems-manager-parameter-store/">supports hierarchies natively</a>, so this permission provides each service with its own directory of secrets.</p> 
<pre><code class="lang-json">{
&quot;Sid&quot;: &quot;&quot;,
&quot;Effect&quot;: &quot;Allow&quot;,
&quot;Action&quot;: &quot;ssm:GetParameters&quot;,
&quot;Resource&quot;: [
&quot;arn:aws:ssm:*:*:parameter/{{service_name}}/*&quot;,
]
},</code></pre> 
<p>In addition to the access control policies, Segment uses a dedicated AWS KMS key to encrypt secure strings within the Parameter Store. Each IAM role is granted a small set of KMS permissions in order to decrypt the secrets they store in Parameter Store.</p> 
<pre><code class="lang-json">{
&quot;Sid&quot;: &quot;&quot;,
&quot;Effect&quot;: &quot;Allow&quot;,
&quot;Action&quot;: [
&quot;kms:ListKeys&quot;,
&quot;kms:ListAliases&quot;,
&quot;kms:Describe*&quot;,
&quot;kms:Decrypt&quot;
],
&quot;Resource&quot;: &quot;parameter_store_key&quot;
}</code></pre> 
<h3>Automating service identity and policies</h3> 
<p class="hide-language">Segment has a small Terraform module that abstracts away the creation of a unique IAM role, load balancers, DNS records, Auto Scaling, and CloudWatch alarms. Below, I show how our nginx load balancer is defined using our service module.</p> 
<pre><code class="lang-yaml">module &quot;nginx&quot; {
source            = &quot;../modules/service&quot;
name              = &quot;nginx&quot;
image             = &quot;segment/nginx&quot;
product_area      = &quot;foudation-security&quot;
health_check_path = &quot;/healthcheck&quot;
environment       = &quot;${var.environment}&quot;
}</code></pre> 
<p>Under the hood, the task role given to each service has all of the IAM policies we previously listed, restricting access to Parameter Store by the value in the name field. No configuration required.</p> 
<p>Additionally, developers have the option to override which secrets their service has access to by providing a “secret label”. This secret label replaces their service name in their IAM policy. If NGINX were to need the same secrets as an HAProxy instance, the two services can share credentials by using the same secret label.</p> 
<pre><code class="lang-yaml"></code><code class="lang-yaml">module &quot;nginx&quot; {
source            = &quot;../modules/service&quot;
name              = &quot;nginx&quot;
image             = &quot;segment/nginx&quot;
product_area      = &quot;foudation-security&quot;
health_check_path = &quot;/healthcheck&quot;
environment       = &quot;${var.environment}&quot;
# Share secrets with loadbalancers
<strong>secret_label = &quot;loadbalancers&quot;</strong>
}</code></pre> 
<h3>Parameter Store in production</h3> 
<p>All Segment employees authenticate with AWS using aws-vault, which can securely store AWS credentials in the macOS keychain or in an encrypted file for Linux users. Segment has several AWS accounts. Engineers can interact with each account using aws-vault, and execute commands locally with their AWS credentials populated in their environment.<code class="lang-json"><br /> </code></p> 
<pre><code class="lang-bash">$ aws-vault exec development -- aws s3 ls s3://segmentio-bucket</code></pre> 
<h4>Using Chamber with Parameter Store</h4> 
<p>Chamber is a CLI tool that Segment built to allow developers and code to communicate with Parameter Store in a consistent manner. By allowing developers to use the same tools that run in production, we decrease the number of differences between code running in development with staging and production.</p> 
<p>Chamber works with aws-vault, and has only a few key subcommands:</p> 
<ul> 
<li>exec—a command after loading secrets in to the environment.</li> 
<li>history—of changes made to a secret in parameter store.</li> 
<li>list—the names of all secrets in a services path.</li> 
<li>write—a secret to the Parameter Store.</li> 
</ul> 
<p>Chamber leverages Parameter Store’s built in search and history mechanisms to implement the list and history subcommands. All strings stored in Parameter Store are automatically versioned. The subcommand used to fetch secrets from the Parameter Store is exec. When developers use the exec subcommand, they use it with aws-vault.</p> 
<p><code class="lang-bash">$ aws-vault exec development -- chamber exec loadbalancers -- nginx</code></p> 
<p>In the preceding command, chamber is executed with the credentials and permissions of the employee in the development account, and it fetches the secrets associated with loadbalancers from Parameter Store. After chamber populates the environment, it runs the NGINX server.</p> 
<h4 class="hide-language">Running chamber in production</h4> 
<p>Chamber is packaged inside our Docker containers as a binary and is the entry point of the container. Chamber passes signals to the program it executes in order to allow the program to gracefully handle them.</p> 
<p>Here’s a diff of what it required to make our main website chamber ready.</p> 
<pre><code class="lang-bash">-ENTRYPOINT [&quot;node&quot;, &quot;server/boot.js&quot;] 
+ENTRYPOINT [&quot;chamber&quot;, &quot;exec&quot;, &quot;app&quot;, &quot;--&quot;, &quot;node&quot;, &quot;server/boot.js&quot;]</code></pre> 
<p>Non-Docker containers can also use chamber to populate the environment before creating configuration files out of templates, run daemons, etc.</p> 
<h3>Auditing</h3> 
<p>All access to Parameter Store is logged with AWS CloudTrail. This makes keeping a full audit trail for all parameters simple and inexpensive. It also makes building custom alerting and audit logging straightforward.</p> 
<pre><code class="lang-json">...
&quot;eventTime&quot;: &quot;2017-08-02T18:54:06Z&quot;,
&quot;eventSource&quot;: &quot;ssm.amazonaws.com&quot;,
&quot;eventName&quot;: &quot;GetParameters&quot;,
&quot;awsRegion&quot;: &quot;us-west-2&quot;,
&quot;sourceIPAddress&quot;: &quot;127.0.0.1&quot;,
&quot;userAgent&quot;: &quot;aws-sdk-go/1.8.1 (go1.8.3; linux; amd64)&quot;,
&quot;requestParameters&quot;: {
&quot;withDecryption&quot;: true,
&quot;names&quot;: [
&quot;test-service.secretname&quot;
]
},
&quot;responseElements&quot;: null,
&quot;requestID&quot;: &quot;88888888-4444-4444-4444-121212121212&quot;,
&quot;eventID&quot;: &quot;88888888-4444-4444-4444-121212121212&quot;,
&quot;readOnly&quot;: true,
...</code></pre> 
<p>CloudTrail makes it possible to determine exactly what secrets are used and can make discovering unused secrets or unauthorized access to secrets possible.</p> 
<p>AWS logs all Parameter Store access for free as a CloudTrail management event. Most security information and events management (SIEM) solutions can be configured to watch, and read data from S3.</p> 
<h3>Summary</h3> 
<p>Using Parameter Store and IAM, Segment was able to build a small tool that provides all of the properties most important in a secrets management system.</p> 
<ul> 
<li>Protect the secrets at rest with strong encryption.</li> 
<li>Enforce strong access control policies.</li> 
<li>Create audit logs of authentication and access history.</li> 
<li>Great developer experience.</li> 
</ul> 
<p>Secrets management is very challenging to get right. Many products have been built to manage secrets, but none fit the use cases needed by Segment better than Parameter Store.</p> 
<h3>About the Author</h3> 
<p><img class="size-full wp-image-1192 alignnone" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/08/25/evan.png" alt="" width="125" height="165" /><a href="https://www.linkedin.com/in/evan-j-johnson-35871871/">Evan Johnson</a> works on security at <a href="http://segment.com/">Segment</a>. Segment is the infrastructure for customer data. Businesses use Segment’s API to unlock 200+ tools for every team across their organization. With Segment, developers can stop building tedious and expensive one-off data integrations, turning on their favorite apps right from the Segment dashboard.</p> 
<p><a href="https://segment.com/"><img class="alignleft size-full wp-image-1193" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/08/25/segment.png" alt="" width="375" height="85" /></a></p> 
<p>&nbsp;</p> 
<p>&nbsp;</p> 
<hr /> 
<p><em>AWS is not responsible for the content or accuracy of this post. The content and opinions in this blog are solely those of the third party author.</em></p> 
<p><code class="lang-bash"></code><code class="lang-bash"></code></p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/mt/tag/configuration-secrets/" rel="tag">Configuration Secrets</a>, <a href="https://aws.amazon.com/blogs/mt/tag/ec2-systems-manager/" rel="tag">EC2 Systems Manager</a>, <a href="https://aws.amazon.com/blogs/mt/tag/parameter-store/" rel="tag">Parameter Store</a>, <a href="https://aws.amazon.com/blogs/mt/tag/ssm/" rel="tag">SSM</a></span> 
</footer> 
</article> 
<article class="post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="b post-title" property="name headline">Multi-Account Strategy: Using AWS CloudFormation Custom Resources to Create Amazon Route 53 Resources in Another Account</b> 
<footer class="meta">
by 
<span property="author" typeof="Person"><span property="name">Brian Beach</span></span> | on 
<time property="datePublished" datetime="2017-08-24T16:06:05+00:00">24 AUG 2017</time> | in 
<span class="categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/aws-cloudformation/" title="View all posts in AWS CloudFormation"><span property="articleSection">AWS CloudFormation</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools"><span property="articleSection">Management Tools</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/multi-account-strategy-using-aws-cloudformation-custom-resources-to-create-amazon-route-53-resources-in-another-account/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog=""><span class="span icon-share"></span>&nbsp;Share</a> 
<ul> 
</ul> 
</footer> 
<p>Today, most customers have more than one AWS account. While a multi-account strategy brings many benefits―simplified billing, security isolation, decentralized control, etc., it also introduces new challenges. One challenge is that the users in one account occasionally need to create resources in another.</p> 
<p>In this post, I will show you how to use a <a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/template-custom-resources.html">custom resource</a> from <a href="https://aws.amazon.com/cloudformation">AWS CloudFormation</a> to create <a href="https://aws.amazon.com/route53">Amazon Route 53</a> resource records in another account.</p> 
<p><span id="more-976"></span></p> 
<b>Multi-account scenario</b> 
<p>A common driver for adopting a multi-account strategy is to give autonomy and agility to individual business units.</p> 
<p>Imagine that you work for a company that has adopted this strategy. There is a centralized IT team that manages consolidated billing and shared resources such as AWS Direct Connect connections. In addition, they manage the Domain Name System (DNS) for the company. They have chosen to host DNS in Amazon Route 53. Various business units have their own accounts and operate with relatively little oversight.</p> 
<p>The marketing team regularly creates short-lived websites for various marketing campaigns. They use CloudFormation to launch and manage these sites, but CloudFormation cannot create resources in other accounts. Therefore, the marketing team has to submit a request to central IT to update DNS. This often takes hours or even days to complete. They want a simple way to create a CNAME record in the central account from a CloudFormation template in their own account.</p> 
<b>CloudFormation custom resources</b> 
<p>One way to create resources in another account is to use a CloudFormation custom resource, which allows you to execute custom code from a CloudFormation template. CloudFormation supports two types of custom resources:</p> 
<ul> 
<li>The first invokes an <a href="https://aws.amazon.com/lambda">AWS Lambda</a> function, allowing you to execute custom code.</li> 
<li>The second sends a message to an <a href="https://aws.amazon.com/sns">Amazon SNS</a> topic to which you have subscribed.</li> 
</ul> 
<p>Here’s an example. The Figure below outlines a solution to the problem scenario described earlier. Marketing is launching a CloudFormation stack and wants to create a CNAME in Amazon Route 53 hosted in another account.</p> 
<p>The high-level workflow goes like this:</p> 
<ol> 
<li>CloudFormation sends a message to an SNS topic in the central account.</li> 
<li>A Lambda function is invoked in response to the message.</li> 
<li>Lambda creates the Amazon Route 53 CNAME record.</li> 
<li>Lambda calls an Amazon S3 presigned URL, indicating that it completed successfully.</li> 
<li>CloudFormation marks the custom resource complete.</li> 
</ol> 
<p><img class="alignnone size-full wp-image-982" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/07/27/cfn-r53-cross-account.png" alt="" width="795" height="761" /><br /> <i>You might be asking yourself why I used SNS when CloudFormation custom resources can invoke Lambda directly. I could have invoked Lambda directly, but SNS simplifies cross account permissions and makes the configuration easier.</i></p> 
<b>Configuring the custom resource</b> 
<p>Begin by configuring the services in the central account. I will assume that Amazon Route 53 is already configured, so you need to configure SNS and Lambda.</p> 
<p>I have included a <a href="https://s3-us-west-2.amazonaws.com/management-tools-blog-cf-template-storage/ConfigCentralAccount.yaml">CloudFormation template to configure these services in the central account</a> for you. The template requires two inputs:</p> 
<ul> 
<li>The ID of the Amazon Route 53 <a href="http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/CreatingHostedZone.html">hosted zone</a> in which to allow the business units to create records.</li> 
<li>A list of the account IDs that are authorized to create resource records in Amazon Route 53.</li> 
</ul> 
<p>This restricts access so that only the accounts that you specify can create resource records in the hosted zone that you specify. Obviously, you don’t want to allow everyone to create―or worse, change―records anywhere in your DNS system.</p> 
<p>After the CloudFormation template completes, it outputs the ARN of the SNS topic used to request new resources. Make note of this, as you use it to configure the custom resource later in this post.</p> 
<p>In the Lambda console, you see a new function called CreateRoute53CNAME. This is the logic for the custom resource. The primary method, lambda_handler, is shown in the code below.</p> 
<p><strong>Example: Lambda function snippet</strong></p> 
<pre><code class="lang-python">def lambda_handler(event, context):
#SNS events contain a wrapper around the Lambda event. Unpack the
#Lambda event from SNS. Not needed if you’re calling Lambda directly.
print(&quot;SNS Event: &quot; + json.dumps(event))
event = json.loads(event['Records'][0]['Sns']['Message'])            
print(&quot;Lambda Event: &quot; + json.dumps(event))
try: 
hostedzone = 'ZXAOMNFL85JIZ'
type = event['RequestType']
source = event['ResourceProperties']['Source']
target = event['ResourceProperties']['Target']
if type == 'Create':
print &quot;Creating CNAME &quot; + source + &quot;-&gt;&quot; + target + &quot; in &quot; + hostedzone
change_resource_record_sets('UPSERT', hostedzone, source, target)
elif type == 'Update':
oldsource = event['OldResourceProperties']['Source']
oldtarget = event['OldResourceProperties']['Target']
print &quot;Deleting old CNAME &quot; + oldsource + &quot;-&gt;&quot; + oldtarget + &quot; in &quot; + hostedzone
change_resource_record_sets('DELETE', hostedzone, oldsource, oldtarget)
print &quot;Creating new CNAME &quot; + source + &quot;-&gt;&quot; + target + &quot; in &quot; + hostedzone
change_resource_record_sets('UPSERT', hostedzone, source, target)
elif type == 'Delete':
print &quot;Deleting CNAME &quot; + source + &quot;-&gt;&quot; + target + &quot; in &quot; + hostedzone
change_resource_record_sets('DELETE', hostedzone, source, target)
else:
print &quot;Unexpected Request Type&quot;
raise Exception(&quot;Unexpected Request Type&quot;)
print &quot;Completed successfully&quot;
responseStatus = 'SUCCESS'
responseData = {}
sendResponse(event, context, responseStatus, responseData)
except: 
print(&quot;Error:&quot;, sys.exc_info()[0])
responseStatus = 'FAILED'
responseData = {}
sendResponse(event, context, responseStatus, responseData)
</code></pre> 
<p>As you can see, the first thing the Lambda function does is unpack the SNS event to get the properties that were passed from CloudFormation. In this example, you pass in a source (for example, www.example.com) and a target (for example, my-loadbalancer-1234567890.us-east-1.elb.amazonaws.com) for a CNAME record.</p> 
<p>In addition, the event always includes a RequestType value of Create, Update, or Delete. The code below is an example of an Update event. In the case of an Update, you get an additional set of OldResourceProperties values that are not included in Create and Delete events.</p> 
<p><strong>Example: Sample update event in SNS</strong></p> 
<pre><code class="lang-json">{ &quot;Records&quot;: [ 
{ &quot;EventVersion&quot;: &quot;1.0&quot;, 
&quot;EventSubscriptionArn&quot;: &quot;arn:aws:sns:us-east-1:…:RequestRoute53CNAME:…&quot;, 
&quot;EventSource&quot;: &quot;aws:sns&quot;, 
&quot;Sns&quot;: { 
&quot;MessageId&quot;: &quot;6ae3f7a1-2772-568c-9175-a603bc40bf03&quot;, 
&quot;Message&quot;: {
&quot;RequestType&quot;:“Update&quot;,
&quot;ResponseURL&quot;:&quot; https://cloudformation-custom-resource-response-useast1...&quot;,
&quot;ResourceType&quot;:&quot;Custom::CNAME&quot;,
&quot;OldResourceProperties&quot;:{
“Target&quot;:&quot;my-first-loadbalancer.us-east-1.elb.amazonaws.com&quot;,
“Source&quot;:&quot;test.example.com“
},
&quot;ResourceProperties&quot;:{
“Target&quot;:&quot;my-second-loadbalancer.us-east-1.elb.amazonaws.com&quot;,
“Source&quot;:&quot;test.example.com“
}
}
} 
} 
} 
]}
</code></pre> 
<p>Depending on the type of event received, call the Amazon Route 53 <a href="http://boto3.readthedocs.io/en/latest/reference/services/route53.html#Route53.Client.change_resource_record_sets">change_resource_record_sets</a> API operation to create or delete the appropriate records. Finally, you must send the result of the operation to CloudFormation so it can mark the resource complete. The code below reports status.</p> 
<p><strong>Example: Reporting results to CloudFormation</strong></p> 
<pre><code class="lang-python">def sendResponse(event, context, responseStatus, responseData):
data = json.dumps({
'Status': responseStatus,
'Reason': 'See the details in CloudWatch Log Stream: ' + context.log_stream_name,
'PhysicalResourceId': context.log_stream_name,
'StackId': event['StackId'],
'RequestId': event['RequestId'],
'LogicalResourceId': event['LogicalResourceId'],
'Data': responseData
})
opener = urllib2.build_opener(urllib2.HTTPHandler)
request = urllib2.Request(url=event['ResponseURL'], data=data)
request.add_header('Content-Type', '')
request.get_method = lambda: 'PUT'
url = opener.open(request)
</code></pre> 
<p>As you can see, CloudFormation expects the Lambda function to provide a JSON document. This document must include a status of either SUCCESS or FAILED. The original request (such as the SNS update event) included a response URL, an <a href="http://docs.aws.amazon.com/AmazonS3/latest/dev/PresignedUrlUploadObject.html">S3 presigned URL</a>. I use the urllib2 module to PUT the JSON document to the presigned URL.</p> 
<b>Using the custom resource</b> 
<p>Now that you have your Lambda function created in the central account, you can invoke it from a custom resource in one of the accounts owned by your authorized business units. The code below shows a simple example stack that uses the custom resource.</p> 
<p>Pass three things to your custom resource. First, pass the ARN of the SNS topic used to initiate the custom resource. The ARN was an output from the template used earlier to create the custom resource in the central account. Second and third, pass the source and target values for the CNAME.</p> 
<p><strong>Example: Using the custom resource</strong></p> 
<pre><code class="lang-yaml">Parameters:
Queue: 
ServiceToken: The ARN of the SNS topic used to request a CNAME record. 
Type: String
Default: arn:aws:sns:us-east-1:999999999999:RequestRoute53CNAME
Source: 
Description: The pretty name for the CNAME record.
Type: String
Default: www.example.com 
Target: 
Description: The target of the CNAME record.
Type: String
Default: my-loadbalancer-1234567890.us-east-1.elb.amazonaws.com
Resources: 
CNAME: 
Type: Custom::CNAME
Properties: 
ServiceToken: !Ref Queue
Source: !Ref Source
Target: !Ref Target
</code></pre> 
<p>As you can see, the custom resource is easy to use but not valuable on its own. Here’s how to incorporate this into a larger solution. In the code below, I create an Elastic Beanstalk stack (using the <a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/quickref-elasticbeanstalk.html">PHP sample application stack</a>) and use the custom resource to create a CNAME record (for example, beanstalk.example.com) and a friendly name for the stack.</p> 
<p><strong>Example: Using the custom resource in a larger solution</strong></p> 
<pre><code class="lang-yaml">Resources: 
sampleApplication:
Type: AWS::ElasticBeanstalk::Application
Properties:
Description: AWS Elastic Beanstalk Sample Application
sampleApplicationVersion:
Type: AWS::ElasticBeanstalk::ApplicationVersion
Properties:
ApplicationName:
Ref: sampleApplication
Description: AWS Elastic Beanstalk Sample Application Version
SourceBundle:
S3Bucket: !Sub &quot;elasticbeanstalk-samples-${AWS::Region}&quot;
S3Key: php-sample.zip
sampleConfigurationTemplate:
Type: AWS::ElasticBeanstalk::ConfigurationTemplate
Properties:
ApplicationName:
Ref: sampleApplication
Description: AWS Elastic Beanstalk Sample Configuration Template
OptionSettings:
- Namespace: aws:autoscaling:asg
OptionName: MinSize
Value: '2'
- Namespace: aws:autoscaling:asg
OptionName: MaxSize
Value: '6'
- Namespace: aws:elasticbeanstalk:environment
OptionName: EnvironmentType
Value: LoadBalanced
SolutionStackName: 64bit Amazon Linux running PHP 5.3
sampleEnvironment:
Type: AWS::ElasticBeanstalk::Environment
Properties:
ApplicationName:
Ref: sampleApplication
Description: AWS Elastic Beanstalk Sample Environment
TemplateName:
Ref: sampleConfigurationTemplate
VersionLabel:
Ref: sampleApplicationVersion
CNAME: 
Type: Custom::CNAME
Properties: 
ServiceToken: arn:aws:sns:us-east-1:999999999999:RequestRoute53CNAME
Source: beanstalk.example.com
Target: !GetAtt sampleEnvironment.EndpointURL
</code></pre> 
<p>This CloudFormation stack waits for the Elastic Beanstalk environment to launch and then creates a CNAME record in the central IT account.</p> 
<b>Conclusion</b> 
<p>In this post, you learned how to create a CloudFormation custom resource, which allows you to execute custom logic in a CloudFormation template. You also learned how to invoke custom code in one AWS account, from a CloudFormation stack in another account.</p> 
<p><strong>About the Author</strong></p> 
<p><img class="size-full wp-image-1180 alignleft" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/08/24/beabrian.jpg" alt="" width="119" height="160" /><a href="https://www.linkedin.com/in/brianjbeach/">Brian Beach</a> is a Solutions Architect on the World Wide Public Sector team&nbsp;where he focuses on higher education. Brian is excited by the growth of cloud computing and enjoys&nbsp;teaching others about technology. He is a frequent author and speaker. In his free time, Brian can be found playing with his three children in Raleigh, NC.</p> 
<footer> 
</footer> 
</article> 
<article class="post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="b post-title" property="name headline">Amazon EC2 Systems Manager Automation is now a Amazon CloudWatch Events Target</b> 
<footer class="meta">
by 
<span property="author" typeof="Person"><span property="name">Venkat Krish</span></span> | on 
<time property="datePublished" datetime="2017-08-21T11:42:35+00:00">21 AUG 2017</time> | in 
<span class="categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/amazon-ec2-systems-manager/" title="View all posts in Amazon EC2 Systems Manager"><span property="articleSection">Amazon EC2 Systems Manager</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools"><span property="articleSection">Management Tools</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/amazon-ec2-systems-manager-automation-is-now-a-amazon-cloudwatch-events-target/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog=""><span class="span icon-share"></span>&nbsp;Share</a> 
<ul> 
</ul> 
</footer> 
<p>Today&nbsp;we are excited to announce a new target for Amazon CloudWatch Events: Amazon EC2 Systems Manager Automation. Through this integration, Automation workflows can be triggered by a schedule, or when specific AWS system events occur.</p> 
<ul> 
<li><a href="https://aws.amazon.com/ec2/systems-manager/automation/">Automation </a>is part of <a href="https://aws.amazon.com/ec2/systems-manager/">Amazon EC2 Systems Manager</a>.&nbsp; Using Automation you can build workflows that are streamlined, repeatable and auditable. For example, you can create workflows to patch, update agents, or bake applications into an Amazon Machine Image (AMI). You can also avoid the time and effort associated with updating your images manually, and instead build AMIs that meet your IT standards and make the approved AMIs available to you teams.</li> 
<li>Amazon&nbsp;<a href="http://docs.aws.amazon.com/AmazonCloudWatch/latest/events/WhatIsCloudWatchEvents.html">CloudWatch Events</a> allows you to create rules that trigger based on AWS events, or on a periodic schedule. &nbsp;CloudWatch Events can be setup to respond to Amazon EC2 Service state changes, Amazon Simple Storage Service (S3) bucket operations, and other events automatically. Supported targets include <a href="https://aws.amazon.com/lambda/">AWS Lambda</a>, Amazon SNS, Amazon EC2 Systems Manager Run Command, and now Amazon EC2 Systems Manager Automation.</li> 
</ul> 
<p>With Automation as a supported CloudWatch Events target, you can take advantage of some interesting use cases. You can perform routine tasks better when you schedule tasks for specific days and times or after specific event patterns. In this blog, we are going to show examples of how you can use CloudWatch Events and Automation to automate repetitive tasks, such as periodically starting and stopping instances.</p> 
<p><span id="more-825"></span></p> 
<h3>Automatically stop and start instances on weekends</h3> 
<p>Identifying and automatically stopping unused non-production instances in your account can save costs and improve efficiency of how you use your resources. Suppose you would like to automatically stop an instance every Friday evening and start it back on Monday morning. You can easily accomplish this using two CloudWatch Events that triggers an Automation Document for stopping and starting instances.</p> 
<h3>Create an Automation Document</h3> 
<p>For this example, follow the steps to <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/automation-createdoc.html">create an Automation Document</a>. The following code can be used to quickly create the Document.</p> 
<pre><code class="lang-json">{
&quot;description&quot;:&quot;Systems Manager Automation Demo - Start Instances via CWE&quot;,
&quot;schemaVersion&quot;:&quot;0.3&quot;,
&quot;parameters&quot;:{
&quot;automationRoleArn&quot;:{
&quot;type&quot;:&quot;String&quot;,
&quot;description&quot;:&quot;(Required) The ARN of the role that allows Automation to perform the actions on your behalf.&quot;
},
&quot;instanceIds&quot;:{
&quot;type&quot;:&quot;StringList&quot;,
&quot;description&quot;:&quot;(Required) The Instance ID(s) to Stop or Start.&quot;
},
&quot;state&quot;:{
&quot;type&quot;:&quot;String&quot;,
&quot;description&quot;:&quot;(Required) The state you would like the Instance(s) placed in. Options are: running | stopped&quot;
}
},
&quot;assumeRole&quot;:&quot;{{automationRoleArn}}&quot;,
&quot;mainSteps&quot;:[
{
&quot;name&quot;:&quot;startStopInstance&quot;,
&quot;action&quot;:&quot;aws:changeInstanceState&quot;,
&quot;maxAttempts&quot;:2,
&quot;timeoutSeconds&quot;:120,
&quot;onFailure&quot;:&quot;Continue&quot;,
&quot;inputs&quot;:{
&quot;InstanceIds&quot;:[&quot;{{instanceIds}}&quot;],
&quot;DesiredState&quot;:&quot;{{state}}&quot;
}
}
]
}</code></pre> 
<h3>Steps to create CloudWatch event rules to trigger Automation</h3> 
<p>After you have created the Document and saved it, you can create two CloudWatch event rules that automatically trigger at specific times.</p> 
<p><strong>Step 1</strong>. In the AWS Management Console, choose CloudWatch, Events, Rules and Create rule.</p> 
<p><img class="alignnone size-full wp-image-854" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/07/24/CWERules.png" alt="" width="1152" height="603" /></p> 
<p><strong>Step 2:&nbsp;</strong>&nbsp;Under <strong>Event Source</strong>, choose <strong>Schedule</strong>, <strong>Cron expression</strong>. To stop specified instances automatically at 6 PM every Friday, enter the following cron expression to trigger the rule:</p> 
<p><em>0 18 ? * FRI *</em></p> 
<p><img class="alignnone size-full wp-image-945" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/07/25/CR1-1.png" alt="" width="1021" height="636" /></p> 
<p>&nbsp;</p> 
<p><strong>Step 3:</strong> Under Targets, choose <strong>Add target</strong>, <strong>SSM Automation</strong>.</p> 
<p><strong>Step 4:</strong>&nbsp;For Document, select the Automation Document you saved for stopping and starting specified instances.</p> 
<p><strong>Step 5:</strong>&nbsp;For Configure document version, choose Default or a particular version number.</p> 
<p><strong>Step 6:</strong>&nbsp;Choose <strong>‘Constant’</strong> automation &nbsp;and enter the enter instance ID that you would like to be stopped automatically per the rule that you are creating. You can also choose&nbsp;<strong>‘Input Transformer’</strong> to provide custom inputs based on a template.</p> 
<p><img class="alignnone size-full wp-image-861" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/07/24/Targets.png" alt="" width="785" height="822" /></p> 
<p><strong>Step 7:</strong>&nbsp;Provide permission for CloudWatch event to call SSM Start Automation Execution. You can either create an existing role that you previously created or create a new role.</p> 
<p><strong>Step 8:</strong>&nbsp;Choose <strong>Configure details</strong>, and enter a name and description for your rule. Ensure that Enabled is selected.</p> 
<p><strong>Step 9:</strong>&nbsp;Choose <strong>Create rule</strong>.</p> 
<p>Your rule is now created and automatically executes every Friday at 6 PM to stop your specified instance. To start the instance back up say on Monday morning, repeat the steps to create another CloudWatch event rule, set your cron expression to Monday AM at your desired time, and target the same Automation Document. Make sure you provide “running” as your desired state.</p> 
<p>With this setup you can now automatically stop and start your instances, thus using your resources optimally.</p> 
<h3>Additional methods to trigger Automation</h3> 
<p>Outside of setting up an Automation workflow to be triggered on a schedule, you can also trigger executions based on event patterns. For example, you can setup a CloudWatch event on a&nbsp;<a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/systems-manager-paramstore.html">Parameter Store</a> value. Based on changes to the value you can trigger an Automation workflow. You can create&nbsp;a Parameter Store key/value to store AMI Ids which you typically use to create golden images for your organization. Every time you change the value of the key to a new AMI ID, you can setup a CloudWatch event rule on that parameter and target Automation. The target can point either to your custom Document or the <em>AWS-UpdateWindowsAMI</em> Document published by AWS. This automatically creates a new image with the latest updates that you can provide as inputs to your CI/CD pipeline or to Auto Scaling groups. For your reference, here is a blog that talks about how you can <a href="https://aws.amazon.com/blogs/mt/windows-ami-patching-and-maintenance-with-amazon-ec2-systems-manager-2/">update and patch your Windows AMIs</a>&nbsp;using Automation.</p> 
<p><img class="alignnone size-full wp-image-857" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/07/24/PS.png" alt="" width="1009" height="852" /></p> 
<p>&nbsp;</p> 
<h3>Conclusion</h3> 
<p>Automation simplifies common system maintenance and deployment tasks. By using CloudWatch Events, you can orchestrate task execution based on any events relating to AWS services. You can also trigger your predefined workflows on a schedule. Using this integration, you can easily orchestrate management of your resources and expect your workflows to perform tasks at scale automatically.</p> 
<p><strong>About the author</strong></p> 
<p><a href="https://www.linkedin.com/in/venkatkr/"><img class="size-full wp-image-831 alignleft" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/07/19/KRVenkt.jpg" alt="" width="119" height="160" /></a></p> 
<p><a href="https://www.linkedin.com/in/venkatkr/">Venkat Krishnamachari</a> is a Product Manager in the Amazon EC2 Systems Manager team. Venkat is excited by the opportunities presented by cloud computing, and loves helping customers benefit from the value of efficient infrastructure and management. In his personal time Venkat volunteers with NGOs and loves producing live theater and music shows.</p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/mt/tag/amazon-cloudwatch-events/" rel="tag">Amazon Cloudwatch Events</a>, <a href="https://aws.amazon.com/blogs/mt/tag/aws-codedeploy/" rel="tag">AWS CodeDeploy</a>, <a href="https://aws.amazon.com/blogs/mt/tag/aws-opsworks/" rel="tag">AWS OpsWorks</a>, <a href="https://aws.amazon.com/blogs/mt/tag/documents/" rel="tag">Documents</a>, <a href="https://aws.amazon.com/blogs/mt/tag/ec2-systems-manager/" rel="tag">EC2 Systems Manager</a>, <a href="https://aws.amazon.com/blogs/mt/tag/ec2-windows/" rel="tag">EC2 Windows</a>, <a href="https://aws.amazon.com/blogs/mt/tag/maintenance-window/" rel="tag">Maintenance Window</a>, <a href="https://aws.amazon.com/blogs/mt/tag/patch-complaince/" rel="tag">Patch Complaince</a>, <a href="https://aws.amazon.com/blogs/mt/tag/patch-manager/" rel="tag">Patch Manager</a>, <a href="https://aws.amazon.com/blogs/mt/tag/ssm/" rel="tag">SSM</a>, <a href="https://aws.amazon.com/blogs/mt/tag/state-manager/" rel="tag">State Manager</a></span> 
</footer> 
</article> 
<article class="post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="b post-title" property="name headline">Maintenance Windows: Support for New Task Types Using Amazon EC2 Systems Manager</b> 
<footer class="meta">
by 
<span property="author" typeof="Person"><span property="name">Lavanya Krishnan</span></span> | on 
<time property="datePublished" datetime="2017-08-16T10:50:46+00:00">16 AUG 2017</time> | in 
<span class="categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/amazon-ec2-systems-manager/" title="View all posts in Amazon EC2 Systems Manager"><span property="articleSection">Amazon EC2 Systems Manager</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools"><span property="articleSection">Management Tools</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/maintenance-windows-support-for-new-task-types-using-amazon-ec2-systems-manager/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog=""><span class="span icon-share"></span>&nbsp;Share</a> 
<ul> 
</ul> 
</footer> 
<p>In <a href="https://aws.amazon.com/ec2/systems-manager">Amazon EC2 Systems Manager</a>, the <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/systems-manager-maintenance.html">Maintenance Windows</a> service allows you to define a set of tasks, along with the instances where those tasks should be run and a run schedule. In this post, I talk about a new feature for Maintenance Windows—support for New Task types.</p> 
<p>Maintenance Windows now supports Systems Manager Automation documents, AWS Step Functions tasks, and AWS Lambda functions as tasks, including support for Parameter Store (when using Step Functions and Lambda).&nbsp;This allows you to perform complex workflows on your instances, such as patching a server running SQL Server using an Automation document.</p> 
<p>In this post, I show you the steps for executing this example and walk through the required configuration steps one-by-one.</p> 
<p><span id="more-1127"></span></p> 
<h4>Walkthrough</h4> 
<p>In this walkthrough, you learn how to create a maintenance window with an Automation task type. This task stops an instance, creates snapshots of attached EBS volumes using a Lambda function, restarts the instance, checks for missing Windows updates using another Lambda function, and installs the missing updates. The walkthrough includes the following steps:</p> 
<ul> 
<li>Set up IAM users and roles.</li> 
<li>Create Lambda functions.</li> 
<li>Create an Automation document.</li> 
<li>Create an EC2 instance.</li> 
<li>Create a maintenance window.</li> 
<li>Register an Automation task with the maintenance window.</li> 
</ul> 
<h4>Set up IAM users and roles</h4> 
<p>Because maintenance windows run on a schedule without a user taking specific actions, you need to create a role that grants the maintenance window the appropriate permissions to run the Automation document you’re creating. Similarly, a role needs to be created for the Automation document that grants the permissions to perform the actions in the document. Finally, create a role for the Lambda function so the function can take EBS snapshots.</p> 
<ol> 
<li>Create a user with Systems Manager full access as defined in <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/sysman-configuring-access-policies.html#sysman-access-user">Create a User Account for Systems Manager</a>.</li> 
<li>Create an instance role for Systems Manager as defined in <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/sysman-configuring-access-policies.html#sysman-configuring-access-role">Create a Role for Systems Manager Managed Instances</a>.</li> 
<li>Create a role for Systems Manager Automation to perform actions as defined in <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/automation-permissions.html#automation-role">Create an IAM Role for Automation</a> and <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/automation-permissions.html#automation-trust2">Add a Trust Relationship for Automation</a>.</li> 
<li>Create a role for the Systems Manager to allow Lambda functions to perform actions as defined in <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/automation-simpatch.html#automation-pet2">Create an IAM Role for AWS Lambda</a> 
<ul> 
<li>Attach a policy: <strong>AmazonEC2FullAccess.</strong></li> 
<li>Add a <strong>lambda.amazonaws.com</strong> trust relationship (similar to what was done in <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/automation-permissions.html#automation-trust2">Add a Trust Relationship for Automation</a> but replacing ssm.amazonaws.com with lambda.amazonaws.com).</li> 
</ul> </li> 
<li>Create a role for the Systems Manager maintenance window to perform actions as defined in <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/sysman-maintenance-permissions.html#sysman-maintenance-perm-console">Controlling Access to Maintenance Windows Using the AWS Console</a>. 
<ul> 
<li>Attach the iam:PassRole policy to this role for passing the Automation role created earlier (similar to what was defined for the Automation role in <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/automation-permissions.html#automation-passpolicy">Attach the iam:PassRole Policy</a>).</li> 
</ul> </li> 
</ol> 
<h4>Create Lambda functions</h4> 
<p>Create two Lambda functions:</p> 
<ul> 
<li>One to initiate the creation of an EBS snapshot.</li> 
<li>One to check the status of the snapshot creation so you can wait for the snapshot to be created.</li> 
</ul> 
<p>Here are the steps to create these functions.</p> 
<ol> 
<li>Open the AWS Lambda console at <a href="https://console.aws.amazon.com/lambda/">https://console.aws.amazon.com/lambda/</a>.</li> 
<li>Choose <strong>Create a Lambda function</strong>.</li> 
<li>On the <strong>Select blueprint</strong> page, choose <strong>Author from scratch</strong>.</li> 
<li>On the <strong>Configure triggers</strong> page, choose <strong>Next</strong>.</li> 
<li>On the <strong>Configure function</strong> page, for Name, type SSM-Automation-CreateSnapshots, and type an optional description.</li> 
<li>For <strong>Runtime</strong>, choose <strong>Python 2.7</strong>.</li> 
<li>In the <strong>Lambda function code</strong> section, delete the pre-populated code and paste the code in Table 1.</li> 
<li>In the <strong>Lambda function handler and role</strong> section, for <strong>Role</strong>, choose the service role for Lambda that you created earlier.</li> 
<li>Choose <strong>Next</strong>, <strong>Create function</strong>.</li> 
</ol> 
<p>Table 1.</p> 
<pre><code class="lang-python">from __future__ import print_function
import json
import boto3
print('Loading function')
#Expects instanceIds
def lambda_handler(event, context):
print(&quot;Received event: &quot; + json.dumps(event, indent=2))
# get EC2 client
ec2 = boto3.client('ec2')
# find volumes for given instances
response = ec2.describe_volumes(
Filters=[
{
'Name': 'attachment.instance-id',
'Values': [ event['instanceIds'] ],
},
]
)
# hold list of snapshot ids
snapshotIdList = []
# create snapshot of each volume id
for ids in response['Volumes']:
print('Creating snapshot for volumeId : %s' % ids['VolumeId'])
# create snapshot
response = ec2.create_snapshot(
Description='New snapshot for test',
VolumeId=ids['VolumeId'],
DryRun=False
)
print('Created snapshotId : %s' % response['SnapshotId'])
# add snapshot id to be returned
snapshotIdList.append(response['SnapshotId'])
returnString = &quot;,&quot;.join(str(id) for id in snapshotIdList)
return returnString</code></pre> 
<ol> 
<li>Repeat steps 1–4 from the first Lambda function.</li> 
<li>On the <strong>Configure function</strong> page, for <strong>Name</strong>, type SSM-Automation-CheckSnapshots and type an optional description.</li> 
<li>For <strong>Runtime</strong>, choose <strong>Python 2.7</strong>.</li> 
<li>In the <strong>Lambda function code</strong> section, delete the pre-populated code and paste the code in Table 2.</li> 
<li>In the <strong>Lambda function handler and role</strong> section, for <strong>Role</strong>, choose the service role for Lambda that you created earlier.</li> 
<li>Choose <strong>Next</strong>, <strong>Create function</strong>.</li> 
</ol> 
<p>Table 2.<code class="lang-python"><br /> </code></p> 
<pre><code class="lang-python">from __future__ import print_function
import json
import boto3
print('Loading function')
#Expects snapshotIds
def lambda_handler(event, context):
print(&quot;Received event: &quot; + json.dumps(event, indent=2))
# get EC2 client
ec2 = boto3.client('ec2')
# get the snapshotIds passed
snapshotIds = event['snapshotIds'].split(',')
# check the state of each snapshot
for id in snapshotIds:
response = ec2.describe_snapshots(
SnapshotIds=[
id,
],
DryRun=False
)
# if the state is not completed then it can't continue, so throw an error
for state in response['Snapshots']:
print('SnapshotId ' + id + ' in state : %s' % state['State'])
if state['State'] != 'completed':
errorString = 'Unable to proceed, snapshot in ' + state['State'] + ' state for: ' + id
raise Exception(errorString)
return &quot;Snapshots completed.&quot;</code></pre> 
<h4>Create an Automation document</h4> 
<p>An Automation document allows you to create your own custom workflow using a series of steps. Automation has several predefined actions that when stitched together can create complex and robust workflows.</p> 
<p>In this example, you use a few of these actions to build a custom workflow, such as <strong>aws:changeInstanceState</strong>, <strong>aws:invokeLambdaFunction</strong>, <strong>aws:sleep</strong> and <strong>aws:runCommand</strong>.&nbsp; The steps in this Automation document perform the following actions:</p> 
<ul> 
<li>Stop an EC2 instance</li> 
<li>Initiate the creation of volume snapshots with a Lambda function</li> 
<li>Wait a specified time while the snapshots are created</li> 
<li>Use another Lambda function to check if the snapshots have been successfully created</li> 
<li>Restart the EC2 instance</li> 
<li>Use a Run Command document to install updates on to the EC2 instance.</li> 
</ul> 
<p>Here are the steps to create the document.</p> 
<ol> 
<li>Open the Amazon EC2 console at https://console.aws.amazon.com/ec2/v2/home.</li> 
<li>In the navigation pane, choose <strong>Documents</strong>, <strong>Create Document</strong>.</li> 
<li>For <strong>Name</strong>, type CreateVolumeSnapshots.</li> 
<li>For <strong>Document Type</strong>, choose <strong>Automation</strong>.</li> 
<li>Delete the brackets in the <strong>Content</strong> box, and then paste the following JSON document.</li> 
<li>Choose <strong>Create Document</strong>.</li> 
</ol> 
<pre><code class="lang-json">{
&quot;schemaVersion&quot;:&quot;0.3&quot;,
&quot;description&quot;:&quot;Create EBS snapshots and update a Windows instance.&quot;,
&quot;assumeRole&quot;:&quot;{{AutomationAssumeRole}}&quot;,
&quot;parameters&quot;:{
&quot;instanceId&quot;:{
&quot;type&quot;:&quot;String&quot;,
&quot;description&quot;:&quot;(Required) Id of the instance&quot;
},
&quot;AutomationAssumeRole&quot;:{
&quot;type&quot;:&quot;String&quot;,
&quot;description&quot;:&quot;(Required) Role under which to execute this automation.&quot;
},
&quot;SnapshotTimeout&quot;:{
&quot;type&quot;:&quot;String&quot;,
&quot;description&quot;:&quot;(Required) Timeout for checking for snapshot completion.&quot;,
&quot;default&quot;: &quot;PT20M&quot;
}
},
&quot;mainSteps&quot;:[
{
&quot;name&quot;:&quot;stopInstance&quot;,
&quot;action&quot;:&quot;aws:changeInstanceState&quot;,
&quot;maxAttempts&quot;:1,
&quot;timeoutSeconds&quot;:300,
&quot;onFailure&quot;:&quot;Abort&quot;,
&quot;inputs&quot;:{
&quot;InstanceIds&quot;:[
&quot;{{ instanceId }}&quot;
],
&quot;DesiredState&quot;:&quot;stopped&quot;
}
},
{
&quot;name&quot;:&quot;createVolumeSnapshots&quot;,
&quot;action&quot;:&quot;aws:invokeLambdaFunction&quot;,
&quot;timeoutSeconds&quot;:120,
&quot;maxAttempts&quot;:1,
&quot;onFailure&quot;:&quot;Abort&quot;,
&quot;inputs&quot;:{
&quot;FunctionName&quot;:&quot;Automation-CreateSnapshots&quot;,
&quot;Payload&quot;:&quot;{\&quot;instanceIds\&quot;:\&quot;{{instanceId}}\&quot;}&quot;
}
},
{
&quot;name&quot;:&quot;waitForSnapshotsToCreate&quot;,
&quot;action&quot;:&quot;aws:sleep&quot;,
&quot;inputs&quot;:{
&quot;Duration&quot;:&quot;{{ SnapshotTimeout }}&quot;
}
},
{
&quot;name&quot;:&quot;checkVolumeSnapshots&quot;,
&quot;action&quot;:&quot;aws:invokeLambdaFunction&quot;,
&quot;timeoutSeconds&quot;:120,
&quot;maxAttempts&quot;:1,
&quot;onFailure&quot;:&quot;Abort&quot;,
&quot;inputs&quot;:{
&quot;FunctionName&quot;:&quot;Automation-CheckSnapshots&quot;,
&quot;Payload&quot;:&quot;{\&quot;snapshotIds\&quot;:\&quot;{{createVolumeSnapshots.Payload}}\&quot;}&quot;
}
},
{
&quot;name&quot;:&quot;startInstance&quot;,
&quot;action&quot;:&quot;aws:changeInstanceState&quot;,
&quot;maxAttempts&quot;:1,
&quot;timeoutSeconds&quot;:600,
&quot;onFailure&quot;:&quot;Abort&quot;,
&quot;inputs&quot;:{
&quot;InstanceIds&quot;:[
&quot;{{ instanceId }}&quot;
],
&quot;DesiredState&quot;:&quot;running&quot;
}
},
{
&quot;name&quot;:&quot;installMissingWindowsUpdates&quot;,
&quot;action&quot;:&quot;aws:runCommand&quot;,
&quot;maxAttempts&quot;:1,
&quot;timeoutSeconds&quot;:14400,
&quot;onFailure&quot;:&quot;Continue&quot;,
&quot;inputs&quot;:{
&quot;DocumentName&quot;:&quot;AWS-InstallWindowsUpdates&quot;,
&quot;InstanceIds&quot;:[
&quot;{{ instanceId }}&quot;
],
&quot;Parameters&quot;:{}
}
}
]
}</code></pre> 
<h4>Create an EC2 instance</h4> 
<p>To try out the Automation document, you need to have an instance running and managed by Systems Manager.&nbsp; For this example, use a Windows instance.</p> 
<p>Create an EC2 instance that uses the Systems Manager instance role created earlier. For more information, see <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/sysman-configuring-access-policies.html#sysman-create-instance-with-role">Create an Amazon EC2 Instance that Uses the Systems Manager Role</a>.</p> 
<h4>Create a maintenance window</h4> 
<p>Maintenance Windows let customers set up recurring schedules to perform defined actions on their instances.&nbsp; Each maintenance window has a schedule, duration, set of registered targets, and set of registered tasks to be performed against the targets. In this example, you create a maintenance window so it can be the initiator of the Automation task created earlier.</p> 
<p>Create a maintenance window and assign the new instance as a target. For more information, see <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/sysman-maintenance-console.html">Maintenance Window Console Walkthrough</a>.</p> 
<h4>Register an Automation task with the maintenance window</h4> 
<p>With the maintenance window created, you can now register an Automation task to run the Automation document and pass it the necessary parameters.</p> 
<ol> 
<li>Open the Amazon EC2 console at <a href="https://console.aws.amazon.com/ec2/v2/home">https://console.aws.amazon.com/ec2/v2/home</a>.</li> 
<li>In the navigation pane, choose <strong>Maintenance Windows</strong> and select the new maintenance window. Enter the following values: 
<ul> 
<li>For <strong>Actions</strong>, choose <strong>Register automation task</strong>.</li> 
<li>For <strong>Document</strong>, choose the CreateVolumeSnapshots document.</li> 
<li>For <strong>Task Priority</strong>, specify a priority for this task. 1 is the highest priority. Tasks in a maintenance window are scheduled in priority order with tasks that have the same priority scheduled in parallel.</li> 
<li>In the <strong>Target by</strong> section, choose <strong>Selecting registered target groups</strong> and select the target that you created earlier.</li> 
<li>In the <strong>Parameters</strong> section, for <strong>Execute</strong> <strong>on</strong>, specify 1. For <strong>Stop after</strong>, specify 1.</li> 
<li>For <strong>Role</strong>, specify the maintenance window role ARN created earlier.</li> 
<li>In the <strong>Input Parameters</strong> section, for <strong>AutomationAssumeRole</strong>, specify the Automation role ARN. Enter a timeout for waiting for the snapshots to complete. For InstanceId, type the instance ID of the instance created earlier.</li> 
</ul> </li> 
<li>Choose <strong>Register automation task</strong>.</li> 
</ol> 
<p>Most of the steps for registering a task in the AWS Management Console can be executed using AWS CLI commands instead.&nbsp; Furthermore, these steps could as easily be executed using the AWS SDK with Java, SDK for Python (Boto), or any of the other languages supported. This gives you many options when working with an AWS service. The following code examples use the AWS CLI for creating a maintenance window, registering a target with that maintenance window, and registering an Automation task using the Automation document created earlier.</p> 
<ol> 
<li>If needed, follow the steps to get started on creating a maintenance window with the AWS CLI in <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/sysman-maintenance-cli.html">Maintenance Window CLI Walkthrough</a>.</li> 
<li>Run the following CLI command and find the WindowId value for the maintenance window created earlier.<br /> <strong><em>aws ssm describe-maintenance-windows</em></strong><br /> This command returns the following, noting that the values for WindowId, name, description, and other fields below are fictional examples:<p></p> <pre><code class="lang-json">{
&quot;WindowIdentities&quot;: [
{
&quot;WindowId&quot;: &quot;mw-abc1234e3ddc9e286&quot;,
&quot;Name&quot;: &quot;MW1&quot;,
&quot;Description&quot;: &quot;MW1 description&quot;,
&quot;Enabled&quot;: true,
&quot;Duration&quot;: 2,
&quot;Cutoff&quot;: 1
}
]
}</code></pre> </li> 
<li>Run the following CLI command and find the WindowTargetId value for the instance that was assigned when you created the maintenance window.</li> 
</ol> 
<p><em>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <strong>aws ssm describe-maintenance-window-targets –window-id “mw-abc1234e3ddc9e286”</strong> </em></p> 
<p>This command returns the following:</p> 
<pre><code class="lang-json">{
&quot;Targets&quot;: [
{
&quot;WindowId&quot;: &quot;mw-abc1234e3ddc9e286&quot;,
&quot;WindowTargetId&quot;: &quot;2ecce06f-130c-41a3-870c-d36deff6cbba&quot;,
&quot;ResourceType&quot;: &quot;INSTANCE&quot;,
&quot;Targets&quot;: [
{
&quot;Key&quot;: &quot;InstanceIds&quot;,
&quot;Values&quot;: [
&quot;i-000a0a0ca4caf9861&quot;
]
}
],
&quot;OwnerInformation&quot;: &quot;test&quot;,
&quot;Name&quot;: &quot;test&quot;,
&quot;Description&quot;: &quot;test description&quot;
}
]
}</code></pre> 
<p>4. Run the following CLI command to register the Automation task to the maintenance window.<code class="lang-json"><br /> </code></p> 
<p><strong><em>aws ssm register-task-with-maintenance-window –window-id “mw-abc1234e3ddc9e286” –targets “Key=WindowTargetIds,Values=2ecce06f-130c-41a3-870c-d36deff6cbba” –task-arn “CreateVolumeSnapshots” –service-role-arn “arn:aws:iam::111111111111:role/MaintenanceWindowRole” –task-type “AUTOMATION” –task-invocation-parameters “Automation={Parameters={instanceId=i-000a0a0ca4caf9861,AutomationAssumeRole=arn:aws:iam::111111111111:role/AutomationRole,SnapshotTimeout=PT20M}}” –priority 1 –max-concurrency 1 –max-errors 1 –name “Automation_Task1” –description “Automation_Task1 description”</em></strong></p> 
<p>This command returns the following:</p> 
<pre><code class="lang-json">{
&quot;WindowTaskId&quot;: &quot;563e10e1-7b9c-4285-8c0c-cb94912b2839&quot;
}</code></pre> 
<h4>View the maintenance window execution</h4> 
<p>A maintenance window is executed based on the schedule that was specified.&nbsp; After the maintenance window execution, results can be viewed in the History tab on the selected maintenance window landing page.</p> 
<h4>Conclusion</h4> 
<p>In this post, I showed you how to use the newly launched task types in Maintenance Windows to schedule and automate the execution of many common systems administration tasks. Using the maintenance window, you can now create different types of tasks, run your tasks when needed on specified targets, and get notified about any problems running these tasks. This helps you get the status on scheduled tasks, with details of the errors, enabling you to take appropriate action.</p> 
<hr /> 
<h4>About the Authors</h4> 
<p><img class="size-full wp-image-1146 alignleft" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/08/16/Profile-pic.jpeg" alt="" width="120" height="120" />Lavanya Krishnan is a Technical Product Manager in the EC2 Systems Manager team responsible for Patch Manager and Maintenance Window capabilities. Lavanya is passionate about building Enterprise and Cloud Products and Services. When not working, she loves to spend time with family, travel, read books and play board games.</p> 
<p>&nbsp;</p> 
<p>&nbsp;</p> 
<p><img class="size-full wp-image-1149 alignleft" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/08/16/Tracy.jpeg" alt="" width="119" height="160" />Tracy Williams is a Software Development Manager in the EC2 Systems Manager team and is responsible for Maintenance Window Capabilities. In his free time Tracy enjoys hiking, movies and sports cars.</p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/mt/tag/ec2-systems-manager/" rel="tag">EC2 Systems Manager</a>, <a href="https://aws.amazon.com/blogs/mt/tag/maintenance-window/" rel="tag">Maintenance Window</a></span> 
</footer> 
</article> 
<article class="post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="b post-title" property="name headline">Improving Security through Delegated Administration with Amazon EC2 Systems Manager Automation</b> 
<footer class="meta">
by 
<span property="author" typeof="Person"><span property="name">Venkat Krish</span></span> | on 
<time property="datePublished" datetime="2017-08-15T01:49:20+00:00">15 AUG 2017</time> | in 
<span class="categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/amazon-ec2-systems-manager/" title="View all posts in Amazon EC2 Systems Manager"><span property="articleSection">Amazon EC2 Systems Manager</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools"><span property="articleSection">Management Tools</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/improving-security-through-delegated-administration-with-amazon-ec2-systems-manager-automation/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog=""><span class="span icon-share"></span>&nbsp;Share</a> 
<ul> 
</ul> 
</footer> 
<p><a href="https://aws.amazon.com/ec2/systems-manager/automation/">EC2 Systems Manager Automation</a> simplifies common system maintenance and deployment tasks. You can create workflows to automate repetitive tasks such as systems configuration, deployment and maintenance. Workflows are authored in JSON and saved as <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/automation-createdoc.html">Automation documents</a>.</p> 
<p>Automation service operates in the context of the user that invokes the execution. Automation documents can be authored with an optional service role (also called an assume Role) with an attached managed policy (<a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/automation-permissions.html">AmazonSSMAutomationRole</a>).</p> 
<ul> 
<li><strong>When the service role is specified:</strong> The Automation service executes the document in the context of the role.</li> 
<li><strong>When the service role is not specified:</strong> The Automation service creates a temporary session in the context of the user and then executes the document.</li> 
</ul> 
<p>In this blog, we are going to show the two methods for executing Automation. If you are using Automation for the first time or when you would like to automate and execute simple workflows in the context of your Account, the service role is not required. When you would like to control the context in which Automation workflows are executed, and limit permissions needed by a user that executes workflows you will use the service role.</p> 
<p>Note: For Automation documents that you expect to run longer than 12 hours, you must specify a service role because the temporary session to execute Automation in the user’s context expires 12 hours after starting the execution.</p> 
<p><span id="more-1116"></span></p> 
<p>By including a service role in the Automation document, you can achieve higher security and control. Here’s how delegated administration can be accomplished in the context of personas, where the personas could be different users or the same users within the organization.</p> 
<ul> 
<li><strong>Author</strong> – Creates Automation documents in JSON. For example, a document can take a service role as one parameter, and an AMI ID as another parameter. The document can incorporate <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/automation-actions.html">Automation actions</a> such as aws:runInstances and awscreateTags to launch and tag instances per corporate IT policies. The author <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/ssm-sharing.html">shares the document </a>with other users in the organization. Every time someone executes this document, EC2 instances are crated with the specified tags.</li> 
<li><strong>Administrator</strong> – Manages the infrastructure and ensures that appropriate permissions allow users to perform their IT systems management and configuration tasks. For example, the administrator requires the author to create tags with values that help easily identify the instance, and enforces that a service role is used in the document to perform actions. The administrator determines which users can create and launch EC2 instances, and <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/automation-permissions.html#automation-passrole">configures permissions</a> to select roles and users to execute the Automation document.</li> 
<li><strong>Operator</strong> – Performs IT tasks. In this post, it is a user who needs to launch an EC2 instance. The user does not require permissions to launch EC2 instances as they have permissions to execute the Automation document.</li> 
</ul> 
<p>In this model, administrators can ensure that only users with permissions to execute the document are able to launch EC2 instances. Thus, you can avoid having to grant permissions directly to operators. The administrator can work with the author to also enforce IT policies on an ongoing basis.</p> 
<h3>Walkthrough</h3> 
<p><strong>To view this model in action, follow the steps below:</strong></p> 
<ol> 
<li>Create an IAM user and attach the following policy that explicitly denies the user permissions to launch EC2 instances: <pre><code class="lang-json">{
&quot;Version&quot;: &quot;2012-10-17&quot;,
&quot;Statement&quot;: [{
&quot;Effect&quot;:&quot;Deny&quot;,
&quot;Action&quot;: [&quot;ec2:*&quot;],
&quot;Resource&quot;:&quot;*&quot;
}]
}</code></pre> </li> 
<li>Login as the IAM user and <a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/LaunchingAndUsingInstances.html">launch an EC2 instance </a>via the console or AWS CLI. This step fails.</li> 
<li>Create a service role. Fpr more information see Task4: <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/automation-permissions.html#automation-passpolicy">Attach the iam:PassRole</a> Policy to your Automation Role.</li> 
<li>Create an Automation document and include the service role that you created in step 4. Allow permissions to execute the document for the IAM user that you created in step 1.</li> 
<li>Login as the IAM user and execute the Automation document. This step succeeds and you can successfully launch the EC2 instance.</li> 
</ol> 
<h3>Summary</h3> 
<p>Automation documents can be executed by any IAM user in their own context without requiring an additional service role. However, it is a best practice to create a service role and enforce delegated administration via Automation. This ensures higher security and control for resources, in addition to auditing. When you use the service role you can tightly scope user permissions. As an administrator, you should also use this model to perform your own operations, and improve safety when managing resources at scale.</p> 
<h3>About the author</h3> 
<p><a href="https://www.linkedin.com/in/venkatkr/"><img class="size-full wp-image-831 alignleft" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/07/19/KRVenkt.jpg" alt="" width="119" height="160" />Venkat Krishnamachari</a>&nbsp;is a Product Manager in the Amazon EC2 Systems Manager team. Venkat is excited by the opportunities presented by cloud computing, and loves helping customers benefit from the value of efficient infrastructure and management. In his personal time Venkat volunteers with NGOs and loves producing live theater and music shows.</p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/mt/tag/automation/" rel="tag">Automation</a>, <a href="https://aws.amazon.com/blogs/mt/tag/ec2-systems-manager/" rel="tag">EC2 Systems Manager</a></span> 
</footer> 
</article> 
<article class="post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="b post-title" property="name headline">Example Scenarios for AWS Config Continuous Monitoring of Amazon S3 Bucket Access Controls</b> 
<footer class="meta">
by 
<span property="author" typeof="Person"><span property="name">Catherine Dodge</span></span> | on 
<time property="datePublished" datetime="2017-08-14T10:36:21+00:00">14 AUG 2017</time> | in 
<span class="categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/aws-config/" title="View all posts in AWS Config"><span property="articleSection">AWS Config</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools"><span property="articleSection">Management Tools</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/example-scenarios-for-aws-config-continuous-monitoring-of-amazon-s3-bucket-access-controls/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog=""><span class="span icon-share"></span>&nbsp;Share</a> 
<ul> 
</ul> 
</footer> 
<p><a href="https://aws.amazon.com/about-aws/whats-new/2017/08/aws-config-supports-new-managed-rules-for-securing-amazon-s3-buckets/">Recently</a>, <a href="https://aws.amazon.com/config/">AWS Config</a> announced two new managed rules to detect Amazon S3 buckets that have overly permissive controls. You can now check your S3 buckets continuously for unrestricted public write access or unrestricted public read access. In addition, you can view compliance of all your S3 buckets against these rules, and receive notifications via Amazon SNS when permissions change. You can also view the permissions history in the Config console.</p> 
<p>With these new rules, you can view the historical state of bucket Access Control Lists (ACLs) and bucket policies, and you can identify when changes were made. If someone changes a bucket policy or a bucket ACL, the Config rule automatically re-evaluates the new effective access. The rules evaluate the ACL to determine whether any anonymous user or any AWS user is allowed read or write permissions. The bucket polices are evaluated using a semantic-based automated reasoning engine, which returns a compliance decision.</p> 
<p>“These AWS Config rules are backed by a new formal model of IAM semantics, offering a dramatic improvement over existing tools that rely on simple pattern matching, which often fails to capture the nuances of the IAM policy language,” said Bridgewater Associates engineer Dan Peebles. “For the first time, <span id="more-1092"></span>we can make strong universal statements about our S3 IAM policies and be confident that our assumptions aren’t violated. We’ve been keenly collaborating with AWS on this formal model during its development; it provides the foundation for future tools that will be game changers in our ability to reason about our AWS infrastructure.”</p> 
<p>Tracking configuration changes to S3 bucket ACLs and policies is valuable from a governance perspective. It tells you how and when a bucket permission was modified. You can use this information to troubleshoot operational issues and outages, and maintain audit compliance. In addition, by turning on CloudTrail Data Events for S3 buckets, you can receive full audit logs around who read or wrote objects to that S3 bucket.</p> 
<p>Learn more: <a href="http://docs.aws.amazon.com/awscloudtrail/latest/userguide/logging-management-and-data-events-with-cloudtrail.html#logging-data-events-with-the-cloudtrail-console">Logging Data Events with the CloudTrail Console</a></p> 
<p>In this post, we present an example scenario in detail.</p> 
<p>&nbsp;</p> 
<b>Use case: S3 Public Write Access Rule</b> 
<p>Granting all AWS users access to write to your S3 bucket is almost never an intended configuration. Ensuring that S3 bucket policies don’t provide unrestricted write access is a security best practice within AWS Security. Misconfigurations of the bucket policy that provide unrestricted write access can allow unauthorized users to add malicious content to a bucket and overwrite content.</p> 
<p>One scenario where you should be sure these rules are in place is after the acquisition of a new company. Often a large enterprise centrally manages a number of AWS accounts, ensuring consistent centralized controls are in place. When a new business unit joins the organization, with their own AWS assets, it can be difficult for a security team to quickly assess the security posture of the acquired business.</p> 
<p>As an engineer tasked with assessing the security posture of newly acquired accounts, you can turn on write access detection to quickly see the status across all buckets in a given account. First, log in to the Config console. Choose <strong>Add rule</strong> to see the list of rules. Type ‘write’ in the search bar to see the s3-bucket-public-write-prohibited rule. The following screenshot shows the Add rule page.</p> 
<p>&nbsp;</p> 
<p>&nbsp;</p> 
<p><img class="alignnone size-full wp-image-1093" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/08/07/Blog1.png" alt="" width="975" height="525" /></p> 
<p>&nbsp;</p> 
<p>&nbsp;</p> 
<p>Click the rule description, which opens the rule configuration page. The default values are set to trigger rule evaluation on any change to S3 resources. Click <strong>Save</strong> and the rule will be enabled for your account, with the status shown as Evaluating…</p> 
<p>&nbsp;</p> 
<p><img class="alignnone size-full wp-image-1094" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/08/07/Blog2.png" alt="" width="975" height="450" /></p> 
<p>&nbsp;</p> 
<p>In this scenario, rule evaluation is completed and returns a status of Noncompliant. The evaluation identifies one bucket belonging to the newly acquired business that has a resource policy granting public write access.</p> 
<p>&nbsp;</p> 
<p><img class="alignnone size-full wp-image-1095" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/08/07/Blog3.png" alt="" width="975" height="194" /></p> 
<p>&nbsp;</p> 
<p>The Annotation field provides information about which access control is Noncompliant: the bucket ACL, the bucket policy, or both. In the example that follows, the Annotation field notes that it is the bucket policy that violates the check.</p> 
<p>The Config rule marks the bucket resource as Noncompliant if either the bucket ACL or the bucket resource policy allow unrestricted public write access. If the bucket ACL and bucket policy are configured with different write accesses, this means that the controls are in conflict. Providing users visibility into these conflicts allows them to correct the conflict.</p> 
<p>In our scenario, the startup you have recently acquired attempted to apply a policy to restrict bucket access to their AWS users logged on using multi-factor authentication (MFA). This is the policy that was used:</p> 
<pre><code class="lang-json">{
&quot;Version&quot;: &quot;2012-10-17&quot;,
&quot;Statement&quot;: [
{
&quot;Effect&quot;: &quot;Allow&quot;,
&quot;Principal&quot;: &quot;*&quot;,
&quot;Action&quot;: &quot;s3:PutObject*&quot;,
&quot;Resource&quot;: &quot;arn:aws:s3:::config-write-test/*&quot;,
&quot;Condition&quot;: {
&quot;Bool&quot;: {
&quot;aws:MultiFactorAuthPresent&quot;: &quot;true&quot;
}
}
}
]
}
</code></pre> 
<p>Here the condition key aws:MultiFactorAuthPresent isn’t sufficient to restrict public write access. Since the Principal value is set to “*” the net effect of this policy is to restrict S3 write access to any AWS user in any account who is logged on with multi-factor authentication. Since anyone could create an AWS account, and enable login using MFA, this policy effectively grants public write permissions. There is no clause tying the principal to the account where the bucket is hosted. The ability to reason in this way about this net effect of a policy can be quite difficult to do using simple scripts or using human inspection, but it is now possible using the semantic-based automated reasoning tool for policies developed by AWS.</p> 
<p>An example of an appropriately configured S3 resource policy that only allows access from a given VPC is shown in the following example:</p> 
<pre><code class="lang-json">{
&quot;Version&quot;: &quot;2012-10-17&quot;,
&quot;Statement&quot;: [
{
&quot;Sid&quot;: &quot;Open access to vpc-01234567&quot;,
&quot;Effect&quot;: &quot;Allow&quot;,
&quot;Principal&quot;: &quot;*&quot;,
&quot;Action&quot;: &quot;s3:*&quot;,
&quot;Resource&quot;: [
&quot;arn:aws:s3:::config-write-test/*&quot;
],
&quot;Condition&quot;: {
&quot;StringEquals&quot;: {
&quot;aws:sourceVpc&quot;: &quot;vpc-01234567&quot;
}
}
},
{
&quot;Sid&quot;: &quot;Deny access to non vpc-012345667&quot;,
&quot;Effect&quot;: &quot;Deny&quot;,
&quot;Principal&quot;: &quot;*&quot;,
&quot;Action&quot;: &quot;*&quot;,
&quot;Resource&quot;: [
&quot;arn:aws:s3:::config-write-test/*&quot;
],
&quot;Condition&quot;: {
&quot;StringNotEqualsIfExists&quot;: {
&quot;aws:sourceVpc&quot;: &quot;vpc-01234567&quot;
}
}
}
]
}
</code></pre> 
<p>The semantic-based automated reasoning tool for policies used by the Config rule correctly determines that the policy correctly limits writes to those coming from the selected VPC. By limiting write access to a given VPC, we can now re-evaluate the rule, and we are now Compliant.</p> 
<p><img class="alignnone size-full wp-image-1096" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/08/07/Blog4.png" alt="" width="975" height="194" /></p> 
<p>Enabling these rules in every account owned by a newly acquired company lets the central IT team within an organization quickly identify any misconfigurations that could pose a potential risk to the organization. If there are multiple accounts, the new <a href="https://aws.amazon.com/about-aws/whats-new/2017/07/aws-cloudformation-supports-multiple-account-and-region-provisioning-with-stackset/">StackSet</a> feature can be used to enable the Config rule across multiple accounts. The rule quickly pinpoints the source of the misconfiguration, enabling quick remediation to bring the account in line with best practices.</p> 
<p>&nbsp;</p> 
<b>Checking unrestricted public read access</b> 
<p>&nbsp;</p> 
<p>You can also check for unrestricted public read access, using a similar new rule. For media or website content, granting public access to read your S3 bucket is the desired configuration. However, if that isn’t your use case, unrestricted read access is likely a misconfiguration. Enabling the s3-bucket-public-read-prohibited rule ensures that you are alerted to any misconfigured buckets that allow public read access today. After any misconfigurations are fixed, the Config rule will continuously re-evaluate any changes made in the future to ensure continued compliance.</p> 
<p>To enable the rule, follow the steps outlined earlier for the public write rule, instead using ‘read’ as the rule search term. After rule evaluation is enabled and completed, the console will report a Compliant status if no S3 buckets allow unrestricted public write access. If any buckets do allow unrestricted public read access, the status will be reported as Noncompliant, along with the number of Noncompliant buckets. The annotation provided explains which access control is Noncompliant, either the bucket ACL, the bucket resource policy, or both.</p> 
<p>&nbsp;</p> 
<b>Summary</b> 
<p>By enabling these new rules, you can now easily monitor S3 access controls and ensure that access to your data is configured as you expect. These rules can be accessed using the AWS Management Console, as shown here, or evaluated using the <a href="http://aws.amazon.com/cli">AWS CLI</a> or <a href="http://aws.amazon.com/tools">AWS SDKs</a>.</p> 
<p>&nbsp;</p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/mt/tag/aws-config/" rel="tag">AWS Config</a>, <a href="https://aws.amazon.com/blogs/mt/tag/config-rules/" rel="tag">Config rules</a></span> 
</footer> 
</article> 
<article class="post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="b post-title" property="name headline">Secure, Scalable, and Efficient Instance Management Using Amazon EC2 Run Command</b> 
<footer class="meta">
by 
<span property="author" typeof="Person"><span property="name">Ananth Vaidyanathan</span></span> | on 
<time property="datePublished" datetime="2017-08-08T13:50:03+00:00">08 AUG 2017</time> | in 
<span class="categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/amazon-ec2-systems-manager/" title="View all posts in Amazon EC2 Systems Manager"><span property="articleSection">Amazon EC2 Systems Manager</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools"><span property="articleSection">Management Tools</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/secure-scalable-and-efficient-instance-management-using-amazon-ec2-run-command/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog=""><span class="span icon-share"></span>&nbsp;Share</a> 
<ul> 
</ul> 
</footer> 
<p><em>This post was written by Miguel Jo&atilde;o, Cloud Software Engineer at OutSystems.</em></p> 
<p>The OutSystems low-code development platform allows users to create and deliver high-quality web and mobile apps a lot faster, leveraging all the advantages of visual programming with few of the drawbacks. Of course, providing this high productivity, enterprise-grade <a href="https://en.wikipedia.org/wiki/Platform_as_a_service">Platform-as-a-Service</a> (PaaS) solution can be challenging. For us at OutSystems, those challenges ended up inspiring us to build custom solutions to manage large infrastructures.</p> 
<p>We were working on a custom offer for clients that would enable them to build their tailored apps. That led us to deploy our own orchestration processes.</p> 
<ul> 
<li>Instead of only using the common configuration management tools, we had to deploy a <strong>custom remote command execution environment</strong>. This resulted in a tight control over all the steps in the deployment and configuration of the infrastructure.</li> 
<li>We needed to provide an <strong>enterprise-grade PaaS solution with secure access, data integrity, and high availability</strong>.</li> 
<li>This solution must scale to meet future demand, and for the long run we’re talking about <strong>1M+ instances</strong>.</li> 
<li>We had to <strong>ensure a path for the solution to evolve</strong> without disrupting the customer service.</li> 
</ul> 
<p>Sounds complicated, right? Well, it was, especially when you consider that we had to apply our custom environment to an existing underlying infrastructure while keeping the security, isolation, and evolution requirements.</p> 
<p>The end result was a leaner and more secure solution. <a href="https://aws.amazon.com/ec2/run-command">Amazon EC2 Run Command</a> service improved the stability of our orchestration processes (error ratio reduction of over 80%), and the performance (10–20 times faster).</p> 
<p><span id="more-1024"></span></p> 
<h3>Problem: Difficult to manage instance proliferation</h3> 
<p>We designed with the standardization of the underlying infrastructure that supports our PaaS offer in mind. However, the need to respond to the specific needs of our enterprise customers led to the development of an orchestration process that takes advantage of configuration management tools like Chef for the initial and base configuration. Afterwards, we extended that orchestration to support the customization using on-demand remote command execution.</p> 
<p>The adoption of these orchestration processes in our cloud services has grown, and it now supports all of our paid and free PaaS offers, and some of our R&amp;D internal development quality assurance requirements.</p> 
<p>We currently provision <a href="https://aws.amazon.com/ec2/">EC2</a> instances and <a href="https://aws.amazon.com/rds/">Amazon RDS</a> instances to meet our needs in six different AWS Regions, in an automated fashion, 24/7. Our current infrastructure landscape consists of more than a thousand EC2 instances, and hundreds of RDS instances with many different software versions and software configurations. We have Windows and Linux operating systems, and at least two database flavors: Microsoft SQL Server and Oracle. This graphic shows the management nightmare for which we signed up.</p> 
<p><img class="size-full wp-image-1030 alignnone" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/08/01/infra_growth-1.png" alt="" width="500" height="327" /></p> 
<h3>Temporary solution (not scalable): SSH and ESB</h3> 
<p>Early in the PaaS project, we determined that direct remote commands would control the infrastructure servers, and we designed the orchestration processes to support that.</p> 
<p>The result was a remote command architecture with an <a href="https://en.wikipedia.org/wiki/Enterprise_service_bus">Enterprise Service Bus (ESB)</a> and <a href="https://en.wikipedia.org/wiki/Secure_Shell">secure shell connections (SSH)</a>. The ESB served as a central point of convergence for all remote connections managing the cloud servers, allowing remote commands to be executed through a synchronous SSH. The orchestration processes invoke the remote command execution via the ESB, and expect a callback from the ESB when the command finishes executing.</p> 
<p><img class="size-full wp-image-1034 alignnone" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/08/01/old_arch.png" alt="" width="450" height="303" /></p> 
<p>However, this solution rapidly began to show its limitations:</p> 
<ul> 
<li><strong>Performance overhead</strong> due to connection handshake and authentication</li> 
<li><strong>Increased error rate</strong> due to <strong>instability</strong> in the network and long standing connections</li> 
<li><strong>Limited parallelism</strong> due to concurrent number of remote long standing connections in the ESB (we started to see instability after 40 concurrent remote executions per ESB node)</li> 
<li><strong>Security concerns</strong> about having SSH inbound traffic on the instances for orchestration purposes, and all the hassle of managing the SSH authentication best practices (keys vs. passwords)</li> 
</ul> 
<p>With the growth in demand for our cloud services, we had to consider other options immediately. Before we committed to searching for or developing better alternatives that would scale for 1M+ instances, AWS answered our prayers with the <a href="https://aws.amazon.com/ec2/run-command/">EC2 Run Command</a> feature.</p> 
<h3>Better solution: Scalable, secure remote commands</h3> 
<p>After a short assessment of Run Command, we realized that it would allow us to greatly improve our efforts and our custom orchestration systems, increasing both reliability and performance. We started changing our orchestration to use this new feature, and replaced the remote command execution engine with Run Command.</p> 
<p><img class="size-full wp-image-1035 alignnone" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/08/01/new_arch.png" alt="" width="450" height="304" /></p> 
<p>Sending the remote command through Run Command removed the SSH connectivity requirement, eliminating security concerns. The feature also keeps network instability concerns at bay because keeping long-standing connections during the command execution is no longer necessary. It’s all asynchronous.</p> 
<p>The most significant changes in our orchestration were:</p> 
<ul> 
<li>Roll out (re-create) EC2 instances with <a href="http://docs.aws.amazon.com/IAM/latest/UserGuide/introduction.html">IAM</a> roles</li> 
<li>Deploy updated EC2Config and SSM Agent services on the EC2 instances</li> 
<li>Implement the callback after execution end, based on the S3 output files, using an AWS Lambda function that runs when a new output file is created</li> 
<li>Change our orchestration command execution engine module to invoke Run Command (using SSM API)</li> 
</ul> 
<p>We were able to evaluate, design, develop, test, and deploy the changes to our orchestration processes in approximately two months. This opened the door to a new growth spurt in our cloud services, mainly because the parallelism limitations were gone.</p> 
<h3>Replacing the ESB services: Additional details</h3> 
<p>We had our system architected to be modular, so replacing the ESB services with the Run Command services seemed like it would be straightforward. But as with any new development, we had to deal with some unexpected challenges. No straightforward replacement—after all, where would be the fun in that?</p> 
<ul> 
<li>To use Run Command, each EC2 instance had to have an associated instance role. Unfortunately, at the time, it was not possible to associate an IAM role with a running instance. Instead, we re-created about 80% of our EC2 instances to activate Run Command. Thankfully, <a href="https://aws.amazon.com/about-aws/whats-new/2017/02/new-attach-an-iam-role-to-your-existing-amazon-ec2-instance/">it is now possible</a> to add an instance role to an existing EC2 instance without having to re-create it</li> 
<li>Run Command requires agents installed in the EC2 instances. However, the configuration and execution outputs of these agents differ between Windows and Linux systems. At the time, to use Run Command on Windows, we needed to have the EC2Config service running. For Linux, we needed the SSM Agent service. These two different applications require different configurations, and as such, the output log files prefixes in the S3 output bucket were also different. So, we had to make allowances for these differences as part of the process. Nowadays, the <span style="text-decoration: underline">SSM Agent service is available for both Windows and Linux</span>, which simplifies the configurations and eases the setup between different operating systems</li> 
<li>Managing the S3 bucket access across the few hundred different AWS accounts that require specific permissions is practically impossible. We had to get creative with the S3 bucket management for the Run Command outputs.<br /> Using a single bucket, each output log would be owned by the account hosting the EC2 instance where the log ran. No other user could access it, so we created a secondary S3 bucket and moved the output logs from the original bucket, fixing the object permissions. This way, we could keep the output logs secured in a bucket with restricted accesses, not allowing the instances to access it anymore. In the meantime, <span style="text-decoration: underline">new versions of the SSM Agent support changing the output log ownership in the bucket</span>.</li> 
</ul> 
<p>After it was all up and running, magic started to happen. Before, with the ESB solution, our average error rate was usually up to 5%, and it increased to over 20% during the second half of 2016. This growing error rate was a reflex of the ESB solution not keeping up with the growing demand. When we started using Run Command, the average error ratio dropped to values below 1%, regardless of the growth in demand. It seriously made our lives better, as you can see in the stability comparison:</p> 
<p><img class="size-full wp-image-1053 alignnone" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/08/01/stability-1.png" alt="" width="505" height="330" /></p> 
<p>Additionally, the Run Command solution improved the remote command execution average time by one order of magnitude: from 10 to 20 times faster. The solution allowed us to remove the bottlenecks in the ESB and the SSH connections, as well as improve stability by reducing the error rate. Here’s the performance comparison so you don’t have to take our word for it:</p> 
<p><img class="size-full wp-image-1052 alignnone" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/08/01/performance.png" alt="" width="505" height="330" /></p> 
<p>The new Run Command feature responded as advertised. The end result is a faster, leaner, and more robust remote command execution engine that complies with our on-demand custom configuration orchestration requirements.</p> 
<h3>About the Author</h3> 
<p><a href="https://www.linkedin.com/in/migueljoao/">Miguel Jo&atilde;o</a><img class="alignleft size-full wp-image-1109" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/08/08/miguel.jpg" alt="" width="119" height="130" /> joined OutSystems R&amp;D in 2005, and became a Cloud Software Engineer in 2013. Since then, he’s been working on the Platform-as-a-Service offer of the industry-leading, low-code platform for mobile and web application development. Miguel is a technology enthusiast, and he is passionate about automation.</p> 
<p>&nbsp;</p> 
<p>&nbsp;</p> 
<p>&nbsp;</p> 
<p>&nbsp;</p> 
<hr /> 
<p><img class="alignnone wp-image-1111 size-full" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/08/08/oustsystems-logo-1.png" alt="" width="300" height="64" /></p> 
<hr /> 
<p><em>AWS is not responsible for the content or accuracy of this post. The content and opinions in this blog are solely those of the third party author. </em></p> 
<footer> 
TAGS: 
<span property="keywords"><a href="https://aws.amazon.com/blogs/mt/tag/ec2-systems-manager/" rel="tag">EC2 Systems Manager</a>, <a href="https://aws.amazon.com/blogs/mt/tag/run-command/" rel="tag">Run Command</a></span> 
</footer> 
</article> 
<p>
© 2017, Amazon Web Services, Inc. or its affiliates. All rights reserved.
</p>

    </div>
  </div>
</div>


    <div id="footer" class="navigation hidden-print">
      <div class="container">
        <div class="row">
          <div class="col-xs-12">
            <ul class="footer-links nav navbar-nav">
              <li><a href="../aws.html">AWS</a></li>
              <li><a href="../linux.html">Linux</a></li>
              <li><a href="../docker.html">Docker</a></li>
              <li><a href="../ibmpower.html">IBM Power</a></li>
              <li><a href="blogsataws1.html">Blogs@AWS (Kindle Friendly)</a></li>
            </ul>
            <ul class="footer-links nav navbar-nav navbar-right">
              <li><a href="../comments.html">Comments?</a></li>
            </ul>
          </div>
        </div>
      </div>
    </div>
  </body>
</html>
