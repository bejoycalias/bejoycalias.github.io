<!DOCTYPE html>
<html lang="en">
  <head>
<!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-593498H');</script>
<!-- End Google Tag Manager -->

    <meta charset="utf-8">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">

    <meta name="msapplication-config" content="/microsoft-tile.xml" />
    <meta name="theme-color" content="#ffffff">

    <meta property="og:url" content="https://bejoycalias.github.io/blogsataws/mgmtblogs1.html" />
    <meta property="og:site_name" content="Bejoy's TechNotes"/>
    <meta property="og:title" content="Bejoy's TechNotes - Kindle Friendly AWS Management Tools Blogs" />
    <meta property="og:image" content="https://bejoycalias.github.io/assets/images/og-image.png"/>
    <meta property="og:image:width" content="1200"/>
    <meta property="og:image:height" content="1200"/>
    <meta property="og:description" content="" />

    <title>Bejoy's TechNotes - Kindle Friendly AWS Management Tools Blogs</title>
    <link href="../assets/stylesheets/application-832aa42c.css" rel="stylesheet" />

    <!--[if lt IE 9]>
      <script src="../assets/javascripts/ie-compat-c141a02d.js"></script>
    <![endif]-->
    <script src="../assets/javascripts/application-ff53d307.js"></script>

    <!-- Typekit script to import Klavika font -->
    <script src="https://use.typekit.net/wxf7mfi.js"></script>
    <script>try{Typekit.load({ async: true });}catch(e){}</script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-100043608-1', 'auto');
  ga('send', 'pageview');

</script>

    
  </head>

  <body id="uh-oh-" class="layout-inner page-uh-oh-">
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-593498H"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->


    <div id="header" class="navigation navbar-static-top hidden-print">
      <div class="container">
        <div class="row">
          <div class="col-xs-12">
            <div class="navbar-header">
              <div class="navbar-brand">
                <a href="/">
                  <svg version="1.0" xmlns="http://www.w3.org/2000/svg" width="135.000000pt" height="50" viewbox="0 0 135.000000 45.000000" preserveaspectratio="xMidYMid meet" class="logo">

<g transform="translate(0.000000,45.000000) scale(0.100000,-0.100000)" fill="#000000" stroke="none">
<path class="text" fill="#000000" d="M527 384 c-4 -4 -7 -18 -7 -31 0 -21 4 -24 28 -21 21 2 27 8 27 28 0
18 -6 26 -20 28 -12 2 -24 0 -28 -4z"></path>
<path class="text" fill="#000000" d="M1080 335 c0 -48 2 -55 20 -55 18 0 20 7 20 55 0 48 -2 55 -20 55
-18 0 -20 -7 -20 -55z"></path>
<path class="text" fill="#000000" d="M54 357 c-2 -7 -3 -69 -2 -138 l3 -124 65 -3 c90 -3 130 20 130 77 0
29 -6 44 -20 54 -20 14 -20 15 -3 45 14 25 15 34 5 56 -6 15 -23 31 -38 36
-38 15 -134 13 -140 -3z m110 -33 c19 -7 21 -45 4 -62 -7 -7 -22 -12 -35 -12
-20 0 -23 5 -23 40 0 41 13 50 54 34z m20 -130 c19 -18 19 -20 6 -45 -8 -13
-21 -19 -45 -19 -34 0 -35 1 -35 40 0 38 2 40 29 40 16 0 37 -7 45 -16z"></path>
<path class="text" fill="#000000" d="M319 271 c-23 -24 -29 -38 -29 -74 0 -25 3 -53 6 -62 20 -50 164 -64
164 -15 0 15 -7 17 -45 12 -46 -5 -75 8 -75 34 0 11 16 14 65 14 l65 0 0 35
c0 80 -92 114 -151 56z m99 -33 c3 -15 -4 -18 -37 -18 -43 0 -50 7 -29 28 18
18 62 11 66 -10z"></path>
<path class="text" fill="#000000" d="M520 184 c0 -107 -1 -116 -20 -121 -11 -3 -20 -12 -20 -19 0 -21 76
-19 84 2 3 9 6 69 6 135 l0 119 -25 0 -25 0 0 -116z"></path>
<path class="text" fill="#000000" d="M649 271 c-24 -25 -29 -37 -29 -78 1 -70 34 -103 105 -103 55 0 95
44 95 103 0 60 -7 75 -41 92 -47 25 -96 19 -130 -14z m111 -30 c25 -48 2 -111
-40 -111 -45 0 -69 80 -34 114 21 22 61 20 74 -3z"></path>
<path class="text" fill="#000000" d="M850 287 c0 -8 16 -57 36 -110 28 -76 33 -100 25 -116 -16 -28 -14
-31 18 -31 27 0 29 4 70 123 23 67 41 128 41 135 0 6 -11 12 -24 12 -21 0 -26
-8 -41 -65 -10 -36 -21 -68 -25 -70 -3 -2 -16 27 -29 66 -19 60 -25 69 -47 69
-13 0 -24 -6 -24 -13z"></path>
<path class="text" fill="#000000" d="M1192 284 c-17 -12 -22 -24 -20 -47 2 -26 10 -36 45 -52 49 -23 59
-55 17 -55 -14 0 -34 5 -45 10 -16 9 -19 7 -19 -13 0 -17 7 -27 23 -31 69 -18
117 6 117 60 0 32 -4 37 -45 55 -60 26 -62 54 -4 46 37 -5 40 -3 37 16 -2 18
-11 23 -43 25 -25 2 -49 -3 -63 -14z"></path>
</g>
</svg>

                </a>
              </div>
              <button class="navbar-toggle" type="button">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
              </button>
            </div>
            <div class="buttons hidden-xs">
              <nav class="navigation-links" role="navigation">
                <ul class="main-links nav navbar-nav navbar-right">
                  <li><a href="../aws.html">AWS</a></li>
                  <li><a href="../linux.html">Linux</a></li>
                  <li><a href="../docker.html">Docker</a></li>
                  <li><a href="../ibmpower.html">IBM Power</a></li>
                  <li><a href="blogsataws1.html">Blogs@AWS (Kindle Friendly)</a></li>
                </ul>
              </nav>
            </div>
          </div>
        </div>
      </div>
    </div>

    <div class="sidebar-overlay"></div>

<aside class="sidebar" role="navigation">
  <div class="sidebar-header">
    <svg version="1.0" xmlns="http://www.w3.org/2000/svg" width="135.000000pt" height="42" viewbox="0 0 135.000000 45.000000" preserveaspectratio="xMidYMid meet">

<g transform="translate(0.000000,45.000000) scale(0.100000,-0.100000)" fill="#000000" stroke="none">
<path class="text" fill="#000000" d="M527 384 c-4 -4 -7 -18 -7 -31 0 -21 4 -24 28 -21 21 2 27 8 27 28 0
18 -6 26 -20 28 -12 2 -24 0 -28 -4z"></path>
<path class="text" fill="#000000" d="M1080 335 c0 -48 2 -55 20 -55 18 0 20 7 20 55 0 48 -2 55 -20 55
-18 0 -20 -7 -20 -55z"></path>
<path class="text" fill="#000000" d="M54 357 c-2 -7 -3 -69 -2 -138 l3 -124 65 -3 c90 -3 130 20 130 77 0
29 -6 44 -20 54 -20 14 -20 15 -3 45 14 25 15 34 5 56 -6 15 -23 31 -38 36
-38 15 -134 13 -140 -3z m110 -33 c19 -7 21 -45 4 -62 -7 -7 -22 -12 -35 -12
-20 0 -23 5 -23 40 0 41 13 50 54 34z m20 -130 c19 -18 19 -20 6 -45 -8 -13
-21 -19 -45 -19 -34 0 -35 1 -35 40 0 38 2 40 29 40 16 0 37 -7 45 -16z"></path>
<path class="text" fill="#000000" d="M319 271 c-23 -24 -29 -38 -29 -74 0 -25 3 -53 6 -62 20 -50 164 -64
164 -15 0 15 -7 17 -45 12 -46 -5 -75 8 -75 34 0 11 16 14 65 14 l65 0 0 35
c0 80 -92 114 -151 56z m99 -33 c3 -15 -4 -18 -37 -18 -43 0 -50 7 -29 28 18
18 62 11 66 -10z"></path>
<path class="text" fill="#000000" d="M520 184 c0 -107 -1 -116 -20 -121 -11 -3 -20 -12 -20 -19 0 -21 76
-19 84 2 3 9 6 69 6 135 l0 119 -25 0 -25 0 0 -116z"></path>
<path class="text" fill="#000000" d="M649 271 c-24 -25 -29 -37 -29 -78 1 -70 34 -103 105 -103 55 0 95
44 95 103 0 60 -7 75 -41 92 -47 25 -96 19 -130 -14z m111 -30 c25 -48 2 -111
-40 -111 -45 0 -69 80 -34 114 21 22 61 20 74 -3z"></path>
<path class="text" fill="#000000" d="M850 287 c0 -8 16 -57 36 -110 28 -76 33 -100 25 -116 -16 -28 -14
-31 18 -31 27 0 29 4 70 123 23 67 41 128 41 135 0 6 -11 12 -24 12 -21 0 -26
-8 -41 -65 -10 -36 -21 -68 -25 -70 -3 -2 -16 27 -29 66 -19 60 -25 69 -47 69
-13 0 -24 -6 -24 -13z"></path>
<path class="text" fill="#000000" d="M1192 284 c-17 -12 -22 -24 -20 -47 2 -26 10 -36 45 -52 49 -23 59
-55 17 -55 -14 0 -34 5 -45 10 -16 9 -19 7 -19 -13 0 -17 7 -27 23 -31 69 -18
117 6 117 60 0 32 -4 37 -45 55 -60 26 -62 54 -4 46 37 -5 40 -3 37 16 -2 18
-11 23 -43 25 -25 2 -49 -3 -63 -14z"></path>
</g>
</svg>

  </div>

  <ul class="nav sidebar-nav">
    <li><a href="../aws.html">AWS</a></li>
    <li><a href="../linux.html">Linux</a></li>
    <li><a href="../docker.html">Docker</a></li>
    <li><a href="../ibmpower.html">IBM Power</a></li>
    <li><a href="blogsataws1.html">Blogs@AWS (Kindle Friendly)</a></li>
  </ul>
</aside>


    <div class="container">
  <div class="row">
    <div id="docs-sidebar" class="col-sm-3 col-md-3 col-xs-12 hidden-print" role="complementary">
      <ul class="nav docs-sidenav">
      <li><a href="blogsataws1.html">Blogs @ AWS</a></li>
      <li><a href="whatsnew1.html">What's New @ AWS</a></li>
      <li><a href="secblogs1.html">Security Blogs @ AWS</a></li>
      <li><a href="computeblogs1.html">Compute Blogs @ AWS</a></li>
      <li><a href="apnblogs1.html">APN Blogs @ AWS</a></li>
      <li><a href="devopsblogs1.html">DevOps Blogs @ AWS</a></li>
      <li class="active"><a href="mgmtblogs1.html">Management Tools Blogs @ AWS</a></li>

    </ul>
    </div>

    <div id="inner" class="col-sm-9 col-md-9 col-xs-12" role="main">
<p></p>
<p><i>Contents of this page is copied directly from AWS blog sites to make it Kindle friendly. Some styles & sections from these pages are removed to render this properly in 'Article Mode' of Kindle e-Reader browser. All the contents of this page is property of AWS.</i></p>
<p><a href="mgmtblogs1.html">Page 1</a>|<a href="mgmtblogs2.html">Page 2</a>|<a href="mgmtblogs3.html">Page 3</a>|<a href="mgmtblogs4.html">Page 4</a></p>
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">The Virtues of YAML CloudFormation and Using CloudFormation Designer to Convert JSON to YAML</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Aaron Fagan</span></span> | on 
<time property="datePublished" datetime="2017-11-10T09:19:38+00:00">10 NOV 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/aws-cloudformation/" title="View all posts in AWS CloudFormation*"><span property="articleSection">AWS CloudFormation*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools*"><span property="articleSection">Management Tools*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/the-virtues-of-yaml-cloudformation-and-using-cloudformation-designer-to-convert-json-to-yaml/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><a href="https://aws.amazon.com/cloudformation/">AWS CloudFormation</a> provides the framework to define infrastructure-as-code in AWS and, until last year, this could only be written in JSON. However, in 2016, AWS added <a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/template-formats.html">YAML 1.1</a> support for CloudFormation. Let’s take a look at some of the advantages of using YAML over JSON, as well as how to overcome some of the challenges in getting started writing CloudFormation in YAML.</p> 
<h3>The virtues of YAML</h3> 
<p>YAML CloudFormation fully supports all of the same features and functions as JSON CloudFormation with some additional features to reduce the length of code and increase readability. Say goodbye to the curly braces and most of the quotation marks of JSON when you use YAML.&nbsp;YAML uses parent nodes, child nodes, and indentation to denote hierarchy rather than curly braces and commas as in JSON.</p> 
<p>YAML also supports comments using the # character. CloudFormation templates can get complex. Including key comments in the code can make it easier to understand, especially as teams get started with CloudFormation and develop templates together.</p> 
<p>Let’s look at a code sample. The following YAML and JSON CloudFormation templates perform the same function, they deploy an Amazon Linux EC2 instance serving a webpage via Apache HTTP Server.<span id="more-1918"></span></p> 
<h3>JSON template</h3> 
<code class="lang-json">{
&quot;AWSTemplateFormatVersion&quot;: &quot;2010-09-09&quot;,
&quot;Parameters&quot;: {
&quot;SubnetID&quot;: {
&quot;Type&quot;: &quot;AWS::EC2::Subnet::Id&quot;,
&quot;Description&quot;: &quot;Subnet to deploy EC2 instance into&quot;
},
&quot;SecurityGroupIDs&quot;: {
&quot;Type&quot;: &quot;List&lt;AWS::EC2::SecurityGroup::Id&gt;&quot;,
&quot;Description&quot;: &quot;List of Security Groups to add to EC2 instance&quot;
},
&quot;KeyName&quot;: {
&quot;Type&quot;: &quot;AWS::EC2::KeyPair::KeyName&quot;,
&quot;Description&quot;: &quot;Name of an existing EC2 KeyPair to enable SSH access to the instance&quot;
},
&quot;InstanceType&quot;: {
&quot;Description&quot;: &quot;EC2 instance type&quot;,
&quot;Type&quot;: &quot;String&quot;,
&quot;Default&quot;: &quot;t2.micro&quot;
}
},
&quot;Mappings&quot;: {
&quot;AWSRegionToAMI&quot;: {
&quot;us-east-1&quot;: {
&quot;AMIID&quot;: &quot;ami-0b33d91d&quot;
},
&quot;us-east-2&quot;: {
&quot;AMIID&quot;: &quot;ami-c55673a0&quot;
}
}
},
&quot;Resources&quot;: {
&quot;EC2Instance&quot;: {
&quot;Type&quot;: &quot;AWS::EC2::Instance&quot;,
&quot;Properties&quot;: {
&quot;ImageId&quot;: {
&quot;Fn::FindInMap&quot;: [
&quot;AWSRegionToAMI&quot;,
{
&quot;Ref&quot;: &quot;AWS::Region&quot;
},
&quot;AMIID&quot;
]
},
&quot;InstanceType&quot;: {
&quot;Ref&quot;: &quot;InstanceType&quot;
},
&quot;KeyName&quot;: {
&quot;Ref&quot;: &quot;KeyName&quot;
},
&quot;SecurityGroupIds&quot;: {
&quot;Ref&quot;: &quot;SecurityGroupIDs&quot;
},
&quot;SubnetId&quot;: {
&quot;Ref&quot;: &quot;SubnetID&quot;
},
&quot;UserData&quot;: {
&quot;Fn::Base64&quot;: {
&quot;Fn::Sub&quot;: &quot;#!/bin/bash -ex\nyum install -y httpd;\necho \&quot;&lt;html&gt;I love YAML CloudFormation!!&lt;/html&gt;\&quot; &gt; /var/www/html/index.html;\ncd /var/www/html;\nchmod 755 index.html;\nservice httpd start;\nchkconfig httpd on;\n&quot;
}
},
&quot;Tags&quot;: [
{
&quot;Key&quot;: &quot;Name&quot;,
&quot;Value&quot;: &quot;CloudFormation Test - YAML&quot;
},
{
&quot;Key&quot;: &quot;Environment&quot;,
&quot;Value&quot;: &quot;Development&quot;
}
]
}
}
}
}
</code> 
<img style="border: 0px;width: 32px;height: 32px;margin-right: 5px !important" src="https://aws-support-gm.s3.amazonaws.com/prod/tiny-url-shrinker/TinyURLShortener-icon-64x64.png" /> 
<h3 title="Shrink this URL">YAML template</h3> 
<code class="lang-yaml">AWSTemplateFormatVersion: 2010-09-09
Parameters:
SubnetID:
Type: AWS::EC2::Subnet::Id
Description: Subnet to deploy EC2 instance into
SecurityGroupIDs:
Type: List&lt;AWS::EC2::SecurityGroup::Id&gt;
Description: List of Security Groups to add to EC2 instance
KeyName:
Type: AWS::EC2::KeyPair::KeyName
Description: &gt;-
Name of an existing EC2 KeyPair to enable SSH access to the instance
InstanceType:
Description: EC2 instance type
Type: String
Default: t2.micro
Mappings:
AWSRegionToAMI:
us-east-1:
AMIID: ami-0b33d91d
us-east-2:
AMIID: ami-c55673a0
Resources:
EC2Instance:
Type: AWS::EC2::Instance                     
Properties:
ImageId:
!FindInMap                                 # This is an example of the short form YAML FindInMap function
- AWSRegionToAMI                         # It accepts three parameters each denoted by a hyphen (-)
- !Ref AWS::Region
- AMIID
InstanceType: !Ref InstanceType
KeyName: !Ref KeyName
SecurityGroupIds: !Ref SecurityGroupIDs
SubnetId: !Ref SubnetID
UserData:
Fn::Base64:                                # YAML makes userdata much cleaner
!Sub |
#!/bin/bash -ex
yum install -y httpd;
echo &quot;&lt;html&gt;I love YAML CloudFormation!!&lt;/html&gt;&quot; &gt; /var/www/html/index.html;
cd /var/www/html;
chmod 755 index.html;
service httpd start;
chkconfig httpd on;
Tags:                                      # Tags are an example of a sequence of mappings in YAML,
-                                        # each key/value pair is separated by a hyphen
Key: Name
Value: CloudFormation Test - YAML      
-
Key: Environment
Value: Development
</code> 
<p>From a readability perspective, it’s pretty clear YAML is the winner. The JSON template is 1200 characters with whitespace removed. The YAML template is 972 characters for the exact same functionality with whitespace and comments removed. Shorter templates are not only more readable and make troubleshooting errors easier, but they also allow more resources to be deployed in a single template without hitting <a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/cloudformation-limits.html">CloudFormation limits</a> for template body size.</p> 
<h3>Converting a JSON CloudFormation template to YAML</h3> 
<p>We’ve established there are some advantages to using YAML, but many organizations already have libraries of JSON-formatted CloudFormation templates and employees with expertise writing JSON. Additionally, many publically available code samples are written in JSON along with many <a href="https://aws.amazon.com/quickstart/">AWS QuickStarts</a>. If only there were an easy, secure way to convert JSON CloudFormation to YAML. Old JSON templates could be reused and public samples could be converted to make learning YAML easier.</p> 
<p>Enter <a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/working-with-templates-cfn-designer.html">CloudFormation Designer</a></p> 
<p>CloudFormation Designer is an easy-to-use graphical user interface to create, edit, and view CloudFormation templates. The Designer is free and is part of the AWS Management Console. One fantastic feature is the ability to convert CloudFormation templates from JSON to YAML, and back again, with the click of a button. There are other online converters out there but the Designer is part of your AWS Management Console, so the code never leaves your possession.</p> 
<p>&nbsp;</p> 
<p>Let’s convert our JSON template to YAML:</p> 
<p>1. Open the AWS Management Console and navigate to the <strong>CloudFormation service</strong>.</p> 
<p>2. Choose the <strong>Design template</strong> button to open the Designer.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/02/step2.png" /></p> 
<p>&nbsp;</p> 
<p>3. Open the JSON CloudFormation template by choosing the File icon, then choosing <strong>Open</strong> from the menu.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/02/step3.png" /></p> 
<p>&nbsp;</p> 
<p>4. <strong>Select the file</strong>, either a local file on your workstation or a file in an Amazon S3 bucket. This opens the CloudFormation template in Designer. We see the familiar JSON code of our template in the bottom pane. In the upper-right pane, we see a graphical representation of the EC2 instance described in our template. Finally, in the upper-left pane, we can optionally drag and drop a variety of Resource Types onto the canvas to include them in our template.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/02/step4.png" /></p> 
<p>&nbsp;</p> 
<p>5. In the upper right-hand corner of the code pane, note the <strong>Choose template language</strong> radio button. Choose the button next to YAML to convert the template to YAML. Just like that our JSON is perfectly formatted YAML. Choosing the JSON button will convert the template back to JSON.</p> 
<p>Caution: <em>Converting a commented YAML template to JSON will remove all comments. Comments will not re-appear if the template is toggled back to YAML</em>.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/02/step51.png" /></p> 
<p>&nbsp;</p> 
<p>6. <strong>Save</strong> the template in YAML format by once again choosing the File icon and choosing Save from the menu.</p> 
<p style="text-align: center"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/03/step61-1.png" /></p> 
<h3>Conclusion</h3> 
<p>In this blog post, we discussed some reasons to convert CloudFormation templates from JSON to YAML format and to code in YAML. We also did a side-by-side comparison of the readability of JSON and YAML using a sample template. Finally, we walked through how to convert existing JSON CloudFormation templates to YAML using CloudFormation Designer. There’s no better time than the present to dive in and get started with CloudFormation YAML. Happy coding!</p> 
<hr /> 
<h3>About the Author</h3> 
<p style="text-align: left"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/02/badgephotobw-200x300.jpg" />Aaron Fagan is a Senior Cloud Infrastructure Architect on the Boston AWS Professional Services team where he works with Enterprises to accelerate and optimize their adoption of the AWS public cloud. When not coding CloudFormation in YAML, he enjoys weightlifting and cooking.</p> 
<img style="border: 0px;width: 32px;height: 32px;margin-right: 5px !important" src="https://aws-support-gm.s3.amazonaws.com/prod/tiny-url-shrinker/TinyURLShortener-icon-64x64.png" /> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">Controlling Projected User Costs Through Monthly Budget Policies</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Adam Westrich</span></span> | on 
<time property="datePublished" datetime="2017-11-06T16:10:43+00:00">06 NOV 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/mt/category/aws-cost-management/" title="View all posts in AWS Cost Management*"><span property="articleSection">AWS Cost Management*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/compute/aws-lambda/" title="View all posts in AWS Lambda*"><span property="articleSection">AWS Lambda*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools*"><span property="articleSection">Management Tools*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/controlling-projected-user-costs-through-monthly-budget-policies/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<h3 style="text-align: left">Introduction</h3> 
<p>With the announcement of our new AWS Price List Query APIs, let’s discuss a use-case that you can deploy directly to your AWS account. Customers often ask for ways to proactively control costs while having the flexibility to experiment with different AWS resource sizes and types. The solution we’ll discuss in this blog post gives you the ability to project monthly <a href="https://aws.amazon.com/ec2/">Amazon EC2</a> costs for individual Identity and Access Management (IAM) users and receive alerts when user projected costs exceed their configured thresholds. You can deploy this solution to your AWS account using <a href="https://aws.amazon.com/cloudformation/">AWS CloudFormation</a>&nbsp;below.</p> 
<p>When a user launches or starts EC2 instances, the solution calculates the projected monthly cost using the Price List Query API, and aggregates those costs for each AWS user. Likewise, when a user stops or terminates instances, the user’s projected cost is reduced. The solution also allows user budget targets to be set, which gives Operational Management the ability to intervene when projected thresholds are exceeded before the actual monthly costs are accrued.</p> 
<p><span id="more-1745"></span></p> 
<h3>Architecture</h3> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/blog_westrich_1-1.png" /></p> 
<h3>Walkthrough</h3> 
<ol> 
<li>When a user launches an EC2 instance, user and launch details are logged in <a href="https://aws.amazon.com/cloudtrail/">AWS CloudTrail</a>, which triggers an <a href="http://docs.aws.amazon.com/AmazonCloudWatch/latest/events/LogEC2InstanceState.html">Amazon CloudWatch event</a>.</li> 
<li>The CloudWatch event triggers a <a href="https://aws.amazon.com/lambda/">Lambda function</a>, which performs three&nbsp;tasks: 
<li>Calls the AWS Price List Query API to retrieve the price of EC2 instance on which action was taken.</li> 
<li>Based on event type (Launch/Start or Stop/Terminate), edits the <a href="https://aws.amazon.com/dynamodb/">DynamoDB</a> table with new price based upon the continued projection for the month.</li> 
<li>Sends a trigger to another Lambda function which will check for a policy breach.</li> 
</ul> </li> 
<li>The policy breach Lambda function checks if the user in the DynamoDB table has breached the budgeted&nbsp;threshold 
<li style="text-align: left">If the budget threshold is breached, the Lambda function generates an Amazon SNS notification to email alert the IT operations team.</li> 
</ul> </li> 
</ol> 
<p>Here is an example of the notification email sent to stakeholders:</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/blog_westrich_2.png" /></p> 
<p>The AWS Price List API makes this process easy to obtain accurate EC2 price information.</p> 
<p>The following CloudFormation templates below can be deployed in your environment with CloudTrail enabled by simply filling in a few parameters:</p> 
<table align="center"> 
<tbody> 
<tr> 
<td><strong>Region</strong></td> 
<td style="text-align: center"><strong>Launch Template</strong></td> 
</tr> 
<tr> 
<td><strong>N. Virginia&nbsp;</strong>(us-east-1)</td> 
<td><a href="https://console.aws.amazon.com/cloudformation/home?region=us-east-1#/stacks/new?stackName=UserCostControl&amp;templateURL=https://s3.us-east-1.amazonaws.com/cost-control-us-east-1/cost_control_v1.yaml"><strong><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/blog_westrich_5.png" /></strong></a></td> 
</tr> 
<tr> 
<td><strong>Ohio&nbsp;</strong>(us-east-2)</td> 
<td><a href="https://console.aws.amazon.com/cloudformation/home?region=us-east-2#/stacks/new?stackName=UserCostControl&amp;templateURL=https://s3.us-east-2.amazonaws.com/cost-control-us-east-2/cost_control_v1.yaml"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/blog_westrich_5.png" /></a></td> 
</tr> 
<tr> 
<td><strong>Oregon&nbsp;</strong>(us-west-2)</td> 
<td><a href="https://console.aws.amazon.com/cloudformation/home?region=us-west-2#/stacks/new?stackName=UserCostControl&amp;templateURL=https://s3.us-west-2.amazonaws.com/cost-control-us-west-2/cost_control_v1.yaml"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/blog_westrich_5.png" /></a></td> 
</tr> 
<tr> 
<td><strong>Asia Pacific – Mumbai</strong> (ap-south-1)</td> 
<td><a href="https://console.aws.amazon.com/cloudformation/home?region=ap-south-1#/stacks/new?stackName=UserCostControl&amp;templateURL=https://s3.ap-south-1.amazonaws.com/cost-control-ap-south-1/cost_control_v1.yaml"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/blog_westrich_5.png" /></a></td> 
</tr> 
<tr> 
<td><strong>Asia Pacific – Sydney</strong> (ap-southeast-2)</td> 
<td><a href="https://console.aws.amazon.com/cloudformation/home?region=ap-southeast-2#/stacks/new?stackName=UserCostControl&amp;templateURL=https://s3.ap-southeast-2.amazonaws.com/cost-control-ap-southeast-2/cost_control_v1.yaml"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/blog_westrich_5.png" /></a></td> 
</tr> 
<tr> 
<td><strong>Asia Pacific – Tokyo</strong> (ap-northeast-1)</td> 
<td><a href="https://console.aws.amazon.com/cloudformation/home?region=ap-northeast-1#/stacks/new?stackName=UserCostControl&amp;templateURL=https://s3.ap-northeast-1.amazonaws.com/cost-control-ap-northeast-1/cost_control_v1.yaml"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/blog_westrich_5.png" /></a></td> 
</tr> 
<tr> 
<td><strong>EU – Ireland</strong> (eu-west-1)</td> 
<td><a href="https://console.aws.amazon.com/cloudformation/home?region=eu-west-1#/stacks/new?stackName=UserCostControl&amp;templateURL=https://s3.eu-west-1.amazonaws.com/cost-control-eu-west-1/cost_control_v1.yaml"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/blog_westrich_5.png" /></a></td> 
</tr> 
<tr> 
<td><strong>EU – London </strong>(eu-west-2)</td> 
<td><a href="https://console.aws.amazon.com/cloudformation/home?region=eu-west-2#/stacks/new?stackName=UserCostControl&amp;templateURL=https://s3.eu-west-2.amazonaws.com/cost-control-eu-west-2/cost_control_v1.yaml"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/blog_westrich_5.png" /></a></td> 
</tr> 
</tbody> 
</table> 
<h4>Notes:</h4> 
<li>This solution should be used as an addition to the AWS Billing and Cost Management tools. The solution calculations are based upon on-demand EC2 costs per second for non-Windows operating systems and per hour for Windows operating systems. They don’t include instances with pre-installed software or AWS Marketplace software licenses.</li> 
<li>The monthly cost of the AWS resources to deploy this cost-control solution&nbsp;is in most scenarios, &lt; $5.</li> 
<li>These projections are only estimates, and monthly charges will be based on your actual usage of AWS services, and may vary from the projections provided.</li> 
<h3>Conclusion</h3> 
<p>As organizations are given freedoms to experiment with computing resources in the AWS cloud, they often need governance controls for an effective solution. The AWS Management Tools and partner ecosystem enable you to deploy or even build the right governance solution for your organization’s needs.</p> 
<h3>About the Author:</h3> 
<table> 
<tbody> 
<tr> 
<td><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/31/blog_westrich_4.png" /></td> 
<td>Adam Westrich is a Solutions Architect based in Southern California. He is passionate about working with customers on their AWS Cloud journey, especially leveraging AWS managed services, including serverless technologies.</td> 
</tr> 
</tbody> 
</table> 
<p><em>Thank you to Shashi Prabhakar for his contributions to this post.</em></p> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">Run Scripts Stored in Private or Public GitHub Repositories Using Amazon EC2 Systems Manager</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Ananth Vaidyanathan</span></span> | on 
<time property="datePublished" datetime="2017-11-06T09:28:29+00:00">06 NOV 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/amazon-ec2-systems-manager/" title="View all posts in Amazon EC2 Systems Manager*"><span property="articleSection">Amazon EC2 Systems Manager*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools*"><span property="articleSection">Management Tools*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/run-scripts-stored-in-private-or-public-github-repositories-using-amazon-ec2-systems-manager/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><em>By Melonia Mendonca, Software Development Engineer at Amazon Web Services</em></p> 
<p><a href="https://aws.amazon.com/ec2/systems-manager/">Amazon EC2 Systems Manager</a> (SSM) lets you configure, manage and automate your AWS and on-premises resources at scale. You can perform safe and secure operations without SSH access or bastion hosts using Systems Manager Run Command, mitigate configuration drift using Systems Manager State Manager, and create an access-controlled environment with full auditing. With SSM Documents, you can author your configurations as code and enable centralized management across accounts, enforcing best practices. Systems Manger provides a number of public documents for common management scenarios, or you can create your own.</p> 
<p>We recently <a href="https://aws.amazon.com/about-aws/whats-new/2017/10/amazon-ec2-systems-manager-now-integrates-with-github/">announced</a> the ability to run scripts from remote locations such as GitHub or Amazon S3. This simplifies how you automate environments by letting you use existing scripts or toolsets without having to port them over to Systems Manager or create Documents as wrapper around those scripts or tools. For information, please read our partner and product integration documentation <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/systems-manager-integration.html">here</a>. &nbsp;For example, you can:</p> 
<li><span style="text-decoration: underline">Execute various types of scripts</span> written in Python, Ruby or PowerShell. You can also run configurations such as Ansible playbooks. You can pretty much run anything on your instances as long as the software (e.g., Python 2.7 or Ansible) is installed on your instance and recognized by Shell on Linux and PowerShell on Windows</li> 
<li><span style="text-decoration: underline">Download scripts</span> stored in private or public GitHub repositories, or on Amazon S3 onto your instances for execution</li> 
<li><span style="text-decoration: underline">Run multiple files</span> by downloading a complete GitHub directory or an S3 bucket</li> 
<p><span id="more-1905"></span></p> 
<p>Systems Manager now provides a new public Document, <strong>AWS-RunRemoteScript</strong> that runs scripts from GitHub or Amazon S3 on specified instances. It does this using the new plugin from <a href="https://github.com/aws/amazon-ssm-agent">Amazon SSM Agent</a>, <a href="https://docs.aws.amazon.com/systems-manager/latest/userguide/ssm-plugins.html#aws-downloadContent">aws:downloadContent</a>, which downloads content from locations such as public or private GitHub repositories, S3 buckets, and Documents already created on SSM. If you create your own documents, you can use the <strong>aws:downloadContent</strong> plugin, and the existing <a href="https://docs.aws.amazon.com/systems-manager/latest/userguide/ssm-plugins.html#aws-runShellScript"><strong>aws:runShellScript</strong></a> (on Linux) or<a href="https://docs.aws.amazon.com/systems-manager/latest/userguide/ssm-plugins.html#aws-runPowerShellScript"><strong> aws:runPowerShellScript</strong></a> (on Windows) to execute the scripts.</p> 
<p>In this blog post, I’ll show you how to run an Ansible playbook located in a public or private GitHub repository using the AWS-RunRemoteScript Document. This lets you run Ansible from an external location without requiring SSH access on your instances.</p> 
<h3>Walkthrough 1 – Run an Ansible playbook from a public GitHub repository</h3> 
<p><strong>Pre-requisites</strong></p> 
<p>We will run an Ansible playbook that installs and configures NGINX from a GitHub public repository. The playbook is expressed in server.yml and this main playbook calls the nginx role.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/02/playbook.png" /></p> 
<p>Before you get started, ensure you have reviewed the Ansible license and then install it on your instances. You can install Ansible using Run Command with the commands below:</p> 
<p>Amazon Linux:</p> 
<code class="lang-bash">sudo pip install ansible</code> 
<p>Ubuntu:</p> 
<code class="lang-bash">sudo apt-get install ansible –y</code> 
<p><strong>Step 1: Find the AWS-RunRemoteScript document for execution</strong></p> 
<p>On the EC2 console, on the navigation pane at the left, under Systems Manager Services, choose <strong>Run Command</strong>. Choose <strong>Run a Command</strong>, and then select the AWS-RunRemoteScript document and the instances you want to execute this document on (whether a list of instances or tag-queries).</p> 
<p><strong>Step 2: Reference the Ansible playbook located on GitHub</strong></p> 
<p>Enter the parameters for the AWS-RunRemoteScript Document to reference the Ansible playbook.</p> 
<li><span style="text-decoration: underline">Source Type</span>: Location of the script – GitHub, S3. In this case, choose GitHub.</li> 
<li><span style="text-decoration: underline">Source Info</span>: Provides location information for accessing the content. &nbsp;In this example, since the repository is public, you only need to provide the owner, repository and the path to the playbook. The playbook needs to access the nginx directory shown in the structure that follows. So we’ll download the entire directory, which includes server.yml and the nginx directory.</li> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/02/github-structure.png" /></p> 
<li><span style="text-decoration: underline">Command Line</span>: The command needed to execute the playbook</li> 
<p>When you are done, the console will look like this:</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/02/console-string-map.png" /></p> 
<p><strong>Step 3: Run the command</strong></p> 
<p>Because you referenced the top-level directory, Systems Manager downloads all the playbook YAML scripts inside the nginx directory as well as the server.yml and user-data.sh files. The server.yml is then executed based on command line parameters, which then installs and configures NGINX.</p> 
<p>You can then view the output and see that NGINX was installed on the specified instances.</p> 
<p>&nbsp;</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/02/public-output.png" /></p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/02/public-script-ouput.png" /></p> 
<p>You can also perform this operation using the AWS CLI by running the following command:</p> 
<code class="lang-bash">aws ssm send-command --document-name &quot;AWS-RunRemoteScript&quot; --parameters '{&quot;sourceType&quot;:[&quot;GitHub&quot;],&quot;sourceInfo&quot;:[&quot;{\&quot;owner\&quot; : \&quot;owner-name\&quot;, \&quot;repository\&quot;:\&quot;repository-name\&quot;, \&quot;path\&quot;:\&quot;path/to/directory\&quot;}&quot;], &quot;commandLine&quot;:[&quot;ansible-playbook -i \&quot;localhost,\&quot; --check -c local server.yml&quot;]}'</code> 
<h3>Walkthrough 2 – Run Ansible playbook from private GitHub repository</h3> 
<p>Now, I’ll show you how to execute scripts from private GitHub repositories. Let’s assume that the playbook in the previous example is stored in a private GitHub repository. To access this playbook, you need to create a private access token on GitHub and store it in Amazon EC2 Systems Manager Parameter Store.</p> 
<p><strong>Step 1: Create your GitHub personal access token</strong></p> 
<p>Create a personal access token for your private GitHub repo to give Systems Manager access to the playbook. <a href="https://github.com/blog/1509-personal-api-tokens">Personal API tokens</a> are a way to provide access to systems to access information from your private GitHub repository. These tokens provide limited access to a subset of repository data as well as the ability to revoke access when needed. You can create a personal access token from information provided <a href="https://help.github.com/articles/creating-a-personal-access-token-for-the-command-line/">here</a> and then save the token value.</p> 
<p><strong>Step 2: Store the tokens in Parameter Store</strong></p> 
<p>After creating the personal access token, go to Parameter Store on the EC2 console. On the Parameter Store page, create a parameter and add the token you created on GitHub here, in the Value text box.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/02/create-parameter.png" /></p> 
<p>If you have an AWS Key Management Service (KMS) key ID, you can add this key ID in the <strong>KMS Key ID</strong> text box. &nbsp;After this, choose <strong>Create Parameter</strong>. You can also perform this operation using the AWS CLI, as follows:</p> 
<code class="lang-bash">aws ssm put-parameter --name example-token --value xxxxxxx --type SecureString</code> 
<p><strong>Step 3: Reference the Ansible playbook located on GitHub</strong></p> 
<p>Along with owner, repository and path, we will add “tokenInfo” that refers to the example-token secure string parameter that we just created. The reference is made using the <strong>ssm-secure</strong> prefix.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/02/stringmap-private.png" /></p> 
<p><strong>Step 3: Run the command</strong></p> 
<p>This command will use the personal access token to access your private GitHub repository. Everything else is the same as if you were to run the playbook from a public GitHub repository.</p> 
<p>You can also perform this operation using the AWS CLI:</p> 
<code class="lang-bash">aws ssm send-command --document-name &quot;AWS-RunRemoteScript&quot; --parameters '{&quot;sourceType&quot;:[&quot;GitHub&quot;],&quot;sourceInfo&quot;:[&quot;{\&quot;owner\&quot; : \&quot;owner-name\&quot;, \&quot;repository\&quot;:\&quot;repository-name\&quot;,\&quot;path\&quot;:\&quot;path/to/directory\&quot;,\&quot;tokenInfo\&quot; : \&quot;{{ssm-secure:example-token}}\&quot;}&quot;],&quot;commandLine&quot;:[&quot;ansible-playbook -i \&quot;localhost,\&quot; --check -c local server.yml&quot;]}' </code> 
<h3>Conclusion</h3> 
<p>In this blog post, I showed you how EC2 Systems Manager is a management platform that lets you use your existing tools to manage your AWS resources and environments. I showed you how to use Systems Manager to run an Ansible playbook on your EC2 instances from a public and private GitHub repository. Using the AWS-RunRemoteScript public document or the aws:downloadContent and aws:runShellScript plugins, you can run any script such as Python, Ruby, or even PowerShell scripts or modules. In a subsequent blogpost, I’ll show you how to enable modular and reusable configurations using composite Documents.</p> 
<h3>About the Author</h3> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/02/melonia.jpg" />Melonia Mendonca is a Software Development Engineer with the Amazon EC2 Systems Manager team. She is a passionate engineer who enjoys the ability to innovate encouraged by Amazon. Outside of work, Melonia likes traveling, playing board games and trying different restaurants/cuisines.</p> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">AWS OpsWorks for Chef Automate Now Supports Compliance</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Rahul Gulati</span></span> | on 
<time property="datePublished" datetime="2017-11-06T08:19:50+00:00">06 NOV 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/aws-ops-works/" title="View all posts in AWS OpsWorks*"><span property="articleSection">AWS OpsWorks*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools*"><span property="articleSection">Management Tools*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/aws-opsworks-for-chef-automate-now-supports-compliance/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p>AWS OpsWorks&nbsp;for Chef Automate gives you a fully managed Chef server with a suite of automation tools. &nbsp;The release of Chef Automate version 1.6 includes the new <a href="https://blog.chef.io/2017/07/05/chef-automate-release-july-2017/">Compliance view</a> for Chef Automate UI. With AWS OpsWorks for Chef Automate integrated with compliance, you can track the compliance of your infrastructure based on a predefined policy. This allows you to frequently audit your applications for vulnerabilities and remediate violations.</p> 
<p><span id="more-1957"></span></p> 
<p><span style="text-decoration: underline">Use cases and benefits</span></p> 
<p>With this update, you can detect and correct security risks and compliance issues across your entire infrastructure.</p> 
<li>Move from manual compliance to <a href="https://learn.chef.io/tracks/compliance-automation#/">continuous compliance</a> by frequently conducting assessments and managing compliance as code. This means that you can bake compliance into your Chef workflow.</li> 
<li>Select from 88 pre-packaged profiles that meet industry benchmarks, available in Profile Store. Further, you can customize these profiles to fulfill your information security needs.</li> 
<li>Use the <strong>Compliance</strong> pane, which offers a unified dashboard for identifying issues, remediating them, and tracking progress. In addition, you can view <strong>Scan Results</strong> for various Nodes and Profiles.</li> 
<li>Describe compliance controls in InSpec, an open-source testing framework, and integrate these automated tests into any stage of your deployment pipeline.</li> 
<p>To get started, go to the AWS Management Console, and open the OpsWorks console. On the AWS OpsWorks Stacks home page, choose <strong>Go to OpsWorks for Chef Automate</strong>. &nbsp;Then choose <strong>Compliance</strong>. In the left navigation pane, choose <strong>Profile Store</strong>. Then, in the <strong>Available</strong> tab, select a profile such as <a href="https://github.com/dev-sec/ssh-baseline/">DevSec SSH Baseline</a>, and choose <strong>Get</strong> to install.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/03/Screen-Shot-2017-10-22-at-7.03.34-PM.png" /></p> 
<p>On the profile details page, you can view a brief profile description, set of controls, and their severity. Choose <strong>+</strong> to see the expected outcome of a control and code that it executes.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/03/Screen-Shot-2017-10-22-at-7.07.34-PM.png" /></p> 
<p>After it’s installed, configure the <a href="https://supermarket.chef.io/cookbooks/audit">Audit Cookbook</a> with the compliance profile you selected in the previous step. Add the recipe to your node’s run list.</p> 
<p>After the node’s run list is executed with audit attributes set as expected, you can see the profile status on the <strong>Compliance</strong> page.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/03/Screen-Shot-2017-10-22-at-9.31.17-PM.png" /></p> 
<p>Go to the <strong>Profiles</strong> tab, choose <strong>Scan Results</strong>, and select a node to find each failed control with details of what failed within that control. This means you can view the expected and actual outcome of each failed test. With this information, you can reconfigure the nodes to ensure that all test cases pass and a rerun is successful.</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/11/03/Screen-Shot-2017-10-22-at-9.39.26-PM.png" /></p> 
<p>This update is now generally available and you can start using it today. With OpsWorks for Chef Automate, you pay for the Amazon EC2 instance used to run your managed Chef server (<a href="https://aws.amazon.com/opsworks/chefautomate/pricing/">pricing details here</a>). You can launch OpsWorks for Chef Automate today in the following AWS Regions: US East (Northern Virginia), US West (Oregon), and EU (Ireland). To learn more, read <a href="http://docs.aws.amazon.com/opsworks/latest/userguide/opscm-starterkit.html">Configure the Chef Server Using the Starter Kit</a> in the OpsWorks User Guide.</p> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">Upgrading SQL Server Using EC2 Systems Manager</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Ananth Vaidyanathan</span></span> | on 
<time property="datePublished" datetime="2017-11-01T12:55:40+00:00">01 NOV 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/amazon-ec2-systems-manager/" title="View all posts in Amazon EC2 Systems Manager*"><span property="articleSection">Amazon EC2 Systems Manager*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools*"><span property="articleSection">Management Tools*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/upgrading-sql-server-using-ec2-systems-manager/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><em>This post was written by Alan Cranfield, Systems Engineer at Amazon Web Services</em></p> 
<p>This is the first in a series of blog posts aimed at the enterprise SQL Server DBA. I’ll demonstrate how to administer your SQL Server workloads on Amazon EC2 using practical examples and best practices.</p> 
<h3>Using Run Command</h3> 
<p>In this post I’ll show you how to use <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/execute-remote-commands.html">Run Command</a> from <a href="https://aws.amazon.com/ec2/systems-manager">Amazon EC2 Systems Manager</a> to update one or many of your SQL Servers to the latest service pack.</p> 
<p>Microsoft SQL Server is a popular workload on Amazon EC2. Keeping your SQL Server instances up to date with the latest service pack is important for the stability and security of your critical data. If you need to support multiple versions and editions of SQL Server keeping track of all the latest service packs can be cumbersome.</p> 
<p>Run Command provides a simple and secure way to remotely execute commands or run scripts against EC2 instances or on-premises servers.&nbsp;With Run Command, you can perform commands that make it easy to accomplish common administrative tasks like upgrading SQL service packs!</p> 
<p><span id="more-1694"></span></p> 
<h3>Pre-requisites</h3> 
<p>When you use EC2 Systems Manager you’ll need to first work through some <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/systems-manager-setting-up.html">prerequisites</a>. The most important prerequisite is that you’ll need the SSM agent installed on your instances. The <a href="http://docs.aws.amazon.com/systems-manager/latest/userguide/ssm-agent.html#sysman-install-ssm-win">SSM agent</a> is installed by default on Windows Server 2016 instances and instances created from Windows Server 2003-2012 R2 Amazon Machine Images (AMIs) published in November 2016 or later.</p> 
<p>Another pre-requisite is that your instances need to be assigned an AWS Identity and Access Management (IAM) role. The IAM role is used to secure the permission policies needed to communicate with the Systems Manager API. Instances are usually added to an IAM role on launch, but you can also add existing instances using the <a href="https://aws.amazon.com/blogs/security/new-attach-an-aws-iam-role-to-an-existing-amazon-ec2-instance-by-using-the-aws-cli/?sc_channel=sm&amp;sc_campaign=rolesforrunninginstances&amp;sc_publisher=tw&amp;sc_medium=social&amp;sc_content=read-post&amp;sc_country=global&amp;sc_geo=global&amp;sc_category=ec2&amp;sc_outcome=launch">AWS CLI</a>.</p> 
<h3>Using PowerShell modules</h3> 
<p>For this exercise we’ll use the Run Command native support for PowerShell modules to download and import a PowerShell module from an Amazon S3 bucket. This module will be called to identify the version of SQL that is running and then download and install the latest service pack. I’ll walk you through updating the SQL service pack by using the AWS Management Console and by using AWS Tools for PowerShell.</p> 
<h3>Updating the SQL service pack from the EC2 console</h3> 
<li>Sign In to the AWS Management Console. To confirm that your instances are in a state to be managed, make sure they are listed in the EC2 console under EC2 Dashboard\Managed Instances.</li> 
<li>Navigate to the Run Command and choose Run a command. Then select the AWS-InstallPowershellModule document, and the servers you’d like to upgrade.<img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/27/install-ps-module.png" /></li> 
<li>For Source enter the location of the S3 bucket that holds the PowerShell module: <a href="https://s3.amazonaws.com/sql-service-pack/InstallSqlServicePack.zip">https://s3.amazonaws.com/sql-service-pack/InstallSqlServicePack.zip</a></li> 
<li>Paste the following PowerShell script into the Commands Window 
<code class="lang-powershell">Set-ExecutionPolicy -ExecutionPolicy Unrestricted -Force
Import-Module InstallSqlServicePack
Install-SQLUpdate -Action &quot;Yes&quot;</code> 
<li>Choose the <strong>Run</strong> button and check the <strong>Status</strong> column for the instance progress.<img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/27/command-success.png" /></li> 
<li>Choose a specific Instance ID in the top pane, and then in the bottom pane choose the Output tab and then choose View Output.</li> 
<li>The results of the service pack upgrade are shown in the Output results window.<img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/27/output.png" /></li> 
<h3>Updating the SQL service pack using the AWS Tools for PowerShell</h3> 
<p>For those who prefer a scripted solution you can call Run Command using the <a href="http://docs.aws.amazon.com/powershell/latest/userguide/pstools-getting-set-up.html">AWS Tools for Windows PowerShell</a>.</p> 
<li>Download and install the latest AWS Tools for Windows PowerShell.</li> 
<code class="lang-powershell">$AWSPSURL = &quot;http://sdk-for-net.amazonwebservices.com/latest/AWSToolsAndSDKForNet.msi&quot; 
$AWSPSSetup = &quot;C:\Windows\Temp\AWSPowerShellSetup.msi&quot;
(New-Object System.Net.WebClient).DownloadFile($AWSPSURL, $AWSPSSetup)
Start-Process -FilePath msiexec.exe -Argument List &quot;/i $AWSPSSetup&quot;
Remove-Item $AWSPSSetup -Force</code> 
<li>Set your credentials and AWS Region</li> 
<code class="lang-powershell"># set credentials
Set-AWSCredentials -StoreAs SQL -AccessKey &lt;your access key&gt; -SecretKey &lt;your secret key&gt;
Set-AWSCredentials -ProfileName SQL
Set-DefaultAWSRegion &quot;us-west-2&quot; 
Get-IAMUser</code> 
<li>Confirm that your instances are managed by SSM</li> 
<p><code class="lang-powershell">Get-SSMInstanceInformation -InstanceInformationFilterList @{Key=&quot;PingStatus&quot;;ValueSet=&quot;Online&quot;} | select ComputerName, InstanceId<br /> </code></p> 
<li>Run a Command against your instances to upgrade the SQL service pack. (Tagging can also be used to group servers.)</li> 
<code class="lang-powershell"></code><code class="lang-powershell">$InstanceIds = (Get-SSMInstanceInformation).InstanceId
$InstanceIds.count
$source = 'https://s3.amazonaws.com/sql-service-pack/InstallSqlServicePack.zip'
$commands = @(
'Set-ExecutionPolicy -ExecutionPolicy Unrestricted -Force',
'Import-Module InstallSqlServicePack',
'Install-SQLUpdate -Action &quot;Yes&quot;'
)
$parameter = @{
source = $source;
commands = $commands;
}
$document = 'AWS-InstallPowerShellModule'
$cmd = Send-SSMCommand –InstanceId $InstanceIds –DocumentName $document –Parameter $parameter </code> 
<li>Check the progress.</li> 
<code class="lang-powershell">Get-SSMCommandInvocation -CommandId $cmd.CommandId -Details $true | select InstanceId, status </code> 
<code class="lang-powershell">InstanceId          Status    
----------          ------    
i-0fff59f73e94a0449 InProgress
i-0f1f7afc2b605b4d1 Success   
i-0ee0c157a87ede81f InProgress
i-0daa300d38d9c42b1 InProgress
i-0b861190458f9381f InProgress
i-09dc29e6a093ac14c InProgress
i-09aee29b50203cf3c Success
</code> 
<li>Check the results.</li> 
<p><code class="lang-powershell">Get-SSMCommandInvocation -CommandId $cmd.CommandId -Details $true | select -ExpandProperty CommandPlugins</code></p> 
<p><code class="lang-powershell">== Install SQL Update ==<br /> </code></p> 
<code class="lang-powershell">2017-08-18 23:54:38.760 Test-SQLInstallation
2017-08-18 23:54:38.856 - SQL server service is installed and started
2017-08-18 23:54:38.866 - Importing SQLPS Module
2017-08-18 23:54:41.048 Check if Clustered
2017-08-18 23:54:41.227 - Not Clustered
2017-08-18 23:54:41.232 Get-InstallableUpdate
2017-08-18 23:54:41.245 - Read current installed version...
2017-08-18 23:54:41.254 - Found Microsoft SQL Server 2016 (RTM-CU3-GDR) (KB3194717) - 13.0.2186.6 (RTM)
2017-08-18 23:54:41.275 - Looking for latest Service Pack...
2017-08-18 23:54:41.351 - Found Microsoft SQL Server 2016 - 13.0.4001.0 (SP1)
2017-08-18 23:54:41.359 Test-DownloadDestinationFolder
2017-08-18 23:54:41.377 - Get disk information on C: drive
2017-08-18 23:54:41.400 - Free space is 27 GB
2017-08-18 23:54:41.410 - Destination folder C:\Windows\temp was successfully created.
2017-08-18 23:54:41.415 Downloading Microsoft SQL Server 2016 - 13.0.4001.0 (SP1) from Microsoft...
2017-08-18 23:54:49.100 - Downloading Update bits completed
2017-08-18 23:54:49.106 Installing Microsoft SQL Server 2016 - 13.0.4001.0 (SP1)
2017-08-18 23:59:01.504 - Installing Microsoft SQL Server 2016 - 13.0.4001.0 (SP1) Completed
2017-08-18 23:59:01.510 Verify SQL version after update
2017-08-18 23:59:01.525 - Version after update 13.0.4001.0
2017-08-18 23:59:01.530 Update Successful!</code> 
<h3>Conclusion</h3> 
<p>Amazon EC2 Systems Manager offers a suite of tools to help you manage both your EC2 and on-premises SQL Server instances. In this post, I showed you how to use the Run Command feature of Systems Manager to easily upgrade SQL Server to the latest service pack.</p> 
<p>In a critical production environment, when you upgrade you might have extra steps to perform before and after, such as database backups, failovers, failbacks, etc. So, in the next post I’ll show you how to use the Automation feature of Systems Manager to achieve custom maintenance workflows.</p> 
<h3>About the Author</h3> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/28/alan_cranfield.jpg" />Alan Cranfield is a Senior Systems Engineer on the EC2 Windows team where he uses his extensive experience managing critical enterprise environments to help make AWS the best cloud platform for running Windows workloads. He spends his spare time in the garage restoring and customizing old motorcycles.</p> 
<p><code class="lang-powershell"></code><code class="lang-powershell"></code></p> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">AWS CloudFormation Guardrails: Protecting your Stacks and Ensuring Safer Updates</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Luis Colon</span></span> | on 
<time property="datePublished" datetime="2017-10-31T17:03:10+00:00">31 OCT 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/aws-cloudformation/" title="View all posts in AWS CloudFormation*"><span property="articleSection">AWS CloudFormation*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/security-identity-compliance/aws-identity-and-access-management-iam/" title="View all posts in AWS Identity and Access Management (IAM)*"><span property="articleSection">AWS Identity and Access Management (IAM)*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/aws-cloudformation-guardrails-protecting-your-stacks-and-ensuring-safer-updates/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<blockquote> 
<p><em>“I wonder what will happen if I touch these two wires together.” – Unix fortune</em></p> 
</blockquote> 
<p>If you’ve worked with cloud-hosted applications or large distributed architectures for any extended period of time, chances are you’ve heard colleagues&nbsp;invoke&nbsp;<a href="https://en.wikipedia.org/wiki/Murphy's_law">Murphy’s law</a>: “Anything that can go wrong, will go wrong”. All of us have&nbsp;experienced one of those events in the middle of the night where a usually well-intentioned colleague decides to run maintenance or cleanup on some systems…and accidentally deletes or changes a volume, server, endpoint, function, or other critical resource.</p> 
<p>If your applications, functions, servers, and other resources are in AWS, and you’re using AWS CloudFormation to automate the deployment and changes to your stacks, you are well positioned to implement several levels of safety guardrails to reduce the likelihood of many of these unplanned events. In this blog post we cover many of these guardrails. We’ll also present ideas collected from user surveys, support cases, and other sources so you can build a strategy&nbsp;to use these safety provisions and improve them over time.</p> 
<p><span id="more-1560"></span></p> 
<p>There are four primary features that you can use to protect your stacks and resources in CloudFormation:</p> 
<table style="height: 203px" border="1" width="100%" cellpadding="4"> 
<tbody> 
<tr> 
<td width="139"><strong>Guardrail</strong></td> 
<td width="328"><strong>Description</strong></td> 
</tr> 
<tr> 
<td width="139">Termination Protection</td> 
<td width="328">Stack level attribute to prevent deletion; also works with nested stacks</td> 
</tr> 
<tr> 
<td width="139">Deletion Policies</td> 
<td width="328">Resource level attribute; can be Delete (default), Retain&nbsp;or Snapshot</td> 
</tr> 
<tr> 
<td width="139">Stack Policies</td> 
<td width="328">Restrict operations at a stack level to multiple resource groups</td> 
</tr> 
<tr> 
<td width="139">IAM Policies</td> 
<td width="328">Restrict operations by users, groups or roles</td> 
</tr> 
</tbody> 
</table> 
<p>These features&nbsp;vary in scope and the granularity of options. Consider implementing several of these features in a layered way, as opposed to using only one of them.</p> 
<p><strong>Using stack termination protection</strong></p> 
<p>Using <a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-cfn-protect-stacks.html">this</a>&nbsp;stack attribute, you can prevent a new or existing stack from being accidentally deleted. This setting is disabled by default, so you have to explicitly enable it when you create new stacks. For existing, non-nested stacks, you can change termination protection&nbsp;using the AWS Management Console or the AWS CLI. For existing nested stacks, you must enable termination protection on the root stack.&nbsp;After it is enabled on the root stack, the protection is also set for the nested or child stacks. However, keep in mind that if you perform a stack update on the root stack that would delete the nested stack, CloudFormation will delete the nested stack. If you attempt to delete a nested stack when its root stack has termination protection in place, the operation will fail and the nested stack will remain unchanged. Like many other CloudFormation operations,&nbsp;you can control who can enable or disable termination protection by using&nbsp;an IAM policy.</p> 
<code class="lang-json">{
&quot;Version&quot;:&quot;2012-10-17&quot;,
&quot;Statement&quot;:[{
&quot;Effect&quot;:&quot;Allow&quot;,
&quot;Action&quot;:[
&quot;cloudformation:UpdateTerminationProtection&quot;
],
&quot;Resource&quot;:&quot;*&quot;
}]
}
</code> 
<p><strong>Figure 1: Sample IAM policy granting permissions to change stack termination protection </strong></p> 
<p>&nbsp;</p> 
<p>So, now that you know about termination protection, should you enable it on all or most of your stacks? Maybe, but you should consider the lifecycle of all your stacks first. Adding termination protection to seldom-changing network resource stacks makes sense, providing yet another layer that can supplement existing controls without interfering with daily application changes. On the other hand, if the application stack changes often, you’ll end up enabling and disabling termination protection often as well. For those types of ephemeral stacks, other guardrails outlined in this article&nbsp;might be more appropriate.</p> 
<p><strong>Using resource-specific deletion policies</strong></p> 
<p>You can use <a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html">Deletion Policies</a> on a resource-by-resource basis in your template code. By default, when a resource is deleted from a stack template and the stack is updated, the resource is deleted by CloudFormation. (The exceptions are some Amazon RDS database resources, which have a different default behavior.) For more information on resource-specific deletion policies, see the CloudFormation <a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-deletionpolicy.html">DeletionPolicy Attribute</a> documentation.</p> 
<p>Keep in mind the&nbsp;Retain option, which deletes the resource from being managed by CloudFormation via stacks and templates, but doesn’t delete it from your AWS account or region. This can be critical for stateful resources like databases and queues, and semi-durable resources like state machines when using AWS Step Functions. For state machines in particular, it’s advisable to retain them because doing so also retains their execution history. In the interest of utmost safety, you should liberally set Deletion Policies to Retain if and until you can make sure you won’t lose valuable historical data for troubleshooting. You can always delete these resources later using other means.</p> 
<p>For some stateful resources like Amazon EC2 volumes, Amazon ElastiCache, Amazon RDS and Amazon Redshift, you also have the option to have CloudFormation create a snapshot before it deletes those resources. To further protect your more critical stateful resources, you&nbsp;can group them into separate stacks with more strict policies, and/or you can create dependencies between stacks&nbsp;using cross-stack references, which implements further implicit checks.</p> 
<code class="lang-json">{
&quot;AWSTemplateFormatVersion&quot;:&quot;2010-09-09&quot;,
&quot;Resources&quot;: {
&quot;myVolume&quot;: {
&quot;Type&quot;:&quot;AWS::EC2::Volume&quot;,
&quot;DeletionPolicy&quot;:&quot;Snapshot&quot;,
&quot;Properties&quot;: {
&quot;AvailabilityZone&quot;:&quot;us-east-1a&quot;,
&quot;Size&quot;:&quot;200&quot;
}
}
}
}
</code> 
<p><strong>Figure 2: Using Deletion Policy to take a snapshot of an EC2 Volume, if deleted</strong></p> 
<p>&nbsp;</p> 
<p><strong>Using stack-level policies</strong></p> 
<p>A <a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/protect-stack-resources.html#protect-stack-resources-protecting">stack policy</a> is a JSON document that defines the update actions that can be performed on a single resource or a group of resources in a flexible yet compact way (versus Deletion Policies, which are defined on a resource-by-resource basis). Stack policies are evaluated and applied in advance of any update actions, which include cases when resources are modified, recreated, or removed. Resources for a rule can be selected with wildcards or by evaluating a condition expression.</p> 
<code class="lang-json">{
&quot;Statement&quot; : [
{
&quot;Effect&quot; : &quot;Deny&quot;,
&quot;Action&quot; : &quot;Update:*&quot;,
&quot;Principal&quot;: &quot;*&quot;,
&quot;Resource&quot; : &quot;*&quot;,
&quot;Condition&quot; : {
&quot;StringEquals&quot; : {
&quot;ResourceType&quot; : [&quot;AWS::RDS::DBInstance&quot;]
}
}
},
{
&quot;Effect&quot; : &quot;Allow&quot;,
&quot;Action&quot; : &quot;Update:*&quot;,
&quot;Principal&quot;: &quot;*&quot;,
&quot;Resource&quot; : &quot;*&quot;
}
]
}
</code> 
<p><strong>Figure 3: A Stack policy that prevents updates to all RDS DB Instances </strong></p> 
<p>&nbsp;</p> 
<p>Stack policies can be set when you create a stack&nbsp;using the AWS Management Console or&nbsp;by using the AWS CLI. However,&nbsp;to set a stack policy on an existing stack, you must do it&nbsp;using&nbsp;the CLI or API. You also must use the CLI or API to modify an existing policy on a stack. You can also opt to create a strict permanent stack policy, and&nbsp;then update policy-protected resources by creating temporary policies that override the permanent stack policy. Finally, if you use AWS Config, you can also record configuration changes to the attributes of a stack policy, as well as other permissions and rollback settings.</p> 
<p><strong>Using IAM Policies</strong></p> 
<p><a href="http://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies.html">IAM Policies</a> explicitly enforce access controls on users, groups or roles. Beyond restricting updates and deletions to a subset of users, you can also restrict users to use only specific templates, use only specific stack policies, create only a few resource types, or assume specific roles. Gaining expertise with IAM policies can benefit you beyond your CloudFormation usage, such as controlling access to logs, who can execute Lambda functions, and many other use cases across all AWS services.</p> 
<code class="lang-json">{
&quot;Effect&quot;:&quot;Allow&quot;,
&quot;Action&quot;:[&quot;cloudformation:CreateStack&quot;]
},
{
&quot;Effect&quot;:&quot;Deny&quot;,
&quot;Action&quot;:[&quot;cloudformation:CreateStack&quot;]
“Condition”:{
‘ForAnyValue:StringLike”:{
“cloudformation:ResourceType”: [“AWS::IAM::*”]
}
}
}
</code> 
<p><strong>Figure 4: IAM policy allowing users to create resources and stacks except for IAM resources</strong></p> 
<p>&nbsp;</p> 
<p><strong>A few more suggestions</strong></p> 
<p>Beyond understanding how these four guardrails work, here are a few other suggestions and ideas you&nbsp;can study&nbsp;as you look to implement these controls, or improve existing controls you may have inherited:</p> 
<li>By having smaller, multiple policies that affect a smaller set of resources and stacks, you can limit the blast radius of policy changes as you improve them over time, to either make them more restrictive or to add layers of control.</li> 
<li>Stack and IAM policies should be treated as code and, with that in mind, they should be periodically tested and versioned. Consider implementing validation pipelines and creating chaos engineering-like tests where critical resource deletions are attempted.</li> 
<li>For your own custom resources, it’s up to you to add code to determine what happens to your resources when they get deleted. For stateful custom resources, it becomes your responsibility to ensure a given resource is backed up or retained. You can also use a Lambda-backed custom resource to pass a stack’s policy from a root stack to a nested stack using the setStackPolicy API call&nbsp;because nested stacks don’t automatically inherit the root stack’s policy.</li> 
<li>These guardrails are preventive steps that you can execute within CloudFormation. If you go outside of CloudFormation and use a resource’s AWS Management Console to update and delete it, your template code will become out-of-sync with the resource’s state. You should update your template to reflect the new changes, and prevent future changes&nbsp;using additional IAM policies.</li> 
<p>You should plan to use most (if not all) of these options. Let’s say, for example, that you’ve just inherited a group of applications (and, with those, the infrastructure stacks and templates associated with them) and are looking at adding layers of protection using these guardrails. A defensible approach may look like this:</p> 
<li>Review your stacks and templates,&nbsp;and review the resources that are more critical, like stateful or semi-durable resources.&nbsp;Determine which of these critical resources are useful candidates for a DeletionPolicy of Retain or Snapshot.</li> 
<li>Go one level up from resources to stacks, and consider what operations will be allowed for resources (or groups of resources) within that stack. On top of your resource deletion policy layer, add stack policy restrictions that reflect the criticality of those stacks. For the more critical stacks, consider also using stack termination protection. Even if it becomes a nuisance, at least you’ll&nbsp;gain understanding about how frequently stack updates are required for those stacks, which stacks have cross stack references or parent/child relationships, etc. Armed with this information, you can adjust your&nbsp;controls accordingly.</li> 
<li>Finally, once you’ve protected the resources and stacks themselves, you should then restrict which users should have the ability to run updates on those stacks using IAM policies.</li> 
<p><strong>Conclusion</strong></p> 
<p>We just walked through a sequence starting with&nbsp;the most detailed controls at the individual resource level, then to the stacks, and finally to the users, and will likely end up with the most enforced or least privileged controls. Alternatively, you can also opt to start with users, groups, and roles first, and then work your way down through stacks and resources. This can probably be justified if, in looking at the history of your unplanned downtime events, you already suspect that your IAM policies need more urgent attention. In either case, you want to ensure that there are multiple layers of safety in place by having multiple guardrails apply to your most critical resources.</p> 
<p>Overall, the key to success in making the most of these features is to carefully test and adapt your use of these guardrails over time, and ensure that you have multiple guardrail layers in place for the most critical stacks and resources. Many existing CloudFormation best practices still apply; for example, smaller stacks will be easier to test and ultimately protect than large, complex ones. &nbsp;Finally, consider ways to establish automated tests for your template code by implementing processes like validation pipelines.</p> 
<p>&nbsp;</p> 
<p><strong>About the Author</strong></p> 
<table class=" alignleft" style="height: 129px" width="100%" cellpadding="4"> 
<tbody> 
<tr> 
<td width="63"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/17/PhoneTool1.jpg" /></td> 
<td width="408"> <p><strong>Luis Colon is a Senior Developer Advocate for the AWS CloudFormation team.&nbsp;</strong>He works with customers and internal development teams to focus on and improve the developer experience for CloudFormation users. In his spare time, he mixes progressive trance music.</p> <p>&nbsp;</p></td> 
</tr> 
</tbody> 
</table> 
<p></p> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<meta property="image" content="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/26/awsreinvent2017banner.png" /> 
<b class="lb-b blog-post-title" property="name headline">Your AWS CloudFormation Guide to re:Invent 2017 &nbsp;</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Chuck Meyer</span></span> | on 
<time property="datePublished" datetime="2017-10-30T14:31:05+00:00">30 OCT 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/aws-cloudformation/" title="View all posts in AWS CloudFormation*"><span property="articleSection">AWS CloudFormation*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/events/reinvent/" title="View all posts in AWS re:Invent*"><span property="articleSection">AWS re:Invent*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/your-aws-cloudformation-guide-to-reinvent-2017/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/26/awsreinvent2017banner.png" /></p> 
<p>There are only five weeks left until <a href="https://reinvent.awsevents.com/">re:Invent 2017</a>. As in years past, AWS CloudFormation will be there, both behind the scenes deploying infrastructure and front-and-center for break-out sessions, workshops, and developer chats.</p> 
<p>Here are a few highlights we’ve pulled from the <a href="https://www.portal.reinvent.awsevents.com/connect/search.ww#loadSearch-searchPhrase=CloudFormation&amp;searchType=session&amp;tc=0&amp;sortBy=abbreviationSort&amp;p=">session catalog</a>, followed by the full list of CloudFormation-focused sessions and workshops to help you plan your week in Las Vegas.</p> 
<p><span id="more-1585"></span></p> 
<b id="breakout-sessions">Breakout Sessions</b> 
<p>Breakout sessions are the traditional, 60 minute, lecture-style content format.</p> 
<li><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=14428">DEV317 – Deep Dive on AWS CloudFormation</a> <em>The AWS CloudFormation team guides you through techniques used for creating modular templates and and considerations for governance.</em></li> 
<li><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=16239">DEV318 – Learn How Intuit Built a Frictionless Infrastructure Management System Using AWS CloudFormation</a> <em>Intuit shows you how they built a standardized serverless solution using AWS CloudFormation to manage infrastructure as code.</em></li> 
<li><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=15142">GPSTEC319 – GPS: Build Once, Deploy Many: Architecting and Building Automated, Reusable Reference Deployments with AWS CloudFormation</a> <em>The AWS Quick Start team shares with you the experience and best practices they’ve gained building over 50 Quick Start reference deployments.</em></li> 
<b id="workshops">Workshops</b> 
<p>Workshops are 2.5 hour, small-scale breakouts where you work in teams to build projects and solve problems on AWS.</p> 
<li><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=14430">DEV336 – Stack Mastery: Create and Optimize Advanced AWS CloudFormationTemplates</a> <em>Take a real-world architecture from a sandbox template to production-ready reusable code.</em></li> 
<li><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=16359">DEV337 – Deploy a Data Lake with AWS CloudFormation</a> <em>You will learn how to build AWS CloudFormation templates using proven methods and best practices to deploy a fully functional data lake architecture.</em></li> 
<li><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=14629">SID312 – DevSecOps Capture the Flag</a> <em>Improve your DevSecOps skills in this Capture the Flag style workshop. Earn points by enforcing policy via CloudFormation static analysis.</em></li> 
<b id="other-relevant-sessions">Other relevant sessions</b> 
<p>While the following sessions aren’t CloudFormation specific, they will show you mature patterns for infrastructure management using CloudFormation alongside other AWS services.</p> 
<li><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=14965">DEV324 – Deep Dive on Advanced Continuous Delivery Techniques Using AWS DevOps Tools</a></li> 
<li><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=15199">DEV340 – How Amazon.com Uses AWS Management Tools</a></li> 
<li><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=14521">MSC201 – Building end-to-end IT Lifecycle Mgmt &amp; Workflows with AWS Service Catalog</a></li> 
<p>You can <a href="https://www.portal.reinvent.awsevents.com/connect/publicDashboard.ww">log in and reserve seats for any of these sessions</a> now.</p> 
<p>In addition, the AWS CloudFormation Developer Advocates will be presenting a series of CloudFormation focused Dev Chats on the Expo floor on Wednesday and Thursday. Stop by the Dev Lounge in the Expo Hall for exact times.</p> 
<p>And finally, you can come chat with any of the Management Tools team at the AWS booth all week long.</p> 
<p>See you at re:Invent!</p> 
<hr /> 
<p><strong><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=14479">AMF301 – Big Data &amp; Analytics for Manufacturing Operations</a></strong><br /> Manufacturing companies collect vast troves of process data for tracking purposes. Using this data with advanced analytics can optimize operations, saving time and money. In this session, we explore the latest analytics capabilities to support your goals for optimizing the manufacturing plant floor. Learn how to build dashboards that connect to prediction models driven by sensors across manufacturing processes. Learn how to build a data lake on AWS, using services and techniques such as AWS CloudFormation, Amazon EC2, Amazon S3, AWS Identity and Access Management, and AWS Lambda. We also review a reference architecture that supports data ingestion, event rules, analytics, and the use of machine learning for manufacturing analytics.</p> 
<p><strong><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=16676">CMP216 – Use Amazon EC2 Spot Instances to Deploy a Deep Learning Framework on Amazon ECS</a></strong><br /> Deep learning, an implementation of machine learning, uses neural networks to solve complex problems like computer vision, natural language processing, and recommendations. Deep learning libraries and frameworks enable developers to enhance the capabilities of their applications and projects. In this workshop, learn how to build and deploy a powerful deep learning framework, Apache MXNet, on containers. The portability and resource management benefit of containers enables developers to focus less on infrastructure and more on building. The lab first demonstrates the automation capabilities of AWS CloudFormation to stand up core infrastructure. We also leverage Spot Fleet for the cost benefit of using Spot Instances, especially important for developer environments. Next we create an MXNet container in Docker and deploy it with Amazon ECS. Finally, we explore image classification with MXNet to validate that everything is working as expected.</p> 
<p><strong><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=16740">CON319 – Interstella 8888: CICD for Containers on AWS</a></strong><br /> Interstella 8888 is an intergalactic trading company that deals in rare resources, but their antiquated monolithic logistics systems are causing the business to lose money. Join this workshop to learn how to set up a CI/CD pipeline for containerized microservices. You’ll get hands-on experience deploying Docker container images using Amazon ECS, AWS CloudFormation, AWS CodeBuild, and AWS CodePipline, automating everything from code check-in to production. AWS credits are provided. Bring your laptop, and have an active AWS account.</p> 
<p><strong><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=14428">DEV317 – Deep Dive on AWS CloudFormation</a></strong></p> 
<p>AWS CloudFormation enables developers and system administrators to harness the power of infrastructure-as-code. As organizations adopt AWS CloudFormation for workload deployments, common patterns emerge and opportunities to streamline deployments become evident. Using AWS CloudFormation support for nested templates, customers can further streamline the creation of new workloads as code through modular reuse. This session guides you through some of the techniques used for creating modular AWS CloudFormation templates, and considerations for design and governance to empower departments and teams to own the architectures.</p> 
<p><strong><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=16239">DEV318 – Learn How Intuit Built a Frictionless Infrastructure Management System Using AWS CloudFormation</a></strong></p> 
<p>Managing Infrastructure as Code (IaC) successfully within an organization is a challenge. Regardless of team size, it can turn into a patchwork of solutions causing difficulties collaborating among individuals and teams. Intuit has faced and learned from these challenges, while coordinating among different teams running workloads that provide solutions for different business units. We developed a system that improved our development process for IaC using AWS CloudFormation. In this session, we demonstrate how to move away from an inconsistent development of infrastructure by complementing common development practices with a solution using the serverless technologies from AWS. We walk through our journey and help you discover an approach to assemble a similar solution for your organization.</p> 
<p><strong><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=14965">DEV324 – Deep Dive on Advanced Continuous Delivery Techniques Using AWS DevOps Tools</a></strong><br /> Continuous delivery (CD) enables teams to be more agile and quickens the pace of innovation. Too often, however, teams adopt CD without putting the right safety mechanisms in place. In this talk, we discuss opportunities for you to transform your software release process into a safer one. We explore various DevOps best practices, showcasing sample applications and code. We discuss how to set up delivery pipelines with nonproduction testing stages, failure cases, rollbacks, machine and Availability Zone redundancy, canary testing and deployments, and monitoring. We’ll use AWS Lambda, AWS CloudFormation, AWS CodePipeline, AWS CodeDeploy, and both Amazon CloudWatch alarms and events.</p> 
<p><strong><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=14778">DEV332 – Using AWS to Achieve Both Autonomy and Governance at 3M</a></strong><br /> There is a constant tension between empowering teams to be agile through autonomy and enforcing governance policies to maintain regulatory compliance. Hear from Nathan Scott, Senior Consultant at AWS and James Martin, Automation Engineering Manager at 3M on how they have achieved both autonomy and governance through self-service automation tools on AWS. Learn how to avoid pitfalls with building the CI/CD team, right sizing and how to address. This session will also feature a demo from Casey Lee, Chief Architect at Stelligent on the tools used to accomplish this for 3M, including AWS Service Catalog, AWS CloudFormation, AWS CodePipeline and Cloud Custodian, an open source tool for managing AWS accounts.</p> 
<p><strong><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=14430">DEV336 – Stack Mastery: Create and Optimize Advanced AWS CloudFormationTemplates</a></strong><br /> AWS CloudFormation gives you an easy way to define your infrastructure as code. But are you using it to its full potential? In this workshop, we take real-world architecture from a sandbox template to production-ready reusable code. We start by reviewing an initial template, which you update throughout the session to incorporate AWS CloudFormation features, like nested stacks and intrinsic functions. By the end of this workshop, expect to have a set of AWS CloudFormation templates that demonstrate the same best practices used in AWS Quick Starts.</p> 
<p><strong><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=16359">DEV337 – Deploy a Data Lake with AWS CloudFormation</a></strong><br /> AWS CloudFormation provides many features to automate the provisioning of infrastructure for all types of complex applications. In this workshop, you will learn how to build AWS CloudFormation templates using proven methods and best practices. You will also deploy a fully functional data lake architecture, which uses AWS services like Amazon RDS and open source components like Apache Zeppelin. The labs will demonstrate the capabilities of AWS CloudFormation to stand up infrastructure in a modular way, walk through the deployment of a complex end-to-end application, and validate that all components of the application are working.</p> 
<p><strong><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=15199">DEV340 – How Amazon.com Uses AWS Management Tools</a></strong><br /> Amazon.com enables all of its developers to be productive on AWS by operating across tens-of-thousands of team-owned AWS accounts, all while raising the bar on security, visibility and operational control. Amazon has been able to achieve these seemingly conflicting ideals by automating setup and management of these accounts at scale using AWS Management Tools such as CloudFormation, Config, CloudTrail, CloudWatch and EC2 Systems Manager. In this session, discover more about how Amazon.com built ASAP using AWS Management tools, and understand some of the decisions they made as their usage of AWS evolved over time. You will learn about the design, architecture and implementation that Amazon.com went through as part of this effort.</p> 
<p><strong><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=14951">ENT326 – Oracle Enterprise Solutions on AWS</a></strong><br /> Oracle enterprise applications and middleware such as E-Business Suite, PeopleSoft, Siebel, and WebLogic are central to many IT departments. They often require complex deployments that can greatly benefit from the flexibility, scalability, and security of the cloud. In this session, we discuss architecture patterns and best practices for migrating these applications to and running these applications on AWS. We cover how to work with Oracle enterprise applications and multiple services including Amazon RDS, AWS Database Migration Service, Amazon Elastic File System, and AWS CloudFormation. As part of this, we show examples of successful customer deployments.</p> 
<p><strong><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=15549">GPSCT308 – GPS: Developing and Deploying at the Speed of Light: Automating Serverless Deployments</a></strong><br /> Planning on going serverless, but want to manage it using DevOps-style processes? In this interactive session, we discuss the art of automating and managing deployments of serverless applications on AWS. We cover a range of AWS tools such as AWS CodePipeline, AWS CloudFormation, and AWS Serverless Application Model (AWS SAM), to name just a few.</p> 
<p><strong><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=15142">GPSTEC319 – GPS: Build Once, Deploy Many: Architecting and Building Automated, Reusable Reference Deployments with AWS CloudFormation</a></strong><br /> This session explains how to build reusable, maintainable AWS CloudFormation–based automation for AWS Cloud deployments. We have built over 50 Quick Start reference deployments with partners and customers, and will share this expertise with you. We explore the anatomy of a typical AWS CloudFormation template, dive deep into best practices for building Quick Start automation across Linux and Windows and explore useful design patterns. This expert-level session is for partners interested in building Quick Starts or other AWS CloudFormation–based automation. It requires familiarity with Git, shell scripting, Windows PowerShell, and AWS services like Amazon EC2, Amazon S3 and AWS CloudFormation.</p> 
<p><strong><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=15749">HLC307 – Building a Secure and Healthcare-Compliant Platform for Adopting a Cloud-First Strategy Using AWS</a></strong><br /> This session provides an overview of how Change Healthcare invested in people, process, and an automation platform to adopt a cloud-first strategy. Starting from building a Cloud Center of Excellence team, they identified the compliance, security, and cost optimization requirements and process required to build a framework. They also embedded healthcare compliance, security, architecture best practices, and customer-specific rules and standards for a managed adoption of the cloud. Change Healthcare is leveraging their Cloud 2.0 framework to rapidly deploy their mission applications into AWS. Come learn how Change Healthcare built a serverless architecture using Amazon ECS, AWS Lambda, AWS CodeDeploy, AWS CodeCommit, AWS CloudFormation, AWS Service Catalog, AWS OpsWorks, AWS Elastic Beanstalk, and other managed services.</p> 
<p><strong><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=15746">LFS307 – Becoming a Dynamic Pharma Marketing Organization Using AWS</a></strong><br /> Pharmaceutical company processes tend to be slow when dealing with customer-facing applications that contain FDA-validated messages, all while maintaining infrastructure and security standards. In this session, discover how Mylan, a US–based global generic and specialty pharmaceutical company, overcame these obstacles and provided scalable solutions by leveraging AWS DevOps methods that lower time to market, while maintaining robust security and release management practices. During the presentation, learn how Mylan redefined process models such as infrastructure change management to define new security and process models. Additionally, learn how Mylan used services like Amazon S3, Elastic Load Balancing (ELB), and AWS CloudFormation to define these new models.</p> 
<p><strong><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=15681">LFS308 – Building Data Lakes for Life Sciences Organizations</a></strong><br /> In this chalk talk, we cover the implementation of data lakes for life sciences organizations, such as Amgen and Merck, that are looking to glean new insights from their existing and new clinical data. AWS life sciences solution architects show how to build a data lake on AWS using services and techniques such as AWS CloudFormation, Amazon EC2, Amazon S3, IAM, and AWS Lambda.</p> 
<p><strong><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=15250">MBL308 – Integrating Video in Mobile Apps and Websites</a></strong><br /> In this session, we will build a highly scalable mobile app, website, and serverless mobile backend architecture that demonstrates on-demand video streaming, adaptive multi-bitrate transcoding, and video content ingestion. We use AWS Lambda and Amazon Elastic Transcoder to automatically convert high resolution videos upon upload, Amazon CloudFront to stream video content to devices using network-aware adaptive multi-bitrate protocols (such as HLS), Amazon Cognito to authenticate users, and AWS Mobile Hub and AWS CloudFormation to automate setting up the required resources.</p> 
<p><strong><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=15878">MCL318 – Deep Dive on Amazon Rekognition Architectures for Image Analysis</a></strong><br /> Join us for a deep dive on how to use Amazon Rekognition for real world image analysis. Learn how to integrate Amazon Rekognition with other AWS services to make your image libraries searchable. Also learn how to verify user identities by comparing their live image with a reference image, and estimate the satisfaction and sentiment of your customers. We also share best practices around fine-tuning and optimizing your Amazon Rekognition usage and refer to AWS CloudFormation templates.</p> 
<p><strong><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=14521">MSC201 – Building end-to-end IT Lifecycle Mgmt &amp; Workflows with AWS Service Catalog</a></strong><br /> In this session, you’ll learn how to leverage AWS Service Catalog, AWS Lambda, AWS Config and AWS CloudFormation to create a robust, agile environment while maintaining enterprise standards, controls and workflows. Fannie Mae demonstrates how they are leveraging this solution to integrate with their existing workflows and CMDB/ITSM systems to create an end-to-end automated and agile IT lifecycle and workflow.</p> 
<p><strong><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=14962">SID206 – Best Practices for Managing Security Operation on AWS</a></strong><br /> To help prevent unexpected access to your AWS resources, it is critical to maintain strong identity and access policies and track, effectively detect, and react to changes. In this session you will learn how to use AWS Identity and Access Management (IAM) to control access to AWS resources and integrate your existing authentication system with IAM. We will cover how to deploy and control AWS infrastructure using code templates, including change management policies with AWS CloudFormation. Further, effectively detecting and reacting to changes in posture or adverse actions requires the ability to monitor and process events. There are several services within AWS that enable this kind of monitoring such as CloudTrail, CloudWatch Events, and the AWS service APIs. We learn how Netflix utilizes a combination of these services to operationalize monitoring of their deployments at scale, and discuss changes made as Netflix’s deployment has grown over the years.</p> 
<p><strong><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=14629">SID312 – DevSecOps Capture the Flag</a></strong><br /> In this Capture the Flag workshop, we divide groups into teams and work on AWS CloudFormation DevSecOps. The AWS Red Team supplies an AWS DevSecOps Policy that needs to be enforced via CloudFormation static analysis. Participant Blue Teams are provided with an AWS Lambda-based reference architecture to be used to inspect CloudFormation templates against that policy. Interesting items need to be logged, and made visible via ChatOps. Dangerous items need to be logged, and recorded accurately as a template fail. The secondary challenge is building a CloudFormation template to thwart the controls being created by the other Blue teams. Throughout the session your DevSecOps static analysis will be tested by increasingly difficult CloudFormation templates from the AWS Red Team, with accurate detection being rewarded with points. Finally, we test all teams’ protection against every other team’s malicious template to see which Blue team’s static analysis was most effective.</p> 
<p><strong><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=14785">SID317 – Automating Security and Compliance Testing of Infrastructure-as-Code for DevSecOps</a></strong><br /> Infrastructure-as-Code (IaC) has emerged as an essential element of organizational DevOps practices. Tools such as AWS CloudFormation and Terraform allow software-defined infrastructure to be deployed quickly and repeatably to AWS. But the agility of CI/CD pipelines also creates new challenges in infrastructure security hardening. How do you ensure that your CloudFormation templates meet your organization’s security, compliance, and governance needs before you deploy them? How do you deploy infrastructure securely to production environments, and monitor the security posture on a continuous basis? And how do you do this repeatedly without hitting a speed bump? This session provides a foundation for how to bring proven software hardening practices into the world of infrastructure deployment. We discuss how to build security and compliance tests for infrastructure analogous to unit tests for application code, and showcase how security, compliance and governance testing fit in a modern CI/CD pipeline. Session Sponsored by: Dome9</p> 
<p><strong><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=16300">SID327 – How Zocdoc Achieved Security and Compliance at Scale With Infrastructure as Code</a></strong><br /> In less than 12 months, Zocdoc became a cloud-first organization, diversifying their tech stack and liberating data to help drive rapid product innovation. Brian Lozada, CISO at Zocdoc, and Zhen Wang, Director of Engineering, provide an overview on how their teams recognized that infrastructure as code was the most effective approach for their security policies to scale across their AWS infrastructure. They leveraged tools such as AWS CloudFormation, hardened AMIs, and hardened containers. The use of DevSecOps within Zocdoc has enhanced data protection with the use of AWS services such as AWS KMS and AWS CloudHSM and auditing capabilities, and event-based policy enforcement with Amazon Elasticsearch Service and Amazon CloudWatch, all built on top of AWS.</p> 
<p><strong><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=15779">SID347 – Securely Automating DevOps on AWS</a></strong><br /> In some organizations, the theme of “can’t we all just get along” accurately describes the relationship between DevOps and network security. DevOps operates at a rapid and dynamic pace, taking advantage of the cloud to create and deploy. Security teams exercise industry best practices of policy change control to eliminate potential security holes. Inevitably, deployment challenges arise. In this session, you learn how to automate the deployment of next-generation security to protect DevOps environments on AWS. Topics covered include “touchless” deployment of a fully-configured firewall using AWS CloudFormation templates and AWS Lambda, consuming AWS tags to execute commitless policy updates, using Amazon CloudWatch and Elastic Load Balancing to deliver scalability and resiliency. Come and learn about the next generation of security, operating at the speed of the cloud. Session sponsored by Palo Alto Networks</p> 
<p><strong><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=17593">SPL09 – Launching and Managing a Web Application with AWS CloudFormation</a></strong><br /> In this lab, you will learn how to use AWS CloudFormation to provision and update a web application with a number of supporting AWS products and services, including Auto Scaling groups, Amazon Elastic Compute Cloud (EC2) instances, and Elastic Load Balancing.</p> 
<p><strong><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=16411">WIN309 – How to Optimize AWS Architectures for SharePoint Deployments</a></strong><br /> AWS can help you rapidly deploy and scale your Microsoft SharePoint environment to help you collaborate more efficiently and cost-effectively. This session reviews architectural considerations for building a SharePoint deployment on AWS, best practices to ensure optimal performance, how to leverage multiple Availability Zones for high availability and disaster recovery, and how to integrate with Active Directory. We also look at new Quick Start guides, AWS CloudFormation templates, and other tools that dramatically reduce the time to deployment. Our Windows experts discuss the best ways to deploy and run SharePoint on AWS.</p> 
<p><strong><a href="https://www.portal.reinvent.awsevents.com/connect/sessionDetail.ww?SESSION_ID=16410">WIN312 – Deploying .NET Application CI/CD Pipelines on AWS</a></strong> In this session, we look at the AWS services that customers are using to build and deploy Microsoft-based solutions that use technologies like Windows, .NET, SQL Server, and PowerShell. We start by showing you how to build a Windows-based CI/CD pipeline on AWS using AWS CodeDeploy, AWS CodePipeline, AWS CloudFormation, and PowerShell using an AWS Quick Start. With new integrations, such as the AWS Tools for VSTS, you have more options than ever. We also cover best practices for creating templates that let you automatically deploy ready-to-use Windows products by using services and tools like AWS CloudFormation, PowerShell, and Git. Our .NET experts discuss the best practices for implementing a .NET CI/CD pipeline with AWS services.</p> 
<hr /> 
<h3><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/23/BadgePhoto-blog.jpg" />About the Author</h3> 
<p>Chuck Meyer&nbsp;is a Senior Developer Advocate for AWS CloudFormation based in New York.&nbsp; He&nbsp;spends his time&nbsp;working with&nbsp;both&nbsp;external and internal development teams to constantly improve the developer experience for CloudFormation users.&nbsp; He’s a live music true believer and spends as much time as possible playing bass and watching bands.</p> 
<p>&nbsp;</p> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">Amazon EC2 Systems Manager Parameter Store adds support for Parameter versions</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Venkat Krish</span></span> | on 
<time property="datePublished" datetime="2017-10-26T12:45:28+00:00">26 OCT 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/amazon-ec2-systems-manager/" title="View all posts in Amazon EC2 Systems Manager*"><span property="articleSection">Amazon EC2 Systems Manager*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools*"><span property="articleSection">Management Tools*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/amazon-ec2-systems-manager-parameter-store-adds-support-for-parameter-versions/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p><em>By Lou de la Torre, AWS Partner Solutions Architect and </em><em>Venkat Krishnamachari, Principal Product Manager, Amazon EC2 Systems Manager</em></p> 
<p>Today we are excited to announce versioning support for Amazon EC2 Systems Manager Parameter Store. With Parameter Store versioning support, each iteration of a parameter is assigned a unique version number at creation time. These individual version numbers can be easily referenced in API actions and Systems Manager Documents. By default, the latest value of the parameter will be returned when no version is specified.</p> 
<h3>Parameter Store</h3> 
<p><a href="https://aws.amazon.com/ec2/systems-manager/parameter-store/">Parameter Store</a> is part of <a href="https://aws.amazon.com/ec2/systems-manager/parameter-store/">Amazon EC2 Systems Manager</a>.&nbsp;It provides a centralized, encrypted store to manage your configuration data, whether it is plain text data (database strings) or secure strings and secrets (such as passwords, and API keys). Because Parameter Store is available through the AWS CLI, APIs, and SDKs, you can easily reference parameters across AWS services such as AWS Lambda and Amazon EC2 Container Service (ECS).</p> 
<p>For additional posts on Parameter Store, see:</p> 
<p><a href="https://aws.amazon.com/blogs/mt/the-right-way-to-store-secrets-using-parameter-store/">The Right Way to Store Secrets using Parameter Store</a></p> 
<p><a href="https://aws.amazon.com/blogs/compute/managing-secrets-for-amazon-ecs-applications-using-parameter-store-and-iam-roles-for-tasks/">Managing Secrets for Amazon ECS Applications Using Parameter Store and IAM Roles for Tasks</a></p> 
<p><a href="https://aws.amazon.com/blogs/mt/organize-parameters-by-hierarchy-tags-or-amazon-cloudwatch-events-with-amazon-ec2-systems-manager-parameter-store/">Organize Parameters by Hierarchy, Tags, or Amazon CloudWatch Events with Amazon EC2 Systems Manager Parameter Store</a></p> 
<p><span id="more-1531"></span></p> 
<h3>Parameter Store Versioning</h3> 
<p>Versioning provides an additional layer of protection for your Parameter Store values. For example, if code deployment fails you can easily roll back and reference older versions of config data saved as parameters in the Parameter Store. You can recover from unintended user errors that caused an overwrite in your parameter value. You can also use versioning to keep track of the number of times your stored values changed over the parameter’s lifetime for auditing purposes (see Figure 1).</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/23/Figure1-1-1024x546.png" /></p> 
<p>By default, the initially created parameters’ version is 1. Versions are incremented automatically by increments of 1 whenever a value is updated in the Parameter Store. To demonstrate the value of Parameter Store versioning, consider the following scenario.</p> 
<p>In an effort to minimize management overhead you decide to migrate your .NET application back-end SQL database from SQL on EC2 to RDS SQL. This will require that you deploy new code to your .NET application to update the database connection string. As with any migration, you want to ensure you can quickly rollback in case of failure.</p> 
<p>With Parameter Store versioning you can quickly rollback by performing the following steps:</p> 
<ol> 
<li>Create a new Parameter pointing to the existing database string (SQL on EC2)</li> 
<li>Create a new version of the Parameter pointing to the new database string (RDS SQL)</li> 
<li>Update your code with a reference to the latest or Default version of the parameter</li> 
<li>Migrate your database from SQL on EC2 to RDS SQL</li> 
<li>Deploy your code updating the .NET application to point to the new SQL database running on RDS via the latest or Default version of the parameter</li> 
<li>If any issues arise, simply update your code with the original version of the Parameter pointing your .NET application back to the original SQL on EC2 instance and re-deploy</li> 
</ol> 
<p>Let’s take a look at how easily you can make that happen by first creating a Parameter, then updating the parameter, viewing all existing versions of the Parameter, retrieving a Parameter by specific version number and finally rolling back to the original version of the Parameter. To do this you can use either the AWS CLI or the AWS Tools for Windows PowerShell. We will walk you through using both.</p> 
<p><strong>Step 1. Create a Parameter</strong></p> 
<p>Execute the following command to create a Parameter using the AWS CLI:</p> 
<code class="lang-bash">aws ssm put-parameter --name &quot;/Prod/dotnet&quot; --type String --value &quot;ec2-13-57-12-38.us-west-1.compute.amazonaws.com:1433&quot;</code> 
<p>or you can use&nbsp;the AWS Tools for Windows PowerShell:</p> 
<code class="lang-powershell">Write-SSMParameter -Name &quot;/Prod/dotnet&quot; -Value &quot;ec2-13-57-12-38.us-west-1.compute.amazonaws.com:1433&quot; -Type &quot;String&quot;</code> 
<p><strong>Step 2. Update the Parameter</strong></p> 
<p>Execute the following command to update the parameter using the AWS CLI (note the change in value and the overwrite option):</p> 
<code class="lang-bash">aws ssm put-parameter --name &quot;/Prod/dotnet&quot; --type String --value &quot;dotnet.ctvzltftaz4x.us-west-1.rds.amazonaws.com:1433&quot; --overwrite</code> 
<p>Or you can use the AWS Tools for Windows PowerShell (note the change in value and the overwrite option):</p> 
<code class="lang-powershell">Write-SSMParameter -Name &quot;/Prod/dotnet&quot; -Value &quot;dotnet.ctvzltftaz4x.us-west-1.rds.amazonaws.com:1433&quot; -Type &quot;String&quot; -Overwrite $true</code> 
<p><strong>Step 3. View all existing Versions of the Parameter</strong></p> 
<p>Execute the following command to view all existing versions of the Parameter using the CLI:</p> 
<code class="lang-bash">aws ssm get-parameter-history --name “/Prod/dotnet”</code> 
<p>The System returns information similar to the following:</p> 
<code class="lang-bash">PS C:\&gt; aws ssm get-parameter-history --name “/Prod/dotnet”
{
&quot;Parameters&quot;: [
{
&quot;LastModifiedUser&quot;: &quot;arn:aws:iam&quot;, 
&quot;LastModifiedDate&quot;: 1507742527.826, 
&quot;Type&quot;: &quot;String&quot;, 
&quot;Name&quot;: &quot;/Prod/dotnet&quot;, 
&quot;Value&quot;: &quot;ec2-13-57-12-38.us-west-1.compute.amazonaws.com:1433&quot;
&quot;Version&quot;: 1
}, 
{
&quot;LastModifiedUser&quot;: &quot;arn:aws:iam&quot;, 
&quot;LastModifiedDate&quot;: 1507743165.366, 
&quot;Type&quot;: &quot;String&quot;, 
&quot;Name&quot;: &quot;/Prod/dotnet&quot;, 
&quot;Value&quot;: &quot;dotnet.ctvzltftaz4x.us-west-1.rds.amazonaws.com:1433&quot;
&quot;Version&quot;: 2
}
]
}</code> 
<p>or you can execute the following command to view all existing versions of the Parameter using the AWS Tools for Windows PowerShell:</p> 
<p><code class="lang-powershell"></code></p> 
<code class="lang-powershell">Get-SSMParameterHistory -Name &quot;/Prod/dotnet&quot;</code> 
<p>The System returns information similar to the following:</p> 
<p>&nbsp;</p> 
<code class="lang-bash">PS C:\&gt; Get-SSMParameterHistory -Name &quot;/Prod/dotnet&quot;
Description&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; :
KeyId&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; :
LastModifiedDate : 10/11/2017 5:22:07 PM
LastModifiedUser: arn:aws:iam
Name&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; : /Prod/dotnet
Type&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; : String
Value&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; : ec2-13-57-12-38.us-west-1.compute.amazonaws.com:1433
Version&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  : 1
Description&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; : 
KeyId&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; :
LastModifiedDate : 10/11/2017 5:32:45 PM
LastModifiedUser : arn:aws:iam
Name&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; : /Prod/dotnet
Type&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; : String
Value&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; : dotnet.ctvzltftaz4x.us-west-1.rds.amazonaws.com:1433
Version&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  : 2</code> 
<p><strong>Step 4. Retrieve the Parameter</strong></p> 
<p>Use the following AWS CLI to retrieve parameters:</p> 
<p>Execute the following command to retrieve the latest version of the Parameter (default):</p> 
<code class="lang-bash">aws ssm get-parameters --names “/Prod/dotnet”</code> 
<p>The System returns information similar to the following:</p> 
<code class="lang-bash">PS C:\&gt; aws ssm get-parameters --name “/Prod/dotnet”
{
&nbsp;&nbsp;&nbsp; &quot;InvalidParameters&quot;: [],
&nbsp;&nbsp;&nbsp; &quot;Parameters&quot;: [
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; {
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;Type&quot;: &quot;String&quot;,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;Name&quot;: &quot;/Prod/dotnet&quot;,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;Value&quot;: &quot;dotnet.ctvzltftaz4x.us-west-1.rds.amazonaws.com:1433&quot;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;Version&quot;: 2
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }
&nbsp;&nbsp;&nbsp; ]
}</code> 
<p><code class="lang-bash"></code></p> 
Execute the following command to retrieve a specific version of the Parameter (by version number): 
<code class="lang-bash">aws ssm get-parameters --names “/Prod/dotnet:1&quot;</code> 
<p>The System returns information similar to the following:</p> 
PS C:\&gt; aws ssm get-parameters --region us-west-1 --name “/Prod/dotnet” 
<code class="lang-bash">
{
&nbsp;&nbsp;&nbsp; &quot;InvalidParameters&quot;: [],
&nbsp;&nbsp;&nbsp; &quot;Parameters&quot;: [
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; {
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;Type&quot;: &quot;String&quot;,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;Name&quot;: &quot;/Prod/dotnet&quot;,
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;Value&quot;: &quot;ec2-13-57-12-38.us-west-1.compute.amazonaws.com:1433&quot;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;Version&quot;: 1
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }
&nbsp;&nbsp;&nbsp; ]
}</code> 
<p><code class="lang-bash"></code></p> 
Note the difference in values. 
<p>or using the&nbsp;the AWS Tools for Windows PowerShell, you can execute the following command to retrieve the latest version of the Parameter (default):</p> 
<p><code class="lang-powershell">(Get-SSMParameterValue -Names &quot;/Prod/dotnet&quot;).Parameters | fl</code></p> 
<p>The System returns information&nbsp;similar to the following:</p> 
<code class="lang-bash">PS C:\&gt; (Get-SSMParameterValue -Name &quot;/Prod/dotnet&quot;).Parameters | fl
Name&nbsp; &nbsp;&nbsp;&nbsp;: /Prod/dotnet
Type&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;: String
Value &nbsp;&nbsp;&nbsp;&nbsp;: dotnet.ctvzltftaz4x.us-west-1.rds.amazonaws.com:1433
Version&nbsp; : 2
</code> 
<p>Execute the following command to retrieve a specific version of the Parameter (by version number):</p> 
<code class="lang-powershell">(Get-SSMParameterValue -Names &quot;/Prod/dotnet:1&quot;).Parameters | fl</code> 
<p>The system returns information similar to the following:</p> 
<code class="lang-bash">PS C:\&gt; (Get-SSMParameterValue -Name &quot;/Prod/dotnet:1&quot;).Parameters | fl
Name&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;: /Prod/dotnet
Type&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;: String
Value &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;: ec2-13-57-12-38.us-west-1.compute.amazonaws.com:1433
Version&nbsp;&nbsp; : 1
</code> 
<p>Note the difference in values.</p> 
<p>To roll back your .NET application to point to the original SQL on EC2 instance, simply update your code to reference the previous version of the Parameter and re-deploy.</p> 
<p>You can reference Parameter Store versioning in Systems Manager Documents as well, as show in the following example:</p> 
<p><strong>Systems Manager AWS-RunShellScript example</strong></p> 
<p>The default value for commands is referenced with version 2 of SSM parameter ‘runcommand’.</p> 
<code class="lang-bash">{
&quot;schemaVersion&quot;:&quot;1.2&quot;,
&quot;description&quot;:&quot;Run a shell script or specify the commands to run.&quot;,
&quot;parameters&quot;:{
&quot;commands&quot;:{
&quot;type&quot;:&quot;StringList&quot;,
&quot;description&quot;:&quot;(Required) Specify a shell script or a command to run.&quot;,
&quot;minItems&quot;:1,
&quot;displayType&quot;:&quot;textarea&quot;
&quot;default&quot;:&quot;{{ssm:runcommand:2}}&quot;
},
&quot;executionTimeout&quot;:{
&quot;type&quot;:&quot;String&quot;,
&quot;default&quot;:&quot;3600&quot;,
&quot;description&quot;:&quot;(Optional) The time in seconds for a command to complete before it is considered to have failed. Default is 3600 (1 hour). Maximum is 28800 (8 hours).&quot;,
&quot;allowedPattern&quot;:&quot;([1-9][0-9]{0,3})|(1[0-9]{1,4})|(2[0-7][0-9]{1,3})|(28[0-7][0-9]{1,2})|(28800)&quot;
}
},
&quot;runtimeConfig&quot;:{
&quot;aws:runShellScript&quot;:{
&quot;properties&quot;:[
{
&quot;id&quot;:&quot;0.aws:runShellScript&quot;,
&quot;runCommand&quot;:&quot;{{ commands }}&quot;,
&quot;timeoutSeconds&quot;:&quot;{{ executionTimeout }}&quot;
}
]
}
}
}</code> 
<p><strong>Summary</strong><br /> Parameter Store provides a centralized, encrypted store to manage your configuration data, whether it is plain text data (database strings) or secure strings and secrets (such as passwords, and API keys). Use versioning to add an extra layer of protection for your Parameter Store values.&nbsp;This new feature is available now and you can start using it today!</p> 
<p><strong>About the author</strong></p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/23/LouDelat-150x150.jpg" />Lou De La Torre is a Partner Solutions Architect with Amazon Web Services. Lou is responsible for assisting Partners and Customers alike with their AWS for Windows architectures and migration strategies. With a career in information technology that spans more than two decades, Lou brings a significant amount of expertise in cloud and systems architecture, systems management, disaster recovery, process improvement and compliance management. Lou consistently strives to ensure that he is delivering solutions that align with the needs and requirements of his customer’s business objectives, while alleviating any pain points they may be experiencing in their IT operations.</p> 
<p>&nbsp;</p> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">OpsWorks for Chef Automate – Automatically Bootstrapping Nodes in Different Accounts</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Darko Meszaros</span></span> | on 
<time property="datePublished" datetime="2017-10-24T23:23:40+00:00">24 OCT 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/mt/category/management-tools/aws-ops-works/" title="View all posts in AWS OpsWorks*"><span property="articleSection">AWS OpsWorks*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools*"><span property="articleSection">Management Tools*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/opsworks-for-chef-automate-automatically-bootstrapping-nodes-in-different-accounts/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p>Lots of us today are managing multiple AWS accounts. Although having multiple accounts can bring you &nbsp;benefits, such as more granular control of resources and access, decentralized control, and simpler billing. Multiple accounts can also introduce some challenges. A challenge we face in this blog post is having a centralized configuration management server with its nodes spread throughout other AWS accounts.</p> 
<h3>Goal</h3> 
<p>Let’s picture working for a company where various teams own Amazon EC2 instances in their own respective AWS accounts. We have a team dedicated to managing the configuration of all EC2 instances (nodes) across all of the company’s AWS accounts. The configuration management is performed by an <a href="https://aws.amazon.com/opsworks/chefautomate/">OpsWorks for Chef Automate</a> server. How do we go about bootstrapping these nodes to the Chef Automate server?</p> 
<p>I’ll show you how you can bootstrap nodes in other AWS accounts to a single/centralized OpsWorks for Chef Automate server. To be precise, I’ll bootstrap an <a href="https://aws.amazon.com/amazon-linux-ami/">Amazon Linux</a> node in AWS account B to an OpsWorks for Chef Automate server in Account A. To bootstrap the instance I’ll use the user data provided in the Chef Automate starter kit we have downloaded during the creation of the server. This user data script uses the built-in AWS API calls to bootstrap your node.</p> 
<p><span id="more-1630"></span></p> 
<h3>A few notes before we start</h3> 
<p>In this tutorial I assume that you don’t have <a href="https://aws.amazon.com/documentation/iam/">IAM</a> roles created for your Chef nodes, so we are creating everything from scratch. If, in fact, you do have roles configured, then just focus on the policy part of this tutorial. Also, we assume that you have the AWS CLI set up on your workstation with adequate privileges. Additionally, make sure all the ARNs mentioned here have the correct account IDs.</p> 
<h3>Step 1: Set up IAM permissions on account A, our Chef Automate account</h3> 
<p>First, we’ll create a role in account A that can be assumed by a node in account B. This role gives the node the necessary permissions to bootstrap itself with the Chef Automate server.</p> 
<p>A) Create a policy that allows us to associate the nodes with our Chef Automate server. Create the policy using the following document:<code> owca_allow_associate.json</code></p> 
<code class="lang-json">{
&quot;Version&quot;: &quot;2012-10-17&quot;,
&quot;Statement&quot;: [
{
&quot;Action&quot;: [
&quot;opsworks-cm:AssociateNode&quot;,
&quot;opsworks-cm:DescribeNodeAssociationStatus&quot;
],
&quot;Effect&quot;: &quot;Allow&quot;,
&quot;Resource&quot;: [
&quot;*&quot;
]
}
]
}</code> 
<p>B)&nbsp;Create the policy with that document, using the AWS CLI:</p> 
<code class="lang-bash">aws iam create-policy 
--policy-name OWCA-AllowAssociate 
--policy-document file://owca_allow_associate.json</code> 
<p>C)&nbsp;Create a role that can be assumed by the other account (Account B – where the nodes are). Create that role using the following document: <code>owca_trust_policy.json</code></p> 
<code class="lang-json">{
&quot;Version&quot;: &quot;2012-10-17&quot;,
&quot;Statement&quot;: [{
&quot;Effect&quot;: &quot;Allow&quot;,
&quot;Principal&quot;: {
&quot;AWS&quot;: &quot;arn:aws:iam::&lt;NODE-ACCOUNT-ID&gt;:root&quot;
},
&quot;Action&quot;: &quot;sts:AssumeRole&quot;
}]
}</code> 
<p>D) Now, let’s use the AWS CLI to create the role:</p> 
<code class="lang-bash">aws iam create-role 
--role-name CrossAccount-OWCA 
--assume-role-policy-document file://./owca_trust_policy.json </code> 
<p>E) And finally, attach the policy we created in step B to the role we created in step D:</p> 
<code class="lang-bash">aws iam attach-role-policy 
--role-name CrossAccountPowerUser 
--policy-arn  arn:aws:iam::&lt;CHEF-ACCOUNT-ID&gt;:policy/OWCA-AllowAssociate </code> 
<h3>Step 2: Set up IAM permissions on account B, our nodes account</h3> 
<p>In this step we create an instance role that will be attached to your node on launch. This role allows the instance to assume a role from account A (the Chef Automate account) so it can associate itself to the Chef Automate server.</p> 
<p>A) To create a role, we first need to create a document: <code>role_owca_associate.json</code></p> 
<code class="lang-json">{
&quot;Version&quot;: &quot;2012-10-17&quot;,
&quot;Statement&quot;: [
{
&quot;Effect&quot;: &quot;Allow&quot;,
&quot;Principal&quot;: {
&quot;Service&quot;: &quot;ec2.amazonaws.com&quot;
},
&quot;Action&quot;: &quot;sts:AssumeRole&quot;
}
]
}</code> 
<p>B) Create the role with the document, by running AWS CLI:</p> 
<code class="lang-bash">aws iam create-role
--role-name AssociateCrossAccount-owca 
--assume-role-policy-document file://role_owca_associate.json</code> 
<p>C) Create a policy document that allows our instance to assume a role: <code>node_assume_role.json</code></p> 
<code class="lang-json">{
&quot;Version&quot;: &quot;2012-10-17&quot;,
&quot;Statement&quot;: {
&quot;Effect&quot;: &quot;Allow&quot;,
&quot;Action&quot;: &quot;sts:AssumeRole&quot;,
&quot;Resource&quot;: &quot;arn:aws:iam::&lt;CHEF-ACCOUNT-ID&gt;:role/CrossAccount-OWCA &quot;
}
}</code> 
<p>D) Create the policy:</p> 
<code class="lang-bash">aws iam create-policy 
--policy-name ChefAssociateAccess 
--policy-document file://./node_assume_role.json</code> 
<p>E) Finally, attach the policy to the role we created earlier:</p> 
<code class="lang-bash">aws iam attach-role-policy 
--role-name CrossAccountPowerUser 
--policy-arn  arn:aws:iam::&lt;NODE-ACCOUNT-ID&gt;:policy/AssociateCrossAccount-owca</code> 
<h3>Step 3: Modifying the user data</h3> 
<p>In this step, we take the generated user data (<code>userdata.sh</code>) from the downloaded OpsWorks for Chef Automate starter_kit.zip and modify it with a few more functions that allow us to bootstrap your nodes across accounts.</p> 
<p>The modifications we are adding here are quite simple. We are just using <code>aws sts assume-role</code> to assume the role that we have created in account A (the Chef server account), and use the temporary credentials it generates to run the <code>associate-node</code> commands, which are required for bootstrapping the node to the Chef Automate server.</p> 
<p>Additionally, we are installing the <a href="https://github.com/stedolan/jq">jq utility for JSON parsing</a> – but this is removed during the cleanup.</p> 
<p>A) Open up the <code>userdata.sh</code> file in a text editor and add the following lines on line 21 (just after the <code>set -e -o pipefail</code> line):</p> 
<code class="lang-bash">set_cli_role() {
yum install -y jq
ASSUMED_ROLE=$(aws sts assume-role --role-arn arn:aws:iam::&lt;CHEF-ACCOUNT-ID&gt;:role/CrossAccount-OWCA --role-session-name owca)
export AWS_ACCESS_KEY_ID=$(echo $ASSUMED_ROLE | jq .Credentials.AccessKeyId | xargs)
export AWS_SECRET_ACCESS_KEY=$(echo $ASSUMED_ROLE | jq .Credentials.SecretAccessKey | xargs)
export AWS_SESSION_TOKEN=$(echo $ASSUMED_ROLE | jq .Credentials.SessionToken | xargs)
}
cleanup_cli_role(){
yum remove -y jq
unset AWS_SESSION_TOKEN
unset AWS_ACCESS_KEY_ID
unset AWS_SECRET_ACCESS_KEY
}</code> 
<p>The first function we create here (<code>set_cli_role</code>) is used for assuming the role from account A, and exporting the temporary credentials to environment variables that will be used by our API calls. The second function is just for cleanup – removing of the <code>jq</code> JSON parser and un-setting the environment variables we set in the function before.</p> 
<p>B) Now on the line 87 insert the <code>set_cli_role</code> function, and on line 93 add the <code>cleanup_cli_role</code>. Your function execution section should go from this:</p> 
<code class="lang-bash">install_aws_cli
node_association_status_token=&quot;$(associate_node)&quot;
install_chef_client
write_chef_config
install_trusted_certs
wait_node_associated &quot;${node_association_status_token}&quot;</code> 
<p>C) To this:</p> 
<code class="lang-bash">install_aws_cli
set_cli_role
node_association_status_token=&quot;$(associate_node)&quot;
install_chef_client
write_chef_config
install_trusted_certs
wait_node_associated &quot;${node_association_status_token}&quot;
cleanup_cli_role</code> 
<p>Here we simply change the execution part of the user data shell script to include our two new functions.</p> 
<p>D) Save the <code>userdata.sh</code> somewhere safe.</p> 
<h3>Step 4: Launch the nodes with the user data script</h3> 
<p>The only thing left now is to run your nodes with the newly edited user data script. We can achieve this either by adding the user data during a manual launch of the EC2 instance, or by setting this on an<a href="https://aws.amazon.com/autoscaling/"> Auto Scaling</a> group launch configuration.</p> 
<h3>Conclusion</h3> 
<p>In this blog post we’ve enabled your nodes from different AWS accounts to bootstrap themselves to a centralized OpsWorks for Chef Automate server that is present in a separate account. We’ve achieved this by creating the required IAM roles and policies, and also by changing the user data that ships with the OpsWorks for Chef Automate starter kit. We’ve done this only for two accounts, but you can modify this to work on any number of accounts.</p> 
<p><strong>About the Author</strong></p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/24/darko-cropped.jpeg" /><br /> Darko Meszaros is a Cloud Support Engineer who supports customers that use various AWS automation tools, such as AWS OpsWorks, AWS CodeDeploy, and AWS CloudFormation. He is a subject matter expert for OpsWorks and CodeDeploy. Outside of work, he loves collecting video games and old computers.</p> 
</article> 
<article class="blog-post" vocab="http://schema.org/" typeof="TechArticle"> 
<meta property="inLanguage" content="en-US" /> 
<b class="lb-b blog-post-title" property="name headline">AWS CloudFormation Feature Updates: Support for Amazon Athena and Coverage Updates for Amazon S3, Amazon RDS, Amazon Kinesis and Amazon CloudWatch</b> 
<footer class="blog-post-meta" data-lb-comp="aws-blog:share-dialog">
by 
<span property="author" typeof="Person"><span property="name">Luis Colon</span></span> | on 
<time property="datePublished" datetime="2017-10-18T18:46:07+00:00">18 OCT 2017</time> | in 
<span class="blog-post-categories"><a href="https://aws.amazon.com/blogs/mt/category/analytics/amazon-athena/" title="View all posts in Amazon Athena*"><span property="articleSection">Amazon Athena*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/amazon-cloudwatch/" title="View all posts in Amazon CloudWatch*"><span property="articleSection">Amazon CloudWatch*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/analytics/amazon-kinesis/" title="View all posts in Amazon Kinesis*"><span property="articleSection">Amazon Kinesis*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/database/amazon-rds/" title="View all posts in Amazon RDS*"><span property="articleSection">Amazon RDS*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/storage/amazon-simple-storage-services-s3/" title="View all posts in Amazon Simple Storage Services (S3)*"><span property="articleSection">Amazon Simple Storage Services (S3)*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/aws-cloudformation/" title="View all posts in AWS CloudFormation*"><span property="articleSection">AWS CloudFormation*</span></a>, <a href="https://aws.amazon.com/blogs/mt/category/management-tools/" title="View all posts in Management Tools*"><span property="articleSection">Management Tools*</span></a></span> | 
<a href="https://aws.amazon.com/blogs/mt/aws-cloudformation-features-update-support-for-amazon-athena-coverage-updates-for-s3-rds-kinesis-and-cloudwatch/" property="url">Permalink</a> | 
<a href="#" role="button" data-share-dialog-toggle=""><span class="span icon-share"></span>&nbsp;Share</a> 
</footer> 
<p>As one of the most widely-used services in AWS, CloudFormation continues to expand its feature set&nbsp;by including adding support for Amazon Athena, two new features to protect stacks and control rollback processes, plus several new coverage updates.</p> 
<p>CloudFormation now supports the creation of an <a href="https://aws.amazon.com/athena/">Amazon Athena</a> named query as a <a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-athena-namedquery.html">resource</a>. Amazon Athena is a query service that makes it easy to analyze data directly from files stored in S3 using standard SQL statements. Named queries can then be executed manually from the AWS Management Console, CLI or programmatically&nbsp;using API calls.</p> 
<p>You can now create a standard set of named queries&nbsp;using CloudFormation templates. To try it out, you can use some of the sample data provided by Athena, as covered in Jeff Barr’s blog post <a href="https://aws.amazon.com/blogs/aws/amazon-athena-interactive-sql-queries-for-data-in-amazon-s3/">here</a>.</p> 
<p><span id="more-1532"></span></p> 
<p>After&nbsp;you’ve verified that your query properly runs on Athena, use CloudFormation to create a query using the <strong>AWS::Athena::NamedQuery</strong> resource type:</p> 
<code class="lang-yaml">---
#===============================================================================
# Template: athena-named-query.yaml
#
# Purpose:  Creates an Athena Named Query via AWS CloudFormation, using the
#           default data set provided by Athena.
#===============================================================================
AWSTemplateFormatVersion: &quot;2010-09-09&quot;
Description: |
Uses the default data set in Amazon Athena, with a sample elb logs table,
to demonstrate how to create a named query via a CloudFormation template.
This query checks for HTTP response codes and counts each code's occurrence
Resources:
AthenaNamedQuery:
Type: AWS::Athena::NamedQuery
Properties:
Database: &quot;default&quot;
Description: &quot;Select and count HTTP response codes&quot;
Name: &quot;HTTPResponseCodeCount&quot;
QueryString: &gt;
SELECT backend_response_code, count(*)
FROM default.&quot;elb_logs&quot;
GROUP BY backend_response_code;</code> 
<p>This YAML template above executes&nbsp;using a Create Stack call in under a minute. Then, go to the Athena console and find&nbsp;the query you created using CloudFormation under the Saved Queries menu:</p> 
<p>&nbsp;</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/17/SavedQueries-1024x397.png" /></p> 
<p>&nbsp;</p> 
<p>Note our new query, HTTPResponseCodeCount, its description, and the first portion of the SQL query shows in our list, which is alphabetically sorted by name (it is the fourth item on the preceding image).&nbsp;Choose&nbsp;the name of your new query, and then&nbsp;choose the <strong>Run Query</strong> button to execute it:</p> 
<p>&nbsp;</p> 
<p><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/17/QueryResults-1024x545.png" /></p> 
<p>&nbsp;</p> 
<p>The <strong>Results</strong> pane shows that most pages return a HTTP 200 response code, which is good (OK). You can inspect the other error codes, like 404 (Not Found), 302 (Redirect) or 500 (Server Error).</p> 
<p>Beyond the new Athena support, two new features have been released within the last few weeks:</p> 
<li><strong><a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-cfn-protect-stacks.html">Stack termination protection</a></strong> prevents a stack from being accidentally deleted. It’s a property that can be enabled on new or existing stacks, and it provides yet another level of protection for stacks and their resources. This setting is disabled by default, so you have to explicitly enable it when you create new stacks. For existing, non-nested stacks, you can change termination protection&nbsp;using the console or CLI.</li> 
<li><strong><a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/APIReference/API_RollbackConfiguration.html">Rollback triggers</a></strong> allow you to have CloudFormation monitor the state of your application while the stack is being created or updated, and to roll back that create or update operation if the application triggers any alarms you have configured. Chuck Meyer’s blog post <a href="https://aws.amazon.com/blogs/mt/use-aws-cloudformation-stack-termination-protection-and-rollback-triggers-to-maintain-infrastructure-availability/">here</a> demonstrates the use of rollback triggers.</li> 
<p>CloudFormation has also introduced the following resource coverage updates:</p> 
<li><strong>Amazon Simple Storage Service (S3)</strong> 
<li><a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-s3-bucket.html">Configure</a> the transfer acceleration state.</li> 
</ul> </li> 
<li><strong>Amazon Relational Database Service (RDS)</strong> 
<li><a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-rds-database-instance.html">Update</a> engine property from Oracle-SE or Oracle SE1&nbsp;to Oracle&nbsp;SE2 without the database instance being replaced.</li> 
</ul> </li> 
<li><strong>AWS Elastic Load Balancing (ELB)</strong> 
<li><a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-elasticloadbalancingv2-loadbalancer.html">Specify</a> the IDs of the subnets to attach to a load balancer, and specify the type of load balancer to create.</li> 
<li>For target groups, <a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-elasticloadbalancingv2-targetgroup.html">specify</a> the Availability Zone where the IP address is to be registered,&nbsp;and also specify the registration type of the targets in a given target group.</li> 
</ul> </li> 
<li><strong>AWS Elastic Beanstalk</strong> 
<li><a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-beanstalk.html">Define</a> lifecycle settings for resources that belong to the application, as well as the service role that Elastic Beanstalk assumes in order to apply lifecycle settings.</li> 
<li><a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-beanstalk-environment.html">Specify</a> a custom platform for Elastic Beanstalk.</li> 
</ul> </li> 
<li><strong>Amazon&nbsp;Elastic Compute Cloud (EC2)</strong> 
<li><a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-ec2-natgateway.html">Specify</a> resource tags for a Network Address Translation (NAT) gateway.</li> 
</ul> </li> 
<li><strong>Amazon&nbsp;Kinesis Firehose</strong> 
<li><a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-kinesisfirehose-deliverystream.html">Specify</a> the stream type, as well as stream and role ARNs for a Kinesis stream used as a source for a delivery stream.</li> 
</ul> </li> 
<li><strong>Amazon CloudWatch</strong> 
<li>Support new <a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-events-rule.html">properties</a> for input transformation of events, as well as setting Amazon ECS tasks and Kinesis stream targets.</li> 
</ul> </li> 
<p>Visit our <a href="https://aws.amazon.com/cloudformation/">product</a> and <a href="https://aws.amazon.com/documentation/cloudformation/">documentation</a> pages for more information, as well as our list of <a href="http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/cfn-supported-resources.html">supported AWS resources</a>.</p> 
<hr /> 
<p><strong>About the Author</strong></p> 
<table class=" alignleft" style="height: 90px" width="900"> 
<tbody> 
<tr> 
<td width="63"><img width="100%" src="https://d2908q01vomqb2.cloudfront.net/972a67c48192728a34979d9a35164c1295401b71/2017/10/17/PhoneTool1.jpg" /></td> 
<td width="408"> <p><strong>Luis Colon is a Senior Developer Advocate for the AWS CloudFormation team.&nbsp;</strong>He works with customers and internal development teams to focus on and improve the developer experience for CloudFormation users. In his spare time, he mixes progressive trance music.</p> <p>&nbsp;</p></td> 
</tr> 
</tbody> 
</table> 
<p>&nbsp;</p> 
</article> 
<p>
© 2017, Amazon Web Services, Inc. or its affiliates. All rights reserved.
</p>

    </div>
  </div>
</div>


    <div id="footer" class="navigation hidden-print">
      <div class="container">
        <div class="row">
          <div class="col-xs-12">
            <ul class="footer-links nav navbar-nav">
              <li><a href="../aws.html">AWS</a></li>
              <li><a href="../linux.html">Linux</a></li>
              <li><a href="../docker.html">Docker</a></li>
              <li><a href="../ibmpower.html">IBM Power</a></li>
              <li><a href="blogsataws1.html">Blogs@AWS (Kindle Friendly)</a></li>
            </ul>
            <ul class="footer-links nav navbar-nav navbar-right">
              <li><a href="../comments.html">Comments?</a></li>
            </ul>
          </div>
        </div>
      </div>
    </div>
  </body>
</html>
